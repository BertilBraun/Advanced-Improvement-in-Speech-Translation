(base) [uxude@uc2n994 train]$ cat finetune_asr_covost_2309*
No extension needed for workspace ASR.
No extension needed for workspace MT.
Fairseq directory exists. Checking if installed...
fairseq                  0.12.2       /home/kit/stud/uxude/fairseq
Fairseq is already installed. Skipping installation.
Setup complete. Starting script execution...
[2024-01-30 15:30:53] [INFO] [Dataset::Prepare Datasets]: Skipping dataset preparation, config file and MT spm data already exists
Finetuning the ASR model...
Training the model...
Model will be stored in /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models
Training time: 6 hours
Training subset: train
Validation subset: dev
Data directory: /pfs/work7/workspace/scratch/uxude-ASR/dataset/covost
2024-01-30 15:31:11 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 4, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 50000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'dev', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 100, 'max_update': 0, 'stop_time_hours': 6.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 50000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 1, 'keep_best_checkpoints': 5, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_text', num_workers=4, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2t_conformer', max_epoch=100, max_update=0, stop_time_hours=6.0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.002], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=50000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=1, keep_best_checkpoints=5, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, label_smoothing=0.0, report_accuracy=False, ignore_prefix_size=0, adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, pos_enc_type='rel_pos', attn_type='espnet', no_seed_provided=False, input_feat_per_channel=80, input_channels=1, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, dropout=0.1, encoder_layers=16, depthwise_conv_kernel_size=31, encoder_freezing_updates=0, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_normalize_before=True, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.1, activation_dropout=0.1, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, no_scale_embedding=False, quant_noise_pq=0, _name='s2t_conformer'), 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_text', num_workers=4, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2t_conformer', max_epoch=100, max_update=0, stop_time_hours=6.0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.002], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=50000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=1, keep_best_checkpoints=5, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, label_smoothing=0.0, report_accuracy=False, ignore_prefix_size=0, adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, pos_enc_type='rel_pos', attn_type='espnet', no_seed_provided=False, input_feat_per_channel=80, input_channels=1, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, dropout=0.1, encoder_layers=16, depthwise_conv_kernel_size=31, encoder_freezing_updates=0, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_normalize_before=True, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.1, activation_dropout=0.1, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, no_scale_embedding=False, quant_noise_pq=0, _name='speech_to_text'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.0, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 10000, 'warmup_init_lr': -1.0, 'lr': [0.002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-01-30 15:31:11 | INFO | fairseq.tasks.speech_to_text | dictionary size (spm.asr.txt): 5,000
2024-01-30 15:31:15 | INFO | fairseq_cli.train | S2TConformerModel(
  (encoder): S2TConformerEncoder(
    (subsample): Conv1dSubsampler(
      (conv_layers): ModuleList(
        (0): Conv1d(80, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        (1): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
      )
    )
    (embed_positions): RelPositionalEncoding()
    (linear): Linear(in_features=256, out_features=256, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (conformer_layers): ModuleList(
      (0-15): 16 x ConformerEncoderLayer(
        (ffn1): FeedForwardModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (activation): SiLU(inplace=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (self_attn_dropout): Dropout(p=0.1, inplace=False)
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (conv_module): ConvolutionModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
          (glu): GLU(dim=1)
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256, bias=False)
          (batch_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): SiLU(inplace=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn2): FeedForwardModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (activation): SiLU(inplace=True)
        )
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(5000, 256, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=256, out_features=5000, bias=False)
  )
)
2024-01-30 15:31:15 | INFO | fairseq_cli.train | task: SpeechToTextTask
2024-01-30 15:31:15 | INFO | fairseq_cli.train | model: S2TConformerModel
2024-01-30 15:31:15 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2024-01-30 15:31:15 | INFO | fairseq_cli.train | num. shared model params: 54,758,144 (num. trained: 54,758,144)
2024-01-30 15:31:15 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2024-01-30 15:31:15 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2024-01-30 15:31:15 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
2024-01-30 15:31:15 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
2024-01-30 15:31:15 | INFO | fairseq.data.audio.speech_to_text_dataset | 'dev' has 0.00% OOV
2024-01-30 15:31:15 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split="dev", n_samples=15_479, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.pointwise_conv1.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.depthwise_conv.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.pointwise_conv2.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.self_attn.linear_pos.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.pointwise_conv1.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.depthwise_conv.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.pointwise_conv2.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.self_attn.linear_pos.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.pointwise_conv1.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.depthwise_conv.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.pointwise_conv2.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.self_attn.linear_pos.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.pointwise_conv1.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.depthwise_conv.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.pointwise_conv2.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.self_attn.linear_pos.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.pointwise_conv1.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.depthwise_conv.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.pointwise_conv2.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.self_attn.linear_pos.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.pointwise_conv1.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.depthwise_conv.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.pointwise_conv2.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.self_attn.linear_pos.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.pointwise_conv1.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.depthwise_conv.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.pointwise_conv2.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.self_attn.linear_pos.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.pointwise_conv1.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.depthwise_conv.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.pointwise_conv2.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.self_attn.linear_pos.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.pointwise_conv1.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.depthwise_conv.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.pointwise_conv2.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.self_attn.linear_pos.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.pointwise_conv1.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.depthwise_conv.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.pointwise_conv2.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.self_attn.linear_pos.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.pointwise_conv1.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.depthwise_conv.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.pointwise_conv2.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.self_attn.linear_pos.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.pointwise_conv1.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.depthwise_conv.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.pointwise_conv2.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.self_attn.linear_pos.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.pointwise_conv1.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.depthwise_conv.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.pointwise_conv2.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.self_attn.linear_pos.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.pointwise_conv1.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.depthwise_conv.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.pointwise_conv2.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.self_attn.linear_pos.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.pointwise_conv1.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.depthwise_conv.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.pointwise_conv2.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.self_attn.linear_pos.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.pointwise_conv1.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.depthwise_conv.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.pointwise_conv2.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- decoder.output_projection.bias
2024-01-30 15:31:16 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-01-30 15:31:16 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-01-30 15:31:16 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 31.739 GB ; name = Tesla V100-SXM2-32GB
2024-01-30 15:31:16 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-01-30 15:31:16 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-01-30 15:31:16 | INFO | fairseq_cli.train | max tokens per device = 50000 and max sentences per device = None
2024-01-30 15:31:16 | INFO | fairseq.trainer | Preparing to load checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt
2024-01-30 15:31:16 | INFO | fairseq.trainer | No existing checkpoint found /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt
2024-01-30 15:31:16 | INFO | fairseq.trainer | loading train data for epoch 1
2024-01-30 15:31:16 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2024-01-30 15:31:16 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
2024-01-30 15:31:18 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
2024-01-30 15:31:23 | INFO | fairseq.data.audio.speech_to_text_dataset | 'train' has 0.00% OOV
2024-01-30 15:31:23 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split="train", n_samples=286_474, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
    SpecAugmentTransform(time_warp_w=0, freq_mask_n=1, freq_mask_f=27, time_mask_n=1, time_mask_t=100, time_mask_p=1.0)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
2024-01-30 15:31:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-30 15:31:23 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-01-30 15:31:23 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-01-30 15:31:23 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
Traceback (most recent call last):
  File "/home/kit/stud/uxude/miniconda3/envs/nmt/bin/fairseq-train", line 8, in <module>
    sys.exit(cli_main())
  File "/home/kit/stud/uxude/fairseq/fairseq_cli/train.py", line 574, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/home/kit/stud/uxude/fairseq/fairseq/distributed/utils.py", line 404, in call_main
    main(cfg, **kwargs)
  File "/home/kit/stud/uxude/fairseq/fairseq_cli/train.py", line 165, in main
    extra_state, epoch_itr = checkpoint_utils.load_checkpoint(
  File "/home/kit/stud/uxude/fairseq/fairseq/checkpoint_utils.py", line 297, in load_checkpoint
    epoch_itr = trainer.get_train_iterator(
  File "/home/kit/stud/uxude/fairseq/fairseq/trainer.py", line 736, in get_train_iterator
    self.reset_dummy_batch(batch_iterator.first_batch)
  File "/home/kit/stud/uxude/fairseq/fairseq/data/iterators.py", line 372, in first_batch
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/home/kit/stud/uxude/fairseq/fairseq/data/iterators.py", line 372, in <listcomp>
    return self.collate_fn([self.dataset[i] for i in self.frozen_batches[0]])
  File "/home/kit/stud/uxude/fairseq/fairseq/data/audio/speech_to_text_dataset.py", line 261, in __getitem__
    source = self._get_source_audio(indices if has_concat else index)
  File "/home/kit/stud/uxude/fairseq/fairseq/data/audio/speech_to_text_dataset.py", line 226, in _get_source_audio
    source = get_features_or_waveform(
  File "/home/kit/stud/uxude/fairseq/fairseq/data/audio/audio_utils.py", line 198, in get_features_or_waveform
    features_or_waveform = get_features_or_waveform_from_stored_zip(
  File "/home/kit/stud/uxude/fairseq/fairseq/data/audio/audio_utils.py", line 165, in get_features_or_waveform_from_stored_zip
    raise ValueError(f'Unknown file format for "{path}"')
ValueError: Unknown file format for "/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/mel/encoded.zip"
Training complete.
Finetuning complete.
----------------------------------------------------------
Transcribing the test set...
Starting transcription...
Average checkpoints...
Checkpoints folder: /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models
Checkpoint path: /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
Namespace(inputs=['/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models'], output='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', num_epoch_checkpoints=5, num_update_checkpoints=None, num_best_checkpoints=0, checkpoint_upper_bound=None)
Traceback (most recent call last):
  File "/home/kit/stud/uxude/fairseq/scripts/average_checkpoints.py", line 176, in <module>
    main()
  File "/home/kit/stud/uxude/fairseq/scripts/average_checkpoints.py", line 149, in main
    args.inputs = last_n_checkpoints(
  File "/home/kit/stud/uxude/fairseq/scripts/average_checkpoints.py", line 94, in last_n_checkpoints
    raise Exception(
Exception: ('Found {} checkpoint files but need at least {}', 0, 5)
Checkpoints averaged
Generating transcriptions...
Test subset: test
Data directory: /pfs/work7/workspace/scratch/uxude-ASR/dataset/covost
Prediction output directory: /home/kit/stud/uxude/predictions/finetune_asr_covost
DEBUG:hydra.core.utils:Setting JobRuntime:name=UNKNOWN_NAME
DEBUG:hydra.core.utils:Setting JobRuntime:name=utils
INFO:fairseq_cli.generate:{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 50000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all'}, 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', simul_type=None, scoring='wer', task='speech_to_text', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, path='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', post_process=None, quiet=False, model_overrides='{}', results_path=None, beam=5, beam_mt=0, nbest=1, max_len_a=0, max_len_b=200, max_len_a_mt=0, max_len_b_mt=200, min_len=1, match_source_len=False, unnormalized=False, no_early_stop=False, no_beamable_mm=False, lenpen=1, lenpen_mt=1, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=None, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, no_seed_provided=False, eos_token=None, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, arch='wav2vec2', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, force_anneal=None, lr_shrink=0.1, warmup_updates=0, wer_tokenizer='none', wer_remove_punct=False, wer_char_level=False, wer_lowercase=False, _name='speech_to_text'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'wer', 'wer_tokenizer': 'none', 'wer_remove_punct': False, 'wer_char_level': False, 'wer_lowercase': False}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
INFO:fairseq.tasks.speech_to_text:dictionary size (spm.asr.txt): 5,000
INFO:fairseq_cli.generate:loading model(s) from /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
Traceback (most recent call last):
  File "/home/kit/stud/uxude/miniconda3/envs/nmt/bin/fairseq-generate", line 8, in <module>
    sys.exit(cli_main())
  File "/home/kit/stud/uxude/fairseq/fairseq_cli/generate.py", line 413, in cli_main
    main(args)
  File "/home/kit/stud/uxude/fairseq/fairseq_cli/generate.py", line 50, in main
    return _main(cfg, sys.stdout)
  File "/home/kit/stud/uxude/fairseq/fairseq_cli/generate.py", line 96, in _main
    models, saved_cfg = checkpoint_utils.load_model_ensemble(
  File "/home/kit/stud/uxude/fairseq/fairseq/checkpoint_utils.py", line 392, in load_model_ensemble
    ensemble, args, _task = load_model_ensemble_and_task(
  File "/home/kit/stud/uxude/fairseq/fairseq/checkpoint_utils.py", line 448, in load_model_ensemble_and_task
    raise IOError("Model file not found: {}".format(filename))
OSError: Model file not found: /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
Transcription done
Prediction files written for /home/kit/stud/uxude/predictions/finetune_asr_covost/hyp.txt and /home/kit/stud/uxude/predictions/finetune_asr_covost/ref.txt
Sample predictions:
Sample:
Reference:
Sample:
Reference:
WER:
BLEU:
sacreBLEU: System and reference streams have different lengths.
Transcription complete.

============================= JOB FEEDBACK =============================

NodeName=uc2n481
Job ID: 23092672
Cluster: uc2
User/Group: uxude/stud
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 2
CPU Utilized: 00:00:34
CPU Efficiency: 7.02% of 00:08:04 core-walltime
Job Wall-clock time: 00:04:02
Memory Utilized: 1.07 GB
Memory Efficiency: 0.55% of 195.31 GB
No extension needed for workspace ASR.
No extension needed for workspace MT.
Fairseq directory exists. Checking if installed...
fairseq                  0.12.2       /home/kit/stud/uxude/fairseq
Fairseq is already installed. Skipping installation.
Setup complete. Starting script execution...
[2024-01-31 05:30:30] [INFO] [Dataset::Prepare Datasets]: Skipping dataset preparation, config file and MT spm data already exists
Finetuning the ASR model...
Training the model...
Model will be stored in /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models
Training time: 6 hours
Training subset: train
Validation subset: dev
Data directory: /pfs/work7/workspace/scratch/uxude-ASR/dataset/covost
2024-01-31 05:30:48 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 4, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 50000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'dev', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 500, 'max_update': 0, 'stop_time_hours': 6.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 50000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 5, 'keep_best_checkpoints': 5, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_text', num_workers=4, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2t_conformer', max_epoch=500, max_update=0, stop_time_hours=6.0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.002], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=50000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=5, keep_best_checkpoints=5, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, label_smoothing=0.0, report_accuracy=False, ignore_prefix_size=0, adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, pos_enc_type='rel_pos', attn_type='espnet', no_seed_provided=False, input_feat_per_channel=80, input_channels=1, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, dropout=0.1, encoder_layers=16, depthwise_conv_kernel_size=31, encoder_freezing_updates=0, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_normalize_before=True, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.1, activation_dropout=0.1, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, no_scale_embedding=False, quant_noise_pq=0, _name='s2t_conformer'), 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_text', num_workers=4, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2t_conformer', max_epoch=500, max_update=0, stop_time_hours=6.0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.002], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=50000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=5, keep_best_checkpoints=5, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, label_smoothing=0.0, report_accuracy=False, ignore_prefix_size=0, adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, pos_enc_type='rel_pos', attn_type='espnet', no_seed_provided=False, input_feat_per_channel=80, input_channels=1, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, dropout=0.1, encoder_layers=16, depthwise_conv_kernel_size=31, encoder_freezing_updates=0, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_normalize_before=True, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.1, activation_dropout=0.1, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, no_scale_embedding=False, quant_noise_pq=0, _name='speech_to_text'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.0, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 10000, 'warmup_init_lr': -1.0, 'lr': [0.002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-01-31 05:30:48 | INFO | fairseq.tasks.speech_to_text | dictionary size (spm.asr.txt): 5,000
2024-01-31 05:30:52 | INFO | fairseq_cli.train | S2TConformerModel(
  (encoder): S2TConformerEncoder(
    (subsample): Conv1dSubsampler(
      (conv_layers): ModuleList(
        (0): Conv1d(80, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        (1): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
      )
    )
    (embed_positions): RelPositionalEncoding()
    (linear): Linear(in_features=256, out_features=256, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (conformer_layers): ModuleList(
      (0-15): 16 x ConformerEncoderLayer(
        (ffn1): FeedForwardModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (activation): SiLU(inplace=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (self_attn_dropout): Dropout(p=0.1, inplace=False)
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (conv_module): ConvolutionModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
          (glu): GLU(dim=1)
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256, bias=False)
          (batch_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): SiLU(inplace=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn2): FeedForwardModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (activation): SiLU(inplace=True)
        )
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(5000, 256, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=256, out_features=5000, bias=False)
  )
)
2024-01-31 05:30:52 | INFO | fairseq_cli.train | task: SpeechToTextTask
2024-01-31 05:30:52 | INFO | fairseq_cli.train | model: S2TConformerModel
2024-01-31 05:30:52 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2024-01-31 05:30:52 | INFO | fairseq_cli.train | num. shared model params: 54,758,144 (num. trained: 54,758,144)
2024-01-31 05:30:52 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2024-01-31 05:30:52 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2024-01-31 05:30:52 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
2024-01-31 05:30:52 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
2024-01-31 05:30:53 | INFO | fairseq.data.audio.speech_to_text_dataset | 'dev' has 0.00% OOV
2024-01-31 05:30:53 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split="dev", n_samples=15_531, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.pointwise_conv1.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.depthwise_conv.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.pointwise_conv2.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.self_attn.linear_pos.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.pointwise_conv1.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.depthwise_conv.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.pointwise_conv2.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.self_attn.linear_pos.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.pointwise_conv1.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.depthwise_conv.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.pointwise_conv2.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.self_attn.linear_pos.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.pointwise_conv1.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.depthwise_conv.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.pointwise_conv2.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.self_attn.linear_pos.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.pointwise_conv1.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.depthwise_conv.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.pointwise_conv2.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.self_attn.linear_pos.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.pointwise_conv1.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.depthwise_conv.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.pointwise_conv2.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.self_attn.linear_pos.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.pointwise_conv1.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.depthwise_conv.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.pointwise_conv2.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.self_attn.linear_pos.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.pointwise_conv1.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.depthwise_conv.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.pointwise_conv2.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.self_attn.linear_pos.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.pointwise_conv1.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.depthwise_conv.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.pointwise_conv2.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.self_attn.linear_pos.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.pointwise_conv1.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.depthwise_conv.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.pointwise_conv2.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.self_attn.linear_pos.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.pointwise_conv1.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.depthwise_conv.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.pointwise_conv2.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.self_attn.linear_pos.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.pointwise_conv1.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.depthwise_conv.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.pointwise_conv2.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.self_attn.linear_pos.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.pointwise_conv1.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.depthwise_conv.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.pointwise_conv2.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.self_attn.linear_pos.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.pointwise_conv1.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.depthwise_conv.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.pointwise_conv2.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.self_attn.linear_pos.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.pointwise_conv1.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.depthwise_conv.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.pointwise_conv2.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.self_attn.linear_pos.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.pointwise_conv1.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.depthwise_conv.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.pointwise_conv2.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- decoder.output_projection.bias
2024-01-31 05:30:53 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-01-31 05:30:53 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-01-31 05:30:53 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 31.739 GB ; name = Tesla V100-SXM2-32GB
2024-01-31 05:30:53 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-01-31 05:30:53 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-01-31 05:30:53 | INFO | fairseq_cli.train | max tokens per device = 50000 and max sentences per device = None
2024-01-31 05:30:53 | INFO | fairseq.trainer | Preparing to load checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt
2024-01-31 05:30:53 | INFO | fairseq.trainer | No existing checkpoint found /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt
2024-01-31 05:30:53 | INFO | fairseq.trainer | loading train data for epoch 1
2024-01-31 05:30:53 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2024-01-31 05:30:53 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
2024-01-31 05:30:56 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
2024-01-31 05:31:01 | INFO | fairseq.data.audio.speech_to_text_dataset | 'train' has 0.00% OOV
2024-01-31 05:31:01 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split="train", n_samples=289_421, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
    SpecAugmentTransform(time_warp_w=0, freq_mask_n=1, freq_mask_f=27, time_mask_n=1, time_mask_t=100, time_mask_p=1.0)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
2024-01-31 05:31:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 05:31:01 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-01-31 05:31:01 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-01-31 05:31:01 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
2024-01-31 05:31:03 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2024-01-31 05:31:04 | INFO | fairseq_cli.train | begin dry-run validation on "dev" subset
2024-01-31 05:31:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 05:31:04 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-01-31 05:31:04 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-01-31 05:31:04 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
/home/kit/stud/uxude/miniconda3/envs/nmt/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2024-01-31 05:32:58 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-01-31 05:32:58 | INFO | fairseq.trainer | begin training epoch 1
2024-01-31 05:32:58 | INFO | fairseq_cli.train | Start iterating over samples
/home/kit/stud/uxude/miniconda3/envs/nmt/lib/python3.10/site-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/home/kit/stud/uxude/fairseq/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-01-31 05:34:46 | INFO | train_inner | epoch 001:    100 / 3236 loss=11.987, nll_loss=11.987, ppl=4059.39, wps=1793.4, ups=1.4, wpb=1282, bsz=85.9, num_updates=100, lr=2e-05, gnorm=2.6, train_wall=89, gb_free=18, wall=233
2024-01-31 05:36:05 | INFO | train_inner | epoch 001:    200 / 3236 loss=10.625, nll_loss=10.625, ppl=1579.64, wps=1663.8, ups=1.28, wpb=1304.5, bsz=92, num_updates=200, lr=4e-05, gnorm=1.252, train_wall=56, gb_free=18.3, wall=312
2024-01-31 05:37:14 | INFO | train_inner | epoch 001:    300 / 3236 loss=9.986, nll_loss=9.986, ppl=1014.39, wps=1862.8, ups=1.43, wpb=1299.5, bsz=91.1, num_updates=300, lr=6e-05, gnorm=1.251, train_wall=56, gb_free=18.1, wall=382
2024-01-31 05:38:25 | INFO | train_inner | epoch 001:    400 / 3236 loss=9.587, nll_loss=9.587, ppl=768.94, wps=1850.3, ups=1.42, wpb=1304.8, bsz=89, num_updates=400, lr=8e-05, gnorm=1.112, train_wall=56, gb_free=17.6, wall=452
2024-01-31 05:39:36 | INFO | train_inner | epoch 001:    500 / 3236 loss=9.377, nll_loss=9.377, ppl=664.89, wps=1813.7, ups=1.4, wpb=1294.2, bsz=96.2, num_updates=500, lr=0.0001, gnorm=1.238, train_wall=56, gb_free=18.4, wall=523
2024-01-31 05:40:44 | INFO | train_inner | epoch 001:    600 / 3236 loss=9.288, nll_loss=9.288, ppl=625.24, wps=1927, ups=1.49, wpb=1296.9, bsz=87.4, num_updates=600, lr=0.00012, gnorm=0.96, train_wall=56, gb_free=18.4, wall=591
2024-01-31 05:41:50 | INFO | train_inner | epoch 001:    700 / 3236 loss=9.104, nll_loss=9.104, ppl=550.37, wps=1970.1, ups=1.5, wpb=1309.3, bsz=89.4, num_updates=700, lr=0.00014, gnorm=0.839, train_wall=56, gb_free=17.7, wall=657
2024-01-31 05:43:07 | INFO | train_inner | epoch 001:    800 / 3236 loss=8.917, nll_loss=8.917, ppl=483.23, wps=1719.1, ups=1.31, wpb=1314.4, bsz=92.5, num_updates=800, lr=0.00016, gnorm=0.903, train_wall=56, gb_free=18.2, wall=734
2024-01-31 05:44:15 | INFO | train_inner | epoch 001:    900 / 3236 loss=8.773, nll_loss=8.773, ppl=437.54, wps=1897.5, ups=1.45, wpb=1305.1, bsz=90.3, num_updates=900, lr=0.00018, gnorm=0.9, train_wall=57, gb_free=18.5, wall=802
2024-01-31 05:45:24 | INFO | train_inner | epoch 001:   1000 / 3236 loss=8.619, nll_loss=8.619, ppl=393.07, wps=1908.2, ups=1.45, wpb=1314.2, bsz=92.3, num_updates=1000, lr=0.0002, gnorm=0.933, train_wall=56, gb_free=18, wall=871
2024-01-31 05:46:37 | INFO | train_inner | epoch 001:   1100 / 3236 loss=8.458, nll_loss=8.458, ppl=351.62, wps=1782.6, ups=1.37, wpb=1300.8, bsz=90.6, num_updates=1100, lr=0.00022, gnorm=0.958, train_wall=56, gb_free=17.9, wall=944
2024-01-31 05:47:54 | INFO | train_inner | epoch 001:   1200 / 3236 loss=8.412, nll_loss=8.412, ppl=340.67, wps=1662.1, ups=1.3, wpb=1280.1, bsz=89, num_updates=1200, lr=0.00024, gnorm=0.978, train_wall=56, gb_free=18.3, wall=1021
2024-01-31 05:48:59 | INFO | train_inner | epoch 001:   1300 / 3236 loss=8.369, nll_loss=8.369, ppl=330.65, wps=1980.9, ups=1.54, wpb=1288.2, bsz=83.4, num_updates=1300, lr=0.00026, gnorm=0.955, train_wall=57, gb_free=17.9, wall=1086
2024-01-31 05:50:07 | INFO | train_inner | epoch 001:   1400 / 3236 loss=8.248, nll_loss=8.248, ppl=304.08, wps=1922.9, ups=1.47, wpb=1307.5, bsz=86.4, num_updates=1400, lr=0.00028, gnorm=0.919, train_wall=57, gb_free=18.4, wall=1154
2024-01-31 05:51:14 | INFO | train_inner | epoch 001:   1500 / 3236 loss=8.189, nll_loss=8.189, ppl=291.77, wps=1940.9, ups=1.49, wpb=1304.2, bsz=85.7, num_updates=1500, lr=0.0003, gnorm=0.923, train_wall=56, gb_free=18, wall=1221
2024-01-31 05:52:25 | INFO | train_inner | epoch 001:   1600 / 3236 loss=8.026, nll_loss=8.026, ppl=260.57, wps=1827.2, ups=1.41, wpb=1298.8, bsz=90.2, num_updates=1600, lr=0.00032, gnorm=0.855, train_wall=56, gb_free=18.5, wall=1293
2024-01-31 05:53:35 | INFO | train_inner | epoch 001:   1700 / 3236 loss=8.004, nll_loss=8.004, ppl=256.73, wps=1880.7, ups=1.44, wpb=1306.2, bsz=88.4, num_updates=1700, lr=0.00034, gnorm=0.884, train_wall=56, gb_free=18.1, wall=1362
2024-01-31 05:54:44 | INFO | train_inner | epoch 001:   1800 / 3236 loss=7.929, nll_loss=7.929, ppl=243.73, wps=1904.4, ups=1.46, wpb=1308, bsz=87.9, num_updates=1800, lr=0.00036, gnorm=0.893, train_wall=56, gb_free=18.4, wall=1431
2024-01-31 05:55:51 | INFO | train_inner | epoch 001:   1900 / 3236 loss=7.884, nll_loss=7.884, ppl=236.18, wps=1907, ups=1.48, wpb=1292.3, bsz=86.2, num_updates=1900, lr=0.00038, gnorm=0.912, train_wall=57, gb_free=18.3, wall=1498
2024-01-31 05:56:54 | INFO | train_inner | epoch 001:   2000 / 3236 loss=7.827, nll_loss=7.827, ppl=227.1, wps=2066.9, ups=1.6, wpb=1291.5, bsz=86.2, num_updates=2000, lr=0.0004, gnorm=0.881, train_wall=56, gb_free=18.5, wall=1561
2024-01-31 05:58:02 | INFO | train_inner | epoch 001:   2100 / 3236 loss=7.783, nll_loss=7.783, ppl=220.33, wps=1909.4, ups=1.47, wpb=1299.8, bsz=87, num_updates=2100, lr=0.00042, gnorm=0.875, train_wall=57, gb_free=17.2, wall=1629
2024-01-31 05:59:17 | INFO | train_inner | epoch 001:   2200 / 3236 loss=7.591, nll_loss=7.591, ppl=192.86, wps=1755.2, ups=1.33, wpb=1321.2, bsz=97.8, num_updates=2200, lr=0.00044, gnorm=0.902, train_wall=56, gb_free=17.8, wall=1704
2024-01-31 06:00:22 | INFO | train_inner | epoch 001:   2300 / 3236 loss=7.629, nll_loss=7.629, ppl=197.95, wps=1985.7, ups=1.54, wpb=1290.1, bsz=89.7, num_updates=2300, lr=0.00046, gnorm=0.916, train_wall=57, gb_free=18.2, wall=1769
2024-01-31 06:01:30 | INFO | train_inner | epoch 001:   2400 / 3236 loss=7.521, nll_loss=7.521, ppl=183.72, wps=1913.6, ups=1.47, wpb=1298.6, bsz=90.6, num_updates=2400, lr=0.00048, gnorm=0.858, train_wall=56, gb_free=18.3, wall=1837
2024-01-31 06:02:38 | INFO | train_inner | epoch 001:   2500 / 3236 loss=7.483, nll_loss=7.483, ppl=178.93, wps=1954.4, ups=1.48, wpb=1318.8, bsz=89.6, num_updates=2500, lr=0.0005, gnorm=0.858, train_wall=56, gb_free=17.5, wall=1905
2024-01-31 06:03:57 | INFO | train_inner | epoch 001:   2600 / 3236 loss=7.394, nll_loss=7.394, ppl=168.24, wps=1674.6, ups=1.26, wpb=1328.8, bsz=94.1, num_updates=2600, lr=0.00052, gnorm=0.926, train_wall=56, gb_free=18.6, wall=1984
2024-01-31 06:05:09 | INFO | train_inner | epoch 001:   2700 / 3236 loss=7.45, nll_loss=7.45, ppl=174.84, wps=1765.2, ups=1.39, wpb=1270.5, bsz=83, num_updates=2700, lr=0.00054, gnorm=0.87, train_wall=57, gb_free=18.5, wall=2056
2024-01-31 06:06:21 | INFO | train_inner | epoch 001:   2800 / 3236 loss=7.357, nll_loss=7.357, ppl=163.98, wps=1789.6, ups=1.38, wpb=1299, bsz=86.1, num_updates=2800, lr=0.00056, gnorm=0.873, train_wall=56, gb_free=18, wall=2129
2024-01-31 06:07:37 | INFO | train_inner | epoch 001:   2900 / 3236 loss=7.265, nll_loss=7.265, ppl=153.81, wps=1751.5, ups=1.33, wpb=1319.5, bsz=90.8, num_updates=2900, lr=0.00058, gnorm=0.888, train_wall=57, gb_free=18.5, wall=2204
2024-01-31 06:08:48 | INFO | train_inner | epoch 001:   3000 / 3236 loss=7.275, nll_loss=7.275, ppl=154.85, wps=1826.7, ups=1.39, wpb=1309.8, bsz=84.2, num_updates=3000, lr=0.0006, gnorm=0.883, train_wall=56, gb_free=18.6, wall=2276
2024-01-31 06:09:59 | INFO | train_inner | epoch 001:   3100 / 3236 loss=7.149, nll_loss=7.149, ppl=141.95, wps=1829.2, ups=1.41, wpb=1297.5, bsz=90.5, num_updates=3100, lr=0.00062, gnorm=0.887, train_wall=56, gb_free=17.7, wall=2346
2024-01-31 06:11:17 | INFO | train_inner | epoch 001:   3200 / 3236 loss=7.027, nll_loss=7.027, ppl=130.44, wps=1699.1, ups=1.29, wpb=1321.8, bsz=98.6, num_updates=3200, lr=0.00064, gnorm=0.901, train_wall=56, gb_free=17.9, wall=2424
2024-01-31 06:11:41 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-01-31 06:11:41 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 06:13:19 | INFO | dev | epoch 001 | valid on 'dev' subset | loss 7.006 | nll_loss 7.006 | ppl 128.57 | wps 2372.5 | wpb 1146.2 | bsz 77.6 | num_updates 3236
2024-01-31 06:13:19 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 3236 updates
2024-01-31 06:13:19 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint1.pt
2024-01-31 06:13:20 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint1.pt
2024-01-31 06:13:25 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint1.pt (epoch 1 @ 3236 updates, score 7.006) (writing took 5.959304186049849 seconds)
2024-01-31 06:13:25 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)
2024-01-31 06:13:25 | INFO | train | epoch 001 | loss 8.312 | nll_loss 8.312 | ppl 317.88 | wps 1763.5 | ups 1.35 | wpb 1302.4 | bsz 89.4 | num_updates 3236 | lr 0.0006472 | gnorm 0.992 | train_wall 1857 | gb_free 17.8 | wall 2552
2024-01-31 06:13:25 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 06:13:25 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-01-31 06:13:25 | INFO | fairseq.trainer | begin training epoch 2
2024-01-31 06:13:25 | INFO | fairseq_cli.train | Start iterating over samples
2024-01-31 06:14:03 | INFO | train_inner | epoch 002:     64 / 3236 loss=7.017, nll_loss=7.017, ppl=129.54, wps=787.7, ups=0.6, wpb=1308, bsz=89.3, num_updates=3300, lr=0.00066, gnorm=0.898, train_wall=56, gb_free=17.2, wall=2590
2024-01-31 06:15:00 | INFO | train_inner | epoch 002:    164 / 3236 loss=6.976, nll_loss=6.976, ppl=125.89, wps=2297, ups=1.76, wpb=1305.3, bsz=87.1, num_updates=3400, lr=0.00068, gnorm=0.875, train_wall=56, gb_free=18.3, wall=2647
2024-01-31 06:15:57 | INFO | train_inner | epoch 002:    264 / 3236 loss=6.838, nll_loss=6.838, ppl=114.43, wps=2321.2, ups=1.76, wpb=1317.6, bsz=91.6, num_updates=3500, lr=0.0007, gnorm=0.898, train_wall=56, gb_free=18.5, wall=2704
2024-01-31 06:16:54 | INFO | train_inner | epoch 002:    364 / 3236 loss=6.98, nll_loss=6.98, ppl=126.25, wps=2249.3, ups=1.75, wpb=1284.8, bsz=87.4, num_updates=3600, lr=0.00072, gnorm=0.964, train_wall=57, gb_free=17.2, wall=2761
2024-01-31 06:17:51 | INFO | train_inner | epoch 002:    464 / 3236 loss=6.827, nll_loss=6.827, ppl=113.53, wps=2240.3, ups=1.75, wpb=1278.5, bsz=88.5, num_updates=3700, lr=0.00074, gnorm=0.885, train_wall=57, gb_free=18.1, wall=2818
2024-01-31 06:18:48 | INFO | train_inner | epoch 002:    564 / 3236 loss=6.793, nll_loss=6.793, ppl=110.9, wps=2249.8, ups=1.75, wpb=1283.6, bsz=85, num_updates=3800, lr=0.00076, gnorm=0.928, train_wall=57, gb_free=18.5, wall=2875
2024-01-31 06:19:45 | INFO | train_inner | epoch 002:    664 / 3236 loss=6.643, nll_loss=6.643, ppl=99.92, wps=2299.1, ups=1.76, wpb=1309.3, bsz=91.6, num_updates=3900, lr=0.00078, gnorm=0.925, train_wall=56, gb_free=18.6, wall=2932
2024-01-31 06:20:42 | INFO | train_inner | epoch 002:    764 / 3236 loss=6.572, nll_loss=6.572, ppl=95.14, wps=2295.1, ups=1.75, wpb=1313.6, bsz=94.7, num_updates=4000, lr=0.0008, gnorm=0.964, train_wall=57, gb_free=18.1, wall=2989
2024-01-31 06:21:39 | INFO | train_inner | epoch 002:    864 / 3236 loss=6.459, nll_loss=6.459, ppl=87.99, wps=2313.5, ups=1.76, wpb=1315.7, bsz=92.1, num_updates=4100, lr=0.00082, gnorm=0.948, train_wall=56, gb_free=18.2, wall=3046
2024-01-31 06:22:36 | INFO | train_inner | epoch 002:    964 / 3236 loss=6.345, nll_loss=6.345, ppl=81.3, wps=2320.9, ups=1.76, wpb=1320, bsz=93.4, num_updates=4200, lr=0.00084, gnorm=0.94, train_wall=56, gb_free=18.3, wall=3103
2024-01-31 06:23:33 | INFO | train_inner | epoch 002:   1064 / 3236 loss=6.391, nll_loss=6.391, ppl=83.92, wps=2274, ups=1.76, wpb=1293.6, bsz=85.9, num_updates=4300, lr=0.00086, gnorm=0.96, train_wall=56, gb_free=18.3, wall=3160
2024-01-31 06:24:30 | INFO | train_inner | epoch 002:   1164 / 3236 loss=6.265, nll_loss=6.265, ppl=76.91, wps=2266.9, ups=1.75, wpb=1293, bsz=88, num_updates=4400, lr=0.00088, gnorm=0.983, train_wall=57, gb_free=18.2, wall=3217
2024-01-31 06:25:27 | INFO | train_inner | epoch 002:   1264 / 3236 loss=6.281, nll_loss=6.281, ppl=77.74, wps=2275.7, ups=1.75, wpb=1296.8, bsz=84, num_updates=4500, lr=0.0009, gnorm=1.002, train_wall=56, gb_free=17.6, wall=3274
2024-01-31 06:26:24 | INFO | train_inner | epoch 002:   1364 / 3236 loss=6.043, nll_loss=6.043, ppl=65.95, wps=2299, ups=1.76, wpb=1306.1, bsz=93.9, num_updates=4600, lr=0.00092, gnorm=0.985, train_wall=56, gb_free=18.3, wall=3331
2024-01-31 06:27:24 | INFO | train_inner | epoch 002:   1464 / 3236 loss=6.024, nll_loss=6.024, ppl=65.06, wps=2171.6, ups=1.67, wpb=1303.7, bsz=93.2, num_updates=4700, lr=0.00094, gnorm=0.992, train_wall=57, gb_free=17.8, wall=3391
2024-01-31 06:28:21 | INFO | train_inner | epoch 002:   1564 / 3236 loss=5.964, nll_loss=5.964, ppl=62.44, wps=2284.8, ups=1.76, wpb=1299, bsz=87.7, num_updates=4800, lr=0.00096, gnorm=1.022, train_wall=56, gb_free=17.6, wall=3448
2024-01-31 06:29:18 | INFO | train_inner | epoch 002:   1664 / 3236 loss=5.888, nll_loss=5.888, ppl=59.23, wps=2282.4, ups=1.75, wpb=1303.8, bsz=89.8, num_updates=4900, lr=0.00098, gnorm=1.019, train_wall=57, gb_free=17.9, wall=3505
2024-01-31 06:30:15 | INFO | train_inner | epoch 002:   1764 / 3236 loss=5.76, nll_loss=5.76, ppl=54.2, wps=2310.2, ups=1.76, wpb=1313.5, bsz=92.4, num_updates=5000, lr=0.001, gnorm=1.018, train_wall=56, gb_free=18.5, wall=3562
2024-01-31 06:31:13 | INFO | train_inner | epoch 002:   1864 / 3236 loss=5.605, nll_loss=5.605, ppl=48.68, wps=2245.8, ups=1.72, wpb=1308.7, bsz=94.5, num_updates=5100, lr=0.00102, gnorm=1.019, train_wall=56, gb_free=18.7, wall=3620
2024-01-31 06:32:15 | INFO | train_inner | epoch 002:   1964 / 3236 loss=5.598, nll_loss=5.598, ppl=48.45, wps=2097.4, ups=1.61, wpb=1304.9, bsz=88.3, num_updates=5200, lr=0.00104, gnorm=1.05, train_wall=60, gb_free=18.5, wall=3682
2024-01-31 06:33:12 | INFO | train_inner | epoch 002:   2064 / 3236 loss=5.57, nll_loss=5.57, ppl=47.52, wps=2260.2, ups=1.75, wpb=1288.3, bsz=84.8, num_updates=5300, lr=0.00106, gnorm=1.052, train_wall=57, gb_free=17.8, wall=3739
2024-01-31 06:34:10 | INFO | train_inner | epoch 002:   2164 / 3236 loss=5.448, nll_loss=5.448, ppl=43.64, wps=2276.2, ups=1.73, wpb=1316.3, bsz=87.2, num_updates=5400, lr=0.00108, gnorm=1.064, train_wall=57, gb_free=18.1, wall=3797
2024-01-31 06:35:07 | INFO | train_inner | epoch 002:   2264 / 3236 loss=5.283, nll_loss=5.283, ppl=38.93, wps=2278.4, ups=1.75, wpb=1299.3, bsz=93, num_updates=5500, lr=0.0011, gnorm=1.048, train_wall=57, gb_free=18, wall=3854
2024-01-31 06:36:05 | INFO | train_inner | epoch 002:   2364 / 3236 loss=5.228, nll_loss=5.228, ppl=37.47, wps=2231.1, ups=1.73, wpb=1289.5, bsz=87.1, num_updates=5600, lr=0.00112, gnorm=1.056, train_wall=57, gb_free=17.6, wall=3912
2024-01-31 06:37:02 | INFO | train_inner | epoch 002:   2464 / 3236 loss=5.182, nll_loss=5.182, ppl=36.3, wps=2233.1, ups=1.74, wpb=1280, bsz=85.7, num_updates=5700, lr=0.00114, gnorm=1.078, train_wall=57, gb_free=17.8, wall=3969
2024-01-31 06:37:59 | INFO | train_inner | epoch 002:   2564 / 3236 loss=5.013, nll_loss=5.013, ppl=32.3, wps=2313.3, ups=1.76, wpb=1312.7, bsz=88.9, num_updates=5800, lr=0.00116, gnorm=1.044, train_wall=56, gb_free=17.9, wall=4026
2024-01-31 06:38:57 | INFO | train_inner | epoch 002:   2664 / 3236 loss=4.987, nll_loss=4.987, ppl=31.71, wps=2230.8, ups=1.72, wpb=1295, bsz=86.8, num_updates=5900, lr=0.00118, gnorm=1.078, train_wall=58, gb_free=18.3, wall=4084
2024-01-31 06:39:54 | INFO | train_inner | epoch 002:   2764 / 3236 loss=4.911, nll_loss=4.911, ppl=30.09, wps=2266, ups=1.75, wpb=1298.4, bsz=88.4, num_updates=6000, lr=0.0012, gnorm=1.078, train_wall=57, gb_free=18.4, wall=4141
2024-01-31 06:40:51 | INFO | train_inner | epoch 002:   2864 / 3236 loss=4.834, nll_loss=4.834, ppl=28.53, wps=2276.6, ups=1.76, wpb=1294.3, bsz=86.9, num_updates=6100, lr=0.00122, gnorm=1.089, train_wall=56, gb_free=17.6, wall=4198
2024-01-31 06:41:48 | INFO | train_inner | epoch 002:   2964 / 3236 loss=4.734, nll_loss=4.734, ppl=26.62, wps=2281.4, ups=1.75, wpb=1307, bsz=90.4, num_updates=6200, lr=0.00124, gnorm=1.062, train_wall=57, gb_free=17.8, wall=4255
2024-01-31 06:42:46 | INFO | train_inner | epoch 002:   3064 / 3236 loss=4.606, nll_loss=4.606, ppl=24.36, wps=2319.5, ups=1.75, wpb=1325.1, bsz=91.3, num_updates=6300, lr=0.00126, gnorm=1.05, train_wall=57, gb_free=17.6, wall=4313
2024-01-31 06:43:43 | INFO | train_inner | epoch 002:   3164 / 3236 loss=4.613, nll_loss=4.613, ppl=24.46, wps=2271.9, ups=1.75, wpb=1298.2, bsz=88.9, num_updates=6400, lr=0.00128, gnorm=1.06, train_wall=57, gb_free=18.3, wall=4370
2024-01-31 06:44:24 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-01-31 06:44:24 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 06:45:55 | INFO | dev | epoch 002 | valid on 'dev' subset | loss 3.966 | nll_loss 3.966 | ppl 15.63 | wps 2532.1 | wpb 1146.2 | bsz 77.6 | num_updates 6472 | best_loss 3.966
2024-01-31 06:45:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 6472 updates
2024-01-31 06:45:55 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint2.pt
2024-01-31 06:45:56 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint2.pt
2024-01-31 06:46:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint2.pt (epoch 2 @ 6472 updates, score 3.966) (writing took 5.870096333092079 seconds)
2024-01-31 06:46:01 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)
2024-01-31 06:46:01 | INFO | train | epoch 002 | loss 5.82 | nll_loss 5.82 | ppl 56.48 | wps 2154.5 | ups 1.65 | wpb 1302.4 | bsz 89.4 | num_updates 6472 | lr 0.0012944 | gnorm 1.003 | train_wall 1835 | gb_free 18.1 | wall 4508
2024-01-31 06:46:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 06:46:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-01-31 06:46:01 | INFO | fairseq.trainer | begin training epoch 3
2024-01-31 06:46:01 | INFO | fairseq_cli.train | Start iterating over samples
2024-01-31 06:46:19 | INFO | train_inner | epoch 003:     28 / 3236 loss=4.373, nll_loss=4.373, ppl=20.71, wps=847.1, ups=0.64, wpb=1327.3, bsz=97, num_updates=6500, lr=0.0013, gnorm=1.017, train_wall=56, gb_free=18.4, wall=4526
2024-01-31 06:47:16 | INFO | train_inner | epoch 003:    128 / 3236 loss=4.348, nll_loss=4.348, ppl=20.37, wps=2292.4, ups=1.76, wpb=1304.7, bsz=90.6, num_updates=6600, lr=0.00132, gnorm=1.053, train_wall=56, gb_free=18.1, wall=4583
2024-01-31 06:48:13 | INFO | train_inner | epoch 003:    228 / 3236 loss=4.286, nll_loss=4.286, ppl=19.5, wps=2291.2, ups=1.77, wpb=1297.1, bsz=93.2, num_updates=6700, lr=0.00134, gnorm=1.028, train_wall=56, gb_free=17.7, wall=4640
2024-01-31 06:49:10 | INFO | train_inner | epoch 003:    328 / 3236 loss=4.308, nll_loss=4.308, ppl=19.81, wps=2241.3, ups=1.75, wpb=1280.1, bsz=85.8, num_updates=6800, lr=0.00136, gnorm=1.067, train_wall=57, gb_free=17.5, wall=4697
2024-01-31 06:50:07 | INFO | train_inner | epoch 003:    428 / 3236 loss=4.292, nll_loss=4.292, ppl=19.59, wps=2232.2, ups=1.75, wpb=1273.7, bsz=82.8, num_updates=6900, lr=0.00138, gnorm=1.058, train_wall=57, gb_free=17.7, wall=4754
2024-01-31 06:51:04 | INFO | train_inner | epoch 003:    528 / 3236 loss=4.118, nll_loss=4.118, ppl=17.37, wps=2323.6, ups=1.76, wpb=1321, bsz=91.7, num_updates=7000, lr=0.0014, gnorm=0.996, train_wall=56, gb_free=18.5, wall=4811
2024-01-31 06:52:01 | INFO | train_inner | epoch 003:    628 / 3236 loss=4.142, nll_loss=4.142, ppl=17.66, wps=2295.2, ups=1.76, wpb=1305, bsz=90.2, num_updates=7100, lr=0.00142, gnorm=1.038, train_wall=56, gb_free=17.6, wall=4868
2024-01-31 06:52:58 | INFO | train_inner | epoch 003:    728 / 3236 loss=4.12, nll_loss=4.12, ppl=17.39, wps=2276.1, ups=1.75, wpb=1298.1, bsz=89.9, num_updates=7200, lr=0.00144, gnorm=1.026, train_wall=57, gb_free=18.1, wall=4925
2024-01-31 06:53:55 | INFO | train_inner | epoch 003:    828 / 3236 loss=4.017, nll_loss=4.017, ppl=16.19, wps=2254.6, ups=1.73, wpb=1300.4, bsz=89.4, num_updates=7300, lr=0.00146, gnorm=0.983, train_wall=56, gb_free=17.9, wall=4983
2024-01-31 06:54:54 | INFO | train_inner | epoch 003:    928 / 3236 loss=3.991, nll_loss=3.991, ppl=15.9, wps=2217.8, ups=1.71, wpb=1300.6, bsz=93.1, num_updates=7400, lr=0.00148, gnorm=0.975, train_wall=56, gb_free=17.7, wall=5041
2024-01-31 06:55:51 | INFO | train_inner | epoch 003:   1028 / 3236 loss=3.991, nll_loss=3.991, ppl=15.9, wps=2238.7, ups=1.75, wpb=1280.3, bsz=82.2, num_updates=7500, lr=0.0015, gnorm=0.989, train_wall=57, gb_free=18.5, wall=5098
2024-01-31 06:56:49 | INFO | train_inner | epoch 003:   1128 / 3236 loss=3.926, nll_loss=3.926, ppl=15.2, wps=2263.6, ups=1.75, wpb=1295.1, bsz=84.6, num_updates=7600, lr=0.00152, gnorm=0.975, train_wall=57, gb_free=18.2, wall=5156
2024-01-31 06:57:48 | INFO | train_inner | epoch 003:   1228 / 3236 loss=3.814, nll_loss=3.814, ppl=14.06, wps=2236.6, ups=1.69, wpb=1322.7, bsz=91.8, num_updates=7700, lr=0.00154, gnorm=0.937, train_wall=56, gb_free=17.6, wall=5215
2024-01-31 06:58:47 | INFO | train_inner | epoch 003:   1328 / 3236 loss=3.867, nll_loss=3.867, ppl=14.59, wps=2180.6, ups=1.67, wpb=1303, bsz=89.7, num_updates=7800, lr=0.00156, gnorm=0.934, train_wall=57, gb_free=18.6, wall=5274
2024-01-31 06:59:48 | INFO | train_inner | epoch 003:   1428 / 3236 loss=3.806, nll_loss=3.806, ppl=13.98, wps=2158.1, ups=1.64, wpb=1313, bsz=93.8, num_updates=7900, lr=0.00158, gnorm=0.945, train_wall=57, gb_free=17, wall=5335
2024-01-31 07:00:55 | INFO | train_inner | epoch 003:   1528 / 3236 loss=3.745, nll_loss=3.745, ppl=13.41, wps=1938.5, ups=1.5, wpb=1292.3, bsz=87.8, num_updates=8000, lr=0.0016, gnorm=0.91, train_wall=56, gb_free=17.9, wall=5402
2024-01-31 07:02:04 | INFO | train_inner | epoch 003:   1628 / 3236 loss=3.755, nll_loss=3.755, ppl=13.5, wps=1874.1, ups=1.44, wpb=1301.9, bsz=92, num_updates=8100, lr=0.00162, gnorm=0.938, train_wall=56, gb_free=17.8, wall=5471
2024-01-31 07:03:25 | INFO | train_inner | epoch 003:   1728 / 3236 loss=3.73, nll_loss=3.73, ppl=13.27, wps=1600.1, ups=1.24, wpb=1292.5, bsz=86.6, num_updates=8200, lr=0.00164, gnorm=0.911, train_wall=56, gb_free=18, wall=5552
2024-01-31 07:04:31 | INFO | train_inner | epoch 003:   1828 / 3236 loss=3.72, nll_loss=3.72, ppl=13.18, wps=1962.6, ups=1.51, wpb=1301.2, bsz=86.5, num_updates=8300, lr=0.00166, gnorm=0.931, train_wall=57, gb_free=18.6, wall=5619
2024-01-31 07:05:40 | INFO | train_inner | epoch 003:   1928 / 3236 loss=3.625, nll_loss=3.625, ppl=12.34, wps=1951.2, ups=1.46, wpb=1337.6, bsz=95.2, num_updates=8400, lr=0.00168, gnorm=0.887, train_wall=56, gb_free=18.6, wall=5687
2024-01-31 07:06:43 | INFO | train_inner | epoch 003:   2028 / 3236 loss=3.643, nll_loss=3.643, ppl=12.49, wps=2065.8, ups=1.58, wpb=1306.8, bsz=87.1, num_updates=8500, lr=0.0017, gnorm=0.9, train_wall=56, gb_free=18.4, wall=5750
2024-01-31 07:07:46 | INFO | train_inner | epoch 003:   2128 / 3236 loss=3.629, nll_loss=3.629, ppl=12.37, wps=2048.9, ups=1.58, wpb=1295.4, bsz=88.2, num_updates=8600, lr=0.00172, gnorm=0.892, train_wall=57, gb_free=18, wall=5814
2024-01-31 07:08:49 | INFO | train_inner | epoch 003:   2228 / 3236 loss=3.639, nll_loss=3.639, ppl=12.46, wps=2098.1, ups=1.59, wpb=1317.2, bsz=90.2, num_updates=8700, lr=0.00174, gnorm=0.893, train_wall=57, gb_free=17.7, wall=5876
2024-01-31 07:09:50 | INFO | train_inner | epoch 003:   2328 / 3236 loss=3.543, nll_loss=3.543, ppl=11.66, wps=2126.5, ups=1.65, wpb=1288.3, bsz=85.4, num_updates=8800, lr=0.00176, gnorm=0.87, train_wall=56, gb_free=17.4, wall=5937
2024-01-31 07:10:54 | INFO | train_inner | epoch 003:   2428 / 3236 loss=3.564, nll_loss=3.564, ppl=11.83, wps=2050.5, ups=1.56, wpb=1310.5, bsz=89.9, num_updates=8900, lr=0.00178, gnorm=0.864, train_wall=57, gb_free=18.3, wall=6001
2024-01-31 07:11:58 | INFO | train_inner | epoch 003:   2528 / 3236 loss=3.516, nll_loss=3.516, ppl=11.44, wps=2057.7, ups=1.57, wpb=1313.6, bsz=93.2, num_updates=9000, lr=0.0018, gnorm=0.846, train_wall=56, gb_free=17.7, wall=6065
2024-01-31 07:13:00 | INFO | train_inner | epoch 003:   2628 / 3236 loss=3.509, nll_loss=3.509, ppl=11.38, wps=2073.1, ups=1.6, wpb=1292.9, bsz=88, num_updates=9100, lr=0.00182, gnorm=0.857, train_wall=56, gb_free=18, wall=6127
2024-01-31 07:14:01 | INFO | train_inner | epoch 003:   2728 / 3236 loss=3.509, nll_loss=3.509, ppl=11.39, wps=2141.4, ups=1.65, wpb=1300.2, bsz=86.7, num_updates=9200, lr=0.00184, gnorm=0.84, train_wall=57, gb_free=17.5, wall=6188
2024-01-31 07:15:07 | INFO | train_inner | epoch 003:   2828 / 3236 loss=3.568, nll_loss=3.568, ppl=11.86, wps=1938.2, ups=1.51, wpb=1282.9, bsz=89.8, num_updates=9300, lr=0.00186, gnorm=0.897, train_wall=56, gb_free=18.9, wall=6254
2024-01-31 07:16:18 | INFO | train_inner | epoch 003:   2928 / 3236 loss=3.479, nll_loss=3.479, ppl=11.15, wps=1845.7, ups=1.42, wpb=1304.3, bsz=91.7, num_updates=9400, lr=0.00188, gnorm=0.845, train_wall=56, gb_free=17.6, wall=6325
2024-01-31 07:17:26 | INFO | train_inner | epoch 003:   3028 / 3236 loss=3.357, nll_loss=3.357, ppl=10.25, wps=1924, ups=1.46, wpb=1318.6, bsz=95.4, num_updates=9500, lr=0.0019, gnorm=0.806, train_wall=56, gb_free=18.1, wall=6393
2024-01-31 07:18:39 | INFO | train_inner | epoch 003:   3128 / 3236 loss=3.353, nll_loss=3.353, ppl=10.22, wps=1781.5, ups=1.36, wpb=1307, bsz=90.1, num_updates=9600, lr=0.00192, gnorm=0.792, train_wall=56, gb_free=17.6, wall=6467
2024-01-31 07:19:51 | INFO | train_inner | epoch 003:   3228 / 3236 loss=3.433, nll_loss=3.433, ppl=10.8, wps=1824.2, ups=1.4, wpb=1300.6, bsz=86.2, num_updates=9700, lr=0.00194, gnorm=0.838, train_wall=57, gb_free=18.6, wall=6538
2024-01-31 07:19:56 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-01-31 07:19:56 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 07:21:33 | INFO | dev | epoch 003 | valid on 'dev' subset | loss 2.712 | nll_loss 2.712 | ppl 6.55 | wps 2382.8 | wpb 1146.2 | bsz 77.6 | num_updates 9708 | best_loss 2.712
2024-01-31 07:21:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 9708 updates
2024-01-31 07:21:33 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint3.pt
2024-01-31 07:21:34 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint3.pt
2024-01-31 07:21:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint3.pt (epoch 3 @ 9708 updates, score 2.712) (writing took 5.798149843933061 seconds)
2024-01-31 07:21:39 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)
2024-01-31 07:21:39 | INFO | train | epoch 003 | loss 3.794 | nll_loss 3.794 | ppl 13.87 | wps 1970.9 | ups 1.51 | wpb 1302.4 | bsz 89.4 | num_updates 9708 | lr 0.0019416 | gnorm 0.929 | train_wall 1825 | gb_free 18.3 | wall 6646
2024-01-31 07:21:39 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 07:21:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-01-31 07:21:39 | INFO | fairseq.trainer | begin training epoch 4
2024-01-31 07:21:39 | INFO | fairseq_cli.train | Start iterating over samples
2024-01-31 07:22:34 | INFO | train_inner | epoch 004:     92 / 3236 loss=3.23, nll_loss=3.23, ppl=9.39, wps=805.8, ups=0.61, wpb=1315.4, bsz=89.7, num_updates=9800, lr=0.00196, gnorm=0.796, train_wall=57, gb_free=17.6, wall=6701
2024-01-31 07:23:31 | INFO | train_inner | epoch 004:    192 / 3236 loss=3.265, nll_loss=3.265, ppl=9.61, wps=2286.5, ups=1.76, wpb=1298.3, bsz=96.2, num_updates=9900, lr=0.00198, gnorm=0.822, train_wall=56, gb_free=18.2, wall=6758
2024-01-31 07:24:27 | INFO | train_inner | epoch 004:    292 / 3236 loss=3.208, nll_loss=3.208, ppl=9.24, wps=2271.8, ups=1.76, wpb=1288.8, bsz=88.1, num_updates=10000, lr=0.002, gnorm=0.775, train_wall=56, gb_free=18.5, wall=6815
2024-01-31 07:25:25 | INFO | train_inner | epoch 004:    392 / 3236 loss=3.3, nll_loss=3.3, ppl=9.85, wps=2256.3, ups=1.75, wpb=1286.6, bsz=85.4, num_updates=10100, lr=0.00199007, gnorm=0.801, train_wall=57, gb_free=18.2, wall=6872
2024-01-31 07:26:21 | INFO | train_inner | epoch 004:    492 / 3236 loss=3.188, nll_loss=3.188, ppl=9.11, wps=2325.7, ups=1.76, wpb=1321.2, bsz=93.2, num_updates=10200, lr=0.0019803, gnorm=0.756, train_wall=56, gb_free=18.1, wall=6928
2024-01-31 07:27:19 | INFO | train_inner | epoch 004:    592 / 3236 loss=3.234, nll_loss=3.234, ppl=9.41, wps=2266.7, ups=1.75, wpb=1295.9, bsz=88.3, num_updates=10300, lr=0.00197066, gnorm=0.799, train_wall=57, gb_free=18.2, wall=6986
2024-01-31 07:28:16 | INFO | train_inner | epoch 004:    692 / 3236 loss=3.167, nll_loss=3.167, ppl=8.98, wps=2261.7, ups=1.75, wpb=1294.5, bsz=93.1, num_updates=10400, lr=0.00196116, gnorm=0.771, train_wall=57, gb_free=17.9, wall=7043
2024-01-31 07:29:13 | INFO | train_inner | epoch 004:    792 / 3236 loss=3.087, nll_loss=3.087, ppl=8.5, wps=2305.8, ups=1.75, wpb=1316, bsz=92.6, num_updates=10500, lr=0.0019518, gnorm=0.748, train_wall=57, gb_free=17.6, wall=7100
2024-01-31 07:30:10 | INFO | train_inner | epoch 004:    892 / 3236 loss=3.085, nll_loss=3.085, ppl=8.49, wps=2288.6, ups=1.76, wpb=1302.6, bsz=90, num_updates=10600, lr=0.00194257, gnorm=0.729, train_wall=56, gb_free=17.2, wall=7157
2024-01-31 07:31:06 | INFO | train_inner | epoch 004:    992 / 3236 loss=3.054, nll_loss=3.054, ppl=8.3, wps=2293.6, ups=1.77, wpb=1298.5, bsz=86.5, num_updates=10700, lr=0.00193347, gnorm=0.746, train_wall=56, gb_free=18.4, wall=7213
2024-01-31 07:32:03 | INFO | train_inner | epoch 004:   1092 / 3236 loss=3.083, nll_loss=3.083, ppl=8.47, wps=2294.5, ups=1.76, wpb=1304.8, bsz=91, num_updates=10800, lr=0.0019245, gnorm=0.763, train_wall=56, gb_free=17.7, wall=7270
2024-01-31 07:33:00 | INFO | train_inner | epoch 004:   1192 / 3236 loss=3.067, nll_loss=3.067, ppl=8.38, wps=2289.7, ups=1.76, wpb=1302, bsz=86.6, num_updates=10900, lr=0.00191565, gnorm=0.725, train_wall=56, gb_free=17.6, wall=7327
2024-01-31 07:33:57 | INFO | train_inner | epoch 004:   1292 / 3236 loss=3.014, nll_loss=3.014, ppl=8.08, wps=2270.3, ups=1.75, wpb=1297.6, bsz=87.1, num_updates=11000, lr=0.00190693, gnorm=0.751, train_wall=57, gb_free=18, wall=7384
2024-01-31 07:34:54 | INFO | train_inner | epoch 004:   1392 / 3236 loss=3.033, nll_loss=3.033, ppl=8.18, wps=2283.7, ups=1.75, wpb=1301.4, bsz=87.6, num_updates=11100, lr=0.00189832, gnorm=0.726, train_wall=57, gb_free=18, wall=7441
2024-01-31 07:35:51 | INFO | train_inner | epoch 004:   1492 / 3236 loss=3.006, nll_loss=3.006, ppl=8.03, wps=2285, ups=1.77, wpb=1293.8, bsz=87, num_updates=11200, lr=0.00188982, gnorm=0.719, train_wall=56, gb_free=18.4, wall=7498
2024-01-31 07:36:47 | INFO | train_inner | epoch 004:   1592 / 3236 loss=2.993, nll_loss=2.993, ppl=7.96, wps=2303.9, ups=1.77, wpb=1303.6, bsz=88.6, num_updates=11300, lr=0.00188144, gnorm=0.728, train_wall=56, gb_free=17.9, wall=7554
2024-01-31 07:37:46 | INFO | train_inner | epoch 004:   1692 / 3236 loss=2.95, nll_loss=2.95, ppl=7.73, wps=2239.2, ups=1.71, wpb=1308.3, bsz=88.9, num_updates=11400, lr=0.00187317, gnorm=0.697, train_wall=58, gb_free=18.4, wall=7613
2024-01-31 07:38:43 | INFO | train_inner | epoch 004:   1792 / 3236 loss=2.916, nll_loss=2.916, ppl=7.55, wps=2280.5, ups=1.76, wpb=1298.7, bsz=87.7, num_updates=11500, lr=0.00186501, gnorm=0.686, train_wall=56, gb_free=18.6, wall=7670
2024-01-31 07:39:40 | INFO | train_inner | epoch 004:   1892 / 3236 loss=2.874, nll_loss=2.874, ppl=7.33, wps=2272.9, ups=1.75, wpb=1301.6, bsz=92.6, num_updates=11600, lr=0.00185695, gnorm=0.689, train_wall=56, gb_free=17.3, wall=7727
2024-01-31 07:40:39 | INFO | train_inner | epoch 004:   1992 / 3236 loss=2.861, nll_loss=2.861, ppl=7.27, wps=2222.8, ups=1.7, wpb=1310.1, bsz=93.4, num_updates=11700, lr=0.001849, gnorm=0.67, train_wall=56, gb_free=18.3, wall=7786
2024-01-31 07:41:39 | INFO | train_inner | epoch 004:   2092 / 3236 loss=2.899, nll_loss=2.899, ppl=7.46, wps=2112.9, ups=1.66, wpb=1276.2, bsz=84.1, num_updates=11800, lr=0.00184115, gnorm=0.697, train_wall=57, gb_free=18.2, wall=7846
2024-01-31 07:42:39 | INFO | train_inner | epoch 004:   2192 / 3236 loss=2.862, nll_loss=2.862, ppl=7.27, wps=2171.2, ups=1.67, wpb=1303.7, bsz=88, num_updates=11900, lr=0.0018334, gnorm=0.69, train_wall=56, gb_free=17.5, wall=7907
2024-01-31 07:43:43 | INFO | train_inner | epoch 004:   2292 / 3236 loss=2.796, nll_loss=2.796, ppl=6.95, wps=2053.6, ups=1.57, wpb=1306.2, bsz=87.8, num_updates=12000, lr=0.00182574, gnorm=0.679, train_wall=63, gb_free=17.6, wall=7970
2024-01-31 07:44:41 | INFO | train_inner | epoch 004:   2392 / 3236 loss=2.779, nll_loss=2.779, ppl=6.86, wps=2299.4, ups=1.74, wpb=1322.5, bsz=90.8, num_updates=12100, lr=0.00181818, gnorm=0.667, train_wall=57, gb_free=17.4, wall=8028
2024-01-31 07:45:40 | INFO | train_inner | epoch 004:   2492 / 3236 loss=2.798, nll_loss=2.798, ppl=6.95, wps=2181.5, ups=1.67, wpb=1305.1, bsz=90.8, num_updates=12200, lr=0.00181071, gnorm=0.697, train_wall=57, gb_free=18.1, wall=8087
2024-01-31 07:46:42 | INFO | train_inner | epoch 004:   2592 / 3236 loss=2.81, nll_loss=2.81, ppl=7.01, wps=2124, ups=1.62, wpb=1311.8, bsz=94, num_updates=12300, lr=0.00180334, gnorm=0.686, train_wall=56, gb_free=18.4, wall=8149
2024-01-31 07:47:45 | INFO | train_inner | epoch 004:   2692 / 3236 loss=2.763, nll_loss=2.763, ppl=6.79, wps=2081.2, ups=1.6, wpb=1300.7, bsz=88.6, num_updates=12400, lr=0.00179605, gnorm=0.667, train_wall=56, gb_free=17.5, wall=8212
2024-01-31 07:48:49 | INFO | train_inner | epoch 004:   2792 / 3236 loss=2.771, nll_loss=2.771, ppl=6.83, wps=2035.6, ups=1.56, wpb=1305, bsz=89.2, num_updates=12500, lr=0.00178885, gnorm=0.671, train_wall=56, gb_free=17.9, wall=8276
2024-01-31 07:49:50 | INFO | train_inner | epoch 004:   2892 / 3236 loss=2.759, nll_loss=2.759, ppl=6.77, wps=2100, ups=1.62, wpb=1295, bsz=87.1, num_updates=12600, lr=0.00178174, gnorm=0.659, train_wall=56, gb_free=18.5, wall=8338
2024-01-31 07:50:59 | INFO | train_inner | epoch 004:   2992 / 3236 loss=2.736, nll_loss=2.736, ppl=6.66, wps=1935.1, ups=1.46, wpb=1322.2, bsz=90.8, num_updates=12700, lr=0.00177471, gnorm=0.645, train_wall=57, gb_free=18.6, wall=8406
2024-01-31 07:52:05 | INFO | train_inner | epoch 004:   3092 / 3236 loss=2.709, nll_loss=2.709, ppl=6.54, wps=1963.8, ups=1.51, wpb=1302.4, bsz=86.4, num_updates=12800, lr=0.00176777, gnorm=0.662, train_wall=56, gb_free=18, wall=8472
2024-01-31 07:53:06 | INFO | train_inner | epoch 004:   3192 / 3236 loss=2.776, nll_loss=2.776, ppl=6.85, wps=2116.4, ups=1.64, wpb=1288, bsz=86.2, num_updates=12900, lr=0.0017609, gnorm=0.675, train_wall=57, gb_free=18.1, wall=8533
2024-01-31 07:53:36 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-01-31 07:53:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 07:55:17 | INFO | dev | epoch 004 | valid on 'dev' subset | loss 2.13 | nll_loss 2.13 | ppl 4.38 | wps 2288.5 | wpb 1146.2 | bsz 77.6 | num_updates 12944 | best_loss 2.13
2024-01-31 07:55:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 12944 updates
2024-01-31 07:55:17 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint4.pt
2024-01-31 07:55:19 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint4.pt
2024-01-31 07:55:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint4.pt (epoch 4 @ 12944 updates, score 2.13) (writing took 6.256664433982223 seconds)
2024-01-31 07:55:23 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)
2024-01-31 07:55:23 | INFO | train | epoch 004 | loss 2.967 | nll_loss 2.967 | ppl 7.82 | wps 2081.8 | ups 1.6 | wpb 1302.4 | bsz 89.4 | num_updates 12944 | lr 0.00175791 | gnorm 0.718 | train_wall 1833 | gb_free 18.4 | wall 8671
2024-01-31 07:55:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 07:55:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-01-31 07:55:24 | INFO | fairseq.trainer | begin training epoch 5
2024-01-31 07:55:24 | INFO | fairseq_cli.train | Start iterating over samples
2024-01-31 07:55:58 | INFO | train_inner | epoch 005:     56 / 3236 loss=2.643, nll_loss=2.643, ppl=6.25, wps=754.5, ups=0.58, wpb=1301.8, bsz=96.9, num_updates=13000, lr=0.00175412, gnorm=0.669, train_wall=56, gb_free=18.3, wall=8706
2024-01-31 07:56:55 | INFO | train_inner | epoch 005:    156 / 3236 loss=2.573, nll_loss=2.573, ppl=5.95, wps=2319.2, ups=1.76, wpb=1318.5, bsz=93.4, num_updates=13100, lr=0.00174741, gnorm=0.656, train_wall=56, gb_free=18.7, wall=8762
2024-01-31 07:57:52 | INFO | train_inner | epoch 005:    256 / 3236 loss=2.591, nll_loss=2.591, ppl=6.02, wps=2301.6, ups=1.77, wpb=1300.8, bsz=92.5, num_updates=13200, lr=0.00174078, gnorm=0.65, train_wall=56, gb_free=17.7, wall=8819
2024-01-31 07:58:49 | INFO | train_inner | epoch 005:    356 / 3236 loss=2.521, nll_loss=2.521, ppl=5.74, wps=2303.1, ups=1.75, wpb=1313.1, bsz=89.6, num_updates=13300, lr=0.00173422, gnorm=0.631, train_wall=56, gb_free=17.1, wall=8876
2024-01-31 07:59:46 | INFO | train_inner | epoch 005:    456 / 3236 loss=2.567, nll_loss=2.567, ppl=5.92, wps=2267.9, ups=1.75, wpb=1296.1, bsz=85.8, num_updates=13400, lr=0.00172774, gnorm=0.669, train_wall=57, gb_free=18.5, wall=8933
2024-01-31 08:00:43 | INFO | train_inner | epoch 005:    556 / 3236 loss=2.571, nll_loss=2.571, ppl=5.94, wps=2305.4, ups=1.75, wpb=1319.9, bsz=92.1, num_updates=13500, lr=0.00172133, gnorm=0.645, train_wall=57, gb_free=17.7, wall=8990
2024-01-31 08:01:40 | INFO | train_inner | epoch 005:    656 / 3236 loss=2.489, nll_loss=2.489, ppl=5.61, wps=2318.9, ups=1.75, wpb=1324.2, bsz=94.9, num_updates=13600, lr=0.00171499, gnorm=0.62, train_wall=57, gb_free=18.3, wall=9047
2024-01-31 08:02:37 | INFO | train_inner | epoch 005:    756 / 3236 loss=2.505, nll_loss=2.505, ppl=5.68, wps=2272.8, ups=1.76, wpb=1289.6, bsz=87.7, num_updates=13700, lr=0.00170872, gnorm=0.632, train_wall=56, gb_free=18.2, wall=9104
2024-01-31 08:03:34 | INFO | train_inner | epoch 005:    856 / 3236 loss=2.499, nll_loss=2.499, ppl=5.65, wps=2300, ups=1.76, wpb=1303.2, bsz=90.1, num_updates=13800, lr=0.00170251, gnorm=0.631, train_wall=56, gb_free=17.6, wall=9161
2024-01-31 08:04:31 | INFO | train_inner | epoch 005:    956 / 3236 loss=2.522, nll_loss=2.522, ppl=5.74, wps=2277.8, ups=1.76, wpb=1294.7, bsz=90.2, num_updates=13900, lr=0.00169638, gnorm=0.638, train_wall=56, gb_free=18, wall=9218
2024-01-31 08:05:28 | INFO | train_inner | epoch 005:   1056 / 3236 loss=2.516, nll_loss=2.516, ppl=5.72, wps=2276.9, ups=1.76, wpb=1297.1, bsz=89.6, num_updates=14000, lr=0.00169031, gnorm=0.641, train_wall=56, gb_free=18.2, wall=9275
2024-01-31 08:06:25 | INFO | train_inner | epoch 005:   1156 / 3236 loss=2.505, nll_loss=2.505, ppl=5.68, wps=2289.7, ups=1.75, wpb=1306.4, bsz=87.4, num_updates=14100, lr=0.0016843, gnorm=0.636, train_wall=57, gb_free=18.1, wall=9332
2024-01-31 08:07:24 | INFO | train_inner | epoch 005:   1256 / 3236 loss=2.487, nll_loss=2.487, ppl=5.6, wps=2173.1, ups=1.69, wpb=1285.3, bsz=87, num_updates=14200, lr=0.00167836, gnorm=0.628, train_wall=59, gb_free=18.6, wall=9391
2024-01-31 08:08:21 | INFO | train_inner | epoch 005:   1356 / 3236 loss=2.458, nll_loss=2.458, ppl=5.49, wps=2315.1, ups=1.76, wpb=1313.3, bsz=93.2, num_updates=14300, lr=0.00167248, gnorm=0.623, train_wall=56, gb_free=18.4, wall=9448
2024-01-31 08:09:18 | INFO | train_inner | epoch 005:   1456 / 3236 loss=2.511, nll_loss=2.511, ppl=5.7, wps=2270.8, ups=1.75, wpb=1294.3, bsz=86.6, num_updates=14400, lr=0.00166667, gnorm=0.661, train_wall=56, gb_free=17.3, wall=9505
2024-01-31 08:10:15 | INFO | train_inner | epoch 005:   1556 / 3236 loss=2.471, nll_loss=2.471, ppl=5.54, wps=2248, ups=1.74, wpb=1289.3, bsz=85.4, num_updates=14500, lr=0.00166091, gnorm=0.62, train_wall=56, gb_free=18.5, wall=9562
2024-01-31 08:11:28 | INFO | train_inner | epoch 005:   1656 / 3236 loss=2.467, nll_loss=2.467, ppl=5.53, wps=1780.8, ups=1.37, wpb=1295.6, bsz=87, num_updates=14600, lr=0.00165521, gnorm=0.631, train_wall=56, gb_free=18, wall=9635
2024-01-31 08:12:29 | INFO | train_inner | epoch 005:   1756 / 3236 loss=2.479, nll_loss=2.479, ppl=5.57, wps=2117.1, ups=1.62, wpb=1303.8, bsz=87.8, num_updates=14700, lr=0.00164957, gnorm=0.62, train_wall=56, gb_free=18.3, wall=9696
2024-01-31 08:13:26 | INFO | train_inner | epoch 005:   1856 / 3236 loss=2.403, nll_loss=2.403, ppl=5.29, wps=2295.3, ups=1.75, wpb=1312.3, bsz=91.5, num_updates=14800, lr=0.00164399, gnorm=0.628, train_wall=56, gb_free=17.4, wall=9753
2024-01-31 08:14:24 | INFO | train_inner | epoch 005:   1956 / 3236 loss=2.475, nll_loss=2.475, ppl=5.56, wps=2246.6, ups=1.73, wpb=1299, bsz=89.8, num_updates=14900, lr=0.00163846, gnorm=0.633, train_wall=57, gb_free=18.3, wall=9811
2024-01-31 08:15:21 | INFO | train_inner | epoch 005:   2056 / 3236 loss=2.441, nll_loss=2.441, ppl=5.43, wps=2285.1, ups=1.75, wpb=1303.4, bsz=87.3, num_updates=15000, lr=0.00163299, gnorm=0.619, train_wall=57, gb_free=18.3, wall=9868
2024-01-31 08:16:18 | INFO | train_inner | epoch 005:   2156 / 3236 loss=2.467, nll_loss=2.467, ppl=5.53, wps=2281, ups=1.75, wpb=1302, bsz=86.7, num_updates=15100, lr=0.00162758, gnorm=0.625, train_wall=57, gb_free=17.6, wall=9925
2024-01-31 08:17:16 | INFO | train_inner | epoch 005:   2256 / 3236 loss=2.422, nll_loss=2.422, ppl=5.36, wps=2259.1, ups=1.75, wpb=1293.2, bsz=86.9, num_updates=15200, lr=0.00162221, gnorm=0.615, train_wall=57, gb_free=18.4, wall=9983
2024-01-31 08:18:12 | INFO | train_inner | epoch 005:   2356 / 3236 loss=2.372, nll_loss=2.372, ppl=5.18, wps=2290.5, ups=1.76, wpb=1300, bsz=90.6, num_updates=15300, lr=0.0016169, gnorm=0.624, train_wall=56, gb_free=18.3, wall=10039
2024-01-31 08:19:11 | INFO | train_inner | epoch 005:   2456 / 3236 loss=2.376, nll_loss=2.376, ppl=5.19, wps=2262.1, ups=1.72, wpb=1317.4, bsz=91.9, num_updates=15400, lr=0.00161165, gnorm=0.61, train_wall=56, gb_free=17.9, wall=10098
2024-01-31 08:20:08 | INFO | train_inner | epoch 005:   2556 / 3236 loss=2.407, nll_loss=2.407, ppl=5.31, wps=2246.2, ups=1.73, wpb=1298.4, bsz=90.6, num_updates=15500, lr=0.00160644, gnorm=0.622, train_wall=57, gb_free=18, wall=10155
2024-01-31 08:21:06 | INFO | train_inner | epoch 005:   2656 / 3236 loss=2.411, nll_loss=2.411, ppl=5.32, wps=2241.6, ups=1.74, wpb=1291.4, bsz=89.4, num_updates=15600, lr=0.00160128, gnorm=0.603, train_wall=56, gb_free=18.2, wall=10213
2024-01-31 08:22:15 | INFO | train_inner | epoch 005:   2756 / 3236 loss=2.37, nll_loss=2.37, ppl=5.17, wps=1888.8, ups=1.44, wpb=1312.7, bsz=92.4, num_updates=15700, lr=0.00159617, gnorm=0.606, train_wall=56, gb_free=17.3, wall=10283
2024-01-31 08:23:17 | INFO | train_inner | epoch 005:   2856 / 3236 loss=2.39, nll_loss=2.39, ppl=5.24, wps=2105.5, ups=1.63, wpb=1290.3, bsz=84.8, num_updates=15800, lr=0.00159111, gnorm=0.624, train_wall=57, gb_free=18.3, wall=10344
2024-01-31 08:24:19 | INFO | train_inner | epoch 005:   2956 / 3236 loss=2.369, nll_loss=2.369, ppl=5.17, wps=2103.1, ups=1.61, wpb=1309.8, bsz=92.3, num_updates=15900, lr=0.0015861, gnorm=0.616, train_wall=56, gb_free=18.4, wall=10406
2024-01-31 08:25:18 | INFO | train_inner | epoch 005:   3056 / 3236 loss=2.394, nll_loss=2.394, ppl=5.26, wps=2191.2, ups=1.7, wpb=1289.7, bsz=83.1, num_updates=16000, lr=0.00158114, gnorm=0.617, train_wall=57, gb_free=18.3, wall=10465
2024-01-31 08:26:19 | INFO | train_inner | epoch 005:   3156 / 3236 loss=2.311, nll_loss=2.311, ppl=4.96, wps=2130.6, ups=1.63, wpb=1311, bsz=91, num_updates=16100, lr=0.00157622, gnorm=0.586, train_wall=56, gb_free=18.3, wall=10527
2024-01-31 08:27:06 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-01-31 08:27:06 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 08:28:39 | INFO | dev | epoch 005 | valid on 'dev' subset | loss 1.765 | nll_loss 1.765 | ppl 3.4 | wps 2492.5 | wpb 1146.2 | bsz 77.6 | num_updates 16180 | best_loss 1.765
2024-01-31 08:28:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 5 @ 16180 updates
2024-01-31 08:28:39 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint5.pt
2024-01-31 08:28:40 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint5.pt
2024-01-31 08:29:19 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint5.pt (epoch 5 @ 16180 updates, score 1.765) (writing took 40.01640456006862 seconds)
2024-01-31 08:29:19 | INFO | fairseq_cli.train | end of epoch 5 (average epoch stats below)
2024-01-31 08:29:19 | INFO | train | epoch 005 | loss 2.459 | nll_loss 2.459 | ppl 5.5 | wps 2070.5 | ups 1.59 | wpb 1302.4 | bsz 89.4 | num_updates 16180 | lr 0.00157232 | gnorm 0.627 | train_wall 1827 | gb_free 17.9 | wall 10706
2024-01-31 08:29:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 08:29:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-01-31 08:29:19 | INFO | fairseq.trainer | begin training epoch 6
2024-01-31 08:29:19 | INFO | fairseq_cli.train | Start iterating over samples
2024-01-31 08:29:33 | INFO | train_inner | epoch 006:     20 / 3236 loss=2.256, nll_loss=2.256, ppl=4.78, wps=670, ups=0.52, wpb=1297.4, bsz=89.4, num_updates=16200, lr=0.00157135, gnorm=0.587, train_wall=57, gb_free=18.2, wall=10720
2024-01-31 08:30:30 | INFO | train_inner | epoch 006:    120 / 3236 loss=2.202, nll_loss=2.202, ppl=4.6, wps=2297.2, ups=1.76, wpb=1305, bsz=87.2, num_updates=16300, lr=0.00156652, gnorm=0.61, train_wall=56, gb_free=17.3, wall=10777
2024-01-31 08:31:26 | INFO | train_inner | epoch 006:    220 / 3236 loss=2.187, nll_loss=2.187, ppl=4.55, wps=2336.4, ups=1.78, wpb=1312.1, bsz=94.6, num_updates=16400, lr=0.00156174, gnorm=0.598, train_wall=56, gb_free=17.6, wall=10833
2024-01-31 08:32:23 | INFO | train_inner | epoch 006:    320 / 3236 loss=2.233, nll_loss=2.233, ppl=4.7, wps=2275.9, ups=1.76, wpb=1290.6, bsz=90.6, num_updates=16500, lr=0.001557, gnorm=0.604, train_wall=56, gb_free=17.3, wall=10890
2024-01-31 08:33:20 | INFO | train_inner | epoch 006:    420 / 3236 loss=2.227, nll_loss=2.227, ppl=4.68, wps=2314.2, ups=1.76, wpb=1314.5, bsz=93.8, num_updates=16600, lr=0.0015523, gnorm=0.588, train_wall=56, gb_free=17.9, wall=10947
2024-01-31 08:34:17 | INFO | train_inner | epoch 006:    520 / 3236 loss=2.198, nll_loss=2.198, ppl=4.59, wps=2276.2, ups=1.75, wpb=1298, bsz=87.2, num_updates=16700, lr=0.00154765, gnorm=0.607, train_wall=57, gb_free=17.9, wall=11004
2024-01-31 08:35:14 | INFO | train_inner | epoch 006:    620 / 3236 loss=2.204, nll_loss=2.204, ppl=4.61, wps=2269.4, ups=1.75, wpb=1296.1, bsz=86.3, num_updates=16800, lr=0.00154303, gnorm=0.606, train_wall=57, gb_free=18.2, wall=11061
2024-01-31 08:36:11 | INFO | train_inner | epoch 006:    720 / 3236 loss=2.225, nll_loss=2.225, ppl=4.68, wps=2268.7, ups=1.76, wpb=1291.1, bsz=89.7, num_updates=16900, lr=0.00153846, gnorm=0.597, train_wall=56, gb_free=18.4, wall=11118
2024-01-31 08:37:08 | INFO | train_inner | epoch 006:    820 / 3236 loss=2.142, nll_loss=2.142, ppl=4.41, wps=2286.7, ups=1.75, wpb=1306.6, bsz=90.1, num_updates=17000, lr=0.00153393, gnorm=0.592, train_wall=57, gb_free=18.1, wall=11175
2024-01-31 08:38:04 | INFO | train_inner | epoch 006:    920 / 3236 loss=2.2, nll_loss=2.2, ppl=4.6, wps=2296, ups=1.76, wpb=1302.3, bsz=88.3, num_updates=17100, lr=0.00152944, gnorm=0.596, train_wall=56, gb_free=18, wall=11232
2024-01-31 08:39:02 | INFO | train_inner | epoch 006:   1020 / 3236 loss=2.201, nll_loss=2.201, ppl=4.6, wps=2304.9, ups=1.75, wpb=1315, bsz=93.3, num_updates=17200, lr=0.00152499, gnorm=0.607, train_wall=57, gb_free=17.9, wall=11289
2024-01-31 08:39:58 | INFO | train_inner | epoch 006:   1120 / 3236 loss=2.17, nll_loss=2.17, ppl=4.5, wps=2311.6, ups=1.76, wpb=1313.1, bsz=91.8, num_updates=17300, lr=0.00152057, gnorm=0.596, train_wall=56, gb_free=17.8, wall=11345
2024-01-31 08:40:55 | INFO | train_inner | epoch 006:   1220 / 3236 loss=2.197, nll_loss=2.197, ppl=4.59, wps=2294.2, ups=1.76, wpb=1302.8, bsz=94.3, num_updates=17400, lr=0.0015162, gnorm=0.593, train_wall=56, gb_free=17.6, wall=11402
2024-01-31 08:41:52 | INFO | train_inner | epoch 006:   1320 / 3236 loss=2.17, nll_loss=2.17, ppl=4.5, wps=2289.5, ups=1.76, wpb=1303.4, bsz=83.5, num_updates=17500, lr=0.00151186, gnorm=0.611, train_wall=56, gb_free=18.4, wall=11459
2024-01-31 08:42:49 | INFO | train_inner | epoch 006:   1420 / 3236 loss=2.204, nll_loss=2.204, ppl=4.61, wps=2274.3, ups=1.74, wpb=1305.2, bsz=88.2, num_updates=17600, lr=0.00150756, gnorm=0.592, train_wall=57, gb_free=17.6, wall=11516
2024-01-31 08:43:46 | INFO | train_inner | epoch 006:   1520 / 3236 loss=2.182, nll_loss=2.182, ppl=4.54, wps=2294.2, ups=1.76, wpb=1306.4, bsz=87.3, num_updates=17700, lr=0.00150329, gnorm=0.594, train_wall=56, gb_free=17.6, wall=11573
2024-01-31 08:44:43 | INFO | train_inner | epoch 006:   1620 / 3236 loss=2.206, nll_loss=2.206, ppl=4.61, wps=2277, ups=1.75, wpb=1298.1, bsz=85.7, num_updates=17800, lr=0.00149906, gnorm=0.611, train_wall=56, gb_free=17.5, wall=11630
2024-01-31 08:45:40 | INFO | train_inner | epoch 006:   1720 / 3236 loss=2.252, nll_loss=2.252, ppl=4.76, wps=2246.8, ups=1.75, wpb=1282.1, bsz=84.2, num_updates=17900, lr=0.00149487, gnorm=0.633, train_wall=57, gb_free=17.3, wall=11688
2024-01-31 08:46:39 | INFO | train_inner | epoch 006:   1820 / 3236 loss=2.17, nll_loss=2.17, ppl=4.5, wps=2236.2, ups=1.71, wpb=1304.5, bsz=88.6, num_updates=18000, lr=0.00149071, gnorm=0.595, train_wall=58, gb_free=18.6, wall=11746
2024-01-31 08:47:36 | INFO | train_inner | epoch 006:   1920 / 3236 loss=2.145, nll_loss=2.145, ppl=4.42, wps=2311.3, ups=1.76, wpb=1312.5, bsz=94.2, num_updates=18100, lr=0.00148659, gnorm=0.577, train_wall=56, gb_free=18.2, wall=11803
2024-01-31 08:48:33 | INFO | train_inner | epoch 006:   2020 / 3236 loss=2.151, nll_loss=2.151, ppl=4.44, wps=2288.6, ups=1.75, wpb=1307.5, bsz=89, num_updates=18200, lr=0.0014825, gnorm=0.598, train_wall=57, gb_free=18.4, wall=11860
2024-01-31 08:49:29 | INFO | train_inner | epoch 006:   2120 / 3236 loss=2.163, nll_loss=2.163, ppl=4.48, wps=2245.9, ups=1.76, wpb=1274.6, bsz=84.2, num_updates=18300, lr=0.00147844, gnorm=0.61, train_wall=56, gb_free=17.8, wall=11917
2024-01-31 08:50:26 | INFO | train_inner | epoch 006:   2220 / 3236 loss=2.131, nll_loss=2.131, ppl=4.38, wps=2326.6, ups=1.76, wpb=1319.6, bsz=90.9, num_updates=18400, lr=0.00147442, gnorm=0.575, train_wall=56, gb_free=18.2, wall=11973
2024-01-31 08:51:23 | INFO | train_inner | epoch 006:   2320 / 3236 loss=2.14, nll_loss=2.14, ppl=4.41, wps=2267.4, ups=1.75, wpb=1295.6, bsz=85.2, num_updates=18500, lr=0.00147043, gnorm=0.596, train_wall=57, gb_free=17.6, wall=12030
2024-01-31 08:52:20 | INFO | train_inner | epoch 006:   2420 / 3236 loss=2.113, nll_loss=2.113, ppl=4.33, wps=2318.3, ups=1.76, wpb=1317.1, bsz=95.3, num_updates=18600, lr=0.00146647, gnorm=0.585, train_wall=56, gb_free=17.7, wall=12087
2024-01-31 08:53:17 | INFO | train_inner | epoch 006:   2520 / 3236 loss=2.109, nll_loss=2.109, ppl=4.31, wps=2292.8, ups=1.76, wpb=1302.3, bsz=87.8, num_updates=18700, lr=0.00146254, gnorm=0.585, train_wall=56, gb_free=17.8, wall=12144
2024-01-31 08:54:14 | INFO | train_inner | epoch 006:   2620 / 3236 loss=2.128, nll_loss=2.128, ppl=4.37, wps=2291.9, ups=1.75, wpb=1306.7, bsz=94.3, num_updates=18800, lr=0.00145865, gnorm=0.593, train_wall=57, gb_free=17.8, wall=12201
2024-01-31 08:55:11 | INFO | train_inner | epoch 006:   2720 / 3236 loss=2.112, nll_loss=2.112, ppl=4.32, wps=2274.8, ups=1.75, wpb=1296.5, bsz=92, num_updates=18900, lr=0.00145479, gnorm=0.592, train_wall=57, gb_free=17.8, wall=12258
2024-01-31 08:56:08 | INFO | train_inner | epoch 006:   2820 / 3236 loss=2.119, nll_loss=2.119, ppl=4.34, wps=2284.3, ups=1.75, wpb=1306.7, bsz=89.6, num_updates=19000, lr=0.00145095, gnorm=0.596, train_wall=56, gb_free=17.6, wall=12315
2024-01-31 08:57:07 | INFO | train_inner | epoch 006:   2920 / 3236 loss=2.063, nll_loss=2.063, ppl=4.18, wps=2228.9, ups=1.7, wpb=1310, bsz=88.1, num_updates=19100, lr=0.00144715, gnorm=0.578, train_wall=56, gb_free=18.2, wall=12374
2024-01-31 08:58:04 | INFO | train_inner | epoch 006:   3020 / 3236 loss=2.121, nll_loss=2.121, ppl=4.35, wps=2269.7, ups=1.74, wpb=1307, bsz=91.4, num_updates=19200, lr=0.00144338, gnorm=0.578, train_wall=56, gb_free=18.1, wall=12432
2024-01-31 08:59:02 | INFO | train_inner | epoch 006:   3120 / 3236 loss=2.117, nll_loss=2.117, ppl=4.34, wps=2264.3, ups=1.75, wpb=1294.8, bsz=88.7, num_updates=19300, lr=0.00143963, gnorm=0.587, train_wall=57, gb_free=17.3, wall=12489
2024-01-31 08:59:58 | INFO | train_inner | epoch 006:   3220 / 3236 loss=2.085, nll_loss=2.085, ppl=4.24, wps=2270.3, ups=1.76, wpb=1286.9, bsz=88.7, num_updates=19400, lr=0.00143592, gnorm=0.594, train_wall=56, gb_free=18.2, wall=12545
2024-01-31 09:00:07 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-01-31 09:00:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 09:01:38 | INFO | dev | epoch 006 | valid on 'dev' subset | loss 1.637 | nll_loss 1.637 | ppl 3.11 | wps 2542.3 | wpb 1146.2 | bsz 77.6 | num_updates 19416 | best_loss 1.637
2024-01-31 09:01:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 6 @ 19416 updates
2024-01-31 09:01:38 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint6.pt
2024-01-31 09:01:39 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint6.pt
2024-01-31 09:01:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint6.pt (epoch 6 @ 19416 updates, score 1.637) (writing took 5.678905279957689 seconds)
2024-01-31 09:01:44 | INFO | fairseq_cli.train | end of epoch 6 (average epoch stats below)
2024-01-31 09:01:44 | INFO | train | epoch 006 | loss 2.164 | nll_loss 2.164 | ppl 4.48 | wps 2167 | ups 1.66 | wpb 1302.4 | bsz 89.4 | num_updates 19416 | lr 0.00143532 | gnorm 0.596 | train_wall 1826 | gb_free 17.2 | wall 12651
2024-01-31 09:01:44 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 09:01:44 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-01-31 09:01:44 | INFO | fairseq.trainer | begin training epoch 7
2024-01-31 09:01:44 | INFO | fairseq_cli.train | Start iterating over samples
2024-01-31 09:02:34 | INFO | train_inner | epoch 007:     84 / 3236 loss=2.055, nll_loss=2.055, ppl=4.16, wps=828.3, ups=0.64, wpb=1288.3, bsz=89.2, num_updates=19500, lr=0.00143223, gnorm=0.606, train_wall=56, gb_free=18.3, wall=12701
2024-01-31 09:03:30 | INFO | train_inner | epoch 007:    184 / 3236 loss=1.918, nll_loss=1.918, ppl=3.78, wps=2356, ups=1.77, wpb=1330.3, bsz=90.7, num_updates=19600, lr=0.00142857, gnorm=0.562, train_wall=56, gb_free=17.9, wall=12757
2024-01-31 09:04:27 | INFO | train_inner | epoch 007:    284 / 3236 loss=1.966, nll_loss=1.966, ppl=3.91, wps=2285.3, ups=1.75, wpb=1302.4, bsz=85.2, num_updates=19700, lr=0.00142494, gnorm=0.57, train_wall=56, gb_free=18.6, wall=12814
2024-01-31 09:05:24 | INFO | train_inner | epoch 007:    384 / 3236 loss=1.954, nll_loss=1.954, ppl=3.87, wps=2321.7, ups=1.75, wpb=1326.9, bsz=91.2, num_updates=19800, lr=0.00142134, gnorm=0.571, train_wall=57, gb_free=18.1, wall=12872
2024-01-31 09:06:21 | INFO | train_inner | epoch 007:    484 / 3236 loss=1.961, nll_loss=1.961, ppl=3.89, wps=2323.4, ups=1.76, wpb=1319.7, bsz=95.8, num_updates=19900, lr=0.00141776, gnorm=0.578, train_wall=56, gb_free=17.7, wall=12928
2024-01-31 09:07:18 | INFO | train_inner | epoch 007:    584 / 3236 loss=1.999, nll_loss=1.999, ppl=4, wps=2263.4, ups=1.76, wpb=1287.2, bsz=84.6, num_updates=20000, lr=0.00141421, gnorm=0.599, train_wall=56, gb_free=18.5, wall=12985
2024-01-31 09:08:15 | INFO | train_inner | epoch 007:    684 / 3236 loss=1.999, nll_loss=1.999, ppl=4, wps=2265.2, ups=1.75, wpb=1297.5, bsz=90.1, num_updates=20100, lr=0.00141069, gnorm=0.6, train_wall=57, gb_free=18.5, wall=13043
2024-01-31 09:09:12 | INFO | train_inner | epoch 007:    784 / 3236 loss=1.982, nll_loss=1.982, ppl=3.95, wps=2279.2, ups=1.76, wpb=1292.8, bsz=87, num_updates=20200, lr=0.0014072, gnorm=0.591, train_wall=56, gb_free=17.9, wall=13099
2024-01-31 09:10:09 | INFO | train_inner | epoch 007:    884 / 3236 loss=2.016, nll_loss=2.016, ppl=4.04, wps=2328.1, ups=1.76, wpb=1320.1, bsz=93.1, num_updates=20300, lr=0.00140372, gnorm=0.602, train_wall=56, gb_free=17.6, wall=13156
2024-01-31 09:11:06 | INFO | train_inner | epoch 007:    984 / 3236 loss=1.971, nll_loss=1.971, ppl=3.92, wps=2277.6, ups=1.75, wpb=1304.2, bsz=86, num_updates=20400, lr=0.00140028, gnorm=0.595, train_wall=57, gb_free=17.8, wall=13213
2024-01-31 09:12:03 | INFO | train_inner | epoch 007:   1084 / 3236 loss=1.967, nll_loss=1.967, ppl=3.91, wps=2269.9, ups=1.75, wpb=1295.5, bsz=89.5, num_updates=20500, lr=0.00139686, gnorm=0.587, train_wall=57, gb_free=18.5, wall=13270
2024-01-31 09:13:00 | INFO | train_inner | epoch 007:   1184 / 3236 loss=2.012, nll_loss=2.012, ppl=4.03, wps=2284.4, ups=1.75, wpb=1303.8, bsz=90.3, num_updates=20600, lr=0.00139347, gnorm=0.579, train_wall=57, gb_free=17.5, wall=13327
2024-01-31 09:13:57 | INFO | train_inner | epoch 007:   1284 / 3236 loss=1.984, nll_loss=1.984, ppl=3.96, wps=2301.6, ups=1.75, wpb=1311.7, bsz=94.7, num_updates=20700, lr=0.0013901, gnorm=0.6, train_wall=56, gb_free=18.2, wall=13384
2024-01-31 09:14:54 | INFO | train_inner | epoch 007:   1384 / 3236 loss=1.965, nll_loss=1.965, ppl=3.9, wps=2285, ups=1.76, wpb=1300.6, bsz=86.5, num_updates=20800, lr=0.00138675, gnorm=0.581, train_wall=56, gb_free=17.6, wall=13441
2024-01-31 09:15:51 | INFO | train_inner | epoch 007:   1484 / 3236 loss=1.981, nll_loss=1.981, ppl=3.95, wps=2242.9, ups=1.75, wpb=1280, bsz=86.9, num_updates=20900, lr=0.00138343, gnorm=0.585, train_wall=57, gb_free=18.4, wall=13498
2024-01-31 09:16:48 | INFO | train_inner | epoch 007:   1584 / 3236 loss=1.995, nll_loss=1.995, ppl=3.98, wps=2236.9, ups=1.75, wpb=1276.6, bsz=84.2, num_updates=21000, lr=0.00138013, gnorm=0.586, train_wall=57, gb_free=18.5, wall=13555
2024-01-31 09:17:45 | INFO | train_inner | epoch 007:   1684 / 3236 loss=1.972, nll_loss=1.972, ppl=3.92, wps=2305.8, ups=1.76, wpb=1312.1, bsz=93.4, num_updates=21100, lr=0.00137686, gnorm=0.567, train_wall=56, gb_free=17.7, wall=13612
2024-01-31 09:18:42 | INFO | train_inner | epoch 007:   1784 / 3236 loss=1.964, nll_loss=1.964, ppl=3.9, wps=2254.1, ups=1.75, wpb=1288.9, bsz=86, num_updates=21200, lr=0.00137361, gnorm=0.584, train_wall=57, gb_free=17.5, wall=13669
2024-01-31 09:19:43 | INFO | train_inner | epoch 007:   1884 / 3236 loss=1.975, nll_loss=1.975, ppl=3.93, wps=2123.7, ups=1.64, wpb=1294.6, bsz=83, num_updates=21300, lr=0.00137038, gnorm=0.596, train_wall=60, gb_free=17.9, wall=13730
2024-01-31 09:20:40 | INFO | train_inner | epoch 007:   1984 / 3236 loss=1.934, nll_loss=1.934, ppl=3.82, wps=2282.4, ups=1.76, wpb=1299.1, bsz=87.9, num_updates=21400, lr=0.00136717, gnorm=0.579, train_wall=56, gb_free=17.9, wall=13787
2024-01-31 09:21:37 | INFO | train_inner | epoch 007:   2084 / 3236 loss=1.985, nll_loss=1.985, ppl=3.96, wps=2300, ups=1.76, wpb=1305.3, bsz=92.2, num_updates=21500, lr=0.00136399, gnorm=0.593, train_wall=56, gb_free=17.9, wall=13844
2024-01-31 09:22:34 | INFO | train_inner | epoch 007:   2184 / 3236 loss=1.912, nll_loss=1.912, ppl=3.76, wps=2304.6, ups=1.75, wpb=1319.8, bsz=94.2, num_updates=21600, lr=0.00136083, gnorm=0.555, train_wall=57, gb_free=18, wall=13901
2024-01-31 09:23:31 | INFO | train_inner | epoch 007:   2284 / 3236 loss=1.968, nll_loss=1.968, ppl=3.91, wps=2251, ups=1.75, wpb=1284.3, bsz=85.3, num_updates=21700, lr=0.00135769, gnorm=0.589, train_wall=57, gb_free=17.8, wall=13958
2024-01-31 09:24:29 | INFO | train_inner | epoch 007:   2384 / 3236 loss=1.943, nll_loss=1.943, ppl=3.85, wps=2289, ups=1.74, wpb=1315.7, bsz=89.8, num_updates=21800, lr=0.00135457, gnorm=0.569, train_wall=57, gb_free=17.5, wall=14016
2024-01-31 09:25:28 | INFO | train_inner | epoch 007:   2484 / 3236 loss=1.947, nll_loss=1.947, ppl=3.86, wps=2198.5, ups=1.68, wpb=1305, bsz=96.3, num_updates=21900, lr=0.00135147, gnorm=0.581, train_wall=56, gb_free=17.9, wall=14075
2024-01-31 09:26:25 | INFO | train_inner | epoch 007:   2584 / 3236 loss=1.975, nll_loss=1.975, ppl=3.93, wps=2266, ups=1.77, wpb=1283.2, bsz=86.9, num_updates=22000, lr=0.0013484, gnorm=0.599, train_wall=56, gb_free=18.6, wall=14132
2024-01-31 09:27:23 | INFO | train_inner | epoch 007:   2684 / 3236 loss=1.985, nll_loss=1.985, ppl=3.96, wps=2230.3, ups=1.72, wpb=1299.4, bsz=94.1, num_updates=22100, lr=0.00134535, gnorm=0.589, train_wall=56, gb_free=17.9, wall=14190
2024-01-31 09:28:21 | INFO | train_inner | epoch 007:   2784 / 3236 loss=1.924, nll_loss=1.924, ppl=3.8, wps=2283.2, ups=1.73, wpb=1321.3, bsz=89.9, num_updates=22200, lr=0.00134231, gnorm=0.561, train_wall=57, gb_free=18.2, wall=14248
2024-01-31 09:29:18 | INFO | train_inner | epoch 007:   2884 / 3236 loss=1.957, nll_loss=1.957, ppl=3.88, wps=2226.1, ups=1.74, wpb=1277, bsz=87.7, num_updates=22300, lr=0.0013393, gnorm=0.595, train_wall=57, gb_free=17.8, wall=14305
2024-01-31 09:30:23 | INFO | train_inner | epoch 007:   2984 / 3236 loss=1.905, nll_loss=1.905, ppl=3.74, wps=2048.8, ups=1.55, wpb=1319.2, bsz=94.8, num_updates=22400, lr=0.00133631, gnorm=0.566, train_wall=56, gb_free=17.6, wall=14370
2024-01-31 09:31:20 | INFO | train_inner | epoch 007:   3084 / 3236 loss=1.941, nll_loss=1.941, ppl=3.84, wps=2281.5, ups=1.75, wpb=1303.3, bsz=87.4, num_updates=22500, lr=0.00133333, gnorm=0.584, train_wall=56, gb_free=17.9, wall=14427
2024-01-31 09:32:19 | INFO | train_inner | epoch 007:   3184 / 3236 loss=1.922, nll_loss=1.922, ppl=3.79, wps=2214.4, ups=1.71, wpb=1298.4, bsz=85.2, num_updates=22600, lr=0.00133038, gnorm=0.582, train_wall=57, gb_free=18.6, wall=14486
2024-01-31 09:32:48 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-01-31 09:32:48 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 09:34:22 | INFO | dev | epoch 007 | valid on 'dev' subset | loss 1.504 | nll_loss 1.504 | ppl 2.84 | wps 2453.9 | wpb 1146.2 | bsz 77.6 | num_updates 22652 | best_loss 1.504
2024-01-31 09:34:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 7 @ 22652 updates
2024-01-31 09:34:22 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint7.pt
2024-01-31 09:34:24 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint7.pt
2024-01-31 09:34:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint7.pt (epoch 7 @ 22652 updates, score 1.504) (writing took 5.946191563038155 seconds)
2024-01-31 09:34:28 | INFO | fairseq_cli.train | end of epoch 7 (average epoch stats below)
2024-01-31 09:34:28 | INFO | train | epoch 007 | loss 1.965 | nll_loss 1.965 | ppl 3.9 | wps 2145.1 | ups 1.65 | wpb 1302.4 | bsz 89.4 | num_updates 22652 | lr 0.00132885 | gnorm 0.584 | train_wall 1831 | gb_free 17.2 | wall 14616
2024-01-31 09:34:28 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 09:34:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-01-31 09:34:29 | INFO | fairseq.trainer | begin training epoch 8
2024-01-31 09:34:29 | INFO | fairseq_cli.train | Start iterating over samples
2024-01-31 09:35:00 | INFO | train_inner | epoch 008:     48 / 3236 loss=1.866, nll_loss=1.866, ppl=3.65, wps=809.9, ups=0.62, wpb=1304.2, bsz=91.2, num_updates=22700, lr=0.00132745, gnorm=0.576, train_wall=57, gb_free=18.6, wall=14647
2024-01-31 09:35:56 | INFO | train_inner | epoch 008:    148 / 3236 loss=1.786, nll_loss=1.786, ppl=3.45, wps=2287.2, ups=1.76, wpb=1301.7, bsz=85.8, num_updates=22800, lr=0.00132453, gnorm=0.574, train_wall=56, gb_free=17.9, wall=14704
2024-01-31 09:36:53 | INFO | train_inner | epoch 008:    248 / 3236 loss=1.833, nll_loss=1.833, ppl=3.56, wps=2281.4, ups=1.76, wpb=1298.9, bsz=94.6, num_updates=22900, lr=0.00132164, gnorm=0.579, train_wall=56, gb_free=18.4, wall=14760
2024-01-31 09:37:50 | INFO | train_inner | epoch 008:    348 / 3236 loss=1.794, nll_loss=1.794, ppl=3.47, wps=2290.9, ups=1.76, wpb=1304.7, bsz=91.4, num_updates=23000, lr=0.00131876, gnorm=0.566, train_wall=56, gb_free=17.7, wall=14817
2024-01-31 09:38:47 | INFO | train_inner | epoch 008:    448 / 3236 loss=1.815, nll_loss=1.815, ppl=3.52, wps=2290.3, ups=1.76, wpb=1303.1, bsz=87.9, num_updates=23100, lr=0.0013159, gnorm=0.579, train_wall=56, gb_free=17.9, wall=14874
2024-01-31 09:39:44 | INFO | train_inner | epoch 008:    548 / 3236 loss=1.819, nll_loss=1.819, ppl=3.53, wps=2281.9, ups=1.76, wpb=1295.8, bsz=87.8, num_updates=23200, lr=0.00131306, gnorm=0.576, train_wall=56, gb_free=17.6, wall=14931
2024-01-31 09:40:41 | INFO | train_inner | epoch 008:    648 / 3236 loss=1.831, nll_loss=1.831, ppl=3.56, wps=2282.9, ups=1.76, wpb=1298.5, bsz=87.6, num_updates=23300, lr=0.00131024, gnorm=0.577, train_wall=56, gb_free=18, wall=14988
2024-01-31 09:41:38 | INFO | train_inner | epoch 008:    748 / 3236 loss=1.837, nll_loss=1.837, ppl=3.57, wps=2299.5, ups=1.76, wpb=1306.3, bsz=89.6, num_updates=23400, lr=0.00130744, gnorm=0.582, train_wall=56, gb_free=17.9, wall=15045
2024-01-31 09:42:35 | INFO | train_inner | epoch 008:    848 / 3236 loss=1.816, nll_loss=1.816, ppl=3.52, wps=2277, ups=1.76, wpb=1296.9, bsz=89, num_updates=23500, lr=0.00130466, gnorm=0.573, train_wall=56, gb_free=18, wall=15102
2024-01-31 09:43:31 | INFO | train_inner | epoch 008:    948 / 3236 loss=1.811, nll_loss=1.811, ppl=3.51, wps=2269.6, ups=1.77, wpb=1285.4, bsz=89.1, num_updates=23600, lr=0.00130189, gnorm=0.586, train_wall=56, gb_free=17.9, wall=15158
2024-01-31 09:44:29 | INFO | train_inner | epoch 008:   1048 / 3236 loss=1.818, nll_loss=1.818, ppl=3.53, wps=2274.1, ups=1.74, wpb=1304.6, bsz=88.9, num_updates=23700, lr=0.00129914, gnorm=0.589, train_wall=57, gb_free=17.4, wall=15216
2024-01-31 09:45:25 | INFO | train_inner | epoch 008:   1148 / 3236 loss=1.861, nll_loss=1.861, ppl=3.63, wps=2291.8, ups=1.77, wpb=1297.8, bsz=87.5, num_updates=23800, lr=0.00129641, gnorm=0.587, train_wall=56, gb_free=18.4, wall=15272
2024-01-31 09:46:22 | INFO | train_inner | epoch 008:   1248 / 3236 loss=1.796, nll_loss=1.796, ppl=3.47, wps=2326.8, ups=1.76, wpb=1323.3, bsz=92.2, num_updates=23900, lr=0.00129369, gnorm=0.554, train_wall=56, gb_free=18.1, wall=15329
2024-01-31 09:47:19 | INFO | train_inner | epoch 008:   1348 / 3236 loss=1.817, nll_loss=1.817, ppl=3.52, wps=2259.8, ups=1.76, wpb=1286, bsz=85.1, num_updates=24000, lr=0.00129099, gnorm=0.58, train_wall=56, gb_free=18.2, wall=15386
2024-01-31 09:48:16 | INFO | train_inner | epoch 008:   1448 / 3236 loss=1.833, nll_loss=1.833, ppl=3.56, wps=2287.8, ups=1.76, wpb=1300.2, bsz=89.1, num_updates=24100, lr=0.00128831, gnorm=0.576, train_wall=56, gb_free=18.6, wall=15443
2024-01-31 09:49:21 | INFO | train_inner | epoch 008:   1548 / 3236 loss=1.865, nll_loss=1.865, ppl=3.64, wps=1980.6, ups=1.54, wpb=1283.5, bsz=85.2, num_updates=24200, lr=0.00128565, gnorm=0.587, train_wall=64, gb_free=18, wall=15508
2024-01-31 09:50:18 | INFO | train_inner | epoch 008:   1648 / 3236 loss=1.83, nll_loss=1.83, ppl=3.56, wps=2274.6, ups=1.76, wpb=1291.8, bsz=83.8, num_updates=24300, lr=0.001283, gnorm=0.579, train_wall=56, gb_free=18.2, wall=15565
2024-01-31 09:51:14 | INFO | train_inner | epoch 008:   1748 / 3236 loss=1.804, nll_loss=1.804, ppl=3.49, wps=2312.7, ups=1.76, wpb=1312.7, bsz=91.4, num_updates=24400, lr=0.00128037, gnorm=0.572, train_wall=56, gb_free=17.9, wall=15621
2024-01-31 09:52:13 | INFO | train_inner | epoch 008:   1848 / 3236 loss=1.82, nll_loss=1.82, ppl=3.53, wps=2215.4, ups=1.7, wpb=1306.5, bsz=89.9, num_updates=24500, lr=0.00127775, gnorm=0.579, train_wall=56, gb_free=18.7, wall=15680
2024-01-31 09:53:18 | INFO | train_inner | epoch 008:   1948 / 3236 loss=1.802, nll_loss=1.802, ppl=3.49, wps=2023, ups=1.54, wpb=1316.2, bsz=90.2, num_updates=24600, lr=0.00127515, gnorm=0.564, train_wall=56, gb_free=17.9, wall=15745
2024-01-31 09:54:19 | INFO | train_inner | epoch 008:   2048 / 3236 loss=1.805, nll_loss=1.805, ppl=3.49, wps=2160.1, ups=1.66, wpb=1303, bsz=89, num_updates=24700, lr=0.00127257, gnorm=0.572, train_wall=56, gb_free=18.4, wall=15806
2024-01-31 09:55:17 | INFO | train_inner | epoch 008:   2148 / 3236 loss=1.755, nll_loss=1.755, ppl=3.37, wps=2298.7, ups=1.73, wpb=1330.9, bsz=94.9, num_updates=24800, lr=0.00127, gnorm=0.549, train_wall=56, gb_free=18.6, wall=15864
2024-01-31 09:56:21 | INFO | train_inner | epoch 008:   2248 / 3236 loss=1.798, nll_loss=1.798, ppl=3.48, wps=2042.3, ups=1.56, wpb=1306.7, bsz=93.5, num_updates=24900, lr=0.00126745, gnorm=0.574, train_wall=56, gb_free=18.4, wall=15928
2024-01-31 09:57:18 | INFO | train_inner | epoch 008:   2348 / 3236 loss=1.804, nll_loss=1.804, ppl=3.49, wps=2257.4, ups=1.74, wpb=1294.5, bsz=90.9, num_updates=25000, lr=0.00126491, gnorm=0.587, train_wall=56, gb_free=17.5, wall=15985
2024-01-31 09:58:19 | INFO | train_inner | epoch 008:   2448 / 3236 loss=1.799, nll_loss=1.799, ppl=3.48, wps=2164.6, ups=1.65, wpb=1313, bsz=92.6, num_updates=25100, lr=0.00126239, gnorm=0.565, train_wall=56, gb_free=18.3, wall=16046
2024-01-31 09:59:20 | INFO | train_inner | epoch 008:   2548 / 3236 loss=1.859, nll_loss=1.859, ppl=3.63, wps=2104.1, ups=1.63, wpb=1290, bsz=86.7, num_updates=25200, lr=0.00125988, gnorm=0.585, train_wall=56, gb_free=17.8, wall=16107
2024-01-31 10:00:18 | INFO | train_inner | epoch 008:   2648 / 3236 loss=1.826, nll_loss=1.826, ppl=3.55, wps=2218.5, ups=1.71, wpb=1295.7, bsz=88.5, num_updates=25300, lr=0.00125739, gnorm=0.569, train_wall=56, gb_free=18, wall=16165
2024-01-31 10:01:16 | INFO | train_inner | epoch 008:   2748 / 3236 loss=1.789, nll_loss=1.789, ppl=3.46, wps=2226.3, ups=1.72, wpb=1295.6, bsz=88.6, num_updates=25400, lr=0.00125491, gnorm=0.574, train_wall=56, gb_free=18.4, wall=16223
2024-01-31 10:02:17 | INFO | train_inner | epoch 008:   2848 / 3236 loss=1.805, nll_loss=1.805, ppl=3.49, wps=2168.3, ups=1.66, wpb=1309.7, bsz=89, num_updates=25500, lr=0.00125245, gnorm=0.582, train_wall=56, gb_free=18.2, wall=16284
2024-01-31 10:03:16 | INFO | train_inner | epoch 008:   2948 / 3236 loss=1.792, nll_loss=1.792, ppl=3.46, wps=2187, ups=1.68, wpb=1300.4, bsz=87.4, num_updates=25600, lr=0.00125, gnorm=0.576, train_wall=56, gb_free=18.3, wall=16343
2024-01-31 10:04:20 | INFO | train_inner | epoch 008:   3048 / 3236 loss=1.791, nll_loss=1.791, ppl=3.46, wps=2056, ups=1.58, wpb=1305.4, bsz=89.2, num_updates=25700, lr=0.00124757, gnorm=0.569, train_wall=56, gb_free=17.9, wall=16407
2024-01-31 10:05:17 | INFO | train_inner | epoch 008:   3148 / 3236 loss=1.811, nll_loss=1.811, ppl=3.51, wps=2303.6, ups=1.75, wpb=1315.8, bsz=95.3, num_updates=25800, lr=0.00124515, gnorm=0.59, train_wall=56, gb_free=18, wall=16464
2024-01-31 10:06:10 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-01-31 10:06:10 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 10:07:39 | INFO | dev | epoch 008 | valid on 'dev' subset | loss 1.431 | nll_loss 1.431 | ppl 2.7 | wps 2611.2 | wpb 1146.2 | bsz 77.6 | num_updates 25888 | best_loss 1.431
2024-01-31 10:07:39 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 8 @ 25888 updates
2024-01-31 10:07:39 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint8.pt
2024-01-31 10:07:40 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint8.pt
2024-01-31 10:07:44 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint8.pt (epoch 8 @ 25888 updates, score 1.431) (writing took 5.842350451042876 seconds)
2024-01-31 10:07:45 | INFO | fairseq_cli.train | end of epoch 8 (average epoch stats below)
2024-01-31 10:07:45 | INFO | train | epoch 008 | loss 1.812 | nll_loss 1.812 | ppl 3.51 | wps 2111.4 | ups 1.62 | wpb 1302.4 | bsz 89.4 | num_updates 25888 | lr 0.00124303 | gnorm 0.576 | train_wall 1830 | gb_free 18.6 | wall 16612
2024-01-31 10:07:45 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 10:07:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-01-31 10:07:45 | INFO | fairseq.trainer | begin training epoch 9
2024-01-31 10:07:45 | INFO | fairseq_cli.train | Start iterating over samples
2024-01-31 10:07:52 | INFO | train_inner | epoch 009:     12 / 3236 loss=1.771, nll_loss=1.771, ppl=3.41, wps=842.6, ups=0.64, wpb=1307.6, bsz=90.3, num_updates=25900, lr=0.00124274, gnorm=0.592, train_wall=56, gb_free=17.4, wall=16619
2024-01-31 10:08:49 | INFO | train_inner | epoch 009:    112 / 3236 loss=1.665, nll_loss=1.665, ppl=3.17, wps=2278.7, ups=1.76, wpb=1292.5, bsz=86.8, num_updates=26000, lr=0.00124035, gnorm=0.571, train_wall=56, gb_free=17.3, wall=16676
2024-01-31 10:09:45 | INFO | train_inner | epoch 009:    212 / 3236 loss=1.709, nll_loss=1.709, ppl=3.27, wps=2310.5, ups=1.77, wpb=1303.9, bsz=93.3, num_updates=26100, lr=0.00123797, gnorm=0.569, train_wall=56, gb_free=17.7, wall=16732
2024-01-31 10:10:42 | INFO | train_inner | epoch 009:    312 / 3236 loss=1.71, nll_loss=1.71, ppl=3.27, wps=2314.3, ups=1.76, wpb=1315.6, bsz=90.1, num_updates=26200, lr=0.0012356, gnorm=0.58, train_wall=56, gb_free=18.3, wall=16789
2024-01-31 10:11:38 | INFO | train_inner | epoch 009:    412 / 3236 loss=1.726, nll_loss=1.726, ppl=3.31, wps=2278.2, ups=1.78, wpb=1283.2, bsz=85.8, num_updates=26300, lr=0.00123325, gnorm=0.596, train_wall=56, gb_free=18.1, wall=16845
2024-01-31 10:12:35 | INFO | train_inner | epoch 009:    512 / 3236 loss=1.693, nll_loss=1.693, ppl=3.23, wps=2291.5, ups=1.77, wpb=1293.3, bsz=86.4, num_updates=26400, lr=0.00123091, gnorm=0.568, train_wall=56, gb_free=17.7, wall=16902
2024-01-31 10:13:31 | INFO | train_inner | epoch 009:    612 / 3236 loss=1.68, nll_loss=1.68, ppl=3.2, wps=2301.9, ups=1.77, wpb=1301.2, bsz=88.4, num_updates=26500, lr=0.00122859, gnorm=0.563, train_wall=56, gb_free=18, wall=16958
2024-01-31 10:14:28 | INFO | train_inner | epoch 009:    712 / 3236 loss=1.707, nll_loss=1.707, ppl=3.27, wps=2283.2, ups=1.75, wpb=1301.1, bsz=91.8, num_updates=26600, lr=0.00122628, gnorm=0.571, train_wall=56, gb_free=18, wall=17015
2024-01-31 10:15:25 | INFO | train_inner | epoch 009:    812 / 3236 loss=1.692, nll_loss=1.692, ppl=3.23, wps=2304.3, ups=1.77, wpb=1301.9, bsz=88.4, num_updates=26700, lr=0.00122398, gnorm=0.579, train_wall=56, gb_free=17.7, wall=17072
2024-01-31 10:16:22 | INFO | train_inner | epoch 009:    912 / 3236 loss=1.699, nll_loss=1.699, ppl=3.25, wps=2239.3, ups=1.76, wpb=1273.9, bsz=82.9, num_updates=26800, lr=0.00122169, gnorm=0.569, train_wall=56, gb_free=17.9, wall=17129
2024-01-31 10:17:21 | INFO | train_inner | epoch 009:   1012 / 3236 loss=1.709, nll_loss=1.709, ppl=3.27, wps=2231.4, ups=1.7, wpb=1313.5, bsz=92, num_updates=26900, lr=0.00121942, gnorm=0.579, train_wall=58, gb_free=17.1, wall=17188
2024-01-31 10:18:17 | INFO | train_inner | epoch 009:   1112 / 3236 loss=1.697, nll_loss=1.697, ppl=3.24, wps=2265.5, ups=1.77, wpb=1277.3, bsz=89, num_updates=27000, lr=0.00121716, gnorm=0.59, train_wall=56, gb_free=18.6, wall=17244
2024-01-31 10:19:14 | INFO | train_inner | epoch 009:   1212 / 3236 loss=1.69, nll_loss=1.69, ppl=3.23, wps=2297.3, ups=1.75, wpb=1309.9, bsz=88.5, num_updates=27100, lr=0.00121491, gnorm=0.571, train_wall=57, gb_free=18.5, wall=17301
2024-01-31 10:20:11 | INFO | train_inner | epoch 009:   1312 / 3236 loss=1.737, nll_loss=1.737, ppl=3.33, wps=2305, ups=1.76, wpb=1311, bsz=87.1, num_updates=27200, lr=0.00121268, gnorm=0.58, train_wall=56, gb_free=17.6, wall=17358
2024-01-31 10:21:08 | INFO | train_inner | epoch 009:   1412 / 3236 loss=1.736, nll_loss=1.736, ppl=3.33, wps=2298, ups=1.77, wpb=1299.9, bsz=86.9, num_updates=27300, lr=0.00121046, gnorm=0.581, train_wall=56, gb_free=18, wall=17415
2024-01-31 10:22:04 | INFO | train_inner | epoch 009:   1512 / 3236 loss=1.692, nll_loss=1.692, ppl=3.23, wps=2296.9, ups=1.76, wpb=1306.2, bsz=91, num_updates=27400, lr=0.00120824, gnorm=0.563, train_wall=56, gb_free=18.4, wall=17471
2024-01-31 10:23:01 | INFO | train_inner | epoch 009:   1612 / 3236 loss=1.722, nll_loss=1.722, ppl=3.3, wps=2317.2, ups=1.77, wpb=1310.8, bsz=92.5, num_updates=27500, lr=0.00120605, gnorm=0.561, train_wall=56, gb_free=17.7, wall=17528
2024-01-31 10:23:58 | INFO | train_inner | epoch 009:   1712 / 3236 loss=1.722, nll_loss=1.722, ppl=3.3, wps=2264.8, ups=1.75, wpb=1291, bsz=88.9, num_updates=27600, lr=0.00120386, gnorm=0.584, train_wall=57, gb_free=18.8, wall=17585
2024-01-31 10:24:56 | INFO | train_inner | epoch 009:   1812 / 3236 loss=1.739, nll_loss=1.739, ppl=3.34, wps=2245.1, ups=1.73, wpb=1300, bsz=91.9, num_updates=27700, lr=0.00120168, gnorm=0.574, train_wall=56, gb_free=18, wall=17643
2024-01-31 10:25:55 | INFO | train_inner | epoch 009:   1912 / 3236 loss=1.678, nll_loss=1.678, ppl=3.2, wps=2244.4, ups=1.71, wpb=1315.5, bsz=90.2, num_updates=27800, lr=0.00119952, gnorm=0.568, train_wall=56, gb_free=17.6, wall=17702
2024-01-31 10:26:56 | INFO | train_inner | epoch 009:   2012 / 3236 loss=1.717, nll_loss=1.717, ppl=3.29, wps=2117.4, ups=1.63, wpb=1301.8, bsz=90.5, num_updates=27900, lr=0.00119737, gnorm=0.568, train_wall=56, gb_free=18.6, wall=17763
2024-01-31 10:27:58 | INFO | train_inner | epoch 009:   2112 / 3236 loss=1.7, nll_loss=1.7, ppl=3.25, wps=2095.3, ups=1.62, wpb=1294, bsz=93.8, num_updates=28000, lr=0.00119523, gnorm=0.574, train_wall=56, gb_free=18.2, wall=17825
2024-01-31 10:29:00 | INFO | train_inner | epoch 009:   2212 / 3236 loss=1.714, nll_loss=1.714, ppl=3.28, wps=2107.4, ups=1.6, wpb=1321.1, bsz=88.8, num_updates=28100, lr=0.0011931, gnorm=0.574, train_wall=56, gb_free=17.9, wall=17888
2024-01-31 10:30:01 | INFO | train_inner | epoch 009:   2312 / 3236 loss=1.715, nll_loss=1.715, ppl=3.28, wps=2106.3, ups=1.64, wpb=1282.2, bsz=87.2, num_updates=28200, lr=0.00119098, gnorm=0.576, train_wall=56, gb_free=18.4, wall=17948
2024-01-31 10:31:07 | INFO | train_inner | epoch 009:   2412 / 3236 loss=1.682, nll_loss=1.682, ppl=3.21, wps=2004, ups=1.51, wpb=1325.9, bsz=94.5, num_updates=28300, lr=0.00118888, gnorm=0.565, train_wall=56, gb_free=17.2, wall=18015
2024-01-31 10:32:07 | INFO | train_inner | epoch 009:   2512 / 3236 loss=1.72, nll_loss=1.72, ppl=3.29, wps=2202.8, ups=1.68, wpb=1314.1, bsz=90.2, num_updates=28400, lr=0.00118678, gnorm=0.575, train_wall=56, gb_free=18.3, wall=18074
2024-01-31 10:33:08 | INFO | train_inner | epoch 009:   2612 / 3236 loss=1.649, nll_loss=1.649, ppl=3.14, wps=2182, ups=1.65, wpb=1325.4, bsz=87.9, num_updates=28500, lr=0.0011847, gnorm=0.552, train_wall=56, gb_free=18.4, wall=18135
2024-01-31 10:34:08 | INFO | train_inner | epoch 009:   2712 / 3236 loss=1.678, nll_loss=1.678, ppl=3.2, wps=2158.3, ups=1.66, wpb=1303.1, bsz=89.8, num_updates=28600, lr=0.00118262, gnorm=0.569, train_wall=56, gb_free=18.2, wall=18195
2024-01-31 10:35:05 | INFO | train_inner | epoch 009:   2812 / 3236 loss=1.717, nll_loss=1.717, ppl=3.29, wps=2268.2, ups=1.76, wpb=1285.7, bsz=84.8, num_updates=28700, lr=0.00118056, gnorm=0.604, train_wall=56, gb_free=18.3, wall=18252
2024-01-31 10:36:02 | INFO | train_inner | epoch 009:   2912 / 3236 loss=1.711, nll_loss=1.711, ppl=3.27, wps=2305.9, ups=1.76, wpb=1310.3, bsz=92.8, num_updates=28800, lr=0.00117851, gnorm=0.561, train_wall=56, gb_free=18, wall=18309
2024-01-31 10:36:59 | INFO | train_inner | epoch 009:   3012 / 3236 loss=1.678, nll_loss=1.678, ppl=3.2, wps=2272.6, ups=1.75, wpb=1296.5, bsz=89.5, num_updates=28900, lr=0.00117647, gnorm=0.58, train_wall=57, gb_free=18.3, wall=18366
2024-01-31 10:37:56 | INFO | train_inner | epoch 009:   3112 / 3236 loss=1.678, nll_loss=1.678, ppl=3.2, wps=2285.7, ups=1.76, wpb=1298.3, bsz=84.8, num_updates=29000, lr=0.00117444, gnorm=0.558, train_wall=56, gb_free=18.7, wall=18423
2024-01-31 10:38:52 | INFO | train_inner | epoch 009:   3212 / 3236 loss=1.676, nll_loss=1.676, ppl=3.19, wps=2307.7, ups=1.76, wpb=1309.2, bsz=93.9, num_updates=29100, lr=0.00117242, gnorm=0.562, train_wall=56, gb_free=17.9, wall=18479
2024-01-31 10:39:06 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-01-31 10:39:06 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 10:40:34 | INFO | dev | epoch 009 | valid on 'dev' subset | loss 1.355 | nll_loss 1.355 | ppl 2.56 | wps 2646.8 | wpb 1146.2 | bsz 77.6 | num_updates 29124 | best_loss 1.355
2024-01-31 10:40:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 9 @ 29124 updates
2024-01-31 10:40:34 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint9.pt
2024-01-31 10:40:35 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint9.pt
2024-01-31 10:40:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint9.pt (epoch 9 @ 29124 updates, score 1.355) (writing took 5.590773177915253 seconds)
2024-01-31 10:40:39 | INFO | fairseq_cli.train | end of epoch 9 (average epoch stats below)
2024-01-31 10:40:39 | INFO | train | epoch 009 | loss 1.701 | nll_loss 1.701 | ppl 3.25 | wps 2134.2 | ups 1.64 | wpb 1302.4 | bsz 89.4 | num_updates 29124 | lr 0.00117194 | gnorm 0.573 | train_wall 1821 | gb_free 17.4 | wall 18586
2024-01-31 10:40:39 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 10:40:39 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-01-31 10:40:39 | INFO | fairseq.trainer | begin training epoch 10
2024-01-31 10:40:39 | INFO | fairseq_cli.train | Start iterating over samples
2024-01-31 10:41:23 | INFO | train_inner | epoch 010:     76 / 3236 loss=1.578, nll_loss=1.578, ppl=2.99, wps=863.4, ups=0.66, wpb=1301.9, bsz=86.9, num_updates=29200, lr=0.00117041, gnorm=0.575, train_wall=56, gb_free=17.5, wall=18630
2024-01-31 10:42:20 | INFO | train_inner | epoch 010:    176 / 3236 loss=1.591, nll_loss=1.591, ppl=3.01, wps=2320.1, ups=1.77, wpb=1313.6, bsz=93, num_updates=29300, lr=0.00116841, gnorm=0.572, train_wall=56, gb_free=18.5, wall=18687
2024-01-31 10:43:16 | INFO | train_inner | epoch 010:    276 / 3236 loss=1.606, nll_loss=1.606, ppl=3.04, wps=2274.6, ups=1.76, wpb=1289.6, bsz=91.2, num_updates=29400, lr=0.00116642, gnorm=0.588, train_wall=56, gb_free=18.5, wall=18744
2024-01-31 10:44:13 | INFO | train_inner | epoch 010:    376 / 3236 loss=1.563, nll_loss=1.563, ppl=2.95, wps=2298.6, ups=1.76, wpb=1307.7, bsz=87.8, num_updates=29500, lr=0.00116445, gnorm=0.574, train_wall=56, gb_free=18.2, wall=18800
2024-01-31 10:45:10 | INFO | train_inner | epoch 010:    476 / 3236 loss=1.596, nll_loss=1.596, ppl=3.02, wps=2334.4, ups=1.77, wpb=1317.7, bsz=92.1, num_updates=29600, lr=0.00116248, gnorm=0.558, train_wall=56, gb_free=17.3, wall=18857
2024-01-31 10:46:06 | INFO | train_inner | epoch 010:    576 / 3236 loss=1.597, nll_loss=1.597, ppl=3.03, wps=2300.1, ups=1.77, wpb=1298.7, bsz=93.9, num_updates=29700, lr=0.00116052, gnorm=0.564, train_wall=56, gb_free=17.7, wall=18913
2024-01-31 10:47:03 | INFO | train_inner | epoch 010:    676 / 3236 loss=1.596, nll_loss=1.596, ppl=3.02, wps=2306.5, ups=1.77, wpb=1301.3, bsz=89.8, num_updates=29800, lr=0.00115857, gnorm=0.578, train_wall=56, gb_free=17.4, wall=18970
2024-01-31 10:47:59 | INFO | train_inner | epoch 010:    776 / 3236 loss=1.593, nll_loss=1.593, ppl=3.02, wps=2288.4, ups=1.76, wpb=1297.7, bsz=89.2, num_updates=29900, lr=0.00115663, gnorm=0.573, train_wall=56, gb_free=18.3, wall=19026
2024-01-31 10:48:56 | INFO | train_inner | epoch 010:    876 / 3236 loss=1.587, nll_loss=1.587, ppl=3.01, wps=2293.3, ups=1.75, wpb=1309.7, bsz=87.6, num_updates=30000, lr=0.0011547, gnorm=0.577, train_wall=57, gb_free=17.8, wall=19084
2024-01-31 10:49:53 | INFO | train_inner | epoch 010:    976 / 3236 loss=1.605, nll_loss=1.605, ppl=3.04, wps=2289, ups=1.76, wpb=1304, bsz=92.3, num_updates=30100, lr=0.00115278, gnorm=0.57, train_wall=56, gb_free=17, wall=19141
2024-01-31 10:50:50 | INFO | train_inner | epoch 010:   1076 / 3236 loss=1.597, nll_loss=1.597, ppl=3.03, wps=2299.7, ups=1.76, wpb=1303.4, bsz=88.8, num_updates=30200, lr=0.00115087, gnorm=0.57, train_wall=56, gb_free=18.4, wall=19197
2024-01-31 10:51:47 | INFO | train_inner | epoch 010:   1176 / 3236 loss=1.607, nll_loss=1.607, ppl=3.05, wps=2291.2, ups=1.76, wpb=1302.7, bsz=86.3, num_updates=30300, lr=0.00114897, gnorm=0.578, train_wall=56, gb_free=18.7, wall=19254
2024-01-31 10:52:44 | INFO | train_inner | epoch 010:   1276 / 3236 loss=1.602, nll_loss=1.602, ppl=3.04, wps=2279.3, ups=1.75, wpb=1303.4, bsz=84.8, num_updates=30400, lr=0.00114708, gnorm=0.571, train_wall=57, gb_free=17.2, wall=19311
2024-01-31 10:53:42 | INFO | train_inner | epoch 010:   1376 / 3236 loss=1.626, nll_loss=1.626, ppl=3.09, wps=2191.3, ups=1.72, wpb=1272.5, bsz=81.9, num_updates=30500, lr=0.0011452, gnorm=0.584, train_wall=57, gb_free=18.2, wall=19369
2024-01-31 10:54:39 | INFO | train_inner | epoch 010:   1476 / 3236 loss=1.615, nll_loss=1.615, ppl=3.06, wps=2290, ups=1.76, wpb=1301.6, bsz=88.2, num_updates=30600, lr=0.00114332, gnorm=0.559, train_wall=56, gb_free=17.8, wall=19426
2024-01-31 10:55:36 | INFO | train_inner | epoch 010:   1576 / 3236 loss=1.573, nll_loss=1.573, ppl=2.98, wps=2333.2, ups=1.76, wpb=1329.2, bsz=93.4, num_updates=30700, lr=0.00114146, gnorm=0.56, train_wall=57, gb_free=18.4, wall=19483
2024-01-31 10:56:33 | INFO | train_inner | epoch 010:   1676 / 3236 loss=1.61, nll_loss=1.61, ppl=3.05, wps=2269.5, ups=1.75, wpb=1298, bsz=87.8, num_updates=30800, lr=0.00113961, gnorm=0.577, train_wall=57, gb_free=17.9, wall=19540
2024-01-31 10:57:30 | INFO | train_inner | epoch 010:   1776 / 3236 loss=1.602, nll_loss=1.602, ppl=3.04, wps=2307.2, ups=1.76, wpb=1308, bsz=91.9, num_updates=30900, lr=0.00113776, gnorm=0.565, train_wall=56, gb_free=18, wall=19597
2024-01-31 10:58:27 | INFO | train_inner | epoch 010:   1876 / 3236 loss=1.597, nll_loss=1.597, ppl=3.02, wps=2289.2, ups=1.75, wpb=1305.1, bsz=85.7, num_updates=31000, lr=0.00113592, gnorm=0.57, train_wall=57, gb_free=18, wall=19654
2024-01-31 10:59:24 | INFO | train_inner | epoch 010:   1976 / 3236 loss=1.603, nll_loss=1.603, ppl=3.04, wps=2308.9, ups=1.76, wpb=1312.7, bsz=88.1, num_updates=31100, lr=0.0011341, gnorm=0.576, train_wall=56, gb_free=18.3, wall=19711
2024-01-31 11:00:20 | INFO | train_inner | epoch 010:   2076 / 3236 loss=1.638, nll_loss=1.638, ppl=3.11, wps=2302.6, ups=1.76, wpb=1305.6, bsz=90.4, num_updates=31200, lr=0.00113228, gnorm=0.583, train_wall=56, gb_free=17.9, wall=19768
2024-01-31 11:01:17 | INFO | train_inner | epoch 010:   2176 / 3236 loss=1.62, nll_loss=1.62, ppl=3.07, wps=2285, ups=1.76, wpb=1295.1, bsz=86.3, num_updates=31300, lr=0.00113047, gnorm=0.58, train_wall=56, gb_free=18.4, wall=19824
2024-01-31 11:02:14 | INFO | train_inner | epoch 010:   2276 / 3236 loss=1.636, nll_loss=1.636, ppl=3.11, wps=2297.3, ups=1.77, wpb=1297.2, bsz=91.4, num_updates=31400, lr=0.00112867, gnorm=0.576, train_wall=56, gb_free=18.4, wall=19881
2024-01-31 11:03:10 | INFO | train_inner | epoch 010:   2376 / 3236 loss=1.605, nll_loss=1.605, ppl=3.04, wps=2287.7, ups=1.77, wpb=1292.6, bsz=87.4, num_updates=31500, lr=0.00112687, gnorm=0.58, train_wall=56, gb_free=18.2, wall=19937
2024-01-31 11:04:07 | INFO | train_inner | epoch 010:   2476 / 3236 loss=1.638, nll_loss=1.638, ppl=3.11, wps=2276.8, ups=1.76, wpb=1292.5, bsz=88.6, num_updates=31600, lr=0.00112509, gnorm=0.583, train_wall=56, gb_free=17.4, wall=19994
2024-01-31 11:05:04 | INFO | train_inner | epoch 010:   2576 / 3236 loss=1.621, nll_loss=1.621, ppl=3.07, wps=2324.6, ups=1.76, wpb=1318.1, bsz=92.8, num_updates=31700, lr=0.00112331, gnorm=0.563, train_wall=56, gb_free=17.8, wall=20051
2024-01-31 11:06:00 | INFO | train_inner | epoch 010:   2676 / 3236 loss=1.606, nll_loss=1.606, ppl=3.04, wps=2304.2, ups=1.76, wpb=1307.6, bsz=92.2, num_updates=31800, lr=0.00112154, gnorm=0.571, train_wall=56, gb_free=18.3, wall=20107
2024-01-31 11:06:57 | INFO | train_inner | epoch 010:   2776 / 3236 loss=1.633, nll_loss=1.633, ppl=3.1, wps=2272, ups=1.76, wpb=1290.7, bsz=88.3, num_updates=31900, lr=0.00111979, gnorm=0.581, train_wall=56, gb_free=18.2, wall=20164
2024-01-31 11:07:54 | INFO | train_inner | epoch 010:   2876 / 3236 loss=1.626, nll_loss=1.626, ppl=3.09, wps=2292.8, ups=1.77, wpb=1298.7, bsz=92.6, num_updates=32000, lr=0.00111803, gnorm=0.568, train_wall=56, gb_free=17.8, wall=20221
2024-01-31 11:08:51 | INFO | train_inner | epoch 010:   2976 / 3236 loss=1.609, nll_loss=1.609, ppl=3.05, wps=2293.1, ups=1.76, wpb=1301.4, bsz=91, num_updates=32100, lr=0.00111629, gnorm=0.563, train_wall=56, gb_free=18.3, wall=20278
2024-01-31 11:09:48 | INFO | train_inner | epoch 010:   3076 / 3236 loss=1.608, nll_loss=1.608, ppl=3.05, wps=2287.4, ups=1.75, wpb=1303.5, bsz=93.3, num_updates=32200, lr=0.00111456, gnorm=0.581, train_wall=57, gb_free=18.2, wall=20335
2024-01-31 11:10:44 | INFO | train_inner | epoch 010:   3176 / 3236 loss=1.629, nll_loss=1.629, ppl=3.09, wps=2279, ups=1.76, wpb=1296, bsz=88.6, num_updates=32300, lr=0.00111283, gnorm=0.57, train_wall=56, gb_free=17.4, wall=20391
2024-01-31 11:11:18 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-01-31 11:11:18 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 11:12:31 | INFO | dev | epoch 010 | valid on 'dev' subset | loss 1.301 | nll_loss 1.301 | ppl 2.46 | wps 3186 | wpb 1146.2 | bsz 77.6 | num_updates 32360 | best_loss 1.301
2024-01-31 11:12:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 10 @ 32360 updates
2024-01-31 11:12:31 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint10.pt
2024-01-31 11:12:32 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint10.pt
2024-01-31 11:12:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint10.pt (epoch 10 @ 32360 updates, score 1.301) (writing took 5.712482304079458 seconds)
2024-01-31 11:12:36 | INFO | fairseq_cli.train | end of epoch 10 (average epoch stats below)
2024-01-31 11:12:36 | INFO | train | epoch 010 | loss 1.607 | nll_loss 1.607 | ppl 3.05 | wps 2198.4 | ups 1.69 | wpb 1302.4 | bsz 89.4 | num_updates 32360 | lr 0.0011118 | gnorm 0.573 | train_wall 1822 | gb_free 18.2 | wall 20503
2024-01-31 11:12:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 11:12:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-01-31 11:12:36 | INFO | fairseq.trainer | begin training epoch 11
2024-01-31 11:12:36 | INFO | fairseq_cli.train | Start iterating over samples
2024-01-31 11:13:01 | INFO | train_inner | epoch 011:     40 / 3236 loss=1.575, nll_loss=1.575, ppl=2.98, wps=949.9, ups=0.73, wpb=1293, bsz=87.1, num_updates=32400, lr=0.00111111, gnorm=0.569, train_wall=56, gb_free=18.1, wall=20528
2024-01-31 11:14:04 | INFO | train_inner | epoch 011:    140 / 3236 loss=1.501, nll_loss=1.501, ppl=2.83, wps=2070.3, ups=1.57, wpb=1319.7, bsz=90.8, num_updates=32500, lr=0.0011094, gnorm=0.562, train_wall=63, gb_free=18.1, wall=20591
2024-01-31 11:15:01 | INFO | train_inner | epoch 011:    240 / 3236 loss=1.511, nll_loss=1.511, ppl=2.85, wps=2304.6, ups=1.77, wpb=1298.8, bsz=88.6, num_updates=32600, lr=0.0011077, gnorm=0.576, train_wall=56, gb_free=18.2, wall=20648
2024-01-31 11:15:57 | INFO | train_inner | epoch 011:    340 / 3236 loss=1.478, nll_loss=1.478, ppl=2.78, wps=2322.1, ups=1.76, wpb=1316.6, bsz=92.1, num_updates=32700, lr=0.001106, gnorm=0.557, train_wall=56, gb_free=18.3, wall=20704
2024-01-31 11:16:54 | INFO | train_inner | epoch 011:    440 / 3236 loss=1.545, nll_loss=1.545, ppl=2.92, wps=2288.2, ups=1.75, wpb=1304.8, bsz=89.8, num_updates=32800, lr=0.00110432, gnorm=0.562, train_wall=57, gb_free=17.5, wall=20761
2024-01-31 11:17:51 | INFO | train_inner | epoch 011:    540 / 3236 loss=1.495, nll_loss=1.495, ppl=2.82, wps=2326.3, ups=1.77, wpb=1313, bsz=90.2, num_updates=32900, lr=0.00110264, gnorm=0.551, train_wall=56, gb_free=18.4, wall=20818
2024-01-31 11:18:47 | INFO | train_inner | epoch 011:    640 / 3236 loss=1.522, nll_loss=1.522, ppl=2.87, wps=2331.4, ups=1.77, wpb=1319, bsz=90.5, num_updates=33000, lr=0.00110096, gnorm=0.585, train_wall=56, gb_free=18.7, wall=20874
2024-01-31 11:19:44 | INFO | train_inner | epoch 011:    740 / 3236 loss=1.509, nll_loss=1.509, ppl=2.85, wps=2317.4, ups=1.77, wpb=1307.8, bsz=92.2, num_updates=33100, lr=0.0010993, gnorm=0.557, train_wall=56, gb_free=17.4, wall=20931
2024-01-31 11:20:41 | INFO | train_inner | epoch 011:    840 / 3236 loss=1.539, nll_loss=1.539, ppl=2.91, wps=2307.1, ups=1.76, wpb=1310.5, bsz=90.1, num_updates=33200, lr=0.00109764, gnorm=0.56, train_wall=56, gb_free=17.6, wall=20988
2024-01-31 11:21:37 | INFO | train_inner | epoch 011:    940 / 3236 loss=1.51, nll_loss=1.51, ppl=2.85, wps=2333.2, ups=1.77, wpb=1316.7, bsz=89.4, num_updates=33300, lr=0.00109599, gnorm=0.575, train_wall=56, gb_free=17.7, wall=21044
2024-01-31 11:22:34 | INFO | train_inner | epoch 011:   1040 / 3236 loss=1.523, nll_loss=1.523, ppl=2.87, wps=2272.9, ups=1.76, wpb=1289.5, bsz=83.8, num_updates=33400, lr=0.00109435, gnorm=0.595, train_wall=56, gb_free=18, wall=21101
2024-01-31 11:23:30 | INFO | train_inner | epoch 011:   1140 / 3236 loss=1.524, nll_loss=1.524, ppl=2.88, wps=2288, ups=1.77, wpb=1290.1, bsz=88.1, num_updates=33500, lr=0.00109272, gnorm=0.591, train_wall=56, gb_free=17.9, wall=21157
2024-01-31 11:24:27 | INFO | train_inner | epoch 011:   1240 / 3236 loss=1.521, nll_loss=1.521, ppl=2.87, wps=2309.5, ups=1.77, wpb=1303.7, bsz=93.9, num_updates=33600, lr=0.00109109, gnorm=0.56, train_wall=56, gb_free=18, wall=21214
2024-01-31 11:25:23 | INFO | train_inner | epoch 011:   1340 / 3236 loss=1.526, nll_loss=1.526, ppl=2.88, wps=2297, ups=1.78, wpb=1291, bsz=91.3, num_updates=33700, lr=0.00108947, gnorm=0.572, train_wall=56, gb_free=18.5, wall=21270
2024-01-31 11:26:19 | INFO | train_inner | epoch 011:   1440 / 3236 loss=1.541, nll_loss=1.541, ppl=2.91, wps=2321.6, ups=1.77, wpb=1312, bsz=90.5, num_updates=33800, lr=0.00108786, gnorm=0.58, train_wall=56, gb_free=17.7, wall=21326
2024-01-31 11:27:16 | INFO | train_inner | epoch 011:   1540 / 3236 loss=1.549, nll_loss=1.549, ppl=2.93, wps=2273.7, ups=1.77, wpb=1283.8, bsz=85, num_updates=33900, lr=0.00108625, gnorm=0.584, train_wall=56, gb_free=17.9, wall=21383
2024-01-31 11:28:13 | INFO | train_inner | epoch 011:   1640 / 3236 loss=1.527, nll_loss=1.527, ppl=2.88, wps=2291.8, ups=1.75, wpb=1312.3, bsz=84.8, num_updates=34000, lr=0.00108465, gnorm=0.575, train_wall=57, gb_free=18.2, wall=21440
2024-01-31 11:29:09 | INFO | train_inner | epoch 011:   1740 / 3236 loss=1.557, nll_loss=1.557, ppl=2.94, wps=2270.3, ups=1.77, wpb=1280.2, bsz=87.8, num_updates=34100, lr=0.00108306, gnorm=0.585, train_wall=56, gb_free=17.8, wall=21497
2024-01-31 11:30:06 | INFO | train_inner | epoch 011:   1840 / 3236 loss=1.572, nll_loss=1.572, ppl=2.97, wps=2281.8, ups=1.76, wpb=1295.8, bsz=87.8, num_updates=34200, lr=0.00108148, gnorm=0.593, train_wall=56, gb_free=17.6, wall=21553
2024-01-31 11:30:53 | INFO | fairseq_cli.train | Stopping training due to cumulative_training_time: 6.000015173488193 > stop_time_hours: 6.0 hour(s)
2024-01-31 11:30:53 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-01-31 11:30:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 11:31:56 | INFO | dev | epoch 011 | valid on 'dev' subset | loss 1.3 | nll_loss 1.3 | ppl 2.46 | wps 3664.9 | wpb 1146.2 | bsz 77.6 | num_updates 34282 | best_loss 1.3
2024-01-31 11:31:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 34282 updates
2024-01-31 11:31:56 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_best.pt
2024-01-31 11:31:57 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_best.pt
2024-01-31 11:32:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_best.pt (epoch 11 @ 34282 updates, score 1.3) (writing took 4.422073389054276 seconds)
2024-01-31 11:32:01 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2024-01-31 11:32:01 | INFO | train | epoch 011 | loss 1.525 | nll_loss 1.525 | ppl 2.88 | wps 2149.5 | ups 1.65 | wpb 1302.1 | bsz 89 | num_updates 34282 | lr 0.00108018 | gnorm 0.573 | train_wall 1086 | gb_free 17.9 | wall 21668
2024-01-31 11:32:01 | INFO | fairseq_cli.train | done training in 21543.0 seconds
Training complete.
Finetuning complete.
----------------------------------------------------------
Transcribing the test set...
Starting transcription...
Average checkpoints...
Checkpoints folder: /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models
Checkpoint path: /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
Namespace(inputs=['/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models'], output='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', num_epoch_checkpoints=5, num_update_checkpoints=None, num_best_checkpoints=0, checkpoint_upper_bound=None)
averaging checkpoints:  ['/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint10.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint9.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint8.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint7.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint6.pt']
Finished writing averaged checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
Checkpoints averaged
Generating transcriptions...
Test subset: test
Data directory: /pfs/work7/workspace/scratch/uxude-ASR/dataset/covost
Prediction output directory: /home/kit/stud/uxude/predictions/finetune_asr_covost
DEBUG:hydra.core.utils:Setting JobRuntime:name=UNKNOWN_NAME
DEBUG:hydra.core.utils:Setting JobRuntime:name=utils
INFO:fairseq_cli.generate:{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 50000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all'}, 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', simul_type=None, scoring='wer', task='speech_to_text', num_workers=1, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, path='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', post_process=None, quiet=False, model_overrides='{}', results_path=None, beam=5, beam_mt=0, nbest=1, max_len_a=0, max_len_b=200, max_len_a_mt=0, max_len_b_mt=200, min_len=1, match_source_len=False, unnormalized=False, no_early_stop=False, no_beamable_mm=False, lenpen=1, lenpen_mt=1, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=None, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, no_seed_provided=False, eos_token=None, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, arch='wav2vec2', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, force_anneal=None, lr_shrink=0.1, warmup_updates=0, wer_tokenizer='none', wer_remove_punct=False, wer_char_level=False, wer_lowercase=False, _name='speech_to_text'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'wer', 'wer_tokenizer': 'none', 'wer_remove_punct': False, 'wer_char_level': False, 'wer_lowercase': False}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
INFO:fairseq.tasks.speech_to_text:dictionary size (spm.asr.txt): 5,000
INFO:fairseq_cli.generate:loading model(s) from /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
INFO:fairseq.tasks.speech_to_text:pre-tokenizer: {'tokenizer': None}
INFO:fairseq.tasks.speech_to_text:tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
WARNING:fairseq.data.audio.data_cfg:Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
INFO:fairseq.data.audio.speech_to_text_dataset:'test' has 0.00% OOV
INFO:fairseq.data.audio.speech_to_text_dataset:SpeechToTextDataset(split="test", n_samples=15_531, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
INFO:fairseq.tasks.fairseq_task:can_reuse_epoch_itr = True
INFO:fairseq.tasks.fairseq_task:reuse_dataloader = True
INFO:fairseq.tasks.fairseq_task:rebuild_batches = False
INFO:fairseq.tasks.fairseq_task:creating new batches for epoch 1
Traceback (most recent call last):
  File "/home/kit/stud/uxude/miniconda3/envs/nmt/bin/fairseq-generate", line 8, in <module>
    sys.exit(cli_main())
  File "/home/kit/stud/uxude/fairseq/fairseq_cli/generate.py", line 413, in cli_main
    main(args)
  File "/home/kit/stud/uxude/fairseq/fairseq_cli/generate.py", line 50, in main
    return _main(cfg, sys.stdout)
  File "/home/kit/stud/uxude/fairseq/fairseq_cli/generate.py", line 141, in _main
    itr = task.get_batch_iterator(
  File "/home/kit/stud/uxude/fairseq/fairseq/tasks/fairseq_task.py", line 318, in get_batch_iterator
    batch_sampler = make_batches(dataset, epoch)
  File "/home/kit/stud/uxude/fairseq/fairseq/tasks/fairseq_task.py", line 295, in make_batches
    indices = self.filter_indices_by_size(
  File "/home/kit/stud/uxude/fairseq/fairseq/tasks/fairseq_task.py", line 187, in filter_indices_by_size
    raise Exception(
Exception: Size of sample #11198 is invalid (=(14252, 19)) since max_positions=(6000, 1024), skip this example with --skip-invalid-size-inputs-valid-test
Transcription done
Prediction files written for /home/kit/stud/uxude/predictions/finetune_asr_covost/hyp.txt and /home/kit/stud/uxude/predictions/finetune_asr_covost/ref.txt
Sample predictions:
Sample:
Reference:
Sample:
Reference:
WER:
BLEU:
sacreBLEU: System and reference streams have different lengths.

============================= JOB FEEDBACK =============================

NodeName=uc2n481
Job ID: 23095549
Cluster: uc2
User/Group: uxude/stud
State: FAILED (exit code 1)
Nodes: 1
Cores per node: 2
CPU Utilized: 06:56:20
CPU Efficiency: 56.55% of 12:16:12 core-walltime
Job Wall-clock time: 06:08:06
Memory Utilized: 6.53 GB
Memory Efficiency: 3.35% of 195.31 GB
No extension needed for workspace ASR.
No extension needed for workspace MT.
Fairseq directory exists. Checking if installed...
fairseq                  0.12.2       /home/kit/stud/uxude/fairseq
Fairseq is already installed. Skipping installation.
Setup complete. Starting script execution...
[2024-01-31 23:21:32] [INFO] [Dataset::Prepare Datasets]: Skipping dataset preparation, config file and MT spm data already exists
Finetuning the ASR model...
Training the model...
Model will be stored in /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models
Training time: 6 hours
Training subset: train
Validation subset: dev
Data directory: /pfs/work7/workspace/scratch/uxude-ASR/dataset/covost
2024-01-31 23:21:45 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 4, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 50000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'dev', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 500, 'max_update': 0, 'stop_time_hours': 6.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 50000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 5, 'keep_best_checkpoints': 5, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_text', num_workers=4, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2t_conformer', max_epoch=500, max_update=0, stop_time_hours=6.0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.002], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=50000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=5, keep_best_checkpoints=5, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, label_smoothing=0.0, report_accuracy=False, ignore_prefix_size=0, adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, pos_enc_type='rel_pos', attn_type='espnet', no_seed_provided=False, input_feat_per_channel=80, input_channels=1, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, dropout=0.1, encoder_layers=16, depthwise_conv_kernel_size=31, encoder_freezing_updates=0, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_normalize_before=True, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.1, activation_dropout=0.1, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, no_scale_embedding=False, quant_noise_pq=0, _name='s2t_conformer'), 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_text', num_workers=4, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2t_conformer', max_epoch=500, max_update=0, stop_time_hours=6.0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.002], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=50000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=5, keep_best_checkpoints=5, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, label_smoothing=0.0, report_accuracy=False, ignore_prefix_size=0, adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, pos_enc_type='rel_pos', attn_type='espnet', no_seed_provided=False, input_feat_per_channel=80, input_channels=1, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, dropout=0.1, encoder_layers=16, depthwise_conv_kernel_size=31, encoder_freezing_updates=0, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_normalize_before=True, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.1, activation_dropout=0.1, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, no_scale_embedding=False, quant_noise_pq=0, _name='speech_to_text'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.0, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 10000, 'warmup_init_lr': -1.0, 'lr': [0.002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-01-31 23:21:45 | INFO | fairseq.tasks.speech_to_text | dictionary size (spm.asr.txt): 5,000
2024-01-31 23:21:46 | INFO | fairseq_cli.train | S2TConformerModel(
  (encoder): S2TConformerEncoder(
    (subsample): Conv1dSubsampler(
      (conv_layers): ModuleList(
        (0): Conv1d(80, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        (1): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
      )
    )
    (embed_positions): RelPositionalEncoding()
    (linear): Linear(in_features=256, out_features=256, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (conformer_layers): ModuleList(
      (0-15): 16 x ConformerEncoderLayer(
        (ffn1): FeedForwardModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (activation): SiLU(inplace=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (self_attn_dropout): Dropout(p=0.1, inplace=False)
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (conv_module): ConvolutionModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
          (glu): GLU(dim=1)
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256, bias=False)
          (batch_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): SiLU(inplace=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn2): FeedForwardModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (activation): SiLU(inplace=True)
        )
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(5000, 256, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=256, out_features=5000, bias=False)
  )
)
2024-01-31 23:21:46 | INFO | fairseq_cli.train | task: SpeechToTextTask
2024-01-31 23:21:46 | INFO | fairseq_cli.train | model: S2TConformerModel
2024-01-31 23:21:46 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2024-01-31 23:21:46 | INFO | fairseq_cli.train | num. shared model params: 54,758,144 (num. trained: 54,758,144)
2024-01-31 23:21:46 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2024-01-31 23:21:46 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2024-01-31 23:21:46 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
2024-01-31 23:21:46 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
2024-01-31 23:21:46 | INFO | fairseq.data.audio.speech_to_text_dataset | 'dev' has 0.00% OOV
2024-01-31 23:21:46 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split="dev", n_samples=15_531, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.pointwise_conv1.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.depthwise_conv.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.pointwise_conv2.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.self_attn.linear_pos.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.pointwise_conv1.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.depthwise_conv.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.pointwise_conv2.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.self_attn.linear_pos.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.pointwise_conv1.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.depthwise_conv.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.pointwise_conv2.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.self_attn.linear_pos.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.pointwise_conv1.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.depthwise_conv.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.pointwise_conv2.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.self_attn.linear_pos.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.pointwise_conv1.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.depthwise_conv.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.pointwise_conv2.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.self_attn.linear_pos.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.pointwise_conv1.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.depthwise_conv.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.pointwise_conv2.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.self_attn.linear_pos.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.pointwise_conv1.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.depthwise_conv.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.pointwise_conv2.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.self_attn.linear_pos.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.pointwise_conv1.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.depthwise_conv.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.pointwise_conv2.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.self_attn.linear_pos.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.pointwise_conv1.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.depthwise_conv.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.pointwise_conv2.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.self_attn.linear_pos.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.pointwise_conv1.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.depthwise_conv.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.pointwise_conv2.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.self_attn.linear_pos.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.pointwise_conv1.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.depthwise_conv.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.pointwise_conv2.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.self_attn.linear_pos.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.pointwise_conv1.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.depthwise_conv.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.pointwise_conv2.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.self_attn.linear_pos.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.pointwise_conv1.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.depthwise_conv.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.pointwise_conv2.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.self_attn.linear_pos.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.pointwise_conv1.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.depthwise_conv.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.pointwise_conv2.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.self_attn.linear_pos.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.pointwise_conv1.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.depthwise_conv.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.pointwise_conv2.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.self_attn.linear_pos.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.pointwise_conv1.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.depthwise_conv.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.pointwise_conv2.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- decoder.output_projection.bias
2024-01-31 23:21:47 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-01-31 23:21:47 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-01-31 23:21:47 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 31.739 GB ; name = Tesla V100-SXM2-32GB
2024-01-31 23:21:47 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-01-31 23:21:47 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-01-31 23:21:47 | INFO | fairseq_cli.train | max tokens per device = 50000 and max sentences per device = None
2024-01-31 23:21:47 | INFO | fairseq.trainer | Preparing to load checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt
2024-01-31 23:21:51 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2024-01-31 23:21:53 | INFO | fairseq.trainer | Loaded checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt (epoch 11 @ 34282 updates)
2024-01-31 23:21:53 | INFO | fairseq.trainer | loading train data for epoch 11
2024-01-31 23:21:53 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2024-01-31 23:21:53 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
2024-01-31 23:21:56 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
2024-01-31 23:22:00 | INFO | fairseq.data.audio.speech_to_text_dataset | 'train' has 0.00% OOV
2024-01-31 23:22:00 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split="train", n_samples=289_421, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
    SpecAugmentTransform(time_warp_w=0, freq_mask_n=1, freq_mask_f=27, time_mask_n=1, time_mask_t=100, time_mask_p=1.0)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
2024-01-31 23:22:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 23:22:00 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-01-31 23:22:00 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-01-31 23:22:00 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 11
/home/kit/stud/uxude/miniconda3/envs/nmt/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2024-01-31 23:22:02 | INFO | fairseq_cli.train | begin dry-run validation on "dev" subset
2024-01-31 23:22:02 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 23:22:02 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-01-31 23:22:02 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-01-31 23:22:02 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
2024-01-31 23:23:46 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-01-31 23:23:46 | INFO | fairseq.trainer | begin training epoch 11
2024-01-31 23:23:46 | INFO | fairseq_cli.train | Start iterating over samples
/home/kit/stud/uxude/miniconda3/envs/nmt/lib/python3.10/site-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/home/kit/stud/uxude/fairseq/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-01-31 23:23:57 | INFO | fairseq_cli.train | Stopping training due to cumulative_training_time: 6.0520781569348445 > stop_time_hours: 6.0 hour(s)
2024-01-31 23:23:57 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-01-31 23:23:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 23:24:30 | INFO | dev | epoch 011 | valid on 'dev' subset | loss 1.302 | nll_loss 1.302 | ppl 2.47 | wps 7009.7 | wpb 1146.2 | bsz 77.6 | num_updates 34283 | best_loss 1.3
2024-01-31 23:24:30 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 34283 updates
2024-01-31 23:24:30 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint.best_loss_1.3020.pt
2024-01-31 23:24:31 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint.best_loss_1.3020.pt
2024-01-31 23:24:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint.best_loss_1.3020.pt (epoch 11 @ 34283 updates, score 1.302) (writing took 2.9232121399836615 seconds)
2024-01-31 23:24:33 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2024-01-31 23:24:33 | INFO | train | epoch 011 | loss 1.525 | nll_loss 1.525 | ppl 2.88 | wps 1896.1 | ups 1.46 | wpb 1302 | bsz 88.9 | num_updates 34283 | lr 0.00108017 | gnorm 0.573 | train_wall 1094 | gb_free 17.1 | wall 0
2024-01-31 23:24:33 | INFO | fairseq_cli.train | done training in 47.2 seconds
Training complete.
Finetuning complete.
----------------------------------------------------------
Transcribing the test set...
Starting transcription...
Average checkpoints...
Checkpoints folder: /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models
Checkpoint path: /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
Namespace(inputs=['/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models'], output='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', num_epoch_checkpoints=5, num_update_checkpoints=None, num_best_checkpoints=0, checkpoint_upper_bound=None)
averaging checkpoints:  ['/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint10.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint9.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint8.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint7.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint6.pt']
Finished writing averaged checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
Checkpoints averaged
Generating transcriptions...
Test subset: test
Data directory: /pfs/work7/workspace/scratch/uxude-ASR/dataset/covost
Prediction output directory: /home/kit/stud/uxude/predictions/finetune_asr_covost
DEBUG:hydra.core.utils:Setting JobRuntime:name=UNKNOWN_NAME
DEBUG:hydra.core.utils:Setting JobRuntime:name=utils
INFO:fairseq_cli.generate:{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 50000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 8, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all'}, 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', simul_type=None, scoring='wer', task='speech_to_text', num_workers=1, skip_invalid_size_inputs_valid_test=True, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, path='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', post_process=None, quiet=False, model_overrides='{}', results_path=None, beam=8, beam_mt=0, nbest=1, max_len_a=0, max_len_b=200, max_len_a_mt=0, max_len_b_mt=200, min_len=1, match_source_len=False, unnormalized=False, no_early_stop=False, no_beamable_mm=False, lenpen=1, lenpen_mt=1, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=None, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, no_seed_provided=False, eos_token=None, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, arch='wav2vec2', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, force_anneal=None, lr_shrink=0.1, warmup_updates=0, wer_tokenizer='none', wer_remove_punct=False, wer_char_level=False, wer_lowercase=False, _name='speech_to_text'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'wer', 'wer_tokenizer': 'none', 'wer_remove_punct': False, 'wer_char_level': False, 'wer_lowercase': False}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
INFO:fairseq.tasks.speech_to_text:dictionary size (spm.asr.txt): 5,000
INFO:fairseq_cli.generate:loading model(s) from /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
INFO:fairseq.tasks.speech_to_text:pre-tokenizer: {'tokenizer': None}
INFO:fairseq.tasks.speech_to_text:tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
WARNING:fairseq.data.audio.data_cfg:Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
INFO:fairseq.data.audio.speech_to_text_dataset:'test' has 0.00% OOV
INFO:fairseq.data.audio.speech_to_text_dataset:SpeechToTextDataset(split="test", n_samples=15_531, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
INFO:fairseq.tasks.fairseq_task:can_reuse_epoch_itr = True
INFO:fairseq.tasks.fairseq_task:reuse_dataloader = True
INFO:fairseq.tasks.fairseq_task:rebuild_batches = False
INFO:fairseq.tasks.fairseq_task:creating new batches for epoch 1
WARNING:fairseq.tasks.fairseq_task:5 samples have invalid sizes and will be skipped, max_positions=(6000, 1024), first few sample ids=[11198, 697, 6107, 3431, 14638]
INFO:fairseq.tasks.speech_to_text:pre-tokenizer: {'tokenizer': None}
INFO:fairseq.tasks.speech_to_text:tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
INFO:fairseq.logging.progress_bar::    101 / 188 wps=1627
INFO:fairseq_cli.generate:NOTE: hypothesis and token scores are output in base 2
INFO:fairseq_cli.generate:Translated 15,520 sentences (198,939 tokens) in 81.8s (189.69 sentences/s, 2431.46 tokens/s)
Transcription done
Prediction files written for /home/kit/stud/uxude/predictions/finetune_asr_covost/hyp_asr.txt and /home/kit/stud/uxude/predictions/finetune_asr_covost/ref_asr.txt
Sample predictions:
Sample: for some reason we were brought from enduring
Reference: for some reason we were blocked from entering
Sample: as they set down on the only table in the place the crystal merchandise
Reference: as they sat down at the only table in the place the crystal merchant laughed
WER:
Generate test with beam=8: WER: 36.40
BLEU:
{
 "name": "BLEU",
 "score": 48.7,
 "signature": "nrefs:1|case:mixed|eff:no|tok:none|smooth:none|version:2.4.0",
 "verbose_score": "67.9/53.6/43.5/35.5 (BP = 1.000 ratio = 1.016 hyp_len = 143463 ref_len = 141203)",
 "nrefs": "1",
 "case": "mixed",
 "eff": "no",
 "tok": "none",
 "smooth": "none",
 "version": "2.4.0"
}

============================= JOB FEEDBACK =============================

NodeName=uc2n482
Job ID: 23098030
Cluster: uc2
User/Group: uxude/stud
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 2
CPU Utilized: 00:04:31
CPU Efficiency: 27.05% of 00:16:42 core-walltime
Job Wall-clock time: 00:08:21
Memory Utilized: 3.45 GB
Memory Efficiency: 1.77% of 195.31 GB
No extension needed for workspace ASR.
No extension needed for workspace MT.
Fairseq directory exists. Checking if installed...
fairseq                  0.12.2       /home/kit/stud/uxude/fairseq
Fairseq is already installed. Skipping installation.
Setup complete. Starting script execution...
[2024-01-31 23:47:40] [INFO] [Dataset::Prepare Datasets]: Skipping dataset preparation, config file and MT spm data already exists
Finetuning the ASR model...
Training the model...
Model will be stored in /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models
Training time: 6 hours
Training subset: train
Validation subset: dev
Data directory: /pfs/work7/workspace/scratch/uxude-ASR/dataset/covost
2024-01-31 23:47:45 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 4, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 50000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'dev', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 500, 'max_update': 0, 'stop_time_hours': 6.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 50000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 5, 'keep_best_checkpoints': 5, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_text', num_workers=4, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2t_conformer', max_epoch=500, max_update=0, stop_time_hours=6.0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.002], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=50000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=5, keep_best_checkpoints=5, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, label_smoothing=0.0, report_accuracy=False, ignore_prefix_size=0, adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, pos_enc_type='rel_pos', attn_type='espnet', no_seed_provided=False, input_feat_per_channel=80, input_channels=1, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, dropout=0.1, encoder_layers=16, depthwise_conv_kernel_size=31, encoder_freezing_updates=0, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_normalize_before=True, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.1, activation_dropout=0.1, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, no_scale_embedding=False, quant_noise_pq=0, _name='s2t_conformer'), 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_text', num_workers=4, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2t_conformer', max_epoch=500, max_update=0, stop_time_hours=6.0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.002], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=50000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=5, keep_best_checkpoints=5, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, label_smoothing=0.0, report_accuracy=False, ignore_prefix_size=0, adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, pos_enc_type='rel_pos', attn_type='espnet', no_seed_provided=False, input_feat_per_channel=80, input_channels=1, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, dropout=0.1, encoder_layers=16, depthwise_conv_kernel_size=31, encoder_freezing_updates=0, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_normalize_before=True, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.1, activation_dropout=0.1, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, no_scale_embedding=False, quant_noise_pq=0, _name='speech_to_text'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.0, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 10000, 'warmup_init_lr': -1.0, 'lr': [0.002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-01-31 23:47:45 | INFO | fairseq.tasks.speech_to_text | dictionary size (spm.asr.txt): 5,000
2024-01-31 23:47:46 | INFO | fairseq_cli.train | S2TConformerModel(
  (encoder): S2TConformerEncoder(
    (subsample): Conv1dSubsampler(
      (conv_layers): ModuleList(
        (0): Conv1d(80, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        (1): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
      )
    )
    (embed_positions): RelPositionalEncoding()
    (linear): Linear(in_features=256, out_features=256, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (conformer_layers): ModuleList(
      (0-15): 16 x ConformerEncoderLayer(
        (ffn1): FeedForwardModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (activation): SiLU(inplace=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (self_attn_dropout): Dropout(p=0.1, inplace=False)
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (conv_module): ConvolutionModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
          (glu): GLU(dim=1)
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256, bias=False)
          (batch_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): SiLU(inplace=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn2): FeedForwardModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (activation): SiLU(inplace=True)
        )
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(5000, 256, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=256, out_features=5000, bias=False)
  )
)
2024-01-31 23:47:46 | INFO | fairseq_cli.train | task: SpeechToTextTask
2024-01-31 23:47:46 | INFO | fairseq_cli.train | model: S2TConformerModel
2024-01-31 23:47:46 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2024-01-31 23:47:46 | INFO | fairseq_cli.train | num. shared model params: 54,758,144 (num. trained: 54,758,144)
2024-01-31 23:47:46 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2024-01-31 23:47:46 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2024-01-31 23:47:46 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
2024-01-31 23:47:46 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
2024-01-31 23:47:46 | INFO | fairseq.data.audio.speech_to_text_dataset | 'dev' has 0.00% OOV
2024-01-31 23:47:46 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split="dev", n_samples=15_531, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.pointwise_conv1.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.depthwise_conv.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.pointwise_conv2.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.self_attn.linear_pos.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.pointwise_conv1.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.depthwise_conv.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.pointwise_conv2.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.self_attn.linear_pos.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.pointwise_conv1.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.depthwise_conv.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.pointwise_conv2.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.self_attn.linear_pos.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.pointwise_conv1.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.depthwise_conv.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.pointwise_conv2.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.self_attn.linear_pos.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.pointwise_conv1.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.depthwise_conv.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.pointwise_conv2.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.self_attn.linear_pos.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.pointwise_conv1.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.depthwise_conv.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.pointwise_conv2.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.self_attn.linear_pos.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.pointwise_conv1.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.depthwise_conv.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.pointwise_conv2.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.self_attn.linear_pos.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.pointwise_conv1.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.depthwise_conv.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.pointwise_conv2.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.self_attn.linear_pos.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.pointwise_conv1.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.depthwise_conv.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.pointwise_conv2.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.self_attn.linear_pos.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.pointwise_conv1.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.depthwise_conv.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.pointwise_conv2.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.self_attn.linear_pos.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.pointwise_conv1.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.depthwise_conv.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.pointwise_conv2.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.self_attn.linear_pos.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.pointwise_conv1.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.depthwise_conv.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.pointwise_conv2.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.self_attn.linear_pos.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.pointwise_conv1.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.depthwise_conv.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.pointwise_conv2.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.self_attn.linear_pos.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.pointwise_conv1.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.depthwise_conv.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.pointwise_conv2.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.self_attn.linear_pos.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.pointwise_conv1.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.depthwise_conv.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.pointwise_conv2.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.self_attn.linear_pos.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.pointwise_conv1.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.depthwise_conv.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.pointwise_conv2.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- decoder.output_projection.bias
2024-01-31 23:47:47 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-01-31 23:47:47 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-01-31 23:47:47 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 31.739 GB ; name = Tesla V100-SXM2-32GB
2024-01-31 23:47:47 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-01-31 23:47:47 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-01-31 23:47:47 | INFO | fairseq_cli.train | max tokens per device = 50000 and max sentences per device = None
2024-01-31 23:47:47 | INFO | fairseq.trainer | Preparing to load checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt
2024-01-31 23:47:51 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2024-01-31 23:47:52 | INFO | fairseq.trainer | Loaded checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt (epoch 11 @ 34283 updates)
2024-01-31 23:47:52 | INFO | fairseq.trainer | loading train data for epoch 11
2024-01-31 23:47:52 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2024-01-31 23:47:52 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
2024-01-31 23:47:55 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
2024-01-31 23:48:00 | INFO | fairseq.data.audio.speech_to_text_dataset | 'train' has 0.00% OOV
2024-01-31 23:48:00 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split="train", n_samples=289_421, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
    SpecAugmentTransform(time_warp_w=0, freq_mask_n=1, freq_mask_f=27, time_mask_n=1, time_mask_t=100, time_mask_p=1.0)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
2024-01-31 23:48:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 23:48:00 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-01-31 23:48:00 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-01-31 23:48:00 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 11
/home/kit/stud/uxude/miniconda3/envs/nmt/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2024-01-31 23:48:01 | INFO | fairseq_cli.train | begin dry-run validation on "dev" subset
2024-01-31 23:48:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 23:48:01 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-01-31 23:48:01 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-01-31 23:48:01 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
2024-01-31 23:49:45 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-01-31 23:49:45 | INFO | fairseq.trainer | begin training epoch 11
2024-01-31 23:49:45 | INFO | fairseq_cli.train | Start iterating over samples
/home/kit/stud/uxude/miniconda3/envs/nmt/lib/python3.10/site-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/home/kit/stud/uxude/fairseq/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-01-31 23:50:03 | INFO | fairseq_cli.train | Stopping training due to cumulative_training_time: 6.09781300008297 > stop_time_hours: 6.0 hour(s)
2024-01-31 23:50:03 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-01-31 23:50:03 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-01-31 23:50:36 | INFO | dev | epoch 011 | valid on 'dev' subset | loss 1.304 | nll_loss 1.304 | ppl 2.47 | wps 7170.6 | wpb 1146.2 | bsz 77.6 | num_updates 34284 | best_loss 1.3
2024-01-31 23:50:36 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 11 @ 34284 updates
2024-01-31 23:50:36 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint.best_loss_1.3044.pt
2024-01-31 23:50:37 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint.best_loss_1.3044.pt
2024-01-31 23:50:39 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint.best_loss_1.3044.pt (epoch 11 @ 34284 updates, score 1.304) (writing took 2.8877266619820148 seconds)
2024-01-31 23:50:39 | INFO | fairseq_cli.train | end of epoch 11 (average epoch stats below)
2024-01-31 23:50:39 | INFO | train | epoch 011 | loss 1.525 | nll_loss 1.525 | ppl 2.88 | wps 1687.9 | ups 1.3 | wpb 1302 | bsz 89 | num_updates 34284 | lr 0.00108015 | gnorm 0.573 | train_wall 1108 | gb_free 18.3 | wall 0
2024-01-31 23:50:39 | INFO | fairseq_cli.train | done training in 53.9 seconds
Training complete.
Finetuning complete.
----------------------------------------------------------
Transcribing the test set...
Starting transcription...
Average checkpoints...
Checkpoints folder: /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models
Checkpoint path: /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
Namespace(inputs=['/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models'], output='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', num_epoch_checkpoints=5, num_update_checkpoints=None, num_best_checkpoints=0, checkpoint_upper_bound=None)
averaging checkpoints:  ['/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint10.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint9.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint8.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint7.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint6.pt']
Finished writing averaged checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
Checkpoints averaged
Generating transcriptions...
Test subset: test
Data directory: /pfs/work7/workspace/scratch/uxude-ASR/dataset/covost
Prediction output directory: /home/kit/stud/uxude/predictions/finetune_asr_covost
DEBUG:hydra.core.utils:Setting JobRuntime:name=UNKNOWN_NAME
DEBUG:hydra.core.utils:Setting JobRuntime:name=utils
INFO:fairseq_cli.generate:{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 50000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 8, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all'}, 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', simul_type=None, scoring='wer', task='speech_to_text', num_workers=1, skip_invalid_size_inputs_valid_test=True, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, path='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', post_process=None, quiet=False, model_overrides='{}', results_path=None, beam=8, beam_mt=0, nbest=1, max_len_a=0, max_len_b=200, max_len_a_mt=0, max_len_b_mt=200, min_len=1, match_source_len=False, unnormalized=False, no_early_stop=False, no_beamable_mm=False, lenpen=1, lenpen_mt=1, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=None, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, no_seed_provided=False, eos_token=None, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, arch='wav2vec2', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, force_anneal=None, lr_shrink=0.1, warmup_updates=0, wer_tokenizer='none', wer_remove_punct=False, wer_char_level=False, wer_lowercase=False, _name='speech_to_text'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'wer', 'wer_tokenizer': 'none', 'wer_remove_punct': False, 'wer_char_level': False, 'wer_lowercase': False}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
INFO:fairseq.tasks.speech_to_text:dictionary size (spm.asr.txt): 5,000
INFO:fairseq_cli.generate:loading model(s) from /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
INFO:fairseq.tasks.speech_to_text:pre-tokenizer: {'tokenizer': None}
INFO:fairseq.tasks.speech_to_text:tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
WARNING:fairseq.data.audio.data_cfg:Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
INFO:fairseq.data.audio.speech_to_text_dataset:'test' has 0.00% OOV
INFO:fairseq.data.audio.speech_to_text_dataset:SpeechToTextDataset(split="test", n_samples=15_531, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
INFO:fairseq.tasks.fairseq_task:can_reuse_epoch_itr = True
INFO:fairseq.tasks.fairseq_task:reuse_dataloader = True
INFO:fairseq.tasks.fairseq_task:rebuild_batches = False
INFO:fairseq.tasks.fairseq_task:creating new batches for epoch 1
WARNING:fairseq.tasks.fairseq_task:5 samples have invalid sizes and will be skipped, max_positions=(6000, 1024), first few sample ids=[11198, 697, 6107, 3431, 14638]
INFO:fairseq.tasks.speech_to_text:pre-tokenizer: {'tokenizer': None}
INFO:fairseq.tasks.speech_to_text:tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
INFO:fairseq.logging.progress_bar::    101 / 188 wps=1554
INFO:fairseq_cli.generate:NOTE: hypothesis and token scores are output in base 2
INFO:fairseq_cli.generate:Translated 15,520 sentences (198,939 tokens) in 84.3s (184.21 sentences/s, 2361.24 tokens/s)
Transcription done
Prediction files written for /home/kit/stud/uxude/predictions/finetune_asr_covost/hyp_asr.txt and /home/kit/stud/uxude/predictions/finetune_asr_covost/ref_asr.txt
Sample predictions:
Sample: for some reason we were brought from enduring
Reference: for some reason we were blocked from entering
Sample: as they set down on the only table in the place the crystal merchandise
Reference: as they sat down at the only table in the place the crystal merchant laughed
WER:
Generate test with beam=8: WER: 36.40
BLEU:
{
 "name": "BLEU",
 "score": 48.7,
 "signature": "nrefs:1|case:mixed|eff:no|tok:none|smooth:none|version:2.4.0",
 "verbose_score": "67.9/53.6/43.5/35.5 (BP = 1.000 ratio = 1.016 hyp_len = 143463 ref_len = 141203)",
 "nrefs": "1",
 "case": "mixed",
 "eff": "no",
 "tok": "none",
 "smooth": "none",
 "version": "2.4.0"
}

============================= JOB FEEDBACK =============================

NodeName=uc2n483
Job ID: 23098277
Cluster: uc2
User/Group: uxude/stud
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 2
CPU Utilized: 00:04:34
CPU Efficiency: 27.57% of 00:16:34 core-walltime
Job Wall-clock time: 00:08:17
Memory Utilized: 3.54 GB
Memory Efficiency: 1.81% of 195.31 GB