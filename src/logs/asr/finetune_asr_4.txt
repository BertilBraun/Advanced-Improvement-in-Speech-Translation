(base) [uxude@uc2n995 train]$ cat finetune_asr_covost_23127064.txt
No extension needed for workspace ASR.
No extension needed for workspace MT.
Fairseq directory exists. Checking if installed...
fairseq                  0.12.2       /home/kit/stud/uxude/fairseq
Fairseq is already installed. Skipping installation.
Setup complete. Starting script execution...
[INFO] 00:46:12 [Dataset::Prepare Datasets]: Skipping dataset preparation, all config data already exists
Finetuning the ASR model...
Training the model...
Model will be stored in /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models
Training time: 46 hours
Training subset: train
Validation subset: dev
Data directory: /pfs/work7/workspace/scratch/uxude-ASR/dataset/covost
2024-02-08 00:46:18 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 4, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 50000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'dev', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 500, 'max_update': 250000, 'stop_time_hours': 46.0, 'clip_norm': 10.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [0.002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': 5, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='cosine', simul_type=None, scoring='bleu', task='speech_to_text', num_workers=4, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2t_conformer', max_epoch=500, max_update=250000, stop_time_hours=46.0, clip_norm=10.0, sentence_avg=False, update_freq=[8], lr=[0.002], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=5, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, label_smoothing=0.0, report_accuracy=False, ignore_prefix_size=0, adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=-1, min_lr=0.0, t_mult=1.0, lr_period_updates=-1, lr_shrink=0.1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, pos_enc_type='rel_pos', attn_type='espnet', no_seed_provided=False, input_feat_per_channel=80, input_channels=1, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, dropout=0.1, encoder_layers=16, depthwise_conv_kernel_size=31, encoder_freezing_updates=0, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_normalize_before=True, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.1, activation_dropout=0.1, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, no_scale_embedding=False, quant_noise_pq=0, _name='s2t_conformer'), 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='cosine', simul_type=None, scoring='bleu', task='speech_to_text', num_workers=4, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2t_conformer', max_epoch=500, max_update=250000, stop_time_hours=46.0, clip_norm=10.0, sentence_avg=False, update_freq=[8], lr=[0.002], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=5, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, label_smoothing=0.0, report_accuracy=False, ignore_prefix_size=0, adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=-1, min_lr=0.0, t_mult=1.0, lr_period_updates=-1, lr_shrink=0.1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, pos_enc_type='rel_pos', attn_type='espnet', no_seed_provided=False, input_feat_per_channel=80, input_channels=1, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, dropout=0.1, encoder_layers=16, depthwise_conv_kernel_size=31, encoder_freezing_updates=0, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_normalize_before=True, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.1, activation_dropout=0.1, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, no_scale_embedding=False, quant_noise_pq=0, _name='speech_to_text'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.0, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.002]}, 'lr_scheduler': {'_name': 'cosine', 'warmup_updates': 10000, 'warmup_init_lr': -1.0, 'lr': [0.002], 'min_lr': 0.0, 't_mult': 1.0, 'lr_period_updates': -1.0, 'lr_shrink': 0.1, 'max_update': 250000}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-02-08 00:46:18 | INFO | fairseq.tasks.speech_to_text | dictionary size (spm.asr.txt): 5,000
2024-02-08 00:46:18 | INFO | fairseq_cli.train | S2TConformerModel(
  (encoder): S2TConformerEncoder(
    (subsample): Conv1dSubsampler(
      (conv_layers): ModuleList(
        (0): Conv1d(80, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        (1): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
      )
    )
    (embed_positions): RelPositionalEncoding()
    (linear): Linear(in_features=256, out_features=256, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (conformer_layers): ModuleList(
      (0-15): 16 x ConformerEncoderLayer(
        (ffn1): FeedForwardModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (activation): SiLU(inplace=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (self_attn_dropout): Dropout(p=0.1, inplace=False)
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (conv_module): ConvolutionModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
          (glu): GLU(dim=1)
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256, bias=False)
          (batch_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): SiLU(inplace=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn2): FeedForwardModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (activation): SiLU(inplace=True)
        )
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(5000, 256, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=256, out_features=5000, bias=False)
  )
)
2024-02-08 00:46:18 | INFO | fairseq_cli.train | task: SpeechToTextTask
2024-02-08 00:46:18 | INFO | fairseq_cli.train | model: S2TConformerModel
2024-02-08 00:46:18 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2024-02-08 00:46:18 | INFO | fairseq_cli.train | num. shared model params: 54,758,144 (num. trained: 54,758,144)
2024-02-08 00:46:18 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2024-02-08 00:46:18 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2024-02-08 00:46:18 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
2024-02-08 00:46:19 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
2024-02-08 00:46:19 | INFO | fairseq.data.audio.speech_to_text_dataset | 'dev' has 0.00% OOV
2024-02-08 00:46:19 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split="dev", n_samples=15_531, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.pointwise_conv1.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.depthwise_conv.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.pointwise_conv2.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.self_attn.linear_pos.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.pointwise_conv1.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.depthwise_conv.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.pointwise_conv2.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.self_attn.linear_pos.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.pointwise_conv1.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.depthwise_conv.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.pointwise_conv2.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.self_attn.linear_pos.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.pointwise_conv1.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.depthwise_conv.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.pointwise_conv2.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.self_attn.linear_pos.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.pointwise_conv1.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.depthwise_conv.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.pointwise_conv2.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.self_attn.linear_pos.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.pointwise_conv1.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.depthwise_conv.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.pointwise_conv2.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.self_attn.linear_pos.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.pointwise_conv1.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.depthwise_conv.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.pointwise_conv2.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.self_attn.linear_pos.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.pointwise_conv1.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.depthwise_conv.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.pointwise_conv2.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.self_attn.linear_pos.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.pointwise_conv1.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.depthwise_conv.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.pointwise_conv2.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.self_attn.linear_pos.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.pointwise_conv1.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.depthwise_conv.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.pointwise_conv2.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.self_attn.linear_pos.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.pointwise_conv1.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.depthwise_conv.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.pointwise_conv2.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.self_attn.linear_pos.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.pointwise_conv1.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.depthwise_conv.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.pointwise_conv2.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.self_attn.linear_pos.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.pointwise_conv1.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.depthwise_conv.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.pointwise_conv2.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.self_attn.linear_pos.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.pointwise_conv1.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.depthwise_conv.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.pointwise_conv2.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.self_attn.linear_pos.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.pointwise_conv1.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.depthwise_conv.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.pointwise_conv2.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.self_attn.linear_pos.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.pointwise_conv1.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.depthwise_conv.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.pointwise_conv2.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- decoder.output_projection.bias
2024-02-08 00:46:19 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-02-08 00:46:19 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-02-08 00:46:19 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 31.739 GB ; name = Tesla V100-SXM2-32GB
2024-02-08 00:46:19 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-02-08 00:46:19 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-02-08 00:46:19 | INFO | fairseq_cli.train | max tokens per device = 50000 and max sentences per device = None
2024-02-08 00:46:19 | INFO | fairseq.trainer | Preparing to load checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt
2024-02-08 00:46:24 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2024-02-08 00:46:25 | INFO | fairseq.trainer | Loaded checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt (epoch 53 @ 169853 updates)
2024-02-08 00:46:25 | INFO | fairseq.trainer | loading train data for epoch 53
2024-02-08 00:46:25 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2024-02-08 00:46:25 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
2024-02-08 00:46:29 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
2024-02-08 00:46:33 | INFO | fairseq.data.audio.speech_to_text_dataset | 'train' has 0.00% OOV
2024-02-08 00:46:33 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split="train", n_samples=289_421, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
    SpecAugmentTransform(time_warp_w=0, freq_mask_n=1, freq_mask_f=27, time_mask_n=1, time_mask_t=100, time_mask_p=1.0)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
2024-02-08 00:46:33 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-08 00:46:33 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-02-08 00:46:33 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-02-08 00:46:33 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 53
/home/kit/stud/uxude/miniconda3/envs/nmt/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2024-02-08 00:46:35 | INFO | fairseq_cli.train | begin dry-run validation on "dev" subset
2024-02-08 00:46:35 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-08 00:46:35 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-02-08 00:46:35 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-02-08 00:46:35 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
2024-02-08 00:48:19 | INFO | fairseq.data.iterators | grouped total_num_itrs = 405
2024-02-08 00:48:19 | INFO | fairseq.trainer | begin training epoch 53
2024-02-08 00:48:19 | INFO | fairseq_cli.train | Start iterating over samples
/home/kit/stud/uxude/miniconda3/envs/nmt/lib/python3.10/site-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/home/kit/stud/uxude/fairseq/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-02-08 00:52:51 | INFO | train_inner | epoch 053:    245 / 405 loss=0.75, nll_loss=0.75, ppl=1.68, wps=1251.8, ups=0.22, wpb=5594.3, bsz=389.4, num_updates=169900, lr=0.000501134, gnorm=0.434, clip=0, train_wall=238, gb_free=17.2, wall=0
2024-02-08 01:01:16 | INFO | train_inner | epoch 053:    345 / 405 loss=0.724, nll_loss=0.724, ppl=1.65, wps=2067.3, ups=0.2, wpb=10442.2, bsz=717.5, num_updates=170000, lr=0.0005, gnorm=0.215, clip=0, train_wall=416, gb_free=16.7, wall=0
2024-02-08 01:06:19 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-08 01:06:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-08 01:07:25 | INFO | dev | epoch 053 | valid on 'dev' subset | loss 1.114 | nll_loss 1.114 | ppl 2.17 | wps 3528.3 | wpb 1146.2 | bsz 77.6 | num_updates 170060 | best_loss 1.094
2024-02-08 01:07:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 170060 updates
2024-02-08 01:07:25 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint53.pt
2024-02-08 01:07:26 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint53.pt
2024-02-08 01:07:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint53.pt (epoch 53 @ 170060 updates, score 1.114) (writing took 2.8273662400897592 seconds)
2024-02-08 01:07:27 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2024-02-08 01:07:27 | INFO | train | epoch 053 | loss 0.736 | nll_loss 0.736 | ppl 1.67 | wps 1934.8 | ups 0.82 | wpb 2357.1 | bsz 161.9 | num_updates 170060 | lr 0.00049932 | gnorm 0.578 | clip 0 | train_wall 1750 | gb_free 17.2 | wall 0
2024-02-08 01:07:27 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-08 01:07:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 405
2024-02-08 01:07:28 | INFO | fairseq.trainer | begin training epoch 54
2024-02-08 01:07:28 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-08 01:10:22 | INFO | train_inner | epoch 054:     40 / 405 loss=0.704, nll_loss=0.704, ppl=1.63, wps=1907.9, ups=0.18, wpb=10411.6, bsz=721, num_updates=170100, lr=0.000498867, gnorm=0.213, clip=0, train_wall=416, gb_free=17.3, wall=0
2024-02-08 01:17:24 | INFO | train_inner | epoch 054:    140 / 405 loss=0.683, nll_loss=0.683, ppl=1.61, wps=2464.7, ups=0.24, wpb=10417.4, bsz=706.5, num_updates=170200, lr=0.000497734, gnorm=0.215, clip=0, train_wall=418, gb_free=17.3, wall=0
2024-02-08 01:25:05 | INFO | train_inner | epoch 054:    240 / 405 loss=0.677, nll_loss=0.677, ppl=1.6, wps=2265.1, ups=0.22, wpb=10427, bsz=720.3, num_updates=170300, lr=0.000496603, gnorm=0.211, clip=0, train_wall=418, gb_free=17.4, wall=0
2024-02-08 01:32:56 | INFO | train_inner | epoch 054:    340 / 405 loss=0.669, nll_loss=0.669, ppl=1.59, wps=2199.4, ups=0.21, wpb=10355.2, bsz=705, num_updates=170400, lr=0.000495472, gnorm=0.215, clip=0, train_wall=417, gb_free=17, wall=0
2024-02-08 01:38:05 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-08 01:38:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-08 01:38:57 | INFO | dev | epoch 054 | valid on 'dev' subset | loss 1.117 | nll_loss 1.117 | ppl 2.17 | wps 4443.3 | wpb 1146.2 | bsz 77.6 | num_updates 170465 | best_loss 1.094
2024-02-08 01:38:57 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 54 @ 170465 updates
2024-02-08 01:38:57 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint54.pt
2024-02-08 01:38:58 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint54.pt
2024-02-08 01:39:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint54.pt (epoch 54 @ 170465 updates, score 1.117) (writing took 2.8630655659362674 seconds)
2024-02-08 01:39:00 | INFO | fairseq_cli.train | end of epoch 54 (average epoch stats below)
2024-02-08 01:39:00 | INFO | train | epoch 054 | loss 0.678 | nll_loss 0.678 | ppl 1.6 | wps 2227.3 | ups 0.21 | wpb 10406.1 | bsz 714.6 | num_updates 170465 | lr 0.000494738 | gnorm 0.213 | clip 0 | train_wall 1689 | gb_free 17.1 | wall 0
2024-02-08 01:39:00 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-08 01:39:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 405
2024-02-08 01:39:00 | INFO | fairseq.trainer | begin training epoch 55
2024-02-08 01:39:00 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-08 01:41:31 | INFO | train_inner | epoch 055:     35 / 405 loss=0.671, nll_loss=0.671, ppl=1.59, wps=2016.7, ups=0.19, wpb=10386.7, bsz=715.4, num_updates=170500, lr=0.000494343, gnorm=0.214, clip=0, train_wall=415, gb_free=17.5, wall=0
2024-02-08 01:48:29 | INFO | train_inner | epoch 055:    135 / 405 loss=0.667, nll_loss=0.667, ppl=1.59, wps=2496.9, ups=0.24, wpb=10453.1, bsz=723.8, num_updates=170600, lr=0.000493214, gnorm=0.213, clip=0, train_wall=418, gb_free=17.3, wall=0
2024-02-08 01:55:33 | INFO | train_inner | epoch 055:    235 / 405 loss=0.668, nll_loss=0.668, ppl=1.59, wps=2449.8, ups=0.24, wpb=10380.7, bsz=712.8, num_updates=170700, lr=0.000492086, gnorm=0.214, clip=0, train_wall=423, gb_free=17.5, wall=0
2024-02-08 02:02:41 | INFO | train_inner | epoch 055:    335 / 405 loss=0.666, nll_loss=0.666, ppl=1.59, wps=2436.6, ups=0.23, wpb=10421.5, bsz=716.2, num_updates=170800, lr=0.000490959, gnorm=0.214, clip=0, train_wall=418, gb_free=17.7, wall=0
2024-02-08 02:07:37 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-08 02:07:37 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-08 02:08:24 | INFO | dev | epoch 055 | valid on 'dev' subset | loss 1.129 | nll_loss 1.129 | ppl 2.19 | wps 4901.8 | wpb 1146.2 | bsz 77.6 | num_updates 170870 | best_loss 1.094
2024-02-08 02:08:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 55 @ 170870 updates
2024-02-08 02:08:24 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint55.pt
2024-02-08 02:08:26 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint55.pt
2024-02-08 02:08:27 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint55.pt (epoch 55 @ 170870 updates, score 1.129) (writing took 2.9740597000345588 seconds)
2024-02-08 02:08:27 | INFO | fairseq_cli.train | end of epoch 55 (average epoch stats below)
2024-02-08 02:08:27 | INFO | train | epoch 055 | loss 0.666 | nll_loss 0.666 | ppl 1.59 | wps 2384.4 | ups 0.23 | wpb 10406.1 | bsz 714.6 | num_updates 170870 | lr 0.00049017 | gnorm 0.214 | clip 0 | train_wall 1696 | gb_free 17.3 | wall 0
2024-02-08 02:08:27 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-08 02:08:27 | INFO | fairseq.data.iterators | grouped total_num_itrs = 405
2024-02-08 02:08:27 | INFO | fairseq.trainer | begin training epoch 56
2024-02-08 02:08:27 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-08 02:10:35 | INFO | train_inner | epoch 056:     30 / 405 loss=0.664, nll_loss=0.664, ppl=1.58, wps=2188, ups=0.21, wpb=10377.1, bsz=707, num_updates=170900, lr=0.000489832, gnorm=0.214, clip=0, train_wall=416, gb_free=17.3, wall=0
2024-02-08 02:17:34 | INFO | train_inner | epoch 056:    130 / 405 loss=0.655, nll_loss=0.655, ppl=1.57, wps=2480.2, ups=0.24, wpb=10382.4, bsz=707.9, num_updates=171000, lr=0.000488707, gnorm=0.215, clip=0, train_wall=418, gb_free=17.5, wall=0
2024-02-08 02:24:32 | INFO | train_inner | epoch 056:    230 / 405 loss=0.662, nll_loss=0.662, ppl=1.58, wps=2482.5, ups=0.24, wpb=10397.4, bsz=707.4, num_updates=171100, lr=0.000487582, gnorm=0.213, clip=0, train_wall=418, gb_free=17.3, wall=0
2024-02-08 02:31:33 | INFO | train_inner | epoch 056:    330 / 405 loss=0.663, nll_loss=0.663, ppl=1.58, wps=2480.9, ups=0.24, wpb=10445.5, bsz=723.1, num_updates=171200, lr=0.000486459, gnorm=0.216, clip=0, train_wall=420, gb_free=17.6, wall=0
2024-02-08 02:36:45 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-08 02:36:45 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-08 02:37:32 | INFO | dev | epoch 056 | valid on 'dev' subset | loss 1.129 | nll_loss 1.129 | ppl 2.19 | wps 4917.9 | wpb 1146.2 | bsz 77.6 | num_updates 171275 | best_loss 1.094
2024-02-08 02:37:32 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 56 @ 171275 updates
2024-02-08 02:37:32 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint56.pt
2024-02-08 02:37:34 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint56.pt
2024-02-08 02:37:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint56.pt (epoch 56 @ 171275 updates, score 1.129) (writing took 3.081254626857117 seconds)
2024-02-08 02:37:35 | INFO | fairseq_cli.train | end of epoch 56 (average epoch stats below)
2024-02-08 02:37:35 | INFO | train | epoch 056 | loss 0.661 | nll_loss 0.661 | ppl 1.58 | wps 2410.7 | ups 0.23 | wpb 10406.1 | bsz 714.6 | num_updates 171275 | lr 0.000485617 | gnorm 0.215 | clip 0 | train_wall 1693 | gb_free 17.7 | wall 0
2024-02-08 02:37:35 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-08 02:37:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 405
2024-02-08 02:37:35 | INFO | fairseq.trainer | begin training epoch 57
2024-02-08 02:37:35 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-08 02:39:22 | INFO | train_inner | epoch 057:     25 / 405 loss=0.663, nll_loss=0.663, ppl=1.58, wps=2223.7, ups=0.21, wpb=10416.6, bsz=727.7, num_updates=171300, lr=0.000485336, gnorm=0.214, clip=0, train_wall=415, gb_free=17.4, wall=0
2024-02-08 02:46:21 | INFO | train_inner | epoch 057:    125 / 405 loss=0.654, nll_loss=0.654, ppl=1.57, wps=2496.6, ups=0.24, wpb=10458.5, bsz=722.8, num_updates=171400, lr=0.000484214, gnorm=0.214, clip=0, train_wall=418, gb_free=17.2, wall=0
2024-02-08 02:53:19 | INFO | train_inner | epoch 057:    225 / 405 loss=0.658, nll_loss=0.658, ppl=1.58, wps=2481.6, ups=0.24, wpb=10374.8, bsz=711.3, num_updates=171500, lr=0.000483093, gnorm=0.219, clip=0, train_wall=417, gb_free=17, wall=0
2024-02-08 03:00:19 | INFO | train_inner | epoch 057:    325 / 405 loss=0.658, nll_loss=0.658, ppl=1.58, wps=2484.8, ups=0.24, wpb=10437.1, bsz=715.4, num_updates=171600, lr=0.000481973, gnorm=0.215, clip=0, train_wall=419, gb_free=17.2, wall=0
2024-02-08 03:05:52 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-08 03:05:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-08 03:06:35 | INFO | dev | epoch 057 | valid on 'dev' subset | loss 1.132 | nll_loss 1.132 | ppl 2.19 | wps 5367.9 | wpb 1146.2 | bsz 77.6 | num_updates 171680 | best_loss 1.094
2024-02-08 03:06:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 57 @ 171680 updates
2024-02-08 03:06:35 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint57.pt
2024-02-08 03:06:36 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint57.pt
2024-02-08 03:06:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint57.pt (epoch 57 @ 171680 updates, score 1.132) (writing took 2.7344550010748208 seconds)
2024-02-08 03:06:37 | INFO | fairseq_cli.train | end of epoch 57 (average epoch stats below)
2024-02-08 03:06:37 | INFO | train | epoch 057 | loss 0.656 | nll_loss 0.656 | ppl 1.58 | wps 2419.3 | ups 0.23 | wpb 10406.1 | bsz 714.6 | num_updates 171680 | lr 0.000481078 | gnorm 0.217 | clip 0 | train_wall 1691 | gb_free 17.4 | wall 0
2024-02-08 03:06:37 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-08 03:06:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 405
2024-02-08 03:06:38 | INFO | fairseq.trainer | begin training epoch 58
2024-02-08 03:06:38 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-08 03:08:06 | INFO | train_inner | epoch 058:     20 / 405 loss=0.66, nll_loss=0.66, ppl=1.58, wps=2216.4, ups=0.21, wpb=10348.5, bsz=701.7, num_updates=171700, lr=0.000480854, gnorm=0.221, clip=0, train_wall=418, gb_free=17.1, wall=0
2024-02-08 03:15:04 | INFO | train_inner | epoch 058:    120 / 405 loss=0.645, nll_loss=0.645, ppl=1.56, wps=2477.5, ups=0.24, wpb=10370, bsz=704.7, num_updates=171800, lr=0.000479735, gnorm=0.217, clip=0, train_wall=418, gb_free=16.7, wall=0
2024-02-08 03:22:03 | INFO | train_inner | epoch 058:    220 / 405 loss=0.656, nll_loss=0.656, ppl=1.58, wps=2485.9, ups=0.24, wpb=10417.1, bsz=719.8, num_updates=171900, lr=0.000478618, gnorm=0.219, clip=0, train_wall=418, gb_free=17.4, wall=0
2024-02-08 03:29:02 | INFO | train_inner | epoch 058:    320 / 405 loss=0.655, nll_loss=0.655, ppl=1.57, wps=2496.4, ups=0.24, wpb=10445.9, bsz=719.4, num_updates=172000, lr=0.000477501, gnorm=0.219, clip=0, train_wall=418, gb_free=17.4, wall=0
2024-02-08 03:34:55 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-08 03:34:55 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-08 03:35:49 | INFO | dev | epoch 058 | valid on 'dev' subset | loss 1.132 | nll_loss 1.132 | ppl 2.19 | wps 4305.1 | wpb 1146.2 | bsz 77.6 | num_updates 172085 | best_loss 1.094
2024-02-08 03:35:49 | INFO | fairseq_cli.train | early stop since valid performance hasn't improved for last 5 runs
2024-02-08 03:35:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 58 @ 172085 updates
2024-02-08 03:35:49 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint58.pt
2024-02-08 03:35:50 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint58.pt
2024-02-08 03:35:52 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint58.pt (epoch 58 @ 172085 updates, score 1.132) (writing took 3.198427092982456 seconds)
2024-02-08 03:35:52 | INFO | fairseq_cli.train | end of epoch 58 (average epoch stats below)
2024-02-08 03:35:52 | INFO | train | epoch 058 | loss 0.654 | nll_loss 0.654 | ppl 1.57 | wps 2402.3 | ups 0.23 | wpb 10406.1 | bsz 714.6 | num_updates 172085 | lr 0.000476553 | gnorm 0.218 | clip 0 | train_wall 1692 | gb_free 16.9 | wall 0
2024-02-08 03:35:52 | INFO | fairseq_cli.train | done training in 10053.0 seconds
Training complete.
Finetuning complete.
----------------------------------------------------------
Transcribing the test set...
Starting transcription...
Average checkpoints...
Checkpoints folder: /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models
Checkpoint path: /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
Namespace(inputs=['/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models'], output='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', num_epoch_checkpoints=5, num_update_checkpoints=None, num_best_checkpoints=0, checkpoint_upper_bound=None)
averaging checkpoints:  ['/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint58.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint57.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint56.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint55.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint54.pt']
Finished writing averaged checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
Checkpoints averaged
Generating transcriptions...
Test subset: test
Data directory: /pfs/work7/workspace/scratch/uxude-ASR/dataset/covost
Prediction output directory: /home/kit/stud/uxude/predictions/finetune_asr_covost
DEBUG:hydra.core.utils:Setting JobRuntime:name=UNKNOWN_NAME
DEBUG:hydra.core.utils:Setting JobRuntime:name=utils
INFO:fairseq_cli.generate:{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 50000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 8, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all'}, 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', simul_type=None, scoring='wer', task='speech_to_text', num_workers=1, skip_invalid_size_inputs_valid_test=True, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, path='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', post_process=None, quiet=False, model_overrides='{}', results_path=None, beam=8, beam_mt=0, nbest=1, max_len_a=0, max_len_b=200, max_len_a_mt=0, max_len_b_mt=200, min_len=1, match_source_len=False, unnormalized=False, no_early_stop=False, no_beamable_mm=False, lenpen=1, lenpen_mt=1, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=None, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, no_seed_provided=False, eos_token=None, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, arch='wav2vec2', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, force_anneal=None, lr_shrink=0.1, warmup_updates=0, wer_tokenizer='none', wer_remove_punct=False, wer_char_level=False, wer_lowercase=False, _name='speech_to_text'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'wer', 'wer_tokenizer': 'none', 'wer_remove_punct': False, 'wer_char_level': False, 'wer_lowercase': False}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
INFO:fairseq.tasks.speech_to_text:dictionary size (spm.asr.txt): 5,000
INFO:fairseq_cli.generate:loading model(s) from /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
INFO:fairseq.tasks.speech_to_text:pre-tokenizer: {'tokenizer': None}
INFO:fairseq.tasks.speech_to_text:tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
WARNING:fairseq.data.audio.data_cfg:Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
INFO:fairseq.data.audio.speech_to_text_dataset:'test' has 0.00% OOV
INFO:fairseq.data.audio.speech_to_text_dataset:SpeechToTextDataset(split="test", n_samples=15_531, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
INFO:fairseq.tasks.fairseq_task:can_reuse_epoch_itr = True
INFO:fairseq.tasks.fairseq_task:reuse_dataloader = True
INFO:fairseq.tasks.fairseq_task:rebuild_batches = False
INFO:fairseq.tasks.fairseq_task:creating new batches for epoch 1
WARNING:fairseq.tasks.fairseq_task:5 samples have invalid sizes and will be skipped, max_positions=(6000, 1024), first few sample ids=[11198, 697, 6107, 3431, 14638]
INFO:fairseq.tasks.speech_to_text:pre-tokenizer: {'tokenizer': None}
INFO:fairseq.tasks.speech_to_text:tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
INFO:fairseq.logging.progress_bar::    101 / 188 wps=591
DEBUG:fairseq.data.iterators:Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.
INFO:fairseq_cli.generate:NOTE: hypothesis and token scores are output in base 2
INFO:fairseq_cli.generate:Translated 15,520 sentences (205,007 tokens) in 91.0s (170.51 sentences/s, 2252.26 tokens/s)
Transcription done
Prediction files written for /home/kit/stud/uxude/predictions/finetune_asr_covost/hyp_asr.txt and /home/kit/stud/uxude/predictions/finetune_asr_covost/ref_asr.txt
Sampled predictions written to /home/kit/stud/uxude/predictions/finetune_asr_covost/hyp_asr.txt.sampled
Sample predictions:
Sample: for some reasons we were dropped from enduring
Reference: for some reason we were blocked from entering
Sample: as they sat down at the only table in the place the crystal much of the earth
Reference: as they sat down at the only table in the place the crystal merchant laughed
Sample: a never more way of a word between six more or five
Reference: im never more aware of a rooms acoustics than when im trying to enjoy a snack i have no intention of sharing
Sample: how am i to get started on
Reference: aw man thats terrible
Sample: its a dream in the language of the world she said
Reference: its a dream in the language of the world she said
Sample: this looks amazing
Reference: this looks amazing
Sample: the army climbed up the rebuilding and rafted itself around the chimney
Reference: the ivy climbed up the building and wrapped itself around the chimney
Sample: nonverbal communication is sometimes more meaningful than the spoken words
Reference: nonverbal communication is sometimes more meaningful than the spoken words
Sample: the whole the sheep cried
Reference: the hull of the ship collapsed
Sample: the cam driver understood while the boy was saying
Reference: the camel driver understood what the boy was saying
Sample: a fair plague doesnt aback
Reference: her hair flowed down her back
Sample: advancing slowly absorbs the mountain with snow drifting and water
Reference: advancing slowly they searched among the stones
Sample: maybe the church with a sycamore groan from it then had been haunted
Reference: maybe the church with the sycamore growing from within had been haunted
Sample: the boy knew a lot of people in the city
Reference: the boy knew a lot of people in the city
Sample: if everything works youll see a window pop up the story
Reference: if everything works youll see a window pop up after starting
Sample: then you taught me something of the universe of language and the soul of the world
Reference: then you taught me something of the universal language and the soul of the world
Sample: the term just my two sense is about a bone
Reference: the term just my two cents is about opinion not about money
Sample: the floor was dubbed
Reference: the drawer was stuck closed
Sample: the woman was saving for some time
Reference: the woman was silent for some time
Sample: they were rarely sighting or prehanded people elbling one another
Reference: there were really i think two or three hundred people elbowing one another
WER:
Generate test with beam=8: WER: 30.35
BLEU:
{
 "name": "BLEU",
 "score": 55.7,
 "signature": "nrefs:1|case:mixed|eff:no|tok:none|smooth:none|version:2.4.0",
 "verbose_score": "73.2/60.4/50.7/42.8 (BP = 1.000 ratio = 1.010 hyp_len = 142615 ref_len = 141203)",
 "nrefs": "1",
 "case": "mixed",
 "eff": "no",
 "tok": "none",
 "smooth": "none",
 "version": "2.4.0"
}