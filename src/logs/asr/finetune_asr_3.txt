(base) [uxude@uc2n994 train]$ cat finetune_asr_covost_23115498.txt
No extension needed for workspace ASR.
No extension needed for workspace MT.
Fairseq directory exists. Checking if installed...
fairseq                  0.12.2       /home/kit/stud/uxude/fairseq
Fairseq is already installed. Skipping installation.
Setup complete. Starting script execution...
[INFO] 12:45:50 [Dataset::Prepare Datasets]: Skipping dataset preparation, all config data already exists
Finetuning the ASR model...
Training the model...
Model will be stored in /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models
Training time: 30 hours
Training subset: train
Validation subset: dev
Data directory: /pfs/work7/workspace/scratch/uxude-ASR/dataset/covost
2024-02-06 12:46:10 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 4, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 50000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'dev', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 500, 'max_update': 0, 'stop_time_hours': 30.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 50000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 5, 'keep_best_checkpoints': 5, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_text', num_workers=4, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2t_conformer', max_epoch=500, max_update=0, stop_time_hours=30.0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.002], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=50000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=5, keep_best_checkpoints=5, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, label_smoothing=0.0, report_accuracy=False, ignore_prefix_size=0, adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, pos_enc_type='rel_pos', attn_type='espnet', no_seed_provided=False, input_feat_per_channel=80, input_channels=1, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, dropout=0.1, encoder_layers=16, depthwise_conv_kernel_size=31, encoder_freezing_updates=0, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_normalize_before=True, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.1, activation_dropout=0.1, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, no_scale_embedding=False, quant_noise_pq=0, _name='s2t_conformer'), 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_text', num_workers=4, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2t_conformer', max_epoch=500, max_update=0, stop_time_hours=30.0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.002], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=50000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=5, keep_best_checkpoints=5, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, label_smoothing=0.0, report_accuracy=False, ignore_prefix_size=0, adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, pos_enc_type='rel_pos', attn_type='espnet', no_seed_provided=False, input_feat_per_channel=80, input_channels=1, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, dropout=0.1, encoder_layers=16, depthwise_conv_kernel_size=31, encoder_freezing_updates=0, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_normalize_before=True, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.1, activation_dropout=0.1, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, no_scale_embedding=False, quant_noise_pq=0, _name='speech_to_text'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.0, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 10000, 'warmup_init_lr': -1.0, 'lr': [0.002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-02-06 12:46:10 | INFO | fairseq.tasks.speech_to_text | dictionary size (spm.asr.txt): 5,000
2024-02-06 12:46:14 | INFO | fairseq_cli.train | S2TConformerModel(
  (encoder): S2TConformerEncoder(
    (subsample): Conv1dSubsampler(
      (conv_layers): ModuleList(
        (0): Conv1d(80, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        (1): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
      )
    )
    (embed_positions): RelPositionalEncoding()
    (linear): Linear(in_features=256, out_features=256, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (conformer_layers): ModuleList(
      (0-15): 16 x ConformerEncoderLayer(
        (ffn1): FeedForwardModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (activation): SiLU(inplace=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (self_attn_dropout): Dropout(p=0.1, inplace=False)
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (conv_module): ConvolutionModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
          (glu): GLU(dim=1)
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256, bias=False)
          (batch_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): SiLU(inplace=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn2): FeedForwardModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (activation): SiLU(inplace=True)
        )
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(5000, 256, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=256, out_features=5000, bias=False)
  )
)
2024-02-06 12:46:14 | INFO | fairseq_cli.train | task: SpeechToTextTask
2024-02-06 12:46:14 | INFO | fairseq_cli.train | model: S2TConformerModel
2024-02-06 12:46:14 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2024-02-06 12:46:14 | INFO | fairseq_cli.train | num. shared model params: 54,758,144 (num. trained: 54,758,144)
2024-02-06 12:46:14 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2024-02-06 12:46:14 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2024-02-06 12:46:14 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
2024-02-06 12:46:14 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
2024-02-06 12:46:14 | INFO | fairseq.data.audio.speech_to_text_dataset | 'dev' has 0.00% OOV
2024-02-06 12:46:14 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split="dev", n_samples=15_531, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.pointwise_conv1.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.depthwise_conv.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.pointwise_conv2.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.self_attn.linear_pos.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.pointwise_conv1.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.depthwise_conv.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.pointwise_conv2.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.self_attn.linear_pos.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.pointwise_conv1.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.depthwise_conv.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.pointwise_conv2.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.self_attn.linear_pos.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.pointwise_conv1.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.depthwise_conv.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.pointwise_conv2.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.self_attn.linear_pos.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.pointwise_conv1.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.depthwise_conv.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.pointwise_conv2.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.self_attn.linear_pos.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.pointwise_conv1.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.depthwise_conv.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.pointwise_conv2.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.self_attn.linear_pos.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.pointwise_conv1.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.depthwise_conv.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.pointwise_conv2.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.self_attn.linear_pos.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.pointwise_conv1.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.depthwise_conv.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.pointwise_conv2.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.self_attn.linear_pos.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.pointwise_conv1.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.depthwise_conv.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.pointwise_conv2.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.self_attn.linear_pos.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.pointwise_conv1.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.depthwise_conv.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.pointwise_conv2.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.self_attn.linear_pos.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.pointwise_conv1.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.depthwise_conv.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.pointwise_conv2.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.self_attn.linear_pos.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.pointwise_conv1.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.depthwise_conv.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.pointwise_conv2.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.self_attn.linear_pos.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.pointwise_conv1.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.depthwise_conv.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.pointwise_conv2.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.self_attn.linear_pos.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.pointwise_conv1.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.depthwise_conv.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.pointwise_conv2.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.self_attn.linear_pos.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.pointwise_conv1.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.depthwise_conv.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.pointwise_conv2.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.self_attn.linear_pos.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.pointwise_conv1.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.depthwise_conv.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.pointwise_conv2.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- decoder.output_projection.bias
2024-02-06 12:46:15 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-02-06 12:46:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-02-06 12:46:15 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 31.739 GB ; name = Tesla V100-SXM2-32GB
2024-02-06 12:46:15 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-02-06 12:46:15 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-02-06 12:46:15 | INFO | fairseq_cli.train | max tokens per device = 50000 and max sentences per device = None
2024-02-06 12:46:15 | INFO | fairseq.trainer | Preparing to load checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt
2024-02-06 12:46:18 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2024-02-06 12:46:21 | INFO | fairseq.trainer | Loaded checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt (epoch 31 @ 97640 updates)
2024-02-06 12:46:21 | INFO | fairseq.trainer | loading train data for epoch 31
2024-02-06 12:46:21 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2024-02-06 12:46:21 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
2024-02-06 12:46:24 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
2024-02-06 12:46:29 | INFO | fairseq.data.audio.speech_to_text_dataset | 'train' has 0.00% OOV
2024-02-06 12:46:29 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split="train", n_samples=289_421, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
    SpecAugmentTransform(time_warp_w=0, freq_mask_n=1, freq_mask_f=27, time_mask_n=1, time_mask_t=100, time_mask_p=1.0)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
2024-02-06 12:46:29 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 12:46:29 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-02-06 12:46:29 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-02-06 12:46:29 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 31
/home/kit/stud/uxude/miniconda3/envs/nmt/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2024-02-06 12:46:31 | INFO | fairseq_cli.train | begin dry-run validation on "dev" subset
2024-02-06 12:46:31 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 12:46:31 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-02-06 12:46:31 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-02-06 12:46:31 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
2024-02-06 12:48:17 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 12:48:17 | INFO | fairseq.trainer | begin training epoch 31
2024-02-06 12:48:17 | INFO | fairseq_cli.train | Start iterating over samples
/home/kit/stud/uxude/miniconda3/envs/nmt/lib/python3.10/site-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/home/kit/stud/uxude/fairseq/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-02-06 12:49:17 | INFO | train_inner | epoch 031:    620 / 3236 loss=0.921, nll_loss=0.921, ppl=1.89, wps=558.7, ups=0.43, wpb=1292.7, bsz=86.2, num_updates=97700, lr=0.000639857, gnorm=0.614, train_wall=79, gb_free=18.3, wall=0
2024-02-06 12:50:25 | INFO | train_inner | epoch 031:    720 / 3236 loss=0.928, nll_loss=0.928, ppl=1.9, wps=1926, ups=1.46, wpb=1316.5, bsz=89.4, num_updates=97800, lr=0.000639529, gnorm=0.583, train_wall=57, gb_free=17.7, wall=0
2024-02-06 12:51:26 | INFO | train_inner | epoch 031:    820 / 3236 loss=0.931, nll_loss=0.931, ppl=1.91, wps=2156, ups=1.66, wpb=1299, bsz=83.1, num_updates=97900, lr=0.000639203, gnorm=0.597, train_wall=56, gb_free=18.2, wall=0
2024-02-06 12:52:37 | INFO | train_inner | epoch 031:    920 / 3236 loss=0.973, nll_loss=0.973, ppl=1.96, wps=1841.9, ups=1.39, wpb=1320.8, bsz=99.1, num_updates=98000, lr=0.000638877, gnorm=0.6, train_wall=56, gb_free=17.6, wall=0
2024-02-06 12:53:44 | INFO | train_inner | epoch 031:   1020 / 3236 loss=0.935, nll_loss=0.935, ppl=1.91, wps=1982.7, ups=1.51, wpb=1317.1, bsz=94.2, num_updates=98100, lr=0.000638551, gnorm=0.577, train_wall=56, gb_free=17.2, wall=0
2024-02-06 12:54:42 | INFO | train_inner | epoch 031:   1120 / 3236 loss=0.911, nll_loss=0.911, ppl=1.88, wps=2203.5, ups=1.71, wpb=1292, bsz=86.4, num_updates=98200, lr=0.000638226, gnorm=0.602, train_wall=56, gb_free=18.3, wall=0
2024-02-06 12:55:46 | INFO | train_inner | epoch 031:   1220 / 3236 loss=0.951, nll_loss=0.951, ppl=1.93, wps=2075.8, ups=1.58, wpb=1311, bsz=92.6, num_updates=98300, lr=0.000637901, gnorm=0.588, train_wall=57, gb_free=17.7, wall=0
2024-02-06 12:56:53 | INFO | train_inner | epoch 031:   1320 / 3236 loss=0.94, nll_loss=0.94, ppl=1.92, wps=1951.8, ups=1.49, wpb=1310.1, bsz=91.8, num_updates=98400, lr=0.000637577, gnorm=0.59, train_wall=56, gb_free=18.3, wall=0
2024-02-06 12:57:58 | INFO | train_inner | epoch 031:   1420 / 3236 loss=0.927, nll_loss=0.927, ppl=1.9, wps=1997.8, ups=1.53, wpb=1306.3, bsz=88.7, num_updates=98500, lr=0.000637253, gnorm=0.595, train_wall=56, gb_free=18.5, wall=0
2024-02-06 12:59:00 | INFO | train_inner | epoch 031:   1520 / 3236 loss=0.95, nll_loss=0.95, ppl=1.93, wps=2091.1, ups=1.62, wpb=1288.5, bsz=85.8, num_updates=98600, lr=0.00063693, gnorm=0.598, train_wall=56, gb_free=18.3, wall=0
2024-02-06 13:00:06 | INFO | train_inner | epoch 031:   1620 / 3236 loss=0.945, nll_loss=0.945, ppl=1.93, wps=1936.5, ups=1.5, wpb=1288.7, bsz=89, num_updates=98700, lr=0.000636607, gnorm=0.618, train_wall=57, gb_free=18, wall=0
2024-02-06 13:01:09 | INFO | train_inner | epoch 031:   1720 / 3236 loss=0.944, nll_loss=0.944, ppl=1.92, wps=2085.9, ups=1.6, wpb=1302.7, bsz=87.4, num_updates=98800, lr=0.000636285, gnorm=0.609, train_wall=56, gb_free=18.1, wall=0
2024-02-06 13:02:11 | INFO | train_inner | epoch 031:   1820 / 3236 loss=0.968, nll_loss=0.968, ppl=1.96, wps=2100.5, ups=1.61, wpb=1308.2, bsz=88.4, num_updates=98900, lr=0.000635963, gnorm=0.603, train_wall=56, gb_free=17.6, wall=0
2024-02-06 13:03:15 | INFO | train_inner | epoch 031:   1920 / 3236 loss=0.964, nll_loss=0.964, ppl=1.95, wps=2050.5, ups=1.56, wpb=1313.4, bsz=94.6, num_updates=99000, lr=0.000635642, gnorm=0.588, train_wall=56, gb_free=18.1, wall=0
2024-02-06 13:04:14 | INFO | train_inner | epoch 031:   2020 / 3236 loss=0.954, nll_loss=0.954, ppl=1.94, wps=2222.2, ups=1.69, wpb=1318, bsz=88.6, num_updates=99100, lr=0.000635321, gnorm=0.602, train_wall=56, gb_free=18, wall=0
2024-02-06 13:05:24 | INFO | train_inner | epoch 031:   2120 / 3236 loss=0.957, nll_loss=0.957, ppl=1.94, wps=1858.4, ups=1.43, wpb=1295.7, bsz=89.7, num_updates=99200, lr=0.000635001, gnorm=0.601, train_wall=64, gb_free=17.7, wall=0
2024-02-06 13:06:36 | INFO | train_inner | epoch 031:   2220 / 3236 loss=0.964, nll_loss=0.964, ppl=1.95, wps=1780, ups=1.38, wpb=1286.5, bsz=88.6, num_updates=99300, lr=0.000634681, gnorm=0.612, train_wall=57, gb_free=18.7, wall=0
2024-02-06 13:07:52 | INFO | train_inner | epoch 031:   2320 / 3236 loss=0.97, nll_loss=0.97, ppl=1.96, wps=1732.7, ups=1.33, wpb=1304.5, bsz=92.4, num_updates=99400, lr=0.000634361, gnorm=0.599, train_wall=56, gb_free=18.3, wall=0
2024-02-06 13:09:04 | INFO | train_inner | epoch 031:   2420 / 3236 loss=0.962, nll_loss=0.962, ppl=1.95, wps=1773.8, ups=1.37, wpb=1293.1, bsz=90.7, num_updates=99500, lr=0.000634043, gnorm=0.604, train_wall=56, gb_free=17.7, wall=0
2024-02-06 13:10:18 | INFO | train_inner | epoch 031:   2520 / 3236 loss=0.953, nll_loss=0.953, ppl=1.94, wps=1766.9, ups=1.36, wpb=1300.3, bsz=89.6, num_updates=99600, lr=0.000633724, gnorm=0.598, train_wall=56, gb_free=18.2, wall=0
2024-02-06 13:11:22 | INFO | train_inner | epoch 031:   2620 / 3236 loss=0.979, nll_loss=0.979, ppl=1.97, wps=2032, ups=1.55, wpb=1308.3, bsz=88.6, num_updates=99700, lr=0.000633406, gnorm=0.609, train_wall=56, gb_free=18.2, wall=0
2024-02-06 13:12:33 | INFO | train_inner | epoch 031:   2720 / 3236 loss=0.967, nll_loss=0.967, ppl=1.95, wps=1857.3, ups=1.42, wpb=1306.7, bsz=91.9, num_updates=99800, lr=0.000633089, gnorm=0.597, train_wall=57, gb_free=18, wall=0
2024-02-06 13:13:33 | INFO | train_inner | epoch 031:   2820 / 3236 loss=0.958, nll_loss=0.958, ppl=1.94, wps=2165, ups=1.67, wpb=1299.7, bsz=85.8, num_updates=99900, lr=0.000632772, gnorm=0.595, train_wall=56, gb_free=18.2, wall=0
2024-02-06 13:14:33 | INFO | train_inner | epoch 031:   2920 / 3236 loss=0.967, nll_loss=0.967, ppl=1.95, wps=2171.3, ups=1.67, wpb=1303.1, bsz=90.2, num_updates=100000, lr=0.000632456, gnorm=0.606, train_wall=57, gb_free=18.1, wall=0
2024-02-06 13:14:33 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 13:14:33 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 13:15:45 | INFO | dev | epoch 031 | valid on 'dev' subset | loss 1.114 | nll_loss 1.114 | ppl 2.16 | wps 3235.5 | wpb 1146.2 | bsz 77.6 | num_updates 100000 | best_loss 1.096
2024-02-06 13:15:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 100000 updates
2024-02-06 13:15:45 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_31_100000.pt
2024-02-06 13:15:47 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_31_100000.pt
2024-02-06 13:15:49 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_31_100000.pt (epoch 31 @ 100000 updates, score 1.114) (writing took 3.299795025959611 seconds)
2024-02-06 13:16:45 | INFO | train_inner | epoch 031:   3020 / 3236 loss=0.979, nll_loss=0.979, ppl=1.97, wps=979, ups=0.76, wpb=1296.6, bsz=89.6, num_updates=100100, lr=0.00063214, gnorm=0.617, train_wall=56, gb_free=18.3, wall=0
2024-02-06 13:17:42 | INFO | train_inner | epoch 031:   3120 / 3236 loss=0.973, nll_loss=0.973, ppl=1.96, wps=2287.7, ups=1.77, wpb=1291, bsz=87.6, num_updates=100200, lr=0.000631824, gnorm=0.608, train_wall=56, gb_free=18.5, wall=0
2024-02-06 13:18:38 | INFO | train_inner | epoch 031:   3220 / 3236 loss=0.954, nll_loss=0.954, ppl=1.94, wps=2286.8, ups=1.77, wpb=1291, bsz=86.8, num_updates=100300, lr=0.000631509, gnorm=0.592, train_wall=56, gb_free=17.9, wall=0
2024-02-06 13:18:47 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 13:18:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 13:19:20 | INFO | dev | epoch 031 | valid on 'dev' subset | loss 1.108 | nll_loss 1.108 | ppl 2.16 | wps 7139.5 | wpb 1146.2 | bsz 77.6 | num_updates 100316 | best_loss 1.096
2024-02-06 13:19:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 100316 updates
2024-02-06 13:19:20 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint31.pt
2024-02-06 13:19:21 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint31.pt
2024-02-06 13:19:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint31.pt (epoch 31 @ 100316 updates, score 1.108) (writing took 3.119569718139246 seconds)
2024-02-06 13:19:23 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2024-02-06 13:19:23 | INFO | train | epoch 031 | loss 0.948 | nll_loss 0.948 | ppl 1.93 | wps 1805.2 | ups 1.39 | wpb 1302.4 | bsz 89.4 | num_updates 100316 | lr 0.000631459 | gnorm 0.599 | train_wall 1851 | gb_free 18 | wall 0
2024-02-06 13:19:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 13:19:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 13:19:23 | INFO | fairseq.trainer | begin training epoch 32
2024-02-06 13:19:23 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 13:20:13 | INFO | train_inner | epoch 032:     84 / 3236 loss=0.902, nll_loss=0.902, ppl=1.87, wps=1377.9, ups=1.05, wpb=1313.1, bsz=94.6, num_updates=100400, lr=0.000631194, gnorm=0.583, train_wall=56, gb_free=17.7, wall=0
2024-02-06 13:21:10 | INFO | train_inner | epoch 032:    184 / 3236 loss=0.901, nll_loss=0.901, ppl=1.87, wps=2272.6, ups=1.76, wpb=1293.9, bsz=90, num_updates=100500, lr=0.00063088, gnorm=0.586, train_wall=56, gb_free=17.3, wall=0
2024-02-06 13:22:07 | INFO | train_inner | epoch 032:    284 / 3236 loss=0.913, nll_loss=0.913, ppl=1.88, wps=2286.3, ups=1.76, wpb=1297.4, bsz=87.5, num_updates=100600, lr=0.000630567, gnorm=0.605, train_wall=56, gb_free=18.4, wall=0
2024-02-06 13:23:04 | INFO | train_inner | epoch 032:    384 / 3236 loss=0.924, nll_loss=0.924, ppl=1.9, wps=2300.5, ups=1.76, wpb=1305.1, bsz=100.4, num_updates=100700, lr=0.000630253, gnorm=0.596, train_wall=56, gb_free=17.9, wall=0
2024-02-06 13:24:01 | INFO | train_inner | epoch 032:    484 / 3236 loss=0.924, nll_loss=0.924, ppl=1.9, wps=2270.7, ups=1.76, wpb=1291.7, bsz=87, num_updates=100800, lr=0.000629941, gnorm=0.601, train_wall=56, gb_free=18.5, wall=0
2024-02-06 13:24:58 | INFO | train_inner | epoch 032:    584 / 3236 loss=0.913, nll_loss=0.913, ppl=1.88, wps=2300.4, ups=1.76, wpb=1307.8, bsz=89.6, num_updates=100900, lr=0.000629629, gnorm=0.605, train_wall=56, gb_free=18.1, wall=0
2024-02-06 13:25:55 | INFO | train_inner | epoch 032:    684 / 3236 loss=0.926, nll_loss=0.926, ppl=1.9, wps=2297.4, ups=1.75, wpb=1309.5, bsz=93.8, num_updates=101000, lr=0.000629317, gnorm=0.596, train_wall=56, gb_free=18.6, wall=0
2024-02-06 13:26:52 | INFO | train_inner | epoch 032:    784 / 3236 loss=0.921, nll_loss=0.921, ppl=1.89, wps=2285.7, ups=1.76, wpb=1301.1, bsz=90.2, num_updates=101100, lr=0.000629005, gnorm=0.597, train_wall=56, gb_free=18.3, wall=0
2024-02-06 13:27:48 | INFO | train_inner | epoch 032:    884 / 3236 loss=0.928, nll_loss=0.928, ppl=1.9, wps=2310.2, ups=1.76, wpb=1312.5, bsz=92.7, num_updates=101200, lr=0.000628695, gnorm=0.603, train_wall=56, gb_free=17.3, wall=0
2024-02-06 13:28:45 | INFO | train_inner | epoch 032:    984 / 3236 loss=0.906, nll_loss=0.906, ppl=1.87, wps=2272.8, ups=1.75, wpb=1295.1, bsz=84.2, num_updates=101300, lr=0.000628384, gnorm=0.607, train_wall=56, gb_free=18.3, wall=0
2024-02-06 13:29:42 | INFO | train_inner | epoch 032:   1084 / 3236 loss=0.941, nll_loss=0.941, ppl=1.92, wps=2300, ups=1.77, wpb=1299.5, bsz=92.2, num_updates=101400, lr=0.000628074, gnorm=0.601, train_wall=56, gb_free=18.1, wall=0
2024-02-06 13:30:39 | INFO | train_inner | epoch 032:   1184 / 3236 loss=0.958, nll_loss=0.958, ppl=1.94, wps=2295.7, ups=1.75, wpb=1313.8, bsz=91.4, num_updates=101500, lr=0.000627765, gnorm=0.605, train_wall=57, gb_free=18.3, wall=0
2024-02-06 13:31:36 | INFO | train_inner | epoch 032:   1284 / 3236 loss=0.938, nll_loss=0.938, ppl=1.92, wps=2344.4, ups=1.77, wpb=1325.9, bsz=93.8, num_updates=101600, lr=0.000627456, gnorm=0.603, train_wall=56, gb_free=18, wall=0
2024-02-06 13:32:33 | INFO | train_inner | epoch 032:   1384 / 3236 loss=0.937, nll_loss=0.937, ppl=1.92, wps=2270.3, ups=1.75, wpb=1295, bsz=85.4, num_updates=101700, lr=0.000627147, gnorm=0.619, train_wall=56, gb_free=18.3, wall=0
2024-02-06 13:33:29 | INFO | train_inner | epoch 032:   1484 / 3236 loss=0.932, nll_loss=0.932, ppl=1.91, wps=2310, ups=1.76, wpb=1312.5, bsz=88.3, num_updates=101800, lr=0.000626839, gnorm=0.585, train_wall=56, gb_free=18.4, wall=0
2024-02-06 13:34:26 | INFO | train_inner | epoch 032:   1584 / 3236 loss=0.934, nll_loss=0.934, ppl=1.91, wps=2299.1, ups=1.76, wpb=1307.8, bsz=87.5, num_updates=101900, lr=0.000626531, gnorm=0.609, train_wall=56, gb_free=17.7, wall=0
2024-02-06 13:35:23 | INFO | train_inner | epoch 032:   1684 / 3236 loss=0.941, nll_loss=0.941, ppl=1.92, wps=2305.5, ups=1.76, wpb=1308.2, bsz=89.9, num_updates=102000, lr=0.000626224, gnorm=0.589, train_wall=56, gb_free=18, wall=0
2024-02-06 13:36:20 | INFO | train_inner | epoch 032:   1784 / 3236 loss=0.917, nll_loss=0.917, ppl=1.89, wps=2305.1, ups=1.76, wpb=1307.2, bsz=89.5, num_updates=102100, lr=0.000625918, gnorm=0.593, train_wall=56, gb_free=17.9, wall=0
2024-02-06 13:37:17 | INFO | train_inner | epoch 032:   1884 / 3236 loss=0.946, nll_loss=0.946, ppl=1.93, wps=2309.9, ups=1.76, wpb=1310.3, bsz=93.7, num_updates=102200, lr=0.000625611, gnorm=0.597, train_wall=56, gb_free=17.9, wall=0
2024-02-06 13:38:13 | INFO | train_inner | epoch 032:   1984 / 3236 loss=0.921, nll_loss=0.921, ppl=1.89, wps=2286.7, ups=1.76, wpb=1301.5, bsz=89.2, num_updates=102300, lr=0.000625305, gnorm=0.598, train_wall=56, gb_free=17.8, wall=0
2024-02-06 13:39:10 | INFO | train_inner | epoch 032:   2084 / 3236 loss=0.939, nll_loss=0.939, ppl=1.92, wps=2272.7, ups=1.75, wpb=1296.4, bsz=86.2, num_updates=102400, lr=0.000625, gnorm=0.618, train_wall=56, gb_free=17.5, wall=0
2024-02-06 13:40:07 | INFO | train_inner | epoch 032:   2184 / 3236 loss=0.947, nll_loss=0.947, ppl=1.93, wps=2267.7, ups=1.76, wpb=1288.6, bsz=86.6, num_updates=102500, lr=0.000624695, gnorm=0.61, train_wall=56, gb_free=18.3, wall=0
2024-02-06 13:41:04 | INFO | train_inner | epoch 032:   2284 / 3236 loss=0.922, nll_loss=0.922, ppl=1.89, wps=2310.6, ups=1.77, wpb=1308.8, bsz=91.1, num_updates=102600, lr=0.000624391, gnorm=0.598, train_wall=56, gb_free=18.3, wall=0
2024-02-06 13:42:01 | INFO | train_inner | epoch 032:   2384 / 3236 loss=0.946, nll_loss=0.946, ppl=1.93, wps=2327.5, ups=1.76, wpb=1320.9, bsz=93.7, num_updates=102700, lr=0.000624086, gnorm=0.586, train_wall=56, gb_free=18.2, wall=0
2024-02-06 13:42:58 | INFO | train_inner | epoch 032:   2484 / 3236 loss=0.923, nll_loss=0.923, ppl=1.9, wps=2292.8, ups=1.75, wpb=1308.9, bsz=87.6, num_updates=102800, lr=0.000623783, gnorm=0.598, train_wall=57, gb_free=18.3, wall=0
2024-02-06 13:43:55 | INFO | train_inner | epoch 032:   2584 / 3236 loss=0.936, nll_loss=0.936, ppl=1.91, wps=2289.8, ups=1.76, wpb=1298.4, bsz=92.8, num_updates=102900, lr=0.00062348, gnorm=0.594, train_wall=56, gb_free=17.7, wall=0
2024-02-06 13:44:51 | INFO | train_inner | epoch 032:   2684 / 3236 loss=0.95, nll_loss=0.95, ppl=1.93, wps=2275.2, ups=1.76, wpb=1294.8, bsz=82.8, num_updates=103000, lr=0.000623177, gnorm=0.621, train_wall=56, gb_free=17.6, wall=0
2024-02-06 13:45:48 | INFO | train_inner | epoch 032:   2784 / 3236 loss=0.954, nll_loss=0.954, ppl=1.94, wps=2308.2, ups=1.75, wpb=1315.4, bsz=92.1, num_updates=103100, lr=0.000622875, gnorm=0.606, train_wall=56, gb_free=17.3, wall=0
2024-02-06 13:46:45 | INFO | train_inner | epoch 032:   2884 / 3236 loss=0.929, nll_loss=0.929, ppl=1.9, wps=2245.6, ups=1.75, wpb=1280.2, bsz=84.4, num_updates=103200, lr=0.000622573, gnorm=0.598, train_wall=56, gb_free=18.2, wall=0
2024-02-06 13:47:42 | INFO | train_inner | epoch 032:   2984 / 3236 loss=0.944, nll_loss=0.944, ppl=1.92, wps=2266.3, ups=1.76, wpb=1289.4, bsz=85.4, num_updates=103300, lr=0.000622271, gnorm=0.599, train_wall=56, gb_free=17.8, wall=0
2024-02-06 13:48:39 | INFO | train_inner | epoch 032:   3084 / 3236 loss=0.975, nll_loss=0.975, ppl=1.97, wps=2299.3, ups=1.77, wpb=1298.5, bsz=90.8, num_updates=103400, lr=0.00062197, gnorm=0.604, train_wall=56, gb_free=17.8, wall=0
2024-02-06 13:49:36 | INFO | train_inner | epoch 032:   3184 / 3236 loss=0.925, nll_loss=0.925, ppl=1.9, wps=2243.6, ups=1.76, wpb=1275, bsz=81.6, num_updates=103500, lr=0.00062167, gnorm=0.611, train_wall=56, gb_free=18.4, wall=0
2024-02-06 13:50:05 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 13:50:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 13:51:24 | INFO | dev | epoch 032 | valid on 'dev' subset | loss 1.097 | nll_loss 1.097 | ppl 2.14 | wps 2931.5 | wpb 1146.2 | bsz 77.6 | num_updates 103552 | best_loss 1.096
2024-02-06 13:51:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 32 @ 103552 updates
2024-02-06 13:51:24 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint32.pt
2024-02-06 13:51:25 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint32.pt
2024-02-06 13:51:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint32.pt (epoch 32 @ 103552 updates, score 1.097) (writing took 4.279535809997469 seconds)
2024-02-06 13:51:28 | INFO | fairseq_cli.train | end of epoch 32 (average epoch stats below)
2024-02-06 13:51:28 | INFO | train | epoch 032 | loss 0.932 | nll_loss 0.932 | ppl 1.91 | wps 2188.9 | ups 1.68 | wpb 1302.4 | bsz 89.4 | num_updates 103552 | lr 0.000621514 | gnorm 0.601 | train_wall 1822 | gb_free 18.2 | wall 0
2024-02-06 13:51:28 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 13:51:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 13:51:28 | INFO | fairseq.trainer | begin training epoch 33
2024-02-06 13:51:28 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 13:51:58 | INFO | train_inner | epoch 033:     48 / 3236 loss=0.925, nll_loss=0.925, ppl=1.9, wps=918.1, ups=0.7, wpb=1310.6, bsz=86.6, num_updates=103600, lr=0.00062137, gnorm=0.601, train_wall=56, gb_free=17.8, wall=0
2024-02-06 13:52:56 | INFO | train_inner | epoch 033:    148 / 3236 loss=0.909, nll_loss=0.909, ppl=1.88, wps=2301, ups=1.74, wpb=1319.3, bsz=97.8, num_updates=103700, lr=0.00062107, gnorm=0.595, train_wall=57, gb_free=18.2, wall=0
2024-02-06 13:53:52 | INFO | train_inner | epoch 033:    248 / 3236 loss=0.906, nll_loss=0.906, ppl=1.87, wps=2306.7, ups=1.77, wpb=1306.5, bsz=90.4, num_updates=103800, lr=0.000620771, gnorm=0.6, train_wall=56, gb_free=17.8, wall=0
2024-02-06 13:54:49 | INFO | train_inner | epoch 033:    348 / 3236 loss=0.888, nll_loss=0.888, ppl=1.85, wps=2275.3, ups=1.76, wpb=1292.7, bsz=84.9, num_updates=103900, lr=0.000620472, gnorm=0.608, train_wall=56, gb_free=17.9, wall=0
2024-02-06 13:55:46 | INFO | train_inner | epoch 033:    448 / 3236 loss=0.896, nll_loss=0.896, ppl=1.86, wps=2345.4, ups=1.77, wpb=1323.2, bsz=90.9, num_updates=104000, lr=0.000620174, gnorm=0.587, train_wall=56, gb_free=18.7, wall=0
2024-02-06 13:56:42 | INFO | train_inner | epoch 033:    548 / 3236 loss=0.903, nll_loss=0.903, ppl=1.87, wps=2313.1, ups=1.78, wpb=1301, bsz=93.4, num_updates=104100, lr=0.000619876, gnorm=0.604, train_wall=56, gb_free=18.6, wall=0
2024-02-06 13:57:39 | INFO | train_inner | epoch 033:    648 / 3236 loss=0.898, nll_loss=0.898, ppl=1.86, wps=2275.9, ups=1.75, wpb=1297.9, bsz=91, num_updates=104200, lr=0.000619578, gnorm=0.601, train_wall=56, gb_free=18.4, wall=0
2024-02-06 13:58:35 | INFO | train_inner | epoch 033:    748 / 3236 loss=0.911, nll_loss=0.911, ppl=1.88, wps=2304.6, ups=1.77, wpb=1302, bsz=87.7, num_updates=104300, lr=0.000619281, gnorm=0.6, train_wall=56, gb_free=17.5, wall=0
2024-02-06 13:59:32 | INFO | train_inner | epoch 033:    848 / 3236 loss=0.918, nll_loss=0.918, ppl=1.89, wps=2326.8, ups=1.77, wpb=1311, bsz=89.4, num_updates=104400, lr=0.000618984, gnorm=0.61, train_wall=56, gb_free=18.4, wall=0
2024-02-06 14:00:28 | INFO | train_inner | epoch 033:    948 / 3236 loss=0.913, nll_loss=0.913, ppl=1.88, wps=2294.8, ups=1.77, wpb=1294.4, bsz=90.3, num_updates=104500, lr=0.000618688, gnorm=0.602, train_wall=56, gb_free=18.2, wall=0
2024-02-06 14:01:25 | INFO | train_inner | epoch 033:   1048 / 3236 loss=0.914, nll_loss=0.914, ppl=1.88, wps=2305.7, ups=1.77, wpb=1305.8, bsz=90.2, num_updates=104600, lr=0.000618392, gnorm=0.603, train_wall=56, gb_free=17.9, wall=0
2024-02-06 14:02:22 | INFO | train_inner | epoch 033:   1148 / 3236 loss=0.926, nll_loss=0.926, ppl=1.9, wps=2296, ups=1.76, wpb=1305.5, bsz=91.9, num_updates=104700, lr=0.000618097, gnorm=0.606, train_wall=56, gb_free=17.5, wall=0
2024-02-06 14:03:18 | INFO | train_inner | epoch 033:   1248 / 3236 loss=0.918, nll_loss=0.918, ppl=1.89, wps=2326.6, ups=1.76, wpb=1320.8, bsz=88.7, num_updates=104800, lr=0.000617802, gnorm=0.604, train_wall=56, gb_free=18.6, wall=0
2024-02-06 14:04:15 | INFO | train_inner | epoch 033:   1348 / 3236 loss=0.903, nll_loss=0.903, ppl=1.87, wps=2268.8, ups=1.77, wpb=1283.8, bsz=83, num_updates=104900, lr=0.000617508, gnorm=0.615, train_wall=56, gb_free=17.6, wall=0
2024-02-06 14:05:12 | INFO | train_inner | epoch 033:   1448 / 3236 loss=0.917, nll_loss=0.917, ppl=1.89, wps=2298.3, ups=1.76, wpb=1303.4, bsz=89.9, num_updates=105000, lr=0.000617213, gnorm=0.591, train_wall=56, gb_free=18.3, wall=0
2024-02-06 14:06:08 | INFO | train_inner | epoch 033:   1548 / 3236 loss=0.913, nll_loss=0.913, ppl=1.88, wps=2272.3, ups=1.77, wpb=1283.2, bsz=89.8, num_updates=105100, lr=0.00061692, gnorm=0.605, train_wall=56, gb_free=17.6, wall=0
2024-02-06 14:07:05 | INFO | train_inner | epoch 033:   1648 / 3236 loss=0.94, nll_loss=0.94, ppl=1.92, wps=2301.8, ups=1.77, wpb=1303.2, bsz=89, num_updates=105200, lr=0.000616626, gnorm=0.605, train_wall=56, gb_free=17.3, wall=0
2024-02-06 14:08:02 | INFO | train_inner | epoch 033:   1748 / 3236 loss=0.911, nll_loss=0.911, ppl=1.88, wps=2277.9, ups=1.76, wpb=1294.6, bsz=89, num_updates=105300, lr=0.000616334, gnorm=0.612, train_wall=56, gb_free=17.7, wall=0
2024-02-06 14:08:58 | INFO | train_inner | epoch 033:   1848 / 3236 loss=0.912, nll_loss=0.912, ppl=1.88, wps=2292.7, ups=1.77, wpb=1297, bsz=88.8, num_updates=105400, lr=0.000616041, gnorm=0.602, train_wall=56, gb_free=18.4, wall=0
2024-02-06 14:09:55 | INFO | train_inner | epoch 033:   1948 / 3236 loss=0.925, nll_loss=0.925, ppl=1.9, wps=2276.3, ups=1.76, wpb=1293.3, bsz=88.9, num_updates=105500, lr=0.000615749, gnorm=0.616, train_wall=56, gb_free=18.1, wall=0
2024-02-06 14:10:52 | INFO | train_inner | epoch 033:   2048 / 3236 loss=0.933, nll_loss=0.933, ppl=1.91, wps=2253.4, ups=1.75, wpb=1289.4, bsz=86.2, num_updates=105600, lr=0.000615457, gnorm=0.607, train_wall=57, gb_free=18.6, wall=0
2024-02-06 14:11:49 | INFO | train_inner | epoch 033:   2148 / 3236 loss=0.925, nll_loss=0.925, ppl=1.9, wps=2279, ups=1.77, wpb=1287.8, bsz=88.3, num_updates=105700, lr=0.000615166, gnorm=0.61, train_wall=56, gb_free=18.5, wall=0
2024-02-06 14:12:46 | INFO | train_inner | epoch 033:   2248 / 3236 loss=0.93, nll_loss=0.93, ppl=1.91, wps=2264.3, ups=1.76, wpb=1289.6, bsz=86, num_updates=105800, lr=0.000614875, gnorm=0.618, train_wall=56, gb_free=18.1, wall=0
2024-02-06 14:13:42 | INFO | train_inner | epoch 033:   2348 / 3236 loss=0.945, nll_loss=0.945, ppl=1.93, wps=2287.9, ups=1.76, wpb=1299.8, bsz=87.5, num_updates=105900, lr=0.000614585, gnorm=0.61, train_wall=56, gb_free=17.3, wall=0
2024-02-06 14:14:39 | INFO | train_inner | epoch 033:   2448 / 3236 loss=0.934, nll_loss=0.934, ppl=1.91, wps=2335.6, ups=1.77, wpb=1318.2, bsz=92.6, num_updates=106000, lr=0.000614295, gnorm=0.596, train_wall=56, gb_free=18.5, wall=0
2024-02-06 14:15:36 | INFO | train_inner | epoch 033:   2548 / 3236 loss=0.943, nll_loss=0.943, ppl=1.92, wps=2327.5, ups=1.76, wpb=1323.6, bsz=91.9, num_updates=106100, lr=0.000614006, gnorm=0.599, train_wall=56, gb_free=18.7, wall=0
2024-02-06 14:16:32 | INFO | train_inner | epoch 033:   2648 / 3236 loss=0.925, nll_loss=0.925, ppl=1.9, wps=2328.8, ups=1.76, wpb=1320.9, bsz=92.1, num_updates=106200, lr=0.000613716, gnorm=0.6, train_wall=56, gb_free=18.1, wall=0
2024-02-06 14:17:29 | INFO | train_inner | epoch 033:   2748 / 3236 loss=0.943, nll_loss=0.943, ppl=1.92, wps=2301.5, ups=1.77, wpb=1303.4, bsz=91, num_updates=106300, lr=0.000613428, gnorm=0.603, train_wall=56, gb_free=17.9, wall=0
2024-02-06 14:18:26 | INFO | train_inner | epoch 033:   2848 / 3236 loss=0.941, nll_loss=0.941, ppl=1.92, wps=2309.1, ups=1.77, wpb=1304.3, bsz=92.5, num_updates=106400, lr=0.000613139, gnorm=0.596, train_wall=56, gb_free=17.6, wall=0
2024-02-06 14:19:22 | INFO | train_inner | epoch 033:   2948 / 3236 loss=0.943, nll_loss=0.943, ppl=1.92, wps=2287, ups=1.77, wpb=1295, bsz=87.3, num_updates=106500, lr=0.000612851, gnorm=0.605, train_wall=56, gb_free=17.8, wall=0
2024-02-06 14:20:21 | INFO | train_inner | epoch 033:   3048 / 3236 loss=0.925, nll_loss=0.925, ppl=1.9, wps=2191.3, ups=1.69, wpb=1295.6, bsz=89.3, num_updates=106600, lr=0.000612564, gnorm=0.602, train_wall=58, gb_free=18.1, wall=0
2024-02-06 14:21:18 | INFO | train_inner | epoch 033:   3148 / 3236 loss=0.951, nll_loss=0.951, ppl=1.93, wps=2292.5, ups=1.77, wpb=1298, bsz=86.6, num_updates=106700, lr=0.000612277, gnorm=0.602, train_wall=56, gb_free=17.7, wall=0
2024-02-06 14:22:08 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 14:22:08 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 14:23:29 | INFO | dev | epoch 033 | valid on 'dev' subset | loss 1.111 | nll_loss 1.111 | ppl 2.16 | wps 2865.4 | wpb 1146.2 | bsz 77.6 | num_updates 106788 | best_loss 1.096
2024-02-06 14:23:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 33 @ 106788 updates
2024-02-06 14:23:29 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint33.pt
2024-02-06 14:23:30 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint33.pt
2024-02-06 14:23:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint33.pt (epoch 33 @ 106788 updates, score 1.111) (writing took 3.088424908928573 seconds)
2024-02-06 14:23:32 | INFO | fairseq_cli.train | end of epoch 33 (average epoch stats below)
2024-02-06 14:23:32 | INFO | train | epoch 033 | loss 0.921 | nll_loss 0.921 | ppl 1.89 | wps 2191 | ups 1.68 | wpb 1302.4 | bsz 89.4 | num_updates 106788 | lr 0.000612024 | gnorm 0.603 | train_wall 1819 | gb_free 18.3 | wall 0
2024-02-06 14:23:32 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 14:23:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 14:23:32 | INFO | fairseq.trainer | begin training epoch 34
2024-02-06 14:23:32 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 14:23:43 | INFO | train_inner | epoch 034:     12 / 3236 loss=0.923, nll_loss=0.923, ppl=1.9, wps=898.2, ups=0.69, wpb=1301.7, bsz=86.8, num_updates=106800, lr=0.00061199, gnorm=0.597, train_wall=56, gb_free=18.3, wall=0
2024-02-06 14:24:40 | INFO | train_inner | epoch 034:    112 / 3236 loss=0.891, nll_loss=0.891, ppl=1.85, wps=2302.6, ups=1.76, wpb=1309.1, bsz=92.9, num_updates=106900, lr=0.000611704, gnorm=0.599, train_wall=56, gb_free=18.2, wall=0
2024-02-06 14:25:37 | INFO | train_inner | epoch 034:    212 / 3236 loss=0.894, nll_loss=0.894, ppl=1.86, wps=2308.6, ups=1.76, wpb=1313.1, bsz=89.7, num_updates=107000, lr=0.000611418, gnorm=0.597, train_wall=56, gb_free=18, wall=0
2024-02-06 14:26:33 | INFO | train_inner | epoch 034:    312 / 3236 loss=0.9, nll_loss=0.9, ppl=1.87, wps=2308.2, ups=1.77, wpb=1301.8, bsz=90.2, num_updates=107100, lr=0.000611132, gnorm=0.608, train_wall=56, gb_free=18.3, wall=0
2024-02-06 14:27:30 | INFO | train_inner | epoch 034:    412 / 3236 loss=0.882, nll_loss=0.882, ppl=1.84, wps=2314.7, ups=1.77, wpb=1304.9, bsz=89, num_updates=107200, lr=0.000610847, gnorm=0.611, train_wall=56, gb_free=17.1, wall=0
2024-02-06 14:28:26 | INFO | train_inner | epoch 034:    512 / 3236 loss=0.886, nll_loss=0.886, ppl=1.85, wps=2299.5, ups=1.77, wpb=1302.5, bsz=86.5, num_updates=107300, lr=0.000610563, gnorm=0.607, train_wall=56, gb_free=18, wall=0
2024-02-06 14:29:23 | INFO | train_inner | epoch 034:    612 / 3236 loss=0.903, nll_loss=0.903, ppl=1.87, wps=2244.2, ups=1.76, wpb=1272, bsz=87.7, num_updates=107400, lr=0.000610278, gnorm=0.622, train_wall=56, gb_free=18.3, wall=0
2024-02-06 14:30:19 | INFO | train_inner | epoch 034:    712 / 3236 loss=0.914, nll_loss=0.914, ppl=1.88, wps=2383.3, ups=1.77, wpb=1344.7, bsz=102.3, num_updates=107500, lr=0.000609994, gnorm=0.594, train_wall=56, gb_free=18.4, wall=0
2024-02-06 14:31:16 | INFO | train_inner | epoch 034:    812 / 3236 loss=0.885, nll_loss=0.885, ppl=1.85, wps=2294.2, ups=1.77, wpb=1297.3, bsz=88.2, num_updates=107600, lr=0.000609711, gnorm=0.603, train_wall=56, gb_free=18.4, wall=0
2024-02-06 14:32:12 | INFO | train_inner | epoch 034:    912 / 3236 loss=0.891, nll_loss=0.891, ppl=1.85, wps=2310.7, ups=1.77, wpb=1303.6, bsz=89.4, num_updates=107700, lr=0.000609428, gnorm=0.6, train_wall=56, gb_free=18, wall=0
2024-02-06 14:33:09 | INFO | train_inner | epoch 034:   1012 / 3236 loss=0.893, nll_loss=0.893, ppl=1.86, wps=2298.3, ups=1.77, wpb=1298, bsz=87, num_updates=107800, lr=0.000609145, gnorm=0.603, train_wall=56, gb_free=17.1, wall=0
2024-02-06 14:34:05 | INFO | train_inner | epoch 034:   1112 / 3236 loss=0.916, nll_loss=0.916, ppl=1.89, wps=2310.6, ups=1.77, wpb=1306.8, bsz=92, num_updates=107900, lr=0.000608863, gnorm=0.589, train_wall=56, gb_free=18.7, wall=0
2024-02-06 14:35:02 | INFO | train_inner | epoch 034:   1212 / 3236 loss=0.909, nll_loss=0.909, ppl=1.88, wps=2318.5, ups=1.77, wpb=1310.7, bsz=89, num_updates=108000, lr=0.000608581, gnorm=0.605, train_wall=56, gb_free=17.9, wall=0
2024-02-06 14:35:58 | INFO | train_inner | epoch 034:   1312 / 3236 loss=0.906, nll_loss=0.906, ppl=1.87, wps=2296.5, ups=1.77, wpb=1297.5, bsz=90.7, num_updates=108100, lr=0.000608299, gnorm=0.614, train_wall=56, gb_free=18.3, wall=0
2024-02-06 14:36:55 | INFO | train_inner | epoch 034:   1412 / 3236 loss=0.905, nll_loss=0.905, ppl=1.87, wps=2333.1, ups=1.77, wpb=1318.4, bsz=91.7, num_updates=108200, lr=0.000608018, gnorm=0.591, train_wall=56, gb_free=17.8, wall=0
2024-02-06 14:37:52 | INFO | train_inner | epoch 034:   1512 / 3236 loss=0.926, nll_loss=0.926, ppl=1.9, wps=2300.3, ups=1.76, wpb=1307.1, bsz=89, num_updates=108300, lr=0.000607737, gnorm=0.632, train_wall=56, gb_free=18, wall=0
2024-02-06 14:38:48 | INFO | train_inner | epoch 034:   1612 / 3236 loss=0.903, nll_loss=0.903, ppl=1.87, wps=2264.6, ups=1.77, wpb=1280.4, bsz=81.8, num_updates=108400, lr=0.000607457, gnorm=0.622, train_wall=56, gb_free=18.6, wall=0
2024-02-06 14:39:45 | INFO | train_inner | epoch 034:   1712 / 3236 loss=0.918, nll_loss=0.918, ppl=1.89, wps=2306.8, ups=1.76, wpb=1307.4, bsz=89.4, num_updates=108500, lr=0.000607177, gnorm=0.605, train_wall=56, gb_free=17.9, wall=0
2024-02-06 14:40:42 | INFO | train_inner | epoch 034:   1812 / 3236 loss=0.919, nll_loss=0.919, ppl=1.89, wps=2292.4, ups=1.76, wpb=1303.4, bsz=86.2, num_updates=108600, lr=0.000606897, gnorm=0.613, train_wall=56, gb_free=17.9, wall=0
2024-02-06 14:41:38 | INFO | train_inner | epoch 034:   1912 / 3236 loss=0.887, nll_loss=0.887, ppl=1.85, wps=2247.3, ups=1.77, wpb=1268, bsz=84.8, num_updates=108700, lr=0.000606618, gnorm=0.619, train_wall=56, gb_free=18.4, wall=0
2024-02-06 14:42:35 | INFO | train_inner | epoch 034:   2012 / 3236 loss=0.925, nll_loss=0.925, ppl=1.9, wps=2312.2, ups=1.76, wpb=1313.1, bsz=91.8, num_updates=108800, lr=0.000606339, gnorm=0.614, train_wall=56, gb_free=17.7, wall=0
2024-02-06 14:43:36 | INFO | train_inner | epoch 034:   2112 / 3236 loss=0.934, nll_loss=0.934, ppl=1.91, wps=2127.7, ups=1.64, wpb=1300.6, bsz=92, num_updates=108900, lr=0.000606061, gnorm=0.617, train_wall=61, gb_free=17.8, wall=0
2024-02-06 14:44:33 | INFO | train_inner | epoch 034:   2212 / 3236 loss=0.919, nll_loss=0.919, ppl=1.89, wps=2307.2, ups=1.76, wpb=1313.5, bsz=89.7, num_updates=109000, lr=0.000605783, gnorm=0.61, train_wall=56, gb_free=18.5, wall=0
2024-02-06 14:45:29 | INFO | train_inner | epoch 034:   2312 / 3236 loss=0.924, nll_loss=0.924, ppl=1.9, wps=2323, ups=1.77, wpb=1311.9, bsz=90.8, num_updates=109100, lr=0.000605505, gnorm=0.6, train_wall=56, gb_free=18.5, wall=0
2024-02-06 14:46:26 | INFO | train_inner | epoch 034:   2412 / 3236 loss=0.93, nll_loss=0.93, ppl=1.9, wps=2284.4, ups=1.77, wpb=1289.4, bsz=89.2, num_updates=109200, lr=0.000605228, gnorm=0.606, train_wall=56, gb_free=18, wall=0
2024-02-06 14:47:23 | INFO | train_inner | epoch 034:   2512 / 3236 loss=0.905, nll_loss=0.905, ppl=1.87, wps=2274.6, ups=1.76, wpb=1293.1, bsz=86.2, num_updates=109300, lr=0.000604951, gnorm=0.603, train_wall=56, gb_free=17.9, wall=0
2024-02-06 14:48:22 | INFO | train_inner | epoch 034:   2612 / 3236 loss=0.901, nll_loss=0.901, ppl=1.87, wps=2165.2, ups=1.69, wpb=1280.9, bsz=91.7, num_updates=109400, lr=0.000604674, gnorm=0.595, train_wall=56, gb_free=17.2, wall=0
2024-02-06 14:49:22 | INFO | train_inner | epoch 034:   2712 / 3236 loss=0.942, nll_loss=0.942, ppl=1.92, wps=2183.4, ups=1.67, wpb=1306.3, bsz=86.3, num_updates=109500, lr=0.000604398, gnorm=0.613, train_wall=56, gb_free=18.6, wall=0
2024-02-06 14:50:25 | INFO | train_inner | epoch 034:   2812 / 3236 loss=0.924, nll_loss=0.924, ppl=1.9, wps=2052, ups=1.58, wpb=1301.3, bsz=84.2, num_updates=109600, lr=0.000604122, gnorm=0.615, train_wall=56, gb_free=18.5, wall=0
2024-02-06 14:51:31 | INFO | train_inner | epoch 034:   2912 / 3236 loss=0.924, nll_loss=0.924, ppl=1.9, wps=1977.9, ups=1.51, wpb=1306.8, bsz=91.5, num_updates=109700, lr=0.000603847, gnorm=0.612, train_wall=56, gb_free=18.2, wall=0
2024-02-06 14:52:31 | INFO | train_inner | epoch 034:   3012 / 3236 loss=0.949, nll_loss=0.949, ppl=1.93, wps=2179.9, ups=1.67, wpb=1303.2, bsz=90.5, num_updates=109800, lr=0.000603572, gnorm=0.609, train_wall=56, gb_free=17.9, wall=0
2024-02-06 14:53:28 | INFO | train_inner | epoch 034:   3112 / 3236 loss=0.935, nll_loss=0.935, ppl=1.91, wps=2268.3, ups=1.76, wpb=1291.9, bsz=88.5, num_updates=109900, lr=0.000603297, gnorm=0.626, train_wall=56, gb_free=18.1, wall=0
2024-02-06 14:54:25 | INFO | train_inner | epoch 034:   3212 / 3236 loss=0.926, nll_loss=0.926, ppl=1.9, wps=2300.9, ups=1.76, wpb=1304.1, bsz=89.6, num_updates=110000, lr=0.000603023, gnorm=0.598, train_wall=56, gb_free=17.8, wall=0
2024-02-06 14:54:38 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 14:54:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 14:55:55 | INFO | dev | epoch 034 | valid on 'dev' subset | loss 1.111 | nll_loss 1.111 | ppl 2.16 | wps 3007.1 | wpb 1146.2 | bsz 77.6 | num_updates 110024 | best_loss 1.096
2024-02-06 14:55:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 34 @ 110024 updates
2024-02-06 14:55:55 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint34.pt
2024-02-06 14:55:57 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint34.pt
2024-02-06 14:55:58 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint34.pt (epoch 34 @ 110024 updates, score 1.111) (writing took 3.141235541086644 seconds)
2024-02-06 14:55:58 | INFO | fairseq_cli.train | end of epoch 34 (average epoch stats below)
2024-02-06 14:55:58 | INFO | train | epoch 034 | loss 0.912 | nll_loss 0.912 | ppl 1.88 | wps 2164.9 | ups 1.66 | wpb 1302.4 | bsz 89.4 | num_updates 110024 | lr 0.000602957 | gnorm 0.608 | train_wall 1819 | gb_free 17.7 | wall 0
2024-02-06 14:55:58 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 14:55:59 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 14:55:59 | INFO | fairseq.trainer | begin training epoch 35
2024-02-06 14:55:59 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 14:56:44 | INFO | train_inner | epoch 035:     76 / 3236 loss=0.883, nll_loss=0.883, ppl=1.84, wps=946.7, ups=0.72, wpb=1323.2, bsz=90.9, num_updates=110100, lr=0.000602749, gnorm=0.586, train_wall=56, gb_free=17.9, wall=0
2024-02-06 14:57:41 | INFO | train_inner | epoch 035:    176 / 3236 loss=0.878, nll_loss=0.878, ppl=1.84, wps=2341.8, ups=1.76, wpb=1332.1, bsz=92.3, num_updates=110200, lr=0.000602475, gnorm=0.598, train_wall=56, gb_free=18.2, wall=0
2024-02-06 14:58:38 | INFO | train_inner | epoch 035:    276 / 3236 loss=0.876, nll_loss=0.876, ppl=1.84, wps=2287.2, ups=1.76, wpb=1297.5, bsz=85, num_updates=110300, lr=0.000602202, gnorm=0.62, train_wall=56, gb_free=17.7, wall=0
2024-02-06 14:59:34 | INFO | train_inner | epoch 035:    376 / 3236 loss=0.885, nll_loss=0.885, ppl=1.85, wps=2309.1, ups=1.78, wpb=1294.5, bsz=88.3, num_updates=110400, lr=0.000601929, gnorm=0.614, train_wall=56, gb_free=17.8, wall=0
2024-02-06 15:00:30 | INFO | train_inner | epoch 035:    476 / 3236 loss=0.869, nll_loss=0.869, ppl=1.83, wps=2313.6, ups=1.78, wpb=1301.1, bsz=89.6, num_updates=110500, lr=0.000601657, gnorm=0.593, train_wall=56, gb_free=18.1, wall=0
2024-02-06 15:01:27 | INFO | train_inner | epoch 035:    576 / 3236 loss=0.882, nll_loss=0.882, ppl=1.84, wps=2334.3, ups=1.77, wpb=1319, bsz=92.2, num_updates=110600, lr=0.000601385, gnorm=0.587, train_wall=56, gb_free=17.9, wall=0
2024-02-06 15:02:23 | INFO | train_inner | epoch 035:    676 / 3236 loss=0.885, nll_loss=0.885, ppl=1.85, wps=2303.2, ups=1.77, wpb=1300.8, bsz=86.7, num_updates=110700, lr=0.000601113, gnorm=0.6, train_wall=56, gb_free=18.4, wall=0
2024-02-06 15:03:20 | INFO | train_inner | epoch 035:    776 / 3236 loss=0.866, nll_loss=0.866, ppl=1.82, wps=2289.2, ups=1.77, wpb=1291.9, bsz=88.1, num_updates=110800, lr=0.000600842, gnorm=0.606, train_wall=56, gb_free=18.1, wall=0
2024-02-06 15:04:16 | INFO | train_inner | epoch 035:    876 / 3236 loss=0.888, nll_loss=0.888, ppl=1.85, wps=2277.6, ups=1.76, wpb=1291.5, bsz=88.4, num_updates=110900, lr=0.000600571, gnorm=0.6, train_wall=56, gb_free=18.2, wall=0
2024-02-06 15:05:13 | INFO | train_inner | epoch 035:    976 / 3236 loss=0.892, nll_loss=0.892, ppl=1.86, wps=2313.6, ups=1.77, wpb=1310.7, bsz=86, num_updates=111000, lr=0.0006003, gnorm=0.592, train_wall=56, gb_free=18.5, wall=0
2024-02-06 15:06:10 | INFO | train_inner | epoch 035:   1076 / 3236 loss=0.915, nll_loss=0.915, ppl=1.89, wps=2328.6, ups=1.77, wpb=1319.3, bsz=94.3, num_updates=111100, lr=0.00060003, gnorm=0.594, train_wall=56, gb_free=18.2, wall=0
2024-02-06 15:07:07 | INFO | train_inner | epoch 035:   1176 / 3236 loss=0.923, nll_loss=0.923, ppl=1.9, wps=2325.3, ups=1.76, wpb=1320.3, bsz=95.4, num_updates=111200, lr=0.00059976, gnorm=0.601, train_wall=56, gb_free=18.3, wall=0
2024-02-06 15:08:03 | INFO | train_inner | epoch 035:   1276 / 3236 loss=0.907, nll_loss=0.907, ppl=1.88, wps=2311.4, ups=1.77, wpb=1304, bsz=93.4, num_updates=111300, lr=0.000599491, gnorm=0.608, train_wall=56, gb_free=18.2, wall=0
2024-02-06 15:08:59 | INFO | train_inner | epoch 035:   1376 / 3236 loss=0.888, nll_loss=0.888, ppl=1.85, wps=2305, ups=1.77, wpb=1302.3, bsz=87.4, num_updates=111400, lr=0.000599222, gnorm=0.599, train_wall=56, gb_free=17.8, wall=0
2024-02-06 15:09:56 | INFO | train_inner | epoch 035:   1476 / 3236 loss=0.861, nll_loss=0.861, ppl=1.82, wps=2286.8, ups=1.77, wpb=1292.8, bsz=88.2, num_updates=111500, lr=0.000598953, gnorm=0.594, train_wall=56, gb_free=18.2, wall=0
2024-02-06 15:10:53 | INFO | train_inner | epoch 035:   1576 / 3236 loss=0.904, nll_loss=0.904, ppl=1.87, wps=2314, ups=1.76, wpb=1313.2, bsz=92.9, num_updates=111600, lr=0.000598684, gnorm=0.601, train_wall=56, gb_free=17.9, wall=0
2024-02-06 15:11:50 | INFO | train_inner | epoch 035:   1676 / 3236 loss=0.903, nll_loss=0.903, ppl=1.87, wps=2293.7, ups=1.76, wpb=1301.8, bsz=88.4, num_updates=111700, lr=0.000598416, gnorm=0.613, train_wall=56, gb_free=18.6, wall=0
2024-02-06 15:12:46 | INFO | train_inner | epoch 035:   1776 / 3236 loss=0.912, nll_loss=0.912, ppl=1.88, wps=2297.3, ups=1.77, wpb=1299.5, bsz=89.4, num_updates=111800, lr=0.000598149, gnorm=0.611, train_wall=56, gb_free=17.8, wall=0
2024-02-06 15:13:43 | INFO | train_inner | epoch 035:   1876 / 3236 loss=0.9, nll_loss=0.9, ppl=1.87, wps=2303.2, ups=1.77, wpb=1302.8, bsz=89.2, num_updates=111900, lr=0.000597881, gnorm=0.612, train_wall=56, gb_free=17.5, wall=0
2024-02-06 15:14:39 | INFO | train_inner | epoch 035:   1976 / 3236 loss=0.924, nll_loss=0.924, ppl=1.9, wps=2327.9, ups=1.76, wpb=1323.6, bsz=89.1, num_updates=112000, lr=0.000597614, gnorm=0.613, train_wall=56, gb_free=17.9, wall=0
2024-02-06 15:15:42 | INFO | train_inner | epoch 035:   2076 / 3236 loss=0.909, nll_loss=0.909, ppl=1.88, wps=2076, ups=1.59, wpb=1301.5, bsz=87, num_updates=112100, lr=0.000597348, gnorm=0.613, train_wall=62, gb_free=18.4, wall=0
2024-02-06 15:16:39 | INFO | train_inner | epoch 035:   2176 / 3236 loss=0.906, nll_loss=0.906, ppl=1.87, wps=2259.8, ups=1.75, wpb=1289.9, bsz=88.2, num_updates=112200, lr=0.000597081, gnorm=0.612, train_wall=57, gb_free=18.4, wall=0
2024-02-06 15:17:36 | INFO | train_inner | epoch 035:   2276 / 3236 loss=0.907, nll_loss=0.907, ppl=1.87, wps=2279.8, ups=1.77, wpb=1286.3, bsz=85.4, num_updates=112300, lr=0.000596816, gnorm=0.621, train_wall=56, gb_free=18.1, wall=0
2024-02-06 15:18:32 | INFO | train_inner | epoch 035:   2376 / 3236 loss=0.905, nll_loss=0.905, ppl=1.87, wps=2311.7, ups=1.77, wpb=1304.2, bsz=96.5, num_updates=112400, lr=0.00059655, gnorm=0.615, train_wall=56, gb_free=18.5, wall=0
2024-02-06 15:19:29 | INFO | train_inner | epoch 035:   2476 / 3236 loss=0.902, nll_loss=0.902, ppl=1.87, wps=2269.5, ups=1.77, wpb=1280.4, bsz=85, num_updates=112500, lr=0.000596285, gnorm=0.605, train_wall=56, gb_free=17.7, wall=0
2024-02-06 15:20:25 | INFO | train_inner | epoch 035:   2576 / 3236 loss=0.914, nll_loss=0.914, ppl=1.88, wps=2319.3, ups=1.77, wpb=1310.3, bsz=92.3, num_updates=112600, lr=0.00059602, gnorm=0.602, train_wall=56, gb_free=18, wall=0
2024-02-06 15:21:22 | INFO | train_inner | epoch 035:   2676 / 3236 loss=0.935, nll_loss=0.935, ppl=1.91, wps=2335.5, ups=1.77, wpb=1319.8, bsz=93, num_updates=112700, lr=0.000595755, gnorm=0.603, train_wall=56, gb_free=18.5, wall=0
2024-02-06 15:22:18 | INFO | train_inner | epoch 035:   2776 / 3236 loss=0.897, nll_loss=0.897, ppl=1.86, wps=2255.4, ups=1.76, wpb=1281, bsz=82.1, num_updates=112800, lr=0.000595491, gnorm=0.62, train_wall=56, gb_free=18.2, wall=0
2024-02-06 15:23:15 | INFO | train_inner | epoch 035:   2876 / 3236 loss=0.903, nll_loss=0.903, ppl=1.87, wps=2265.4, ups=1.77, wpb=1282.4, bsz=87.8, num_updates=112900, lr=0.000595228, gnorm=0.597, train_wall=56, gb_free=17.9, wall=0
2024-02-06 15:24:12 | INFO | train_inner | epoch 035:   2976 / 3236 loss=0.926, nll_loss=0.926, ppl=1.9, wps=2302.1, ups=1.77, wpb=1303.6, bsz=91, num_updates=113000, lr=0.000594964, gnorm=0.613, train_wall=56, gb_free=17.1, wall=0
2024-02-06 15:25:08 | INFO | train_inner | epoch 035:   3076 / 3236 loss=0.927, nll_loss=0.927, ppl=1.9, wps=2273.4, ups=1.77, wpb=1284.6, bsz=89, num_updates=113100, lr=0.000594701, gnorm=0.63, train_wall=56, gb_free=18.5, wall=0
2024-02-06 15:26:09 | INFO | train_inner | epoch 035:   3176 / 3236 loss=0.913, nll_loss=0.913, ppl=1.88, wps=2115.7, ups=1.63, wpb=1298.7, bsz=87.8, num_updates=113200, lr=0.000594438, gnorm=0.601, train_wall=61, gb_free=18.5, wall=0
2024-02-06 15:26:43 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 15:26:43 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 15:28:02 | INFO | dev | epoch 035 | valid on 'dev' subset | loss 1.102 | nll_loss 1.102 | ppl 2.15 | wps 2953.5 | wpb 1146.2 | bsz 77.6 | num_updates 113260 | best_loss 1.096
2024-02-06 15:28:02 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 35 @ 113260 updates
2024-02-06 15:28:02 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint35.pt
2024-02-06 15:28:03 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint35.pt
2024-02-06 15:28:05 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint35.pt (epoch 35 @ 113260 updates, score 1.102) (writing took 3.104239121079445 seconds)
2024-02-06 15:28:05 | INFO | fairseq_cli.train | end of epoch 35 (average epoch stats below)
2024-02-06 15:28:05 | INFO | train | epoch 035 | loss 0.9 | nll_loss 0.9 | ppl 1.87 | wps 2187.8 | ups 1.68 | wpb 1302.4 | bsz 89.4 | num_updates 113260 | lr 0.000594281 | gnorm 0.606 | train_wall 1825 | gb_free 18.1 | wall 0
2024-02-06 15:28:05 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 15:28:05 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 15:28:05 | INFO | fairseq.trainer | begin training epoch 36
2024-02-06 15:28:05 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 15:28:30 | INFO | train_inner | epoch 036:     40 / 3236 loss=0.906, nll_loss=0.906, ppl=1.87, wps=925.9, ups=0.71, wpb=1299.4, bsz=91.6, num_updates=113300, lr=0.000594176, gnorm=0.61, train_wall=56, gb_free=17.9, wall=0
2024-02-06 15:29:26 | INFO | train_inner | epoch 036:    140 / 3236 loss=0.868, nll_loss=0.868, ppl=1.83, wps=2299, ups=1.77, wpb=1298.7, bsz=88.6, num_updates=113400, lr=0.000593914, gnorm=0.612, train_wall=56, gb_free=17.7, wall=0
2024-02-06 15:30:23 | INFO | train_inner | epoch 036:    240 / 3236 loss=0.872, nll_loss=0.872, ppl=1.83, wps=2328.5, ups=1.78, wpb=1311.3, bsz=90.9, num_updates=113500, lr=0.000593652, gnorm=0.592, train_wall=56, gb_free=18.2, wall=0
2024-02-06 15:31:19 | INFO | train_inner | epoch 036:    340 / 3236 loss=0.879, nll_loss=0.879, ppl=1.84, wps=2298.4, ups=1.77, wpb=1298, bsz=88.2, num_updates=113600, lr=0.000593391, gnorm=0.603, train_wall=56, gb_free=17.8, wall=0
2024-02-06 15:32:16 | INFO | train_inner | epoch 036:    440 / 3236 loss=0.856, nll_loss=0.856, ppl=1.81, wps=2304.9, ups=1.77, wpb=1302.6, bsz=88.2, num_updates=113700, lr=0.00059313, gnorm=0.598, train_wall=56, gb_free=18.6, wall=0
2024-02-06 15:33:12 | INFO | train_inner | epoch 036:    540 / 3236 loss=0.873, nll_loss=0.873, ppl=1.83, wps=2297.6, ups=1.77, wpb=1297.8, bsz=88.6, num_updates=113800, lr=0.000592869, gnorm=0.605, train_wall=56, gb_free=17.4, wall=0
2024-02-06 15:34:08 | INFO | train_inner | epoch 036:    640 / 3236 loss=0.868, nll_loss=0.868, ppl=1.83, wps=2316.1, ups=1.77, wpb=1304.9, bsz=96.8, num_updates=113900, lr=0.000592609, gnorm=0.599, train_wall=56, gb_free=17.6, wall=0
2024-02-06 15:35:05 | INFO | train_inner | epoch 036:    740 / 3236 loss=0.861, nll_loss=0.861, ppl=1.82, wps=2333.9, ups=1.77, wpb=1316.5, bsz=92.5, num_updates=114000, lr=0.000592349, gnorm=0.593, train_wall=56, gb_free=18.5, wall=0
2024-02-06 15:36:01 | INFO | train_inner | epoch 036:    840 / 3236 loss=0.866, nll_loss=0.866, ppl=1.82, wps=2322.3, ups=1.77, wpb=1311.7, bsz=92.6, num_updates=114100, lr=0.000592089, gnorm=0.599, train_wall=56, gb_free=18.2, wall=0
2024-02-06 15:36:58 | INFO | train_inner | epoch 036:    940 / 3236 loss=0.885, nll_loss=0.885, ppl=1.85, wps=2276.6, ups=1.77, wpb=1284.9, bsz=85.1, num_updates=114200, lr=0.00059183, gnorm=0.613, train_wall=56, gb_free=18, wall=0
2024-02-06 15:37:54 | INFO | train_inner | epoch 036:   1040 / 3236 loss=0.887, nll_loss=0.887, ppl=1.85, wps=2309.1, ups=1.78, wpb=1300.6, bsz=89.9, num_updates=114300, lr=0.000591571, gnorm=0.604, train_wall=56, gb_free=18.2, wall=0
2024-02-06 15:38:51 | INFO | train_inner | epoch 036:   1140 / 3236 loss=0.883, nll_loss=0.883, ppl=1.84, wps=2309.4, ups=1.77, wpb=1307.5, bsz=89.5, num_updates=114400, lr=0.000591312, gnorm=0.604, train_wall=56, gb_free=17.5, wall=0
2024-02-06 15:39:47 | INFO | train_inner | epoch 036:   1240 / 3236 loss=0.886, nll_loss=0.886, ppl=1.85, wps=2335.1, ups=1.76, wpb=1324.2, bsz=94.2, num_updates=114500, lr=0.000591054, gnorm=0.617, train_wall=56, gb_free=18.3, wall=0
2024-02-06 15:40:44 | INFO | train_inner | epoch 036:   1340 / 3236 loss=0.887, nll_loss=0.887, ppl=1.85, wps=2301.7, ups=1.76, wpb=1304.7, bsz=89.6, num_updates=114600, lr=0.000590796, gnorm=0.614, train_wall=56, gb_free=18.2, wall=0
2024-02-06 15:41:41 | INFO | train_inner | epoch 036:   1440 / 3236 loss=0.874, nll_loss=0.874, ppl=1.83, wps=2264, ups=1.77, wpb=1278.1, bsz=87.4, num_updates=114700, lr=0.000590539, gnorm=0.61, train_wall=56, gb_free=18.4, wall=0
2024-02-06 15:42:37 | INFO | train_inner | epoch 036:   1540 / 3236 loss=0.893, nll_loss=0.893, ppl=1.86, wps=2314.4, ups=1.77, wpb=1309.3, bsz=92.3, num_updates=114800, lr=0.000590281, gnorm=0.612, train_wall=56, gb_free=17.8, wall=0
2024-02-06 15:43:34 | INFO | train_inner | epoch 036:   1640 / 3236 loss=0.885, nll_loss=0.885, ppl=1.85, wps=2295.9, ups=1.76, wpb=1301.5, bsz=85.6, num_updates=114900, lr=0.000590024, gnorm=0.612, train_wall=56, gb_free=17.8, wall=0
2024-02-06 15:44:31 | INFO | train_inner | epoch 036:   1740 / 3236 loss=0.863, nll_loss=0.863, ppl=1.82, wps=2320, ups=1.76, wpb=1315.7, bsz=93.7, num_updates=115000, lr=0.000589768, gnorm=0.594, train_wall=56, gb_free=17.2, wall=0
2024-02-06 15:45:27 | INFO | train_inner | epoch 036:   1840 / 3236 loss=0.887, nll_loss=0.887, ppl=1.85, wps=2297.9, ups=1.78, wpb=1292.8, bsz=88.9, num_updates=115100, lr=0.000589512, gnorm=0.62, train_wall=56, gb_free=18.3, wall=0
2024-02-06 15:46:23 | INFO | train_inner | epoch 036:   1940 / 3236 loss=0.904, nll_loss=0.904, ppl=1.87, wps=2295, ups=1.77, wpb=1299.8, bsz=87, num_updates=115200, lr=0.000589256, gnorm=0.614, train_wall=56, gb_free=17.6, wall=0
2024-02-06 15:47:21 | INFO | train_inner | epoch 036:   2040 / 3236 loss=0.9, nll_loss=0.9, ppl=1.87, wps=2226.3, ups=1.74, wpb=1277.2, bsz=86.4, num_updates=115300, lr=0.000589, gnorm=0.605, train_wall=56, gb_free=17.6, wall=0
2024-02-06 15:48:18 | INFO | train_inner | epoch 036:   2140 / 3236 loss=0.884, nll_loss=0.884, ppl=1.85, wps=2340.8, ups=1.76, wpb=1327.5, bsz=89.9, num_updates=115400, lr=0.000588745, gnorm=0.596, train_wall=56, gb_free=17.6, wall=0
2024-02-06 15:49:15 | INFO | train_inner | epoch 036:   2240 / 3236 loss=0.936, nll_loss=0.936, ppl=1.91, wps=2279.4, ups=1.75, wpb=1299.9, bsz=84.8, num_updates=115500, lr=0.00058849, gnorm=0.625, train_wall=57, gb_free=17.9, wall=0
2024-02-06 15:50:11 | INFO | train_inner | epoch 036:   2340 / 3236 loss=0.899, nll_loss=0.899, ppl=1.86, wps=2291.8, ups=1.77, wpb=1297.1, bsz=90.1, num_updates=115600, lr=0.000588235, gnorm=0.617, train_wall=56, gb_free=17.5, wall=0
2024-02-06 15:51:08 | INFO | train_inner | epoch 036:   2440 / 3236 loss=0.913, nll_loss=0.913, ppl=1.88, wps=2297.6, ups=1.75, wpb=1309.7, bsz=90.3, num_updates=115700, lr=0.000587981, gnorm=0.635, train_wall=56, gb_free=18.3, wall=0
2024-02-06 15:52:05 | INFO | train_inner | epoch 036:   2540 / 3236 loss=0.905, nll_loss=0.905, ppl=1.87, wps=2316.8, ups=1.76, wpb=1316.2, bsz=92.5, num_updates=115800, lr=0.000587727, gnorm=0.617, train_wall=56, gb_free=17.8, wall=0
2024-02-06 15:53:02 | INFO | train_inner | epoch 036:   2640 / 3236 loss=0.898, nll_loss=0.898, ppl=1.86, wps=2295.4, ups=1.76, wpb=1306.6, bsz=89.2, num_updates=115900, lr=0.000587473, gnorm=0.604, train_wall=56, gb_free=17, wall=0
2024-02-06 15:53:59 | INFO | train_inner | epoch 036:   2740 / 3236 loss=0.896, nll_loss=0.896, ppl=1.86, wps=2290.2, ups=1.76, wpb=1300, bsz=87.7, num_updates=116000, lr=0.00058722, gnorm=0.608, train_wall=56, gb_free=17.6, wall=0
2024-02-06 15:54:55 | INFO | train_inner | epoch 036:   2840 / 3236 loss=0.893, nll_loss=0.893, ppl=1.86, wps=2320.9, ups=1.77, wpb=1308.3, bsz=91.9, num_updates=116100, lr=0.000586967, gnorm=0.602, train_wall=56, gb_free=18.4, wall=0
2024-02-06 15:55:51 | INFO | train_inner | epoch 036:   2940 / 3236 loss=0.883, nll_loss=0.883, ppl=1.84, wps=2282.5, ups=1.78, wpb=1285.3, bsz=85.6, num_updates=116200, lr=0.000586715, gnorm=0.606, train_wall=56, gb_free=18.1, wall=0
2024-02-06 15:57:13 | INFO | train_inner | epoch 036:   3040 / 3236 loss=0.921, nll_loss=0.921, ppl=1.89, wps=1593.6, ups=1.23, wpb=1294.6, bsz=86.3, num_updates=116300, lr=0.000586462, gnorm=0.604, train_wall=56, gb_free=18.6, wall=0
2024-02-06 15:58:28 | INFO | train_inner | epoch 036:   3140 / 3236 loss=0.89, nll_loss=0.89, ppl=1.85, wps=1708.7, ups=1.32, wpb=1292.9, bsz=89.5, num_updates=116400, lr=0.00058621, gnorm=0.598, train_wall=56, gb_free=17.7, wall=0
2024-02-06 15:59:25 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 15:59:25 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 16:00:56 | INFO | dev | epoch 036 | valid on 'dev' subset | loss 1.094 | nll_loss 1.094 | ppl 2.13 | wps 2535.6 | wpb 1146.2 | bsz 77.6 | num_updates 116496 | best_loss 1.094
2024-02-06 16:00:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 36 @ 116496 updates
2024-02-06 16:00:56 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint36.pt
2024-02-06 16:00:57 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint36.pt
2024-02-06 16:01:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint36.pt (epoch 36 @ 116496 updates, score 1.094) (writing took 6.066635875031352 seconds)
2024-02-06 16:01:02 | INFO | fairseq_cli.train | end of epoch 36 (average epoch stats below)
2024-02-06 16:01:02 | INFO | train | epoch 036 | loss 0.887 | nll_loss 0.887 | ppl 1.85 | wps 2131.5 | ups 1.64 | wpb 1302.4 | bsz 89.4 | num_updates 116496 | lr 0.000585969 | gnorm 0.608 | train_wall 1815 | gb_free 18.2 | wall 0
2024-02-06 16:01:02 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 16:01:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 16:01:02 | INFO | fairseq.trainer | begin training epoch 37
2024-02-06 16:01:02 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 16:01:05 | INFO | train_inner | epoch 037:      4 / 3236 loss=0.89, nll_loss=0.89, ppl=1.85, wps=827.4, ups=0.64, wpb=1296.4, bsz=87.2, num_updates=116500, lr=0.000585959, gnorm=0.618, train_wall=57, gb_free=17.8, wall=0
2024-02-06 16:02:03 | INFO | train_inner | epoch 037:    104 / 3236 loss=0.855, nll_loss=0.855, ppl=1.81, wps=2247.8, ups=1.73, wpb=1296.9, bsz=88.7, num_updates=116600, lr=0.000585707, gnorm=0.596, train_wall=56, gb_free=17.9, wall=0
2024-02-06 16:02:59 | INFO | train_inner | epoch 037:    204 / 3236 loss=0.86, nll_loss=0.86, ppl=1.81, wps=2346.5, ups=1.76, wpb=1331.3, bsz=92.9, num_updates=116700, lr=0.000585456, gnorm=0.591, train_wall=56, gb_free=18.1, wall=0
2024-02-06 16:03:56 | INFO | train_inner | epoch 037:    304 / 3236 loss=0.854, nll_loss=0.854, ppl=1.81, wps=2316.1, ups=1.77, wpb=1309.2, bsz=88.6, num_updates=116800, lr=0.000585206, gnorm=0.587, train_wall=56, gb_free=17.7, wall=0
2024-02-06 16:04:53 | INFO | train_inner | epoch 037:    404 / 3236 loss=0.843, nll_loss=0.843, ppl=1.79, wps=2260.7, ups=1.77, wpb=1280.3, bsz=88.8, num_updates=116900, lr=0.000584955, gnorm=0.596, train_wall=56, gb_free=18.8, wall=0
2024-02-06 16:05:50 | INFO | train_inner | epoch 037:    504 / 3236 loss=0.849, nll_loss=0.849, ppl=1.8, wps=2255.1, ups=1.75, wpb=1286.9, bsz=85.5, num_updates=117000, lr=0.000584705, gnorm=0.619, train_wall=57, gb_free=18.8, wall=0
2024-02-06 16:06:46 | INFO | train_inner | epoch 037:    604 / 3236 loss=0.866, nll_loss=0.866, ppl=1.82, wps=2337.7, ups=1.77, wpb=1318.5, bsz=93.5, num_updates=117100, lr=0.000584456, gnorm=0.602, train_wall=56, gb_free=18.5, wall=0
2024-02-06 16:07:43 | INFO | train_inner | epoch 037:    704 / 3236 loss=0.859, nll_loss=0.859, ppl=1.81, wps=2292.7, ups=1.76, wpb=1300.3, bsz=87.1, num_updates=117200, lr=0.000584206, gnorm=0.614, train_wall=56, gb_free=18.5, wall=0
2024-02-06 16:08:40 | INFO | train_inner | epoch 037:    804 / 3236 loss=0.887, nll_loss=0.887, ppl=1.85, wps=2278.6, ups=1.75, wpb=1299.3, bsz=88.6, num_updates=117300, lr=0.000583957, gnorm=0.62, train_wall=57, gb_free=17.9, wall=0
2024-02-06 16:09:45 | INFO | train_inner | epoch 037:    904 / 3236 loss=0.877, nll_loss=0.877, ppl=1.84, wps=2005, ups=1.53, wpb=1310.8, bsz=91.8, num_updates=117400, lr=0.000583708, gnorm=0.598, train_wall=56, gb_free=17.6, wall=0
2024-02-06 16:10:45 | INFO | train_inner | epoch 037:   1004 / 3236 loss=0.887, nll_loss=0.887, ppl=1.85, wps=2190.3, ups=1.66, wpb=1316, bsz=92.1, num_updates=117500, lr=0.00058346, gnorm=0.606, train_wall=56, gb_free=18.2, wall=0
2024-02-06 16:11:43 | INFO | train_inner | epoch 037:   1104 / 3236 loss=0.878, nll_loss=0.878, ppl=1.84, wps=2270.9, ups=1.73, wpb=1312, bsz=88.4, num_updates=117600, lr=0.000583212, gnorm=0.617, train_wall=56, gb_free=18.3, wall=0
2024-02-06 16:12:40 | INFO | train_inner | epoch 037:   1204 / 3236 loss=0.863, nll_loss=0.863, ppl=1.82, wps=2289.4, ups=1.76, wpb=1299.5, bsz=86.6, num_updates=117700, lr=0.000582964, gnorm=0.613, train_wall=56, gb_free=18.3, wall=0
2024-02-06 16:13:36 | INFO | train_inner | epoch 037:   1304 / 3236 loss=0.864, nll_loss=0.864, ppl=1.82, wps=2305.4, ups=1.77, wpb=1302.3, bsz=90.2, num_updates=117800, lr=0.000582717, gnorm=0.601, train_wall=56, gb_free=17.9, wall=0
2024-02-06 16:14:33 | INFO | train_inner | epoch 037:   1404 / 3236 loss=0.884, nll_loss=0.884, ppl=1.84, wps=2296.3, ups=1.78, wpb=1291.9, bsz=94.9, num_updates=117900, lr=0.000582469, gnorm=0.614, train_wall=56, gb_free=18.3, wall=0
2024-02-06 16:15:29 | INFO | train_inner | epoch 037:   1504 / 3236 loss=0.87, nll_loss=0.87, ppl=1.83, wps=2302.3, ups=1.77, wpb=1298.8, bsz=89.4, num_updates=118000, lr=0.000582223, gnorm=0.604, train_wall=56, gb_free=18, wall=0
2024-02-06 16:16:26 | INFO | train_inner | epoch 037:   1604 / 3236 loss=0.879, nll_loss=0.879, ppl=1.84, wps=2292.9, ups=1.76, wpb=1301.6, bsz=87.3, num_updates=118100, lr=0.000581976, gnorm=0.614, train_wall=56, gb_free=17.3, wall=0
2024-02-06 16:17:22 | INFO | train_inner | epoch 037:   1704 / 3236 loss=0.881, nll_loss=0.881, ppl=1.84, wps=2309.7, ups=1.76, wpb=1309.8, bsz=87, num_updates=118200, lr=0.00058173, gnorm=0.608, train_wall=56, gb_free=18.2, wall=0
2024-02-06 16:18:21 | INFO | train_inner | epoch 037:   1804 / 3236 loss=0.888, nll_loss=0.888, ppl=1.85, wps=2242.6, ups=1.71, wpb=1307.8, bsz=98.2, num_updates=118300, lr=0.000581484, gnorm=0.596, train_wall=58, gb_free=17.9, wall=0
2024-02-06 16:19:17 | INFO | train_inner | epoch 037:   1904 / 3236 loss=0.881, nll_loss=0.881, ppl=1.84, wps=2322.4, ups=1.76, wpb=1318.2, bsz=92.1, num_updates=118400, lr=0.000581238, gnorm=0.593, train_wall=56, gb_free=17.7, wall=0
2024-02-06 16:20:15 | INFO | train_inner | epoch 037:   2004 / 3236 loss=0.893, nll_loss=0.893, ppl=1.86, wps=2247.6, ups=1.73, wpb=1300.1, bsz=90.1, num_updates=118500, lr=0.000580993, gnorm=0.61, train_wall=57, gb_free=18, wall=0
2024-02-06 16:21:12 | INFO | train_inner | epoch 037:   2104 / 3236 loss=0.89, nll_loss=0.89, ppl=1.85, wps=2283.3, ups=1.77, wpb=1288, bsz=86.8, num_updates=118600, lr=0.000580748, gnorm=0.625, train_wall=56, gb_free=18.2, wall=0
2024-02-06 16:22:08 | INFO | train_inner | epoch 037:   2204 / 3236 loss=0.875, nll_loss=0.875, ppl=1.83, wps=2306.7, ups=1.77, wpb=1304.2, bsz=89.8, num_updates=118700, lr=0.000580503, gnorm=0.602, train_wall=56, gb_free=17.8, wall=0
2024-02-06 16:23:05 | INFO | train_inner | epoch 037:   2304 / 3236 loss=0.878, nll_loss=0.878, ppl=1.84, wps=2296.2, ups=1.77, wpb=1298, bsz=87.6, num_updates=118800, lr=0.000580259, gnorm=0.606, train_wall=56, gb_free=18.3, wall=0
2024-02-06 16:24:02 | INFO | train_inner | epoch 037:   2404 / 3236 loss=0.873, nll_loss=0.873, ppl=1.83, wps=2295.6, ups=1.76, wpb=1304, bsz=91.6, num_updates=118900, lr=0.000580015, gnorm=0.594, train_wall=56, gb_free=17.8, wall=0
2024-02-06 16:24:58 | INFO | train_inner | epoch 037:   2504 / 3236 loss=0.892, nll_loss=0.892, ppl=1.86, wps=2319.4, ups=1.76, wpb=1316.2, bsz=88.7, num_updates=119000, lr=0.000579771, gnorm=0.607, train_wall=56, gb_free=18.1, wall=0
2024-02-06 16:25:55 | INFO | train_inner | epoch 037:   2604 / 3236 loss=0.899, nll_loss=0.899, ppl=1.86, wps=2301.1, ups=1.77, wpb=1301.8, bsz=88.2, num_updates=119100, lr=0.000579528, gnorm=0.615, train_wall=56, gb_free=18, wall=0
2024-02-06 16:26:52 | INFO | train_inner | epoch 037:   2704 / 3236 loss=0.884, nll_loss=0.884, ppl=1.85, wps=2300.5, ups=1.77, wpb=1302.8, bsz=91.1, num_updates=119200, lr=0.000579284, gnorm=0.613, train_wall=56, gb_free=18.3, wall=0
2024-02-06 16:27:48 | INFO | train_inner | epoch 037:   2804 / 3236 loss=0.893, nll_loss=0.893, ppl=1.86, wps=2305.8, ups=1.76, wpb=1309.7, bsz=89.3, num_updates=119300, lr=0.000579042, gnorm=0.61, train_wall=56, gb_free=18.5, wall=0
2024-02-06 16:28:45 | INFO | train_inner | epoch 037:   2904 / 3236 loss=0.881, nll_loss=0.881, ppl=1.84, wps=2286.2, ups=1.76, wpb=1295.5, bsz=89.2, num_updates=119400, lr=0.000578799, gnorm=0.617, train_wall=56, gb_free=16.9, wall=0
2024-02-06 16:29:41 | INFO | train_inner | epoch 037:   3004 / 3236 loss=0.896, nll_loss=0.896, ppl=1.86, wps=2284.8, ups=1.78, wpb=1284.4, bsz=83.9, num_updates=119500, lr=0.000578557, gnorm=0.62, train_wall=56, gb_free=18.6, wall=0
2024-02-06 16:30:38 | INFO | train_inner | epoch 037:   3104 / 3236 loss=0.903, nll_loss=0.903, ppl=1.87, wps=2282.7, ups=1.75, wpb=1304.5, bsz=89.6, num_updates=119600, lr=0.000578315, gnorm=0.615, train_wall=57, gb_free=18.6, wall=0
2024-02-06 16:31:35 | INFO | train_inner | epoch 037:   3204 / 3236 loss=0.886, nll_loss=0.886, ppl=1.85, wps=2256.1, ups=1.77, wpb=1275.4, bsz=84.1, num_updates=119700, lr=0.000578073, gnorm=0.627, train_wall=56, gb_free=18.7, wall=0
2024-02-06 16:31:53 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 16:31:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 16:33:11 | INFO | dev | epoch 037 | valid on 'dev' subset | loss 1.103 | nll_loss 1.103 | ppl 2.15 | wps 2957.9 | wpb 1146.2 | bsz 77.6 | num_updates 119732 | best_loss 1.094
2024-02-06 16:33:11 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 37 @ 119732 updates
2024-02-06 16:33:11 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint37.pt
2024-02-06 16:33:13 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint37.pt
2024-02-06 16:33:14 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint37.pt (epoch 37 @ 119732 updates, score 1.103) (writing took 3.2340676970779896 seconds)
2024-02-06 16:33:14 | INFO | fairseq_cli.train | end of epoch 37 (average epoch stats below)
2024-02-06 16:33:14 | INFO | train | epoch 037 | loss 0.877 | nll_loss 0.877 | ppl 1.84 | wps 2181.2 | ups 1.67 | wpb 1302.4 | bsz 89.4 | num_updates 119732 | lr 0.000577996 | gnorm 0.608 | train_wall 1819 | gb_free 17.8 | wall 0
2024-02-06 16:33:14 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 16:33:14 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 16:33:14 | INFO | fairseq.trainer | begin training epoch 38
2024-02-06 16:33:14 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 16:33:55 | INFO | train_inner | epoch 038:     68 / 3236 loss=0.853, nll_loss=0.853, ppl=1.81, wps=933.4, ups=0.72, wpb=1305.1, bsz=92.7, num_updates=119800, lr=0.000577832, gnorm=0.596, train_wall=56, gb_free=17.6, wall=0
2024-02-06 16:34:51 | INFO | train_inner | epoch 038:    168 / 3236 loss=0.825, nll_loss=0.825, ppl=1.77, wps=2292.5, ups=1.76, wpb=1299.1, bsz=88.2, num_updates=119900, lr=0.000577591, gnorm=0.591, train_wall=56, gb_free=18, wall=0
2024-02-06 16:35:48 | INFO | train_inner | epoch 038:    268 / 3236 loss=0.841, nll_loss=0.841, ppl=1.79, wps=2322.2, ups=1.77, wpb=1312, bsz=90.7, num_updates=120000, lr=0.00057735, gnorm=0.603, train_wall=56, gb_free=17.6, wall=0
2024-02-06 16:36:45 | INFO | train_inner | epoch 038:    368 / 3236 loss=0.834, nll_loss=0.834, ppl=1.78, wps=2242, ups=1.77, wpb=1269.8, bsz=84.2, num_updates=120100, lr=0.00057711, gnorm=0.62, train_wall=56, gb_free=17.4, wall=0
2024-02-06 16:37:41 | INFO | train_inner | epoch 038:    468 / 3236 loss=0.845, nll_loss=0.845, ppl=1.8, wps=2292.9, ups=1.77, wpb=1297.5, bsz=88.8, num_updates=120200, lr=0.00057687, gnorm=0.604, train_wall=56, gb_free=18, wall=0
2024-02-06 16:38:38 | INFO | train_inner | epoch 038:    568 / 3236 loss=0.857, nll_loss=0.857, ppl=1.81, wps=2339.1, ups=1.77, wpb=1320.4, bsz=93.2, num_updates=120300, lr=0.00057663, gnorm=0.594, train_wall=56, gb_free=18.3, wall=0
2024-02-06 16:39:34 | INFO | train_inner | epoch 038:    668 / 3236 loss=0.853, nll_loss=0.853, ppl=1.81, wps=2285.2, ups=1.77, wpb=1290.5, bsz=83.8, num_updates=120400, lr=0.00057639, gnorm=0.617, train_wall=56, gb_free=17.5, wall=0
2024-02-06 16:40:31 | INFO | train_inner | epoch 038:    768 / 3236 loss=0.859, nll_loss=0.859, ppl=1.81, wps=2281.9, ups=1.76, wpb=1297, bsz=86.2, num_updates=120500, lr=0.000576151, gnorm=0.624, train_wall=56, gb_free=17.9, wall=0
2024-02-06 16:41:27 | INFO | train_inner | epoch 038:    868 / 3236 loss=0.857, nll_loss=0.857, ppl=1.81, wps=2308.7, ups=1.77, wpb=1301.2, bsz=86.9, num_updates=120600, lr=0.000575912, gnorm=0.613, train_wall=56, gb_free=17.8, wall=0
2024-02-06 16:42:24 | INFO | train_inner | epoch 038:    968 / 3236 loss=0.852, nll_loss=0.852, ppl=1.8, wps=2279.1, ups=1.77, wpb=1289.7, bsz=87.2, num_updates=120700, lr=0.000575674, gnorm=0.616, train_wall=56, gb_free=17.2, wall=0
2024-02-06 16:43:20 | INFO | train_inner | epoch 038:   1068 / 3236 loss=0.866, nll_loss=0.866, ppl=1.82, wps=2277.6, ups=1.77, wpb=1287.7, bsz=86.6, num_updates=120800, lr=0.000575435, gnorm=0.62, train_wall=56, gb_free=17.7, wall=0
2024-02-06 16:44:17 | INFO | train_inner | epoch 038:   1168 / 3236 loss=0.848, nll_loss=0.848, ppl=1.8, wps=2334.7, ups=1.77, wpb=1320.4, bsz=93.3, num_updates=120900, lr=0.000575197, gnorm=0.589, train_wall=56, gb_free=18, wall=0
2024-02-06 16:45:14 | INFO | train_inner | epoch 038:   1268 / 3236 loss=0.871, nll_loss=0.871, ppl=1.83, wps=2287.4, ups=1.76, wpb=1299.8, bsz=91.3, num_updates=121000, lr=0.00057496, gnorm=0.629, train_wall=56, gb_free=18.1, wall=0
2024-02-06 16:46:10 | INFO | train_inner | epoch 038:   1368 / 3236 loss=0.88, nll_loss=0.88, ppl=1.84, wps=2313.9, ups=1.77, wpb=1310.4, bsz=91.3, num_updates=121100, lr=0.000574722, gnorm=0.602, train_wall=56, gb_free=18.7, wall=0
2024-02-06 16:47:07 | INFO | train_inner | epoch 038:   1468 / 3236 loss=0.86, nll_loss=0.86, ppl=1.82, wps=2332.9, ups=1.77, wpb=1315.8, bsz=94.6, num_updates=121200, lr=0.000574485, gnorm=0.595, train_wall=56, gb_free=18, wall=0
2024-02-06 16:48:04 | INFO | train_inner | epoch 038:   1568 / 3236 loss=0.875, nll_loss=0.875, ppl=1.83, wps=2345.1, ups=1.76, wpb=1330.1, bsz=94.5, num_updates=121300, lr=0.000574248, gnorm=0.595, train_wall=56, gb_free=18.5, wall=0
2024-02-06 16:49:03 | INFO | train_inner | epoch 038:   1668 / 3236 loss=0.86, nll_loss=0.86, ppl=1.82, wps=2225.5, ups=1.69, wpb=1319.3, bsz=92.6, num_updates=121400, lr=0.000574012, gnorm=0.602, train_wall=56, gb_free=17.7, wall=0
2024-02-06 16:50:01 | INFO | train_inner | epoch 038:   1768 / 3236 loss=0.861, nll_loss=0.861, ppl=1.82, wps=2236.5, ups=1.72, wpb=1303.9, bsz=86.2, num_updates=121500, lr=0.000573775, gnorm=0.625, train_wall=57, gb_free=17.3, wall=0
2024-02-06 16:50:58 | INFO | train_inner | epoch 038:   1868 / 3236 loss=0.902, nll_loss=0.902, ppl=1.87, wps=2314.6, ups=1.76, wpb=1317, bsz=90.9, num_updates=121600, lr=0.000573539, gnorm=0.619, train_wall=56, gb_free=17.6, wall=0
2024-02-06 16:51:55 | INFO | train_inner | epoch 038:   1968 / 3236 loss=0.882, nll_loss=0.882, ppl=1.84, wps=2224.5, ups=1.77, wpb=1259.3, bsz=82.7, num_updates=121700, lr=0.000573304, gnorm=0.625, train_wall=56, gb_free=17.8, wall=0
2024-02-06 16:52:52 | INFO | train_inner | epoch 038:   2068 / 3236 loss=0.881, nll_loss=0.881, ppl=1.84, wps=2285.3, ups=1.74, wpb=1314.1, bsz=91, num_updates=121800, lr=0.000573068, gnorm=0.608, train_wall=57, gb_free=18.6, wall=0
2024-02-06 16:53:48 | INFO | train_inner | epoch 038:   2168 / 3236 loss=0.87, nll_loss=0.87, ppl=1.83, wps=2301, ups=1.78, wpb=1293.2, bsz=91.5, num_updates=121900, lr=0.000572833, gnorm=0.626, train_wall=56, gb_free=18.3, wall=0
2024-02-06 16:54:45 | INFO | train_inner | epoch 038:   2268 / 3236 loss=0.863, nll_loss=0.863, ppl=1.82, wps=2318.3, ups=1.76, wpb=1314.4, bsz=93.4, num_updates=122000, lr=0.000572598, gnorm=0.604, train_wall=56, gb_free=17.7, wall=0
2024-02-06 16:55:48 | INFO | train_inner | epoch 038:   2368 / 3236 loss=0.879, nll_loss=0.879, ppl=1.84, wps=2089.3, ups=1.59, wpb=1317.3, bsz=94.6, num_updates=122100, lr=0.000572364, gnorm=0.616, train_wall=56, gb_free=17.9, wall=0
2024-02-06 16:56:51 | INFO | train_inner | epoch 038:   2468 / 3236 loss=0.889, nll_loss=0.889, ppl=1.85, wps=2054.2, ups=1.59, wpb=1295.6, bsz=90.2, num_updates=122200, lr=0.00057213, gnorm=0.612, train_wall=56, gb_free=18.1, wall=0
2024-02-06 16:57:48 | INFO | train_inner | epoch 038:   2568 / 3236 loss=0.879, nll_loss=0.879, ppl=1.84, wps=2316.3, ups=1.76, wpb=1318.3, bsz=86.7, num_updates=122300, lr=0.000571896, gnorm=0.607, train_wall=56, gb_free=18.1, wall=0
2024-02-06 16:58:48 | INFO | train_inner | epoch 038:   2668 / 3236 loss=0.883, nll_loss=0.883, ppl=1.84, wps=2154.8, ups=1.66, wpb=1299, bsz=86.2, num_updates=122400, lr=0.000571662, gnorm=0.627, train_wall=60, gb_free=17.5, wall=0
2024-02-06 16:59:45 | INFO | train_inner | epoch 038:   2768 / 3236 loss=0.896, nll_loss=0.896, ppl=1.86, wps=2275.9, ups=1.76, wpb=1294.7, bsz=88.5, num_updates=122500, lr=0.000571429, gnorm=0.623, train_wall=56, gb_free=17.6, wall=0
2024-02-06 17:00:42 | INFO | train_inner | epoch 038:   2868 / 3236 loss=0.881, nll_loss=0.881, ppl=1.84, wps=2269.8, ups=1.76, wpb=1290, bsz=87.4, num_updates=122600, lr=0.000571195, gnorm=0.63, train_wall=56, gb_free=18.3, wall=0
2024-02-06 17:01:39 | INFO | train_inner | epoch 038:   2968 / 3236 loss=0.89, nll_loss=0.89, ppl=1.85, wps=2269.7, ups=1.76, wpb=1292.7, bsz=88, num_updates=122700, lr=0.000570963, gnorm=0.611, train_wall=56, gb_free=17.2, wall=0
2024-02-06 17:02:38 | INFO | train_inner | epoch 038:   3068 / 3236 loss=0.879, nll_loss=0.879, ppl=1.84, wps=2214.4, ups=1.69, wpb=1309.9, bsz=89, num_updates=122800, lr=0.00057073, gnorm=0.594, train_wall=56, gb_free=17.6, wall=0
2024-02-06 17:03:38 | INFO | train_inner | epoch 038:   3168 / 3236 loss=0.891, nll_loss=0.891, ppl=1.85, wps=2163.3, ups=1.68, wpb=1291.3, bsz=88, num_updates=122900, lr=0.000570498, gnorm=0.619, train_wall=56, gb_free=18.4, wall=0
2024-02-06 17:04:18 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 17:04:18 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 17:05:52 | INFO | dev | epoch 038 | valid on 'dev' subset | loss 1.114 | nll_loss 1.114 | ppl 2.16 | wps 2472.5 | wpb 1146.2 | bsz 77.6 | num_updates 122968 | best_loss 1.094
2024-02-06 17:05:52 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 38 @ 122968 updates
2024-02-06 17:05:52 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint38.pt
2024-02-06 17:05:54 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint38.pt
2024-02-06 17:05:55 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint38.pt (epoch 38 @ 122968 updates, score 1.114) (writing took 3.1770283149089664 seconds)
2024-02-06 17:05:55 | INFO | fairseq_cli.train | end of epoch 38 (average epoch stats below)
2024-02-06 17:05:55 | INFO | train | epoch 038 | loss 0.868 | nll_loss 0.868 | ppl 1.82 | wps 2149.1 | ups 1.65 | wpb 1302.4 | bsz 89.4 | num_updates 122968 | lr 0.00057034 | gnorm 0.611 | train_wall 1820 | gb_free 18.5 | wall 0
2024-02-06 17:05:55 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 17:05:55 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 17:05:55 | INFO | fairseq.trainer | begin training epoch 39
2024-02-06 17:05:55 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 17:06:16 | INFO | train_inner | epoch 039:     32 / 3236 loss=0.868, nll_loss=0.868, ppl=1.83, wps=824.4, ups=0.63, wpb=1300, bsz=92.6, num_updates=123000, lr=0.000570266, gnorm=0.62, train_wall=56, gb_free=18.1, wall=0
2024-02-06 17:07:13 | INFO | train_inner | epoch 039:    132 / 3236 loss=0.827, nll_loss=0.827, ppl=1.77, wps=2301.2, ups=1.75, wpb=1314.2, bsz=90.3, num_updates=123100, lr=0.000570034, gnorm=0.593, train_wall=57, gb_free=17.8, wall=0
2024-02-06 17:08:09 | INFO | train_inner | epoch 039:    232 / 3236 loss=0.836, nll_loss=0.836, ppl=1.79, wps=2318, ups=1.77, wpb=1311.8, bsz=87.9, num_updates=123200, lr=0.000569803, gnorm=0.605, train_wall=56, gb_free=17.9, wall=0
2024-02-06 17:09:06 | INFO | train_inner | epoch 039:    332 / 3236 loss=0.84, nll_loss=0.84, ppl=1.79, wps=2318.3, ups=1.77, wpb=1312.7, bsz=92, num_updates=123300, lr=0.000569572, gnorm=0.602, train_wall=56, gb_free=17.8, wall=0
2024-02-06 17:10:02 | INFO | train_inner | epoch 039:    432 / 3236 loss=0.831, nll_loss=0.831, ppl=1.78, wps=2295.8, ups=1.77, wpb=1298.3, bsz=88.6, num_updates=123400, lr=0.000569341, gnorm=0.601, train_wall=56, gb_free=18.5, wall=0
2024-02-06 17:10:59 | INFO | train_inner | epoch 039:    532 / 3236 loss=0.838, nll_loss=0.838, ppl=1.79, wps=2305.5, ups=1.76, wpb=1306.6, bsz=87.4, num_updates=123500, lr=0.00056911, gnorm=0.602, train_wall=56, gb_free=18.4, wall=0
2024-02-06 17:11:56 | INFO | train_inner | epoch 039:    632 / 3236 loss=0.844, nll_loss=0.844, ppl=1.79, wps=2257.5, ups=1.77, wpb=1275.2, bsz=84.1, num_updates=123600, lr=0.00056888, gnorm=0.62, train_wall=56, gb_free=18.4, wall=0
2024-02-06 17:12:53 | INFO | train_inner | epoch 039:    732 / 3236 loss=0.844, nll_loss=0.844, ppl=1.79, wps=2321.6, ups=1.75, wpb=1323.5, bsz=89.5, num_updates=123700, lr=0.00056865, gnorm=0.61, train_wall=56, gb_free=18.1, wall=0
2024-02-06 17:13:50 | INFO | train_inner | epoch 039:    832 / 3236 loss=0.849, nll_loss=0.849, ppl=1.8, wps=2282.8, ups=1.75, wpb=1304, bsz=92.6, num_updates=123800, lr=0.00056842, gnorm=0.608, train_wall=57, gb_free=17.9, wall=0
2024-02-06 17:14:46 | INFO | train_inner | epoch 039:    932 / 3236 loss=0.863, nll_loss=0.863, ppl=1.82, wps=2287.8, ups=1.76, wpb=1296.4, bsz=91.9, num_updates=123900, lr=0.000568191, gnorm=0.611, train_wall=56, gb_free=18.1, wall=0
2024-02-06 17:15:43 | INFO | train_inner | epoch 039:   1032 / 3236 loss=0.845, nll_loss=0.845, ppl=1.8, wps=2265.4, ups=1.76, wpb=1284.2, bsz=86.4, num_updates=124000, lr=0.000567962, gnorm=0.624, train_wall=56, gb_free=17.9, wall=0
2024-02-06 17:16:40 | INFO | train_inner | epoch 039:   1132 / 3236 loss=0.862, nll_loss=0.862, ppl=1.82, wps=2330.1, ups=1.77, wpb=1317.6, bsz=90.8, num_updates=124100, lr=0.000567733, gnorm=0.608, train_wall=56, gb_free=18.6, wall=0
2024-02-06 17:17:36 | INFO | train_inner | epoch 039:   1232 / 3236 loss=0.873, nll_loss=0.873, ppl=1.83, wps=2282.6, ups=1.78, wpb=1284.7, bsz=90, num_updates=124200, lr=0.000567504, gnorm=0.626, train_wall=56, gb_free=17.5, wall=0
2024-02-06 17:18:32 | INFO | train_inner | epoch 039:   1332 / 3236 loss=0.846, nll_loss=0.846, ppl=1.8, wps=2283, ups=1.78, wpb=1285.9, bsz=84.6, num_updates=124300, lr=0.000567276, gnorm=0.615, train_wall=56, gb_free=17.6, wall=0
2024-02-06 17:19:29 | INFO | train_inner | epoch 039:   1432 / 3236 loss=0.873, nll_loss=0.873, ppl=1.83, wps=2318, ups=1.76, wpb=1319.6, bsz=89.4, num_updates=124400, lr=0.000567048, gnorm=0.614, train_wall=56, gb_free=18.5, wall=0
2024-02-06 17:20:26 | INFO | train_inner | epoch 039:   1532 / 3236 loss=0.865, nll_loss=0.865, ppl=1.82, wps=2320.6, ups=1.76, wpb=1316.3, bsz=93.5, num_updates=124500, lr=0.00056682, gnorm=0.618, train_wall=56, gb_free=18.2, wall=0
2024-02-06 17:21:23 | INFO | train_inner | epoch 039:   1632 / 3236 loss=0.863, nll_loss=0.863, ppl=1.82, wps=2273.8, ups=1.76, wpb=1289.7, bsz=89.6, num_updates=124600, lr=0.000566593, gnorm=0.65, train_wall=56, gb_free=18.5, wall=0
2024-02-06 17:22:19 | INFO | train_inner | epoch 039:   1732 / 3236 loss=0.879, nll_loss=0.879, ppl=1.84, wps=2328.5, ups=1.77, wpb=1318.7, bsz=90.5, num_updates=124700, lr=0.000566365, gnorm=0.616, train_wall=56, gb_free=18.5, wall=0
2024-02-06 17:23:19 | INFO | train_inner | epoch 039:   1832 / 3236 loss=0.856, nll_loss=0.856, ppl=1.81, wps=2170.1, ups=1.66, wpb=1306, bsz=86.5, num_updates=124800, lr=0.000566139, gnorm=0.608, train_wall=60, gb_free=18.5, wall=0
2024-02-06 17:24:16 | INFO | train_inner | epoch 039:   1932 / 3236 loss=0.864, nll_loss=0.864, ppl=1.82, wps=2268, ups=1.76, wpb=1289.3, bsz=90.6, num_updates=124900, lr=0.000565912, gnorm=0.615, train_wall=56, gb_free=18.4, wall=0
2024-02-06 17:25:13 | INFO | train_inner | epoch 039:   2032 / 3236 loss=0.858, nll_loss=0.858, ppl=1.81, wps=2275, ups=1.76, wpb=1290.6, bsz=88.9, num_updates=125000, lr=0.000565685, gnorm=0.614, train_wall=56, gb_free=17.6, wall=0
2024-02-06 17:26:09 | INFO | train_inner | epoch 039:   2132 / 3236 loss=0.88, nll_loss=0.88, ppl=1.84, wps=2312.8, ups=1.77, wpb=1306.9, bsz=89.5, num_updates=125100, lr=0.000565459, gnorm=0.618, train_wall=56, gb_free=18.3, wall=0
2024-02-06 17:27:06 | INFO | train_inner | epoch 039:   2232 / 3236 loss=0.873, nll_loss=0.873, ppl=1.83, wps=2292.6, ups=1.76, wpb=1302.3, bsz=88.2, num_updates=125200, lr=0.000565233, gnorm=0.629, train_wall=56, gb_free=17.6, wall=0
2024-02-06 17:28:03 | INFO | train_inner | epoch 039:   2332 / 3236 loss=0.871, nll_loss=0.871, ppl=1.83, wps=2285, ups=1.76, wpb=1295.5, bsz=91.8, num_updates=125300, lr=0.000565008, gnorm=0.618, train_wall=56, gb_free=17.8, wall=0
2024-02-06 17:29:00 | INFO | train_inner | epoch 039:   2432 / 3236 loss=0.885, nll_loss=0.885, ppl=1.85, wps=2299.2, ups=1.76, wpb=1309.1, bsz=90.9, num_updates=125400, lr=0.000564782, gnorm=0.617, train_wall=56, gb_free=18.2, wall=0
2024-02-06 17:29:57 | INFO | train_inner | epoch 039:   2532 / 3236 loss=0.872, nll_loss=0.872, ppl=1.83, wps=2278.9, ups=1.77, wpb=1291.1, bsz=87, num_updates=125500, lr=0.000564557, gnorm=0.626, train_wall=56, gb_free=18.4, wall=0
2024-02-06 17:30:53 | INFO | train_inner | epoch 039:   2632 / 3236 loss=0.865, nll_loss=0.865, ppl=1.82, wps=2279.4, ups=1.76, wpb=1297.7, bsz=86.3, num_updates=125600, lr=0.000564333, gnorm=0.608, train_wall=56, gb_free=17.8, wall=0
2024-02-06 17:31:50 | INFO | train_inner | epoch 039:   2732 / 3236 loss=0.876, nll_loss=0.876, ppl=1.84, wps=2272.9, ups=1.76, wpb=1289.2, bsz=86.6, num_updates=125700, lr=0.000564108, gnorm=0.629, train_wall=56, gb_free=17.9, wall=0
2024-02-06 17:32:47 | INFO | train_inner | epoch 039:   2832 / 3236 loss=0.872, nll_loss=0.872, ppl=1.83, wps=2284.9, ups=1.75, wpb=1302, bsz=89, num_updates=125800, lr=0.000563884, gnorm=0.618, train_wall=56, gb_free=17.9, wall=0
2024-02-06 17:33:44 | INFO | train_inner | epoch 039:   2932 / 3236 loss=0.865, nll_loss=0.865, ppl=1.82, wps=2306.8, ups=1.76, wpb=1312.2, bsz=92.6, num_updates=125900, lr=0.00056366, gnorm=0.613, train_wall=56, gb_free=18, wall=0
2024-02-06 17:34:41 | INFO | train_inner | epoch 039:   3032 / 3236 loss=0.883, nll_loss=0.883, ppl=1.84, wps=2342.4, ups=1.76, wpb=1327.7, bsz=95, num_updates=126000, lr=0.000563436, gnorm=0.593, train_wall=56, gb_free=18.5, wall=0
2024-02-06 17:35:37 | INFO | train_inner | epoch 039:   3132 / 3236 loss=0.893, nll_loss=0.893, ppl=1.86, wps=2274.2, ups=1.77, wpb=1287.1, bsz=87.8, num_updates=126100, lr=0.000563213, gnorm=0.64, train_wall=56, gb_free=17.5, wall=0
2024-02-06 17:36:34 | INFO | train_inner | epoch 039:   3232 / 3236 loss=0.879, nll_loss=0.879, ppl=1.84, wps=2319.6, ups=1.76, wpb=1314.5, bsz=91.1, num_updates=126200, lr=0.00056299, gnorm=0.596, train_wall=56, gb_free=17.6, wall=0
2024-02-06 17:36:36 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 17:36:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 17:37:59 | INFO | dev | epoch 039 | valid on 'dev' subset | loss 1.095 | nll_loss 1.095 | ppl 2.14 | wps 2804.4 | wpb 1146.2 | bsz 77.6 | num_updates 126204 | best_loss 1.094
2024-02-06 17:37:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 39 @ 126204 updates
2024-02-06 17:37:59 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint39.pt
2024-02-06 17:38:00 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint39.pt
2024-02-06 17:38:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint39.pt (epoch 39 @ 126204 updates, score 1.095) (writing took 4.606550162192434 seconds)
2024-02-06 17:38:03 | INFO | fairseq_cli.train | end of epoch 39 (average epoch stats below)
2024-02-06 17:38:03 | INFO | train | epoch 039 | loss 0.861 | nll_loss 0.861 | ppl 1.82 | wps 2185.7 | ups 1.68 | wpb 1302.4 | bsz 89.4 | num_updates 126204 | lr 0.000562981 | gnorm 0.615 | train_wall 1822 | gb_free 18.4 | wall 0
2024-02-06 17:38:03 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 17:38:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 17:38:04 | INFO | fairseq.trainer | begin training epoch 40
2024-02-06 17:38:04 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 17:38:59 | INFO | train_inner | epoch 040:     96 / 3236 loss=0.831, nll_loss=0.831, ppl=1.78, wps=900.2, ups=0.69, wpb=1308.7, bsz=88.6, num_updates=126300, lr=0.000562767, gnorm=0.594, train_wall=57, gb_free=18.1, wall=0
2024-02-06 17:39:56 | INFO | train_inner | epoch 040:    196 / 3236 loss=0.816, nll_loss=0.816, ppl=1.76, wps=2263, ups=1.75, wpb=1289.7, bsz=85.7, num_updates=126400, lr=0.000562544, gnorm=0.619, train_wall=56, gb_free=17.6, wall=0
2024-02-06 17:40:53 | INFO | train_inner | epoch 040:    296 / 3236 loss=0.821, nll_loss=0.821, ppl=1.77, wps=2278.4, ups=1.77, wpb=1290.7, bsz=87.6, num_updates=126500, lr=0.000562322, gnorm=0.609, train_wall=56, gb_free=18.5, wall=0
2024-02-06 17:41:50 | INFO | train_inner | epoch 040:    396 / 3236 loss=0.831, nll_loss=0.831, ppl=1.78, wps=2300.9, ups=1.77, wpb=1300.7, bsz=88.5, num_updates=126600, lr=0.000562099, gnorm=0.601, train_wall=56, gb_free=18.2, wall=0
2024-02-06 17:42:46 | INFO | train_inner | epoch 040:    496 / 3236 loss=0.828, nll_loss=0.828, ppl=1.78, wps=2309, ups=1.78, wpb=1294.8, bsz=92.6, num_updates=126700, lr=0.000561878, gnorm=0.604, train_wall=56, gb_free=18.1, wall=0
2024-02-06 17:43:42 | INFO | train_inner | epoch 040:    596 / 3236 loss=0.816, nll_loss=0.816, ppl=1.76, wps=2262.1, ups=1.76, wpb=1282.1, bsz=84.9, num_updates=126800, lr=0.000561656, gnorm=0.609, train_wall=56, gb_free=17.6, wall=0
2024-02-06 17:44:39 | INFO | train_inner | epoch 040:    696 / 3236 loss=0.823, nll_loss=0.823, ppl=1.77, wps=2276.2, ups=1.77, wpb=1289.1, bsz=89.4, num_updates=126900, lr=0.000561435, gnorm=0.615, train_wall=56, gb_free=18.1, wall=0
2024-02-06 17:45:36 | INFO | train_inner | epoch 040:    796 / 3236 loss=0.848, nll_loss=0.848, ppl=1.8, wps=2285.3, ups=1.77, wpb=1293.8, bsz=84.4, num_updates=127000, lr=0.000561214, gnorm=0.633, train_wall=56, gb_free=18.1, wall=0
2024-02-06 17:46:32 | INFO | train_inner | epoch 040:    896 / 3236 loss=0.849, nll_loss=0.849, ppl=1.8, wps=2336.5, ups=1.77, wpb=1318.2, bsz=92.8, num_updates=127100, lr=0.000560993, gnorm=0.601, train_wall=56, gb_free=18.1, wall=0
2024-02-06 17:47:28 | INFO | train_inner | epoch 040:    996 / 3236 loss=0.839, nll_loss=0.839, ppl=1.79, wps=2283.6, ups=1.77, wpb=1288.6, bsz=88.2, num_updates=127200, lr=0.000560772, gnorm=0.627, train_wall=56, gb_free=18, wall=0
2024-02-06 17:48:25 | INFO | train_inner | epoch 040:   1096 / 3236 loss=0.835, nll_loss=0.835, ppl=1.78, wps=2305.4, ups=1.76, wpb=1307.3, bsz=92.1, num_updates=127300, lr=0.000560552, gnorm=0.603, train_wall=56, gb_free=17.6, wall=0
2024-02-06 17:49:22 | INFO | train_inner | epoch 040:   1196 / 3236 loss=0.842, nll_loss=0.842, ppl=1.79, wps=2310.9, ups=1.76, wpb=1312, bsz=93.7, num_updates=127400, lr=0.000560332, gnorm=0.613, train_wall=56, gb_free=18.2, wall=0
2024-02-06 17:50:19 | INFO | train_inner | epoch 040:   1296 / 3236 loss=0.859, nll_loss=0.859, ppl=1.81, wps=2283.6, ups=1.76, wpb=1294.5, bsz=88.6, num_updates=127500, lr=0.000560112, gnorm=0.621, train_wall=56, gb_free=18.5, wall=0
2024-02-06 17:51:15 | INFO | train_inner | epoch 040:   1396 / 3236 loss=0.842, nll_loss=0.842, ppl=1.79, wps=2299.1, ups=1.77, wpb=1302, bsz=90.3, num_updates=127600, lr=0.000559893, gnorm=0.612, train_wall=56, gb_free=17.3, wall=0
2024-02-06 17:52:12 | INFO | train_inner | epoch 040:   1496 / 3236 loss=0.854, nll_loss=0.854, ppl=1.81, wps=2315, ups=1.77, wpb=1305.3, bsz=91.6, num_updates=127700, lr=0.000559673, gnorm=0.599, train_wall=56, gb_free=18.5, wall=0
2024-02-06 17:53:08 | INFO | train_inner | epoch 040:   1596 / 3236 loss=0.845, nll_loss=0.845, ppl=1.8, wps=2314.6, ups=1.76, wpb=1314.5, bsz=90.5, num_updates=127800, lr=0.000559454, gnorm=0.599, train_wall=56, gb_free=17.7, wall=0
2024-02-06 17:54:05 | INFO | train_inner | epoch 040:   1696 / 3236 loss=0.85, nll_loss=0.85, ppl=1.8, wps=2329.7, ups=1.77, wpb=1318.4, bsz=91.7, num_updates=127900, lr=0.000559235, gnorm=0.615, train_wall=56, gb_free=17.5, wall=0
2024-02-06 17:55:01 | INFO | train_inner | epoch 040:   1796 / 3236 loss=0.859, nll_loss=0.859, ppl=1.81, wps=2334.6, ups=1.77, wpb=1315.7, bsz=93, num_updates=128000, lr=0.000559017, gnorm=0.604, train_wall=56, gb_free=17.8, wall=0
2024-02-06 17:55:58 | INFO | train_inner | epoch 040:   1896 / 3236 loss=0.839, nll_loss=0.839, ppl=1.79, wps=2324.1, ups=1.76, wpb=1322.4, bsz=88.6, num_updates=128100, lr=0.000558799, gnorm=0.609, train_wall=56, gb_free=18.3, wall=0
2024-02-06 17:56:55 | INFO | train_inner | epoch 040:   1996 / 3236 loss=0.863, nll_loss=0.863, ppl=1.82, wps=2280, ups=1.76, wpb=1292.8, bsz=88.1, num_updates=128200, lr=0.000558581, gnorm=0.613, train_wall=56, gb_free=18.2, wall=0
2024-02-06 17:57:52 | INFO | train_inner | epoch 040:   2096 / 3236 loss=0.862, nll_loss=0.862, ppl=1.82, wps=2268, ups=1.76, wpb=1291.1, bsz=85.8, num_updates=128300, lr=0.000558363, gnorm=0.631, train_wall=56, gb_free=17.5, wall=0
2024-02-06 17:58:49 | INFO | train_inner | epoch 040:   2196 / 3236 loss=0.859, nll_loss=0.859, ppl=1.81, wps=2282.2, ups=1.76, wpb=1298.8, bsz=89.4, num_updates=128400, lr=0.000558146, gnorm=0.62, train_wall=56, gb_free=17.8, wall=0
2024-02-06 17:59:46 | INFO | train_inner | epoch 040:   2296 / 3236 loss=0.869, nll_loss=0.869, ppl=1.83, wps=2298.7, ups=1.76, wpb=1303.9, bsz=90, num_updates=128500, lr=0.000557928, gnorm=0.612, train_wall=56, gb_free=18.1, wall=0
2024-02-06 18:00:42 | INFO | train_inner | epoch 040:   2396 / 3236 loss=0.853, nll_loss=0.853, ppl=1.81, wps=2307.4, ups=1.76, wpb=1309.9, bsz=88.2, num_updates=128600, lr=0.000557711, gnorm=0.593, train_wall=56, gb_free=18, wall=0
2024-02-06 18:01:39 | INFO | train_inner | epoch 040:   2496 / 3236 loss=0.838, nll_loss=0.838, ppl=1.79, wps=2302.5, ups=1.76, wpb=1308.1, bsz=90.2, num_updates=128700, lr=0.000557495, gnorm=0.612, train_wall=56, gb_free=17.7, wall=0
2024-02-06 18:02:36 | INFO | train_inner | epoch 040:   2596 / 3236 loss=0.858, nll_loss=0.858, ppl=1.81, wps=2304.2, ups=1.76, wpb=1310, bsz=89.6, num_updates=128800, lr=0.000557278, gnorm=0.611, train_wall=56, gb_free=18.3, wall=0
2024-02-06 18:03:32 | INFO | train_inner | epoch 040:   2696 / 3236 loss=0.896, nll_loss=0.896, ppl=1.86, wps=2358.3, ups=1.77, wpb=1331.2, bsz=98.2, num_updates=128900, lr=0.000557062, gnorm=0.615, train_wall=56, gb_free=17.9, wall=0
2024-02-06 18:04:29 | INFO | train_inner | epoch 040:   2796 / 3236 loss=0.863, nll_loss=0.863, ppl=1.82, wps=2289.3, ups=1.77, wpb=1297, bsz=87.6, num_updates=129000, lr=0.000556846, gnorm=0.606, train_wall=56, gb_free=18.4, wall=0
2024-02-06 18:05:26 | INFO | train_inner | epoch 040:   2896 / 3236 loss=0.84, nll_loss=0.84, ppl=1.79, wps=2269.7, ups=1.76, wpb=1292.1, bsz=84.5, num_updates=129100, lr=0.00055663, gnorm=0.608, train_wall=56, gb_free=17.9, wall=0
2024-02-06 18:06:23 | INFO | train_inner | epoch 040:   2996 / 3236 loss=0.862, nll_loss=0.862, ppl=1.82, wps=2253.8, ups=1.76, wpb=1281.7, bsz=87.4, num_updates=129200, lr=0.000556415, gnorm=0.631, train_wall=56, gb_free=18.5, wall=0
2024-02-06 18:07:20 | INFO | train_inner | epoch 040:   3096 / 3236 loss=0.876, nll_loss=0.876, ppl=1.83, wps=2285.8, ups=1.76, wpb=1301.8, bsz=89.9, num_updates=129300, lr=0.0005562, gnorm=0.613, train_wall=56, gb_free=18.1, wall=0
2024-02-06 18:08:17 | INFO | train_inner | epoch 040:   3196 / 3236 loss=0.873, nll_loss=0.873, ppl=1.83, wps=2313.1, ups=1.76, wpb=1314, bsz=90.6, num_updates=129400, lr=0.000555985, gnorm=0.618, train_wall=56, gb_free=18.4, wall=0
2024-02-06 18:08:39 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 18:08:39 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 18:09:58 | INFO | dev | epoch 040 | valid on 'dev' subset | loss 1.111 | nll_loss 1.111 | ppl 2.16 | wps 2919.5 | wpb 1146.2 | bsz 77.6 | num_updates 129440 | best_loss 1.094
2024-02-06 18:09:58 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 40 @ 129440 updates
2024-02-06 18:09:59 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint40.pt
2024-02-06 18:10:00 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint40.pt
2024-02-06 18:10:02 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint40.pt (epoch 40 @ 129440 updates, score 1.111) (writing took 3.253574965056032 seconds)
2024-02-06 18:10:02 | INFO | fairseq_cli.train | end of epoch 40 (average epoch stats below)
2024-02-06 18:10:02 | INFO | train | epoch 040 | loss 0.848 | nll_loss 0.848 | ppl 1.8 | wps 2197 | ups 1.69 | wpb 1302.4 | bsz 89.4 | num_updates 129440 | lr 0.000555899 | gnorm 0.612 | train_wall 1817 | gb_free 18.5 | wall 0
2024-02-06 18:10:02 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 18:10:02 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 18:10:02 | INFO | fairseq.trainer | begin training epoch 41
2024-02-06 18:10:02 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 18:10:40 | INFO | train_inner | epoch 041:     60 / 3236 loss=0.834, nll_loss=0.834, ppl=1.78, wps=897.5, ups=0.7, wpb=1283.4, bsz=84.7, num_updates=129500, lr=0.00055577, gnorm=0.624, train_wall=59, gb_free=18.5, wall=0
2024-02-06 18:11:38 | INFO | train_inner | epoch 041:    160 / 3236 loss=0.831, nll_loss=0.831, ppl=1.78, wps=2219.4, ups=1.72, wpb=1291, bsz=90, num_updates=129600, lr=0.000555556, gnorm=0.629, train_wall=58, gb_free=18, wall=0
2024-02-06 18:12:35 | INFO | train_inner | epoch 041:    260 / 3236 loss=0.828, nll_loss=0.828, ppl=1.77, wps=2284, ups=1.75, wpb=1304.2, bsz=89.4, num_updates=129700, lr=0.000555341, gnorm=0.62, train_wall=57, gb_free=18.2, wall=0
2024-02-06 18:13:32 | INFO | train_inner | epoch 041:    360 / 3236 loss=0.827, nll_loss=0.827, ppl=1.77, wps=2259.2, ups=1.76, wpb=1283.2, bsz=91, num_updates=129800, lr=0.000555127, gnorm=0.617, train_wall=56, gb_free=17.9, wall=0
2024-02-06 18:14:28 | INFO | train_inner | epoch 041:    460 / 3236 loss=0.822, nll_loss=0.822, ppl=1.77, wps=2249.5, ups=1.77, wpb=1273.6, bsz=84.2, num_updates=129900, lr=0.000554914, gnorm=0.614, train_wall=56, gb_free=17.7, wall=0
2024-02-06 18:15:25 | INFO | train_inner | epoch 041:    560 / 3236 loss=0.83, nll_loss=0.83, ppl=1.78, wps=2298.3, ups=1.77, wpb=1300.1, bsz=85.4, num_updates=130000, lr=0.0005547, gnorm=0.619, train_wall=56, gb_free=18.3, wall=0
2024-02-06 18:16:21 | INFO | train_inner | epoch 041:    660 / 3236 loss=0.828, nll_loss=0.828, ppl=1.77, wps=2320.5, ups=1.77, wpb=1312, bsz=90.2, num_updates=130100, lr=0.000554487, gnorm=0.607, train_wall=56, gb_free=17.7, wall=0
2024-02-06 18:17:18 | INFO | train_inner | epoch 041:    760 / 3236 loss=0.821, nll_loss=0.821, ppl=1.77, wps=2292.9, ups=1.77, wpb=1297.1, bsz=89.4, num_updates=130200, lr=0.000554274, gnorm=0.61, train_wall=56, gb_free=18.5, wall=0
2024-02-06 18:18:17 | INFO | train_inner | epoch 041:    860 / 3236 loss=0.844, nll_loss=0.844, ppl=1.79, wps=2210.5, ups=1.69, wpb=1306.6, bsz=88.1, num_updates=130300, lr=0.000554061, gnorm=0.615, train_wall=59, gb_free=17.1, wall=0
2024-02-06 18:19:14 | INFO | train_inner | epoch 041:    960 / 3236 loss=0.827, nll_loss=0.827, ppl=1.77, wps=2349.6, ups=1.77, wpb=1326.2, bsz=100.1, num_updates=130400, lr=0.000553849, gnorm=0.593, train_wall=56, gb_free=18.4, wall=0
2024-02-06 18:20:10 | INFO | train_inner | epoch 041:   1060 / 3236 loss=0.818, nll_loss=0.818, ppl=1.76, wps=2290, ups=1.77, wpb=1293.8, bsz=87, num_updates=130500, lr=0.000553637, gnorm=0.607, train_wall=56, gb_free=18, wall=0
2024-02-06 18:21:07 | INFO | train_inner | epoch 041:   1160 / 3236 loss=0.835, nll_loss=0.835, ppl=1.78, wps=2330.2, ups=1.76, wpb=1324.6, bsz=88.8, num_updates=130600, lr=0.000553425, gnorm=0.61, train_wall=56, gb_free=18.1, wall=0
2024-02-06 18:22:03 | INFO | train_inner | epoch 041:   1260 / 3236 loss=0.857, nll_loss=0.857, ppl=1.81, wps=2301.2, ups=1.77, wpb=1300.1, bsz=89.5, num_updates=130700, lr=0.000553213, gnorm=0.623, train_wall=56, gb_free=18.1, wall=0
2024-02-06 18:23:01 | INFO | train_inner | epoch 041:   1360 / 3236 loss=0.854, nll_loss=0.854, ppl=1.81, wps=2240.7, ups=1.72, wpb=1299.7, bsz=86.9, num_updates=130800, lr=0.000553001, gnorm=0.622, train_wall=57, gb_free=18.5, wall=0
2024-02-06 18:24:01 | INFO | train_inner | epoch 041:   1460 / 3236 loss=0.829, nll_loss=0.829, ppl=1.78, wps=2202.8, ups=1.68, wpb=1308.4, bsz=88.1, num_updates=130900, lr=0.00055279, gnorm=0.614, train_wall=59, gb_free=18.2, wall=0
2024-02-06 18:25:01 | INFO | train_inner | epoch 041:   1560 / 3236 loss=0.87, nll_loss=0.87, ppl=1.83, wps=2173.8, ups=1.67, wpb=1303.2, bsz=91, num_updates=131000, lr=0.000552579, gnorm=0.631, train_wall=59, gb_free=18.6, wall=0
2024-02-06 18:26:00 | INFO | train_inner | epoch 041:   1660 / 3236 loss=0.856, nll_loss=0.856, ppl=1.81, wps=2251.4, ups=1.7, wpb=1323.5, bsz=98.5, num_updates=131100, lr=0.000552368, gnorm=0.614, train_wall=58, gb_free=17.1, wall=0
2024-02-06 18:26:58 | INFO | train_inner | epoch 041:   1760 / 3236 loss=0.853, nll_loss=0.853, ppl=1.81, wps=2249.2, ups=1.71, wpb=1318.1, bsz=91.9, num_updates=131200, lr=0.000552158, gnorm=0.615, train_wall=58, gb_free=17.3, wall=0
2024-02-06 18:27:56 | INFO | train_inner | epoch 041:   1860 / 3236 loss=0.826, nll_loss=0.826, ppl=1.77, wps=2227.8, ups=1.73, wpb=1290.4, bsz=87.5, num_updates=131300, lr=0.000551947, gnorm=0.615, train_wall=57, gb_free=17.7, wall=0
2024-02-06 18:28:54 | INFO | train_inner | epoch 041:   1960 / 3236 loss=0.864, nll_loss=0.864, ppl=1.82, wps=2252.1, ups=1.73, wpb=1301.9, bsz=88.9, num_updates=131400, lr=0.000551737, gnorm=0.611, train_wall=57, gb_free=18, wall=0
2024-02-06 18:29:54 | INFO | train_inner | epoch 041:   2060 / 3236 loss=0.851, nll_loss=0.851, ppl=1.8, wps=2174.3, ups=1.66, wpb=1307.4, bsz=91.6, num_updates=131500, lr=0.000551527, gnorm=0.606, train_wall=59, gb_free=18.4, wall=0
2024-02-06 18:30:53 | INFO | train_inner | epoch 041:   2160 / 3236 loss=0.845, nll_loss=0.845, ppl=1.8, wps=2201.4, ups=1.7, wpb=1296.3, bsz=86.6, num_updates=131600, lr=0.000551318, gnorm=0.624, train_wall=58, gb_free=18.2, wall=0
2024-02-06 18:31:52 | INFO | train_inner | epoch 041:   2260 / 3236 loss=0.853, nll_loss=0.853, ppl=1.81, wps=2259.5, ups=1.7, wpb=1326.6, bsz=92.6, num_updates=131700, lr=0.000551108, gnorm=0.612, train_wall=58, gb_free=18, wall=0
2024-02-06 18:32:49 | INFO | train_inner | epoch 041:   2360 / 3236 loss=0.866, nll_loss=0.866, ppl=1.82, wps=2232, ups=1.73, wpb=1291.3, bsz=87.7, num_updates=131800, lr=0.000550899, gnorm=0.631, train_wall=57, gb_free=17.6, wall=0
2024-02-06 18:33:47 | INFO | train_inner | epoch 041:   2460 / 3236 loss=0.845, nll_loss=0.845, ppl=1.8, wps=2227.9, ups=1.74, wpb=1282.7, bsz=84.2, num_updates=131900, lr=0.000550691, gnorm=0.622, train_wall=57, gb_free=18.8, wall=0
2024-02-06 18:34:45 | INFO | train_inner | epoch 041:   2560 / 3236 loss=0.83, nll_loss=0.83, ppl=1.78, wps=2233.2, ups=1.73, wpb=1294, bsz=86.3, num_updates=132000, lr=0.000550482, gnorm=0.613, train_wall=57, gb_free=17.7, wall=0
2024-02-06 18:35:43 | INFO | train_inner | epoch 041:   2660 / 3236 loss=0.846, nll_loss=0.846, ppl=1.8, wps=2258.9, ups=1.73, wpb=1304.1, bsz=88.4, num_updates=132100, lr=0.000550273, gnorm=0.616, train_wall=57, gb_free=18, wall=0
2024-02-06 18:36:41 | INFO | train_inner | epoch 041:   2760 / 3236 loss=0.877, nll_loss=0.877, ppl=1.84, wps=2224.5, ups=1.72, wpb=1296.5, bsz=90.1, num_updates=132200, lr=0.000550065, gnorm=0.621, train_wall=58, gb_free=18.1, wall=0
2024-02-06 18:37:39 | INFO | train_inner | epoch 041:   2860 / 3236 loss=0.855, nll_loss=0.855, ppl=1.81, wps=2219.8, ups=1.71, wpb=1294.4, bsz=85.7, num_updates=132300, lr=0.000549857, gnorm=0.636, train_wall=58, gb_free=17.6, wall=0
2024-02-06 18:38:37 | INFO | train_inner | epoch 041:   2960 / 3236 loss=0.851, nll_loss=0.851, ppl=1.8, wps=2270.5, ups=1.73, wpb=1316, bsz=96.6, num_updates=132400, lr=0.00054965, gnorm=0.612, train_wall=57, gb_free=17.9, wall=0
2024-02-06 18:39:35 | INFO | train_inner | epoch 041:   3060 / 3236 loss=0.855, nll_loss=0.855, ppl=1.81, wps=2223.7, ups=1.72, wpb=1293.2, bsz=89.3, num_updates=132500, lr=0.000549442, gnorm=0.624, train_wall=58, gb_free=18.4, wall=0
2024-02-06 18:40:35 | INFO | train_inner | epoch 041:   3160 / 3236 loss=0.87, nll_loss=0.87, ppl=1.83, wps=2211.5, ups=1.69, wpb=1311.4, bsz=89, num_updates=132600, lr=0.000549235, gnorm=0.632, train_wall=59, gb_free=18.3, wall=0
2024-02-06 18:41:19 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 18:41:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 18:42:20 | INFO | dev | epoch 041 | valid on 'dev' subset | loss 1.109 | nll_loss 1.109 | ppl 2.16 | wps 3818 | wpb 1146.2 | bsz 77.6 | num_updates 132676 | best_loss 1.094
2024-02-06 18:42:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 41 @ 132676 updates
2024-02-06 18:42:20 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint41.pt
2024-02-06 18:42:22 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint41.pt
2024-02-06 18:42:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint41.pt (epoch 41 @ 132676 updates, score 1.109) (writing took 3.475515828933567 seconds)
2024-02-06 18:42:24 | INFO | fairseq_cli.train | end of epoch 41 (average epoch stats below)
2024-02-06 18:42:24 | INFO | train | epoch 041 | loss 0.844 | nll_loss 0.844 | ppl 1.79 | wps 2170.1 | ups 1.67 | wpb 1302.4 | bsz 89.4 | num_updates 132676 | lr 0.000549078 | gnorm 0.617 | train_wall 1858 | gb_free 18.1 | wall 0
2024-02-06 18:42:24 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 18:42:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 18:42:24 | INFO | fairseq.trainer | begin training epoch 42
2024-02-06 18:42:24 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 18:42:38 | INFO | train_inner | epoch 042:     24 / 3236 loss=0.858, nll_loss=0.858, ppl=1.81, wps=1069.8, ups=0.81, wpb=1322.3, bsz=93.7, num_updates=132700, lr=0.000549028, gnorm=0.605, train_wall=58, gb_free=18.5, wall=0
2024-02-06 18:43:37 | INFO | train_inner | epoch 042:    124 / 3236 loss=0.809, nll_loss=0.809, ppl=1.75, wps=2259.5, ups=1.71, wpb=1317.7, bsz=94.6, num_updates=132800, lr=0.000548821, gnorm=0.606, train_wall=58, gb_free=18.2, wall=0
2024-02-06 18:44:35 | INFO | train_inner | epoch 042:    224 / 3236 loss=0.801, nll_loss=0.801, ppl=1.74, wps=2254.1, ups=1.7, wpb=1324.5, bsz=87.9, num_updates=132900, lr=0.000548615, gnorm=0.601, train_wall=58, gb_free=18.3, wall=0
2024-02-06 18:45:34 | INFO | train_inner | epoch 042:    324 / 3236 loss=0.796, nll_loss=0.796, ppl=1.74, wps=2255.5, ups=1.7, wpb=1325.8, bsz=91.7, num_updates=133000, lr=0.000548408, gnorm=0.59, train_wall=58, gb_free=18.1, wall=0
2024-02-06 18:46:32 | INFO | train_inner | epoch 042:    424 / 3236 loss=0.821, nll_loss=0.821, ppl=1.77, wps=2249.5, ups=1.72, wpb=1307.9, bsz=90.6, num_updates=133100, lr=0.000548202, gnorm=0.613, train_wall=57, gb_free=18.5, wall=0
2024-02-06 18:47:31 | INFO | train_inner | epoch 042:    524 / 3236 loss=0.806, nll_loss=0.806, ppl=1.75, wps=2235.2, ups=1.71, wpb=1305.9, bsz=87.6, num_updates=133200, lr=0.000547997, gnorm=0.608, train_wall=58, gb_free=17.4, wall=0
2024-02-06 18:48:30 | INFO | train_inner | epoch 042:    624 / 3236 loss=0.811, nll_loss=0.811, ppl=1.75, wps=2242, ups=1.7, wpb=1316, bsz=90.1, num_updates=133300, lr=0.000547791, gnorm=0.623, train_wall=58, gb_free=18, wall=0
2024-02-06 18:49:27 | INFO | train_inner | epoch 042:    724 / 3236 loss=0.81, nll_loss=0.81, ppl=1.75, wps=2256.9, ups=1.73, wpb=1306, bsz=91.8, num_updates=133400, lr=0.000547586, gnorm=0.599, train_wall=57, gb_free=17.6, wall=0
2024-02-06 18:50:25 | INFO | train_inner | epoch 042:    824 / 3236 loss=0.823, nll_loss=0.823, ppl=1.77, wps=2298.8, ups=1.74, wpb=1318.3, bsz=92.2, num_updates=133500, lr=0.000547381, gnorm=0.596, train_wall=57, gb_free=17.1, wall=0
2024-02-06 18:51:23 | INFO | train_inner | epoch 042:    924 / 3236 loss=0.834, nll_loss=0.834, ppl=1.78, wps=2207.9, ups=1.72, wpb=1285, bsz=86.1, num_updates=133600, lr=0.000547176, gnorm=0.615, train_wall=58, gb_free=18.4, wall=0
2024-02-06 18:52:21 | INFO | train_inner | epoch 042:   1024 / 3236 loss=0.827, nll_loss=0.827, ppl=1.77, wps=2243.5, ups=1.71, wpb=1308.2, bsz=88.5, num_updates=133700, lr=0.000546971, gnorm=0.607, train_wall=58, gb_free=17.7, wall=0
2024-02-06 18:53:20 | INFO | train_inner | epoch 042:   1124 / 3236 loss=0.828, nll_loss=0.828, ppl=1.77, wps=2203.2, ups=1.71, wpb=1287.2, bsz=85.4, num_updates=133800, lr=0.000546767, gnorm=0.625, train_wall=58, gb_free=17.9, wall=0
2024-02-06 18:54:17 | INFO | train_inner | epoch 042:   1224 / 3236 loss=0.813, nll_loss=0.813, ppl=1.76, wps=2258.1, ups=1.76, wpb=1285.5, bsz=83.8, num_updates=133900, lr=0.000546562, gnorm=0.616, train_wall=56, gb_free=18.7, wall=0
2024-02-06 18:55:14 | INFO | train_inner | epoch 042:   1324 / 3236 loss=0.842, nll_loss=0.842, ppl=1.79, wps=2281.1, ups=1.76, wpb=1299.6, bsz=90.3, num_updates=134000, lr=0.000546358, gnorm=0.628, train_wall=56, gb_free=17.7, wall=0
2024-02-06 18:56:10 | INFO | train_inner | epoch 042:   1424 / 3236 loss=0.836, nll_loss=0.836, ppl=1.79, wps=2287, ups=1.76, wpb=1297.1, bsz=89.7, num_updates=134100, lr=0.000546155, gnorm=0.619, train_wall=56, gb_free=18.5, wall=0
2024-02-06 18:57:07 | INFO | train_inner | epoch 042:   1524 / 3236 loss=0.813, nll_loss=0.813, ppl=1.76, wps=2292.5, ups=1.77, wpb=1295.8, bsz=86.2, num_updates=134200, lr=0.000545951, gnorm=0.606, train_wall=56, gb_free=17.6, wall=0
2024-02-06 18:58:03 | INFO | train_inner | epoch 042:   1624 / 3236 loss=0.835, nll_loss=0.835, ppl=1.78, wps=2311.9, ups=1.78, wpb=1301.7, bsz=93.9, num_updates=134300, lr=0.000545748, gnorm=0.608, train_wall=56, gb_free=17.9, wall=0
2024-02-06 18:59:01 | INFO | train_inner | epoch 042:   1724 / 3236 loss=0.824, nll_loss=0.824, ppl=1.77, wps=2275.1, ups=1.74, wpb=1306.7, bsz=91.6, num_updates=134400, lr=0.000545545, gnorm=0.596, train_wall=57, gb_free=18.1, wall=0
2024-02-06 18:59:59 | INFO | train_inner | epoch 042:   1824 / 3236 loss=0.821, nll_loss=0.821, ppl=1.77, wps=2206, ups=1.72, wpb=1282.8, bsz=87.5, num_updates=134500, lr=0.000545342, gnorm=0.623, train_wall=58, gb_free=18, wall=0
2024-02-06 19:00:58 | INFO | train_inner | epoch 042:   1924 / 3236 loss=0.846, nll_loss=0.846, ppl=1.8, wps=2172.2, ups=1.69, wpb=1286.7, bsz=89.8, num_updates=134600, lr=0.000545139, gnorm=0.624, train_wall=59, gb_free=18.6, wall=0
2024-02-06 19:01:55 | INFO | train_inner | epoch 042:   2024 / 3236 loss=0.843, nll_loss=0.843, ppl=1.79, wps=2291.1, ups=1.76, wpb=1304.5, bsz=86.1, num_updates=134700, lr=0.000544937, gnorm=0.628, train_wall=56, gb_free=18.4, wall=0
2024-02-06 19:02:51 | INFO | train_inner | epoch 042:   2124 / 3236 loss=0.839, nll_loss=0.839, ppl=1.79, wps=2320.7, ups=1.77, wpb=1313.4, bsz=91.2, num_updates=134800, lr=0.000544735, gnorm=0.607, train_wall=56, gb_free=18, wall=0
2024-02-06 19:03:49 | INFO | train_inner | epoch 042:   2224 / 3236 loss=0.852, nll_loss=0.852, ppl=1.81, wps=2273.7, ups=1.75, wpb=1298.4, bsz=87.2, num_updates=134900, lr=0.000544533, gnorm=0.637, train_wall=57, gb_free=17.4, wall=0
2024-02-06 19:04:45 | INFO | train_inner | epoch 042:   2324 / 3236 loss=0.84, nll_loss=0.84, ppl=1.79, wps=2297.6, ups=1.77, wpb=1298.1, bsz=90.7, num_updates=135000, lr=0.000544331, gnorm=0.616, train_wall=56, gb_free=18, wall=0
2024-02-06 19:05:42 | INFO | train_inner | epoch 042:   2424 / 3236 loss=0.851, nll_loss=0.851, ppl=1.8, wps=2309.1, ups=1.76, wpb=1315.6, bsz=90.5, num_updates=135100, lr=0.00054413, gnorm=0.627, train_wall=56, gb_free=18.5, wall=0
2024-02-06 19:06:39 | INFO | train_inner | epoch 042:   2524 / 3236 loss=0.839, nll_loss=0.839, ppl=1.79, wps=2239.5, ups=1.74, wpb=1285.4, bsz=84.2, num_updates=135200, lr=0.000543928, gnorm=0.635, train_wall=57, gb_free=18.2, wall=0
2024-02-06 19:07:39 | INFO | train_inner | epoch 042:   2624 / 3236 loss=0.854, nll_loss=0.854, ppl=1.81, wps=2233.1, ups=1.69, wpb=1321.5, bsz=95.4, num_updates=135300, lr=0.000543727, gnorm=0.615, train_wall=59, gb_free=17.9, wall=0
2024-02-06 19:08:36 | INFO | train_inner | epoch 042:   2724 / 3236 loss=0.852, nll_loss=0.852, ppl=1.81, wps=2306.8, ups=1.76, wpb=1313.6, bsz=95.3, num_updates=135400, lr=0.000543526, gnorm=0.63, train_wall=56, gb_free=17.3, wall=0
2024-02-06 19:09:33 | INFO | train_inner | epoch 042:   2824 / 3236 loss=0.849, nll_loss=0.849, ppl=1.8, wps=2256.8, ups=1.75, wpb=1287.9, bsz=87.8, num_updates=135500, lr=0.000543326, gnorm=0.641, train_wall=57, gb_free=18.4, wall=0
2024-02-06 19:10:29 | INFO | train_inner | epoch 042:   2924 / 3236 loss=0.834, nll_loss=0.834, ppl=1.78, wps=2290.9, ups=1.76, wpb=1299.1, bsz=92.6, num_updates=135600, lr=0.000543125, gnorm=0.611, train_wall=56, gb_free=18.5, wall=0
2024-02-06 19:11:26 | INFO | train_inner | epoch 042:   3024 / 3236 loss=0.843, nll_loss=0.843, ppl=1.79, wps=2290.8, ups=1.76, wpb=1300.9, bsz=86.6, num_updates=135700, lr=0.000542925, gnorm=0.618, train_wall=56, gb_free=18, wall=0
2024-02-06 19:12:23 | INFO | train_inner | epoch 042:   3124 / 3236 loss=0.848, nll_loss=0.848, ppl=1.8, wps=2250.8, ups=1.75, wpb=1285.6, bsz=85.1, num_updates=135800, lr=0.000542725, gnorm=0.632, train_wall=57, gb_free=17.9, wall=0
2024-02-06 19:13:21 | INFO | train_inner | epoch 042:   3224 / 3236 loss=0.854, nll_loss=0.854, ppl=1.81, wps=2239.1, ups=1.73, wpb=1293, bsz=90.2, num_updates=135900, lr=0.000542526, gnorm=0.62, train_wall=57, gb_free=18.8, wall=0
2024-02-06 19:13:28 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 19:13:28 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 19:14:45 | INFO | dev | epoch 042 | valid on 'dev' subset | loss 1.116 | nll_loss 1.116 | ppl 2.17 | wps 3005.7 | wpb 1146.2 | bsz 77.6 | num_updates 135912 | best_loss 1.094
2024-02-06 19:14:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 42 @ 135912 updates
2024-02-06 19:14:45 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint42.pt
2024-02-06 19:14:46 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint42.pt
2024-02-06 19:14:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint42.pt (epoch 42 @ 135912 updates, score 1.116) (writing took 2.982861877884716 seconds)
2024-02-06 19:14:48 | INFO | fairseq_cli.train | end of epoch 42 (average epoch stats below)
2024-02-06 19:14:48 | INFO | train | epoch 042 | loss 0.831 | nll_loss 0.831 | ppl 1.78 | wps 2167.8 | ups 1.66 | wpb 1302.4 | bsz 89.4 | num_updates 135912 | lr 0.000542502 | gnorm 0.616 | train_wall 1845 | gb_free 18 | wall 0
2024-02-06 19:14:48 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 19:14:48 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 19:14:48 | INFO | fairseq.trainer | begin training epoch 43
2024-02-06 19:14:48 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 19:15:40 | INFO | train_inner | epoch 043:     88 / 3236 loss=0.811, nll_loss=0.811, ppl=1.75, wps=955.8, ups=0.72, wpb=1323.4, bsz=96.2, num_updates=136000, lr=0.000542326, gnorm=0.611, train_wall=56, gb_free=18, wall=0
2024-02-06 19:16:36 | INFO | train_inner | epoch 043:    188 / 3236 loss=0.799, nll_loss=0.799, ppl=1.74, wps=2280.6, ups=1.76, wpb=1295, bsz=83.2, num_updates=136100, lr=0.000542127, gnorm=0.618, train_wall=56, gb_free=17.9, wall=0
2024-02-06 19:17:33 | INFO | train_inner | epoch 043:    288 / 3236 loss=0.81, nll_loss=0.81, ppl=1.75, wps=2320.1, ups=1.78, wpb=1306.7, bsz=89.2, num_updates=136200, lr=0.000541928, gnorm=0.595, train_wall=56, gb_free=18, wall=0
2024-02-06 19:18:30 | INFO | train_inner | epoch 043:    388 / 3236 loss=0.815, nll_loss=0.815, ppl=1.76, wps=2318.7, ups=1.76, wpb=1319.5, bsz=90.9, num_updates=136300, lr=0.000541729, gnorm=0.614, train_wall=56, gb_free=17.8, wall=0
2024-02-06 19:19:27 | INFO | train_inner | epoch 043:    488 / 3236 loss=0.805, nll_loss=0.805, ppl=1.75, wps=2277.7, ups=1.75, wpb=1303.7, bsz=89.4, num_updates=136400, lr=0.00054153, gnorm=0.614, train_wall=56, gb_free=18.3, wall=0
2024-02-06 19:20:24 | INFO | train_inner | epoch 043:    588 / 3236 loss=0.788, nll_loss=0.788, ppl=1.73, wps=2256.8, ups=1.74, wpb=1297.5, bsz=90.4, num_updates=136500, lr=0.000541332, gnorm=0.603, train_wall=57, gb_free=19.1, wall=0
2024-02-06 19:21:23 | INFO | train_inner | epoch 043:    688 / 3236 loss=0.809, nll_loss=0.809, ppl=1.75, wps=2194, ups=1.7, wpb=1289.6, bsz=83.7, num_updates=136600, lr=0.000541134, gnorm=0.626, train_wall=58, gb_free=18.5, wall=0
2024-02-06 19:22:20 | INFO | train_inner | epoch 043:    788 / 3236 loss=0.806, nll_loss=0.806, ppl=1.75, wps=2369.8, ups=1.77, wpb=1340.5, bsz=97, num_updates=136700, lr=0.000540936, gnorm=0.593, train_wall=56, gb_free=17.3, wall=0
2024-02-06 19:23:16 | INFO | train_inner | epoch 043:    888 / 3236 loss=0.807, nll_loss=0.807, ppl=1.75, wps=2290.7, ups=1.76, wpb=1299.6, bsz=85.7, num_updates=136800, lr=0.000540738, gnorm=0.62, train_wall=56, gb_free=18, wall=0
2024-02-06 19:24:13 | INFO | train_inner | epoch 043:    988 / 3236 loss=0.818, nll_loss=0.818, ppl=1.76, wps=2292.9, ups=1.77, wpb=1295.9, bsz=84.9, num_updates=136900, lr=0.000540541, gnorm=0.623, train_wall=56, gb_free=18.3, wall=0
2024-02-06 19:25:10 | INFO | train_inner | epoch 043:   1088 / 3236 loss=0.819, nll_loss=0.819, ppl=1.76, wps=2279.2, ups=1.74, wpb=1311.8, bsz=90, num_updates=137000, lr=0.000540343, gnorm=0.622, train_wall=57, gb_free=17.1, wall=0
2024-02-06 19:26:09 | INFO | train_inner | epoch 043:   1188 / 3236 loss=0.823, nll_loss=0.823, ppl=1.77, wps=2218.4, ups=1.7, wpb=1301.3, bsz=91, num_updates=137100, lr=0.000540146, gnorm=0.611, train_wall=58, gb_free=17.9, wall=0
2024-02-06 19:27:07 | INFO | train_inner | epoch 043:   1288 / 3236 loss=0.827, nll_loss=0.827, ppl=1.77, wps=2268.5, ups=1.72, wpb=1321.6, bsz=91.8, num_updates=137200, lr=0.000539949, gnorm=0.604, train_wall=58, gb_free=18.2, wall=0
2024-02-06 19:28:06 | INFO | train_inner | epoch 043:   1388 / 3236 loss=0.82, nll_loss=0.82, ppl=1.77, wps=2232.8, ups=1.71, wpb=1302.5, bsz=91.1, num_updates=137300, lr=0.000539753, gnorm=0.613, train_wall=58, gb_free=18.2, wall=0
2024-02-06 19:29:04 | INFO | train_inner | epoch 043:   1488 / 3236 loss=0.813, nll_loss=0.813, ppl=1.76, wps=2255.1, ups=1.71, wpb=1316, bsz=91.4, num_updates=137400, lr=0.000539556, gnorm=0.607, train_wall=58, gb_free=18.5, wall=0
2024-02-06 19:30:03 | INFO | train_inner | epoch 043:   1588 / 3236 loss=0.828, nll_loss=0.828, ppl=1.78, wps=2245.5, ups=1.71, wpb=1314.3, bsz=92.2, num_updates=137500, lr=0.00053936, gnorm=0.632, train_wall=58, gb_free=17.3, wall=0
2024-02-06 19:31:01 | INFO | train_inner | epoch 043:   1688 / 3236 loss=0.833, nll_loss=0.833, ppl=1.78, wps=2237.8, ups=1.72, wpb=1297.6, bsz=89, num_updates=137600, lr=0.000539164, gnorm=0.617, train_wall=57, gb_free=17.9, wall=0
2024-02-06 19:31:58 | INFO | train_inner | epoch 043:   1788 / 3236 loss=0.829, nll_loss=0.829, ppl=1.78, wps=2239.8, ups=1.75, wpb=1283.3, bsz=86.2, num_updates=137700, lr=0.000538968, gnorm=0.629, train_wall=57, gb_free=18.1, wall=0
2024-02-06 19:32:56 | INFO | train_inner | epoch 043:   1888 / 3236 loss=0.827, nll_loss=0.827, ppl=1.77, wps=2226.3, ups=1.71, wpb=1299, bsz=88.2, num_updates=137800, lr=0.000538772, gnorm=0.618, train_wall=58, gb_free=18.3, wall=0
2024-02-06 19:33:55 | INFO | train_inner | epoch 043:   1988 / 3236 loss=0.825, nll_loss=0.825, ppl=1.77, wps=2235.5, ups=1.71, wpb=1305.9, bsz=93, num_updates=137900, lr=0.000538577, gnorm=0.616, train_wall=58, gb_free=18, wall=0
2024-02-06 19:34:52 | INFO | train_inner | epoch 043:   2088 / 3236 loss=0.812, nll_loss=0.812, ppl=1.76, wps=2214.7, ups=1.73, wpb=1278.3, bsz=85.1, num_updates=138000, lr=0.000538382, gnorm=0.611, train_wall=57, gb_free=18.7, wall=0
2024-02-06 19:35:50 | INFO | train_inner | epoch 043:   2188 / 3236 loss=0.835, nll_loss=0.835, ppl=1.78, wps=2234.8, ups=1.73, wpb=1289.9, bsz=89.4, num_updates=138100, lr=0.000538187, gnorm=0.618, train_wall=57, gb_free=17.9, wall=0
2024-02-06 19:36:48 | INFO | train_inner | epoch 043:   2288 / 3236 loss=0.831, nll_loss=0.831, ppl=1.78, wps=2202.6, ups=1.72, wpb=1278.3, bsz=87.9, num_updates=138200, lr=0.000537992, gnorm=0.659, train_wall=57, gb_free=18.4, wall=0
2024-02-06 19:37:46 | INFO | train_inner | epoch 043:   2388 / 3236 loss=0.84, nll_loss=0.84, ppl=1.79, wps=2253.4, ups=1.72, wpb=1308.2, bsz=91.8, num_updates=138300, lr=0.000537798, gnorm=0.614, train_wall=57, gb_free=17.8, wall=0
2024-02-06 19:38:44 | INFO | train_inner | epoch 043:   2488 / 3236 loss=0.845, nll_loss=0.845, ppl=1.8, wps=2261.4, ups=1.72, wpb=1311.9, bsz=91.4, num_updates=138400, lr=0.000537603, gnorm=0.62, train_wall=57, gb_free=17.8, wall=0
2024-02-06 19:39:42 | INFO | train_inner | epoch 043:   2588 / 3236 loss=0.832, nll_loss=0.832, ppl=1.78, wps=2275.9, ups=1.74, wpb=1304.5, bsz=91.4, num_updates=138500, lr=0.000537409, gnorm=0.605, train_wall=57, gb_free=17.7, wall=0
2024-02-06 19:40:39 | INFO | train_inner | epoch 043:   2688 / 3236 loss=0.84, nll_loss=0.84, ppl=1.79, wps=2228.4, ups=1.74, wpb=1280.5, bsz=86.4, num_updates=138600, lr=0.000537215, gnorm=0.617, train_wall=57, gb_free=18.2, wall=0
2024-02-06 19:41:37 | INFO | train_inner | epoch 043:   2788 / 3236 loss=0.83, nll_loss=0.83, ppl=1.78, wps=2233.1, ups=1.72, wpb=1296.5, bsz=94.1, num_updates=138700, lr=0.000537022, gnorm=0.619, train_wall=57, gb_free=17.4, wall=0
2024-02-06 19:42:35 | INFO | train_inner | epoch 043:   2888 / 3236 loss=0.841, nll_loss=0.841, ppl=1.79, wps=2277.4, ups=1.73, wpb=1314.9, bsz=87.6, num_updates=138800, lr=0.000536828, gnorm=0.624, train_wall=57, gb_free=18.1, wall=0
2024-02-06 19:43:32 | INFO | train_inner | epoch 043:   2988 / 3236 loss=0.822, nll_loss=0.822, ppl=1.77, wps=2231.9, ups=1.74, wpb=1285.3, bsz=88.6, num_updates=138900, lr=0.000536635, gnorm=0.63, train_wall=57, gb_free=18.5, wall=0
2024-02-06 19:44:30 | INFO | train_inner | epoch 043:   3088 / 3236 loss=0.843, nll_loss=0.843, ppl=1.79, wps=2252.2, ups=1.74, wpb=1297.2, bsz=87.2, num_updates=139000, lr=0.000536442, gnorm=0.623, train_wall=57, gb_free=18.6, wall=0
2024-02-06 19:45:27 | INFO | train_inner | epoch 043:   3188 / 3236 loss=0.825, nll_loss=0.825, ppl=1.77, wps=2262.9, ups=1.75, wpb=1291, bsz=80.8, num_updates=139100, lr=0.000536249, gnorm=0.623, train_wall=57, gb_free=17.5, wall=0
2024-02-06 19:45:54 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 19:45:54 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 19:46:59 | INFO | dev | epoch 043 | valid on 'dev' subset | loss 1.12 | nll_loss 1.12 | ppl 2.17 | wps 3570.1 | wpb 1146.2 | bsz 77.6 | num_updates 139148 | best_loss 1.094
2024-02-06 19:46:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 43 @ 139148 updates
2024-02-06 19:46:59 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint43.pt
2024-02-06 19:47:02 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint43.pt
2024-02-06 19:47:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint43.pt (epoch 43 @ 139148 updates, score 1.12) (writing took 4.841167805949226 seconds)
2024-02-06 19:47:04 | INFO | fairseq_cli.train | end of epoch 43 (average epoch stats below)
2024-02-06 19:47:04 | INFO | train | epoch 043 | loss 0.822 | nll_loss 0.822 | ppl 1.77 | wps 2177 | ups 1.67 | wpb 1302.4 | bsz 89.4 | num_updates 139148 | lr 0.000536156 | gnorm 0.617 | train_wall 1845 | gb_free 17.9 | wall 0
2024-02-06 19:47:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 19:47:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 19:47:04 | INFO | fairseq.trainer | begin training epoch 44
2024-02-06 19:47:04 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 19:47:34 | INFO | train_inner | epoch 044:     52 / 3236 loss=0.811, nll_loss=0.811, ppl=1.75, wps=1037.4, ups=0.79, wpb=1319.1, bsz=97.8, num_updates=139200, lr=0.000536056, gnorm=0.591, train_wall=56, gb_free=18.5, wall=0
2024-02-06 19:48:31 | INFO | train_inner | epoch 044:    152 / 3236 loss=0.794, nll_loss=0.794, ppl=1.73, wps=2286.5, ups=1.77, wpb=1294.2, bsz=89.3, num_updates=139300, lr=0.000535864, gnorm=0.603, train_wall=56, gb_free=18, wall=0
2024-02-06 19:49:27 | INFO | train_inner | epoch 044:    252 / 3236 loss=0.796, nll_loss=0.796, ppl=1.74, wps=2279.1, ups=1.77, wpb=1284.1, bsz=88.3, num_updates=139400, lr=0.000535672, gnorm=0.626, train_wall=56, gb_free=17.7, wall=0
2024-02-06 19:50:24 | INFO | train_inner | epoch 044:    352 / 3236 loss=0.802, nll_loss=0.802, ppl=1.74, wps=2330.8, ups=1.77, wpb=1317.4, bsz=92.6, num_updates=139500, lr=0.00053548, gnorm=0.605, train_wall=56, gb_free=17.2, wall=0
2024-02-06 19:51:21 | INFO | train_inner | epoch 044:    452 / 3236 loss=0.774, nll_loss=0.774, ppl=1.71, wps=2263.6, ups=1.75, wpb=1292.6, bsz=86.9, num_updates=139600, lr=0.000535288, gnorm=0.6, train_wall=57, gb_free=18.1, wall=0
2024-02-06 19:52:18 | INFO | train_inner | epoch 044:    552 / 3236 loss=0.811, nll_loss=0.811, ppl=1.75, wps=2274.7, ups=1.74, wpb=1309.6, bsz=93.8, num_updates=139700, lr=0.000535096, gnorm=0.62, train_wall=57, gb_free=18, wall=0
2024-02-06 19:53:16 | INFO | train_inner | epoch 044:    652 / 3236 loss=0.819, nll_loss=0.819, ppl=1.76, wps=2252.8, ups=1.73, wpb=1303, bsz=89.3, num_updates=139800, lr=0.000534905, gnorm=0.607, train_wall=57, gb_free=17.4, wall=0
2024-02-06 19:54:14 | INFO | train_inner | epoch 044:    752 / 3236 loss=0.799, nll_loss=0.799, ppl=1.74, wps=2250.8, ups=1.74, wpb=1293.2, bsz=85.4, num_updates=139900, lr=0.000534713, gnorm=0.629, train_wall=57, gb_free=17.7, wall=0
2024-02-06 19:55:11 | INFO | train_inner | epoch 044:    852 / 3236 loss=0.821, nll_loss=0.821, ppl=1.77, wps=2268.3, ups=1.75, wpb=1295.7, bsz=92.3, num_updates=140000, lr=0.000534522, gnorm=0.623, train_wall=57, gb_free=18.3, wall=0
2024-02-06 19:56:09 | INFO | train_inner | epoch 044:    952 / 3236 loss=0.83, nll_loss=0.83, ppl=1.78, wps=2267.8, ups=1.73, wpb=1312, bsz=91, num_updates=140100, lr=0.000534332, gnorm=0.619, train_wall=57, gb_free=17.6, wall=0
2024-02-06 19:57:07 | INFO | train_inner | epoch 044:   1052 / 3236 loss=0.806, nll_loss=0.806, ppl=1.75, wps=2245.3, ups=1.73, wpb=1300, bsz=87.2, num_updates=140200, lr=0.000534141, gnorm=0.624, train_wall=57, gb_free=18.5, wall=0
2024-02-06 19:58:04 | INFO | train_inner | epoch 044:   1152 / 3236 loss=0.822, nll_loss=0.822, ppl=1.77, wps=2266.8, ups=1.73, wpb=1307.5, bsz=86.9, num_updates=140300, lr=0.000533951, gnorm=0.62, train_wall=57, gb_free=18.5, wall=0
2024-02-06 19:59:02 | INFO | train_inner | epoch 044:   1252 / 3236 loss=0.812, nll_loss=0.812, ppl=1.76, wps=2232.2, ups=1.73, wpb=1290, bsz=87.8, num_updates=140400, lr=0.000533761, gnorm=0.62, train_wall=57, gb_free=17.9, wall=0
2024-02-06 20:00:00 | INFO | train_inner | epoch 044:   1352 / 3236 loss=0.818, nll_loss=0.818, ppl=1.76, wps=2281.1, ups=1.74, wpb=1314.2, bsz=88.3, num_updates=140500, lr=0.000533571, gnorm=0.609, train_wall=57, gb_free=18.5, wall=0
2024-02-06 20:00:58 | INFO | train_inner | epoch 044:   1452 / 3236 loss=0.832, nll_loss=0.832, ppl=1.78, wps=2234, ups=1.72, wpb=1297.3, bsz=87.7, num_updates=140600, lr=0.000533381, gnorm=0.626, train_wall=57, gb_free=18.7, wall=0
2024-02-06 20:01:55 | INFO | train_inner | epoch 044:   1552 / 3236 loss=0.815, nll_loss=0.815, ppl=1.76, wps=2285.8, ups=1.73, wpb=1318.5, bsz=88.4, num_updates=140700, lr=0.000533191, gnorm=0.605, train_wall=57, gb_free=17.3, wall=0
2024-02-06 20:02:54 | INFO | train_inner | epoch 044:   1652 / 3236 loss=0.808, nll_loss=0.808, ppl=1.75, wps=2243.5, ups=1.71, wpb=1313.6, bsz=89.8, num_updates=140800, lr=0.000533002, gnorm=0.607, train_wall=58, gb_free=18.3, wall=0
2024-02-06 20:03:51 | INFO | train_inner | epoch 044:   1752 / 3236 loss=0.808, nll_loss=0.808, ppl=1.75, wps=2311.5, ups=1.76, wpb=1309.8, bsz=91, num_updates=140900, lr=0.000532813, gnorm=0.599, train_wall=56, gb_free=18.3, wall=0
2024-02-06 20:04:47 | INFO | train_inner | epoch 044:   1852 / 3236 loss=0.818, nll_loss=0.818, ppl=1.76, wps=2324.6, ups=1.76, wpb=1317.4, bsz=96.4, num_updates=141000, lr=0.000532624, gnorm=0.601, train_wall=56, gb_free=18.6, wall=0
2024-02-06 20:05:44 | INFO | train_inner | epoch 044:   1952 / 3236 loss=0.831, nll_loss=0.831, ppl=1.78, wps=2321, ups=1.76, wpb=1315.9, bsz=90.7, num_updates=141100, lr=0.000532435, gnorm=0.619, train_wall=56, gb_free=17.3, wall=0
2024-02-06 20:06:41 | INFO | train_inner | epoch 044:   2052 / 3236 loss=0.85, nll_loss=0.85, ppl=1.8, wps=2297.3, ups=1.74, wpb=1317.7, bsz=95.6, num_updates=141200, lr=0.000532246, gnorm=0.624, train_wall=57, gb_free=17.9, wall=0
2024-02-06 20:07:39 | INFO | train_inner | epoch 044:   2152 / 3236 loss=0.83, nll_loss=0.83, ppl=1.78, wps=2245.5, ups=1.73, wpb=1294.7, bsz=89.5, num_updates=141300, lr=0.000532058, gnorm=0.636, train_wall=57, gb_free=17.8, wall=0
2024-02-06 20:08:37 | INFO | train_inner | epoch 044:   2252 / 3236 loss=0.824, nll_loss=0.824, ppl=1.77, wps=2200.5, ups=1.73, wpb=1272.4, bsz=83, num_updates=141400, lr=0.00053187, gnorm=0.654, train_wall=57, gb_free=18.3, wall=0
2024-02-06 20:09:36 | INFO | train_inner | epoch 044:   2352 / 3236 loss=0.817, nll_loss=0.817, ppl=1.76, wps=2232.8, ups=1.7, wpb=1317.2, bsz=87, num_updates=141500, lr=0.000531682, gnorm=0.606, train_wall=58, gb_free=18.2, wall=0
2024-02-06 20:10:33 | INFO | train_inner | epoch 044:   2452 / 3236 loss=0.836, nll_loss=0.836, ppl=1.79, wps=2259.6, ups=1.76, wpb=1282.1, bsz=87.8, num_updates=141600, lr=0.000531494, gnorm=0.635, train_wall=56, gb_free=18, wall=0
2024-02-06 20:11:29 | INFO | train_inner | epoch 044:   2552 / 3236 loss=0.82, nll_loss=0.82, ppl=1.77, wps=2248.9, ups=1.76, wpb=1279, bsz=85.7, num_updates=141700, lr=0.000531306, gnorm=0.628, train_wall=56, gb_free=17.8, wall=0
2024-02-06 20:12:26 | INFO | train_inner | epoch 044:   2652 / 3236 loss=0.821, nll_loss=0.821, ppl=1.77, wps=2290.8, ups=1.76, wpb=1300.7, bsz=89.1, num_updates=141800, lr=0.000531119, gnorm=0.61, train_wall=56, gb_free=18.1, wall=0
2024-02-06 20:13:24 | INFO | train_inner | epoch 044:   2752 / 3236 loss=0.827, nll_loss=0.827, ppl=1.77, wps=2297.5, ups=1.73, wpb=1326, bsz=86.1, num_updates=141900, lr=0.000530932, gnorm=0.611, train_wall=57, gb_free=18.2, wall=0
2024-02-06 20:14:22 | INFO | train_inner | epoch 044:   2852 / 3236 loss=0.842, nll_loss=0.842, ppl=1.79, wps=2237.2, ups=1.73, wpb=1291, bsz=88.6, num_updates=142000, lr=0.000530745, gnorm=0.614, train_wall=57, gb_free=18.4, wall=0
2024-02-06 20:15:19 | INFO | train_inner | epoch 044:   2952 / 3236 loss=0.821, nll_loss=0.821, ppl=1.77, wps=2319.9, ups=1.76, wpb=1319.4, bsz=91.7, num_updates=142100, lr=0.000530558, gnorm=0.601, train_wall=56, gb_free=17.9, wall=0
2024-02-06 20:16:16 | INFO | train_inner | epoch 044:   3052 / 3236 loss=0.823, nll_loss=0.823, ppl=1.77, wps=2261.2, ups=1.75, wpb=1295.4, bsz=90.7, num_updates=142200, lr=0.000530372, gnorm=0.605, train_wall=57, gb_free=17.7, wall=0
2024-02-06 20:17:15 | INFO | train_inner | epoch 044:   3152 / 3236 loss=0.819, nll_loss=0.819, ppl=1.76, wps=2204, ups=1.7, wpb=1298.7, bsz=89.9, num_updates=142300, lr=0.000530185, gnorm=0.62, train_wall=58, gb_free=17.9, wall=0
2024-02-06 20:18:02 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 20:18:02 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 20:18:54 | INFO | dev | epoch 044 | valid on 'dev' subset | loss 1.112 | nll_loss 1.112 | ppl 2.16 | wps 4472 | wpb 1146.2 | bsz 77.6 | num_updates 142384 | best_loss 1.094
2024-02-06 20:18:54 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 44 @ 142384 updates
2024-02-06 20:18:54 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint44.pt
2024-02-06 20:18:55 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint44.pt
2024-02-06 20:18:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint44.pt (epoch 44 @ 142384 updates, score 1.112) (writing took 2.970585773931816 seconds)
2024-02-06 20:18:57 | INFO | fairseq_cli.train | end of epoch 44 (average epoch stats below)
2024-02-06 20:18:57 | INFO | train | epoch 044 | loss 0.817 | nll_loss 0.817 | ppl 1.76 | wps 2203.1 | ups 1.69 | wpb 1302.4 | bsz 89.4 | num_updates 142384 | lr 0.000530029 | gnorm 0.616 | train_wall 1839 | gb_free 18 | wall 0
2024-02-06 20:18:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 20:18:57 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 20:18:57 | INFO | fairseq.trainer | begin training epoch 45
2024-02-06 20:18:57 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 20:19:07 | INFO | train_inner | epoch 045:     16 / 3236 loss=0.808, nll_loss=0.808, ppl=1.75, wps=1153.3, ups=0.89, wpb=1293.4, bsz=89.8, num_updates=142400, lr=0.000529999, gnorm=0.611, train_wall=56, gb_free=17.7, wall=0
2024-02-06 20:20:03 | INFO | train_inner | epoch 045:    116 / 3236 loss=0.802, nll_loss=0.802, ppl=1.74, wps=2316.7, ups=1.78, wpb=1299.1, bsz=89.3, num_updates=142500, lr=0.000529813, gnorm=0.626, train_wall=56, gb_free=18.2, wall=0
2024-02-06 20:21:02 | INFO | train_inner | epoch 045:    216 / 3236 loss=0.786, nll_loss=0.786, ppl=1.72, wps=2211, ups=1.69, wpb=1310.9, bsz=93, num_updates=142600, lr=0.000529627, gnorm=0.615, train_wall=59, gb_free=17.4, wall=0
2024-02-06 20:21:58 | INFO | train_inner | epoch 045:    316 / 3236 loss=0.786, nll_loss=0.786, ppl=1.72, wps=2296.5, ups=1.78, wpb=1287.2, bsz=88.9, num_updates=142700, lr=0.000529442, gnorm=0.628, train_wall=55, gb_free=17.3, wall=0
2024-02-06 20:22:55 | INFO | train_inner | epoch 045:    416 / 3236 loss=0.799, nll_loss=0.799, ppl=1.74, wps=2316.3, ups=1.77, wpb=1307.9, bsz=89, num_updates=142800, lr=0.000529256, gnorm=0.609, train_wall=56, gb_free=17.9, wall=0
2024-02-06 20:23:51 | INFO | train_inner | epoch 045:    516 / 3236 loss=0.782, nll_loss=0.782, ppl=1.72, wps=2297.6, ups=1.77, wpb=1297.8, bsz=94, num_updates=142900, lr=0.000529071, gnorm=0.615, train_wall=56, gb_free=18.4, wall=0
2024-02-06 20:24:48 | INFO | train_inner | epoch 045:    616 / 3236 loss=0.804, nll_loss=0.804, ppl=1.75, wps=2318.4, ups=1.78, wpb=1303.7, bsz=88.5, num_updates=143000, lr=0.000528886, gnorm=0.617, train_wall=56, gb_free=17.6, wall=0
2024-02-06 20:25:44 | INFO | train_inner | epoch 045:    716 / 3236 loss=0.802, nll_loss=0.802, ppl=1.74, wps=2309.2, ups=1.78, wpb=1299.8, bsz=96.7, num_updates=143100, lr=0.000528701, gnorm=0.633, train_wall=56, gb_free=18.2, wall=0
2024-02-06 20:26:41 | INFO | train_inner | epoch 045:    816 / 3236 loss=0.797, nll_loss=0.797, ppl=1.74, wps=2249.7, ups=1.73, wpb=1297.4, bsz=82.7, num_updates=143200, lr=0.000528516, gnorm=0.62, train_wall=57, gb_free=17.9, wall=0
2024-02-06 20:27:41 | INFO | train_inner | epoch 045:    916 / 3236 loss=0.792, nll_loss=0.792, ppl=1.73, wps=2200.6, ups=1.69, wpb=1305.4, bsz=86.1, num_updates=143300, lr=0.000528332, gnorm=0.613, train_wall=59, gb_free=18.2, wall=0
2024-02-06 20:28:37 | INFO | train_inner | epoch 045:   1016 / 3236 loss=0.828, nll_loss=0.828, ppl=1.77, wps=2371.9, ups=1.78, wpb=1333.1, bsz=94.6, num_updates=143400, lr=0.000528148, gnorm=0.606, train_wall=56, gb_free=18.4, wall=0
2024-02-06 20:29:34 | INFO | train_inner | epoch 045:   1116 / 3236 loss=0.802, nll_loss=0.802, ppl=1.74, wps=2284.5, ups=1.77, wpb=1290.3, bsz=87.8, num_updates=143500, lr=0.000527964, gnorm=0.618, train_wall=56, gb_free=18.6, wall=0
2024-02-06 20:30:30 | INFO | train_inner | epoch 045:   1216 / 3236 loss=0.81, nll_loss=0.81, ppl=1.75, wps=2321.7, ups=1.77, wpb=1308.2, bsz=89.9, num_updates=143600, lr=0.00052778, gnorm=0.622, train_wall=56, gb_free=17.6, wall=0
2024-02-06 20:31:26 | INFO | train_inner | epoch 045:   1316 / 3236 loss=0.804, nll_loss=0.804, ppl=1.75, wps=2257.4, ups=1.77, wpb=1272.9, bsz=84, num_updates=143700, lr=0.000527596, gnorm=0.665, train_wall=56, gb_free=17.8, wall=0
2024-02-06 20:32:23 | INFO | train_inner | epoch 045:   1416 / 3236 loss=0.808, nll_loss=0.808, ppl=1.75, wps=2302.7, ups=1.77, wpb=1302.7, bsz=86.3, num_updates=143800, lr=0.000527413, gnorm=0.632, train_wall=56, gb_free=17.7, wall=0
2024-02-06 20:33:20 | INFO | train_inner | epoch 045:   1516 / 3236 loss=0.808, nll_loss=0.808, ppl=1.75, wps=2300.7, ups=1.75, wpb=1317.9, bsz=95.8, num_updates=143900, lr=0.000527229, gnorm=0.6, train_wall=57, gb_free=16.9, wall=0
2024-02-06 20:34:19 | INFO | train_inner | epoch 045:   1616 / 3236 loss=0.802, nll_loss=0.802, ppl=1.74, wps=2190.8, ups=1.69, wpb=1293.4, bsz=89, num_updates=144000, lr=0.000527046, gnorm=0.635, train_wall=58, gb_free=18.5, wall=0
2024-02-06 20:35:16 | INFO | train_inner | epoch 045:   1716 / 3236 loss=0.816, nll_loss=0.816, ppl=1.76, wps=2291.1, ups=1.76, wpb=1300.8, bsz=89.2, num_updates=144100, lr=0.000526863, gnorm=0.614, train_wall=56, gb_free=17.5, wall=0
2024-02-06 20:36:12 | INFO | train_inner | epoch 045:   1816 / 3236 loss=0.806, nll_loss=0.806, ppl=1.75, wps=2294.5, ups=1.78, wpb=1292.5, bsz=87.4, num_updates=144200, lr=0.000526681, gnorm=0.629, train_wall=56, gb_free=17.5, wall=0
2024-02-06 20:37:09 | INFO | train_inner | epoch 045:   1916 / 3236 loss=0.813, nll_loss=0.813, ppl=1.76, wps=2315.4, ups=1.76, wpb=1314.2, bsz=87.5, num_updates=144300, lr=0.000526498, gnorm=0.604, train_wall=56, gb_free=17.5, wall=0
2024-02-06 20:38:05 | INFO | train_inner | epoch 045:   2016 / 3236 loss=0.797, nll_loss=0.797, ppl=1.74, wps=2354, ups=1.79, wpb=1318.3, bsz=92.5, num_updates=144400, lr=0.000526316, gnorm=0.602, train_wall=55, gb_free=18.5, wall=0
2024-02-06 20:39:05 | INFO | train_inner | epoch 045:   2116 / 3236 loss=0.82, nll_loss=0.82, ppl=1.77, wps=2142.6, ups=1.66, wpb=1292.3, bsz=85, num_updates=144500, lr=0.000526134, gnorm=0.633, train_wall=60, gb_free=18.3, wall=0
2024-02-06 20:40:02 | INFO | train_inner | epoch 045:   2216 / 3236 loss=0.804, nll_loss=0.804, ppl=1.75, wps=2297.6, ups=1.77, wpb=1295.8, bsz=88.4, num_updates=144600, lr=0.000525952, gnorm=0.617, train_wall=56, gb_free=18.5, wall=0
2024-02-06 20:40:59 | INFO | train_inner | epoch 045:   2316 / 3236 loss=0.82, nll_loss=0.82, ppl=1.76, wps=2273.4, ups=1.74, wpb=1305.7, bsz=87.8, num_updates=144700, lr=0.00052577, gnorm=0.612, train_wall=57, gb_free=18.3, wall=0
2024-02-06 20:41:55 | INFO | train_inner | epoch 045:   2416 / 3236 loss=0.818, nll_loss=0.818, ppl=1.76, wps=2337.4, ups=1.79, wpb=1306.5, bsz=90.5, num_updates=144800, lr=0.000525588, gnorm=0.61, train_wall=55, gb_free=17.6, wall=0
2024-02-06 20:42:51 | INFO | train_inner | epoch 045:   2516 / 3236 loss=0.834, nll_loss=0.834, ppl=1.78, wps=2299.9, ups=1.78, wpb=1290.2, bsz=85, num_updates=144900, lr=0.000525407, gnorm=0.624, train_wall=56, gb_free=18.3, wall=0
2024-02-06 20:43:48 | INFO | train_inner | epoch 045:   2616 / 3236 loss=0.828, nll_loss=0.828, ppl=1.78, wps=2320.7, ups=1.78, wpb=1306.8, bsz=93.4, num_updates=145000, lr=0.000525226, gnorm=0.627, train_wall=56, gb_free=17.8, wall=0
2024-02-06 20:44:44 | INFO | train_inner | epoch 045:   2716 / 3236 loss=0.83, nll_loss=0.83, ppl=1.78, wps=2296.7, ups=1.77, wpb=1294.4, bsz=91.2, num_updates=145100, lr=0.000525045, gnorm=0.633, train_wall=56, gb_free=18.1, wall=0
2024-02-06 20:45:40 | INFO | train_inner | epoch 045:   2816 / 3236 loss=0.851, nll_loss=0.851, ppl=1.8, wps=2301.3, ups=1.77, wpb=1302.4, bsz=91, num_updates=145200, lr=0.000524864, gnorm=0.623, train_wall=56, gb_free=17.9, wall=0
2024-02-06 20:46:37 | INFO | train_inner | epoch 045:   2916 / 3236 loss=0.819, nll_loss=0.819, ppl=1.76, wps=2299.2, ups=1.77, wpb=1298.2, bsz=86.1, num_updates=145300, lr=0.000524683, gnorm=0.632, train_wall=56, gb_free=18.6, wall=0
2024-02-06 20:47:36 | INFO | train_inner | epoch 045:   3016 / 3236 loss=0.832, nll_loss=0.832, ppl=1.78, wps=2223.4, ups=1.69, wpb=1317.1, bsz=94.2, num_updates=145400, lr=0.000524503, gnorm=0.619, train_wall=59, gb_free=18.9, wall=0
2024-02-06 20:48:33 | INFO | train_inner | epoch 045:   3116 / 3236 loss=0.826, nll_loss=0.826, ppl=1.77, wps=2296.1, ups=1.75, wpb=1311.4, bsz=89.2, num_updates=145500, lr=0.000524323, gnorm=0.608, train_wall=57, gb_free=18.3, wall=0
2024-02-06 20:49:30 | INFO | train_inner | epoch 045:   3216 / 3236 loss=0.816, nll_loss=0.816, ppl=1.76, wps=2288.6, ups=1.77, wpb=1291.9, bsz=87.2, num_updates=145600, lr=0.000524142, gnorm=0.612, train_wall=56, gb_free=18.3, wall=0
2024-02-06 20:49:41 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 20:49:41 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 20:50:33 | INFO | dev | epoch 045 | valid on 'dev' subset | loss 1.119 | nll_loss 1.119 | ppl 2.17 | wps 4408.3 | wpb 1146.2 | bsz 77.6 | num_updates 145620 | best_loss 1.094
2024-02-06 20:50:33 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 45 @ 145620 updates
2024-02-06 20:50:33 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint45.pt
2024-02-06 20:50:35 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint45.pt
2024-02-06 20:50:36 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint45.pt (epoch 45 @ 145620 updates, score 1.119) (writing took 2.9621401999611408 seconds)
2024-02-06 20:50:36 | INFO | fairseq_cli.train | end of epoch 45 (average epoch stats below)
2024-02-06 20:50:36 | INFO | train | epoch 045 | loss 0.811 | nll_loss 0.811 | ppl 1.75 | wps 2218.6 | ups 1.7 | wpb 1302.4 | bsz 89.4 | num_updates 145620 | lr 0.000524106 | gnorm 0.62 | train_wall 1825 | gb_free 18.1 | wall 0
2024-02-06 20:50:36 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 20:50:36 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 20:50:36 | INFO | fairseq.trainer | begin training epoch 46
2024-02-06 20:50:36 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 20:51:22 | INFO | train_inner | epoch 046:     80 / 3236 loss=0.77, nll_loss=0.77, ppl=1.71, wps=1160.6, ups=0.89, wpb=1304.1, bsz=90.8, num_updates=145700, lr=0.000523963, gnorm=0.612, train_wall=56, gb_free=18.1, wall=0
2024-02-06 20:52:18 | INFO | train_inner | epoch 046:    180 / 3236 loss=0.758, nll_loss=0.758, ppl=1.69, wps=2330, ups=1.78, wpb=1312, bsz=89.5, num_updates=145800, lr=0.000523783, gnorm=0.601, train_wall=56, gb_free=18.7, wall=0
2024-02-06 20:53:15 | INFO | train_inner | epoch 046:    280 / 3236 loss=0.779, nll_loss=0.779, ppl=1.72, wps=2290.3, ups=1.77, wpb=1293.9, bsz=84.8, num_updates=145900, lr=0.000523603, gnorm=0.615, train_wall=56, gb_free=17.9, wall=0
2024-02-06 20:54:15 | INFO | train_inner | epoch 046:    380 / 3236 loss=0.797, nll_loss=0.797, ppl=1.74, wps=2183, ups=1.68, wpb=1302.8, bsz=91.8, num_updates=146000, lr=0.000523424, gnorm=0.616, train_wall=59, gb_free=18.3, wall=0
2024-02-06 20:55:11 | INFO | train_inner | epoch 046:    480 / 3236 loss=0.786, nll_loss=0.786, ppl=1.72, wps=2298.2, ups=1.78, wpb=1292.1, bsz=87.3, num_updates=146100, lr=0.000523245, gnorm=0.615, train_wall=56, gb_free=17.7, wall=0
2024-02-06 20:56:07 | INFO | train_inner | epoch 046:    580 / 3236 loss=0.791, nll_loss=0.791, ppl=1.73, wps=2281.2, ups=1.77, wpb=1287.4, bsz=86.9, num_updates=146200, lr=0.000523066, gnorm=0.627, train_wall=56, gb_free=17.8, wall=0
2024-02-06 20:57:03 | INFO | train_inner | epoch 046:    680 / 3236 loss=0.784, nll_loss=0.784, ppl=1.72, wps=2292.3, ups=1.78, wpb=1286, bsz=85.4, num_updates=146300, lr=0.000522887, gnorm=0.632, train_wall=56, gb_free=18.2, wall=0
2024-02-06 20:57:59 | INFO | train_inner | epoch 046:    780 / 3236 loss=0.788, nll_loss=0.788, ppl=1.73, wps=2296.2, ups=1.78, wpb=1289.5, bsz=89.2, num_updates=146400, lr=0.000522708, gnorm=0.619, train_wall=56, gb_free=18.2, wall=0
2024-02-06 20:58:56 | INFO | train_inner | epoch 046:    880 / 3236 loss=0.789, nll_loss=0.789, ppl=1.73, wps=2257.4, ups=1.77, wpb=1274.1, bsz=84.7, num_updates=146500, lr=0.00052253, gnorm=0.638, train_wall=56, gb_free=18.7, wall=0
2024-02-06 20:59:52 | INFO | train_inner | epoch 046:    980 / 3236 loss=0.796, nll_loss=0.796, ppl=1.74, wps=2299.1, ups=1.78, wpb=1295.2, bsz=87.4, num_updates=146600, lr=0.000522352, gnorm=0.617, train_wall=56, gb_free=18.4, wall=0
2024-02-06 21:00:50 | INFO | train_inner | epoch 046:   1080 / 3236 loss=0.793, nll_loss=0.793, ppl=1.73, wps=2290.2, ups=1.74, wpb=1313.2, bsz=93.4, num_updates=146700, lr=0.000522174, gnorm=0.61, train_wall=57, gb_free=17.5, wall=0
2024-02-06 21:01:49 | INFO | train_inner | epoch 046:   1180 / 3236 loss=0.792, nll_loss=0.792, ppl=1.73, wps=2218.1, ups=1.67, wpb=1327.5, bsz=90.2, num_updates=146800, lr=0.000521996, gnorm=0.605, train_wall=59, gb_free=18.1, wall=0
2024-02-06 21:02:46 | INFO | train_inner | epoch 046:   1280 / 3236 loss=0.831, nll_loss=0.831, ppl=1.78, wps=2318.2, ups=1.77, wpb=1310.8, bsz=95.4, num_updates=146900, lr=0.000521818, gnorm=0.617, train_wall=56, gb_free=18.6, wall=0
2024-02-06 21:03:42 | INFO | train_inner | epoch 046:   1380 / 3236 loss=0.791, nll_loss=0.791, ppl=1.73, wps=2310.1, ups=1.78, wpb=1298.6, bsz=89, num_updates=147000, lr=0.000521641, gnorm=0.614, train_wall=56, gb_free=17.4, wall=0
2024-02-06 21:04:39 | INFO | train_inner | epoch 046:   1480 / 3236 loss=0.812, nll_loss=0.812, ppl=1.76, wps=2281.9, ups=1.77, wpb=1288.2, bsz=88.1, num_updates=147100, lr=0.000521463, gnorm=0.637, train_wall=56, gb_free=18.7, wall=0
2024-02-06 21:05:35 | INFO | train_inner | epoch 046:   1580 / 3236 loss=0.794, nll_loss=0.794, ppl=1.73, wps=2300.9, ups=1.77, wpb=1298.3, bsz=89.7, num_updates=147200, lr=0.000521286, gnorm=0.622, train_wall=56, gb_free=18.3, wall=0
2024-02-06 21:06:32 | INFO | train_inner | epoch 046:   1680 / 3236 loss=0.81, nll_loss=0.81, ppl=1.75, wps=2332.5, ups=1.77, wpb=1319.9, bsz=88.2, num_updates=147300, lr=0.000521109, gnorm=0.63, train_wall=56, gb_free=18, wall=0
2024-02-06 21:07:29 | INFO | train_inner | epoch 046:   1780 / 3236 loss=0.807, nll_loss=0.807, ppl=1.75, wps=2274.1, ups=1.73, wpb=1312.2, bsz=89.2, num_updates=147400, lr=0.000520932, gnorm=0.609, train_wall=57, gb_free=17.9, wall=0
2024-02-06 21:08:27 | INFO | train_inner | epoch 046:   1880 / 3236 loss=0.815, nll_loss=0.815, ppl=1.76, wps=2291.4, ups=1.73, wpb=1327.4, bsz=94.2, num_updates=147500, lr=0.000520756, gnorm=0.602, train_wall=57, gb_free=18.2, wall=0
2024-02-06 21:09:28 | INFO | train_inner | epoch 046:   1980 / 3236 loss=0.81, nll_loss=0.81, ppl=1.75, wps=2149.8, ups=1.66, wpb=1298.8, bsz=87.6, num_updates=147600, lr=0.000520579, gnorm=0.611, train_wall=60, gb_free=18, wall=0
2024-02-06 21:10:24 | INFO | train_inner | epoch 046:   2080 / 3236 loss=0.804, nll_loss=0.804, ppl=1.75, wps=2285.7, ups=1.77, wpb=1294.5, bsz=84.9, num_updates=147700, lr=0.000520403, gnorm=0.631, train_wall=56, gb_free=18, wall=0
2024-02-06 21:11:21 | INFO | train_inner | epoch 046:   2180 / 3236 loss=0.814, nll_loss=0.814, ppl=1.76, wps=2284.4, ups=1.77, wpb=1293.7, bsz=88.1, num_updates=147800, lr=0.000520227, gnorm=0.623, train_wall=56, gb_free=18.2, wall=0
2024-02-06 21:12:17 | INFO | train_inner | epoch 046:   2280 / 3236 loss=0.814, nll_loss=0.814, ppl=1.76, wps=2311.9, ups=1.77, wpb=1303.2, bsz=88.6, num_updates=147900, lr=0.000520051, gnorm=0.626, train_wall=56, gb_free=17.7, wall=0
2024-02-06 21:13:14 | INFO | train_inner | epoch 046:   2380 / 3236 loss=0.805, nll_loss=0.805, ppl=1.75, wps=2313.6, ups=1.78, wpb=1301.3, bsz=90.8, num_updates=148000, lr=0.000519875, gnorm=0.61, train_wall=56, gb_free=17.5, wall=0
2024-02-06 21:14:10 | INFO | train_inner | epoch 046:   2480 / 3236 loss=0.808, nll_loss=0.808, ppl=1.75, wps=2307.1, ups=1.77, wpb=1301.2, bsz=87.8, num_updates=148100, lr=0.0005197, gnorm=0.615, train_wall=56, gb_free=18, wall=0
2024-02-06 21:15:08 | INFO | train_inner | epoch 046:   2580 / 3236 loss=0.826, nll_loss=0.826, ppl=1.77, wps=2238.2, ups=1.72, wpb=1302.9, bsz=92.7, num_updates=148200, lr=0.000519524, gnorm=0.648, train_wall=58, gb_free=18.1, wall=0
2024-02-06 21:16:07 | INFO | train_inner | epoch 046:   2680 / 3236 loss=0.82, nll_loss=0.82, ppl=1.77, wps=2257.7, ups=1.71, wpb=1317.7, bsz=92.2, num_updates=148300, lr=0.000519349, gnorm=0.612, train_wall=58, gb_free=18, wall=0
2024-02-06 21:17:05 | INFO | train_inner | epoch 046:   2780 / 3236 loss=0.846, nll_loss=0.846, ppl=1.8, wps=2254.2, ups=1.72, wpb=1310.5, bsz=92, num_updates=148400, lr=0.000519174, gnorm=0.629, train_wall=58, gb_free=18.7, wall=0
2024-02-06 21:18:04 | INFO | train_inner | epoch 046:   2880 / 3236 loss=0.803, nll_loss=0.803, ppl=1.74, wps=2202.4, ups=1.7, wpb=1297.4, bsz=86.6, num_updates=148500, lr=0.000518999, gnorm=0.61, train_wall=58, gb_free=18.7, wall=0
2024-02-06 21:19:02 | INFO | train_inner | epoch 046:   2980 / 3236 loss=0.812, nll_loss=0.812, ppl=1.76, wps=2240.8, ups=1.7, wpb=1314.5, bsz=91.1, num_updates=148600, lr=0.000518825, gnorm=0.616, train_wall=58, gb_free=18.1, wall=0
2024-02-06 21:20:01 | INFO | train_inner | epoch 046:   3080 / 3236 loss=0.808, nll_loss=0.808, ppl=1.75, wps=2212.9, ups=1.69, wpb=1305.7, bsz=93, num_updates=148700, lr=0.00051865, gnorm=0.603, train_wall=58, gb_free=17.6, wall=0
2024-02-06 21:20:59 | INFO | train_inner | epoch 046:   3180 / 3236 loss=0.828, nll_loss=0.828, ppl=1.77, wps=2244.5, ups=1.73, wpb=1298.8, bsz=90.2, num_updates=148800, lr=0.000518476, gnorm=0.617, train_wall=57, gb_free=18.3, wall=0
2024-02-06 21:21:31 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 21:21:31 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 21:22:12 | INFO | dev | epoch 046 | valid on 'dev' subset | loss 1.131 | nll_loss 1.131 | ppl 2.19 | wps 5746.8 | wpb 1146.2 | bsz 77.6 | num_updates 148856 | best_loss 1.094
2024-02-06 21:22:12 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 46 @ 148856 updates
2024-02-06 21:22:12 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint46.pt
2024-02-06 21:22:13 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint46.pt
2024-02-06 21:22:15 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint46.pt (epoch 46 @ 148856 updates, score 1.131) (writing took 3.229156458983198 seconds)
2024-02-06 21:22:15 | INFO | fairseq_cli.train | end of epoch 46 (average epoch stats below)
2024-02-06 21:22:15 | INFO | train | epoch 046 | loss 0.803 | nll_loss 0.803 | ppl 1.74 | wps 2219.6 | ups 1.7 | wpb 1302.4 | bsz 89.4 | num_updates 148856 | lr 0.000518378 | gnorm 0.618 | train_wall 1836 | gb_free 18.4 | wall 0
2024-02-06 21:22:15 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 21:22:15 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 21:22:15 | INFO | fairseq.trainer | begin training epoch 47
2024-02-06 21:22:15 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 21:22:42 | INFO | train_inner | epoch 047:     44 / 3236 loss=0.786, nll_loss=0.786, ppl=1.72, wps=1274.4, ups=0.97, wpb=1316, bsz=95, num_updates=148900, lr=0.000518302, gnorm=0.594, train_wall=58, gb_free=18.2, wall=0
2024-02-06 21:23:40 | INFO | train_inner | epoch 047:    144 / 3236 loss=0.767, nll_loss=0.767, ppl=1.7, wps=2263.2, ups=1.74, wpb=1299.4, bsz=90.3, num_updates=149000, lr=0.000518128, gnorm=0.608, train_wall=57, gb_free=18.2, wall=0
2024-02-06 21:24:37 | INFO | train_inner | epoch 047:    244 / 3236 loss=0.773, nll_loss=0.773, ppl=1.71, wps=2258, ups=1.74, wpb=1298.9, bsz=86.1, num_updates=149100, lr=0.000517954, gnorm=0.616, train_wall=57, gb_free=18, wall=0
2024-02-06 21:25:35 | INFO | train_inner | epoch 047:    344 / 3236 loss=0.775, nll_loss=0.775, ppl=1.71, wps=2252.1, ups=1.73, wpb=1301, bsz=87.4, num_updates=149200, lr=0.00051778, gnorm=0.62, train_wall=57, gb_free=18.2, wall=0
2024-02-06 21:26:33 | INFO | train_inner | epoch 047:    444 / 3236 loss=0.785, nll_loss=0.785, ppl=1.72, wps=2241.8, ups=1.74, wpb=1289, bsz=84.2, num_updates=149300, lr=0.000517607, gnorm=0.629, train_wall=57, gb_free=17.9, wall=0
2024-02-06 21:27:31 | INFO | train_inner | epoch 047:    544 / 3236 loss=0.767, nll_loss=0.767, ppl=1.7, wps=2193.1, ups=1.72, wpb=1273, bsz=87.4, num_updates=149400, lr=0.000517434, gnorm=0.641, train_wall=57, gb_free=18.1, wall=0
2024-02-06 21:28:29 | INFO | train_inner | epoch 047:    644 / 3236 loss=0.78, nll_loss=0.78, ppl=1.72, wps=2212.5, ups=1.72, wpb=1285.7, bsz=83.9, num_updates=149500, lr=0.000517261, gnorm=0.618, train_wall=57, gb_free=17.7, wall=0
2024-02-06 21:29:27 | INFO | train_inner | epoch 047:    744 / 3236 loss=0.794, nll_loss=0.794, ppl=1.73, wps=2261.8, ups=1.71, wpb=1322.7, bsz=92.4, num_updates=149600, lr=0.000517088, gnorm=0.623, train_wall=58, gb_free=17.6, wall=0
2024-02-06 21:30:26 | INFO | train_inner | epoch 047:    844 / 3236 loss=0.8, nll_loss=0.8, ppl=1.74, wps=2233.6, ups=1.72, wpb=1302.2, bsz=94.1, num_updates=149700, lr=0.000516915, gnorm=0.614, train_wall=58, gb_free=18.2, wall=0
2024-02-06 21:31:23 | INFO | train_inner | epoch 047:    944 / 3236 loss=0.79, nll_loss=0.79, ppl=1.73, wps=2262.5, ups=1.73, wpb=1304.5, bsz=90, num_updates=149800, lr=0.000516742, gnorm=0.624, train_wall=57, gb_free=17.4, wall=0
2024-02-06 21:32:21 | INFO | train_inner | epoch 047:   1044 / 3236 loss=0.8, nll_loss=0.8, ppl=1.74, wps=2273.9, ups=1.72, wpb=1320.7, bsz=89.4, num_updates=149900, lr=0.00051657, gnorm=0.617, train_wall=57, gb_free=17.8, wall=0
2024-02-06 21:33:19 | INFO | train_inner | epoch 047:   1144 / 3236 loss=0.794, nll_loss=0.794, ppl=1.73, wps=2280.4, ups=1.74, wpb=1314.3, bsz=93.8, num_updates=150000, lr=0.000516398, gnorm=0.601, train_wall=57, gb_free=18.6, wall=0
2024-02-06 21:33:19 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 21:33:19 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 21:33:53 | INFO | dev | epoch 047 | valid on 'dev' subset | loss 1.142 | nll_loss 1.142 | ppl 2.21 | wps 6719.2 | wpb 1146.2 | bsz 77.6 | num_updates 150000 | best_loss 1.094
2024-02-06 21:33:53 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 150000 updates
2024-02-06 21:33:53 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_47_150000.pt
2024-02-06 21:33:55 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_47_150000.pt
2024-02-06 21:33:56 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_47_150000.pt (epoch 47 @ 150000 updates, score 1.142) (writing took 2.8114802329801023 seconds)
2024-02-06 21:34:54 | INFO | train_inner | epoch 047:   1244 / 3236 loss=0.79, nll_loss=0.79, ppl=1.73, wps=1347.6, ups=1.05, wpb=1284.3, bsz=85, num_updates=150100, lr=0.000516226, gnorm=0.633, train_wall=57, gb_free=17.4, wall=0
2024-02-06 21:35:52 | INFO | train_inner | epoch 047:   1344 / 3236 loss=0.792, nll_loss=0.792, ppl=1.73, wps=2265.8, ups=1.73, wpb=1306.8, bsz=94.8, num_updates=150200, lr=0.000516054, gnorm=0.61, train_wall=57, gb_free=18.2, wall=0
2024-02-06 21:36:50 | INFO | train_inner | epoch 047:   1444 / 3236 loss=0.793, nll_loss=0.793, ppl=1.73, wps=2257, ups=1.73, wpb=1303.6, bsz=90.2, num_updates=150300, lr=0.000515882, gnorm=0.62, train_wall=57, gb_free=18, wall=0
2024-02-06 21:37:48 | INFO | train_inner | epoch 047:   1544 / 3236 loss=0.785, nll_loss=0.785, ppl=1.72, wps=2207.4, ups=1.72, wpb=1284.9, bsz=86, num_updates=150400, lr=0.000515711, gnorm=0.624, train_wall=58, gb_free=17.9, wall=0
2024-02-06 21:38:46 | INFO | train_inner | epoch 047:   1644 / 3236 loss=0.805, nll_loss=0.805, ppl=1.75, wps=2252, ups=1.72, wpb=1308.1, bsz=89.4, num_updates=150500, lr=0.000515539, gnorm=0.627, train_wall=57, gb_free=18.3, wall=0
2024-02-06 21:39:49 | INFO | train_inner | epoch 047:   1744 / 3236 loss=0.789, nll_loss=0.789, ppl=1.73, wps=2069.6, ups=1.59, wpb=1301.9, bsz=88.2, num_updates=150600, lr=0.000515368, gnorm=0.615, train_wall=62, gb_free=18.3, wall=0
2024-02-06 21:40:50 | INFO | train_inner | epoch 047:   1844 / 3236 loss=0.805, nll_loss=0.805, ppl=1.75, wps=2176, ups=1.64, wpb=1329.2, bsz=91.9, num_updates=150700, lr=0.000515197, gnorm=0.613, train_wall=60, gb_free=17.6, wall=0
2024-02-06 21:41:48 | INFO | train_inner | epoch 047:   1944 / 3236 loss=0.804, nll_loss=0.804, ppl=1.75, wps=2274.9, ups=1.74, wpb=1309.8, bsz=91.8, num_updates=150800, lr=0.000515026, gnorm=0.614, train_wall=57, gb_free=17.7, wall=0
2024-02-06 21:42:46 | INFO | train_inner | epoch 047:   2044 / 3236 loss=0.804, nll_loss=0.804, ppl=1.75, wps=2255.5, ups=1.72, wpb=1312.5, bsz=91.4, num_updates=150900, lr=0.000514856, gnorm=0.606, train_wall=58, gb_free=17.7, wall=0
2024-02-06 21:43:44 | INFO | train_inner | epoch 047:   2144 / 3236 loss=0.815, nll_loss=0.815, ppl=1.76, wps=2233, ups=1.72, wpb=1300.1, bsz=90.8, num_updates=151000, lr=0.000514685, gnorm=0.624, train_wall=58, gb_free=17.7, wall=0
2024-02-06 21:44:42 | INFO | train_inner | epoch 047:   2244 / 3236 loss=0.802, nll_loss=0.802, ppl=1.74, wps=2268.5, ups=1.73, wpb=1313.4, bsz=95.4, num_updates=151100, lr=0.000514515, gnorm=0.62, train_wall=57, gb_free=17.7, wall=0
2024-02-06 21:45:40 | INFO | train_inner | epoch 047:   2344 / 3236 loss=0.792, nll_loss=0.792, ppl=1.73, wps=2243, ups=1.73, wpb=1298.7, bsz=93.4, num_updates=151200, lr=0.000514344, gnorm=0.622, train_wall=57, gb_free=18.3, wall=0
2024-02-06 21:46:38 | INFO | train_inner | epoch 047:   2444 / 3236 loss=0.809, nll_loss=0.809, ppl=1.75, wps=2267.5, ups=1.73, wpb=1310.5, bsz=87.4, num_updates=151300, lr=0.000514174, gnorm=0.621, train_wall=57, gb_free=18.8, wall=0
2024-02-06 21:47:35 | INFO | train_inner | epoch 047:   2544 / 3236 loss=0.79, nll_loss=0.79, ppl=1.73, wps=2264.6, ups=1.75, wpb=1290.8, bsz=86.2, num_updates=151400, lr=0.000514005, gnorm=0.614, train_wall=56, gb_free=18, wall=0
2024-02-06 21:48:31 | INFO | train_inner | epoch 047:   2644 / 3236 loss=0.8, nll_loss=0.8, ppl=1.74, wps=2266.9, ups=1.76, wpb=1286.9, bsz=87.8, num_updates=151500, lr=0.000513835, gnorm=0.623, train_wall=56, gb_free=17.9, wall=0
2024-02-06 21:49:29 | INFO | train_inner | epoch 047:   2744 / 3236 loss=0.8, nll_loss=0.8, ppl=1.74, wps=2247.6, ups=1.75, wpb=1282.1, bsz=87.4, num_updates=151600, lr=0.000513665, gnorm=0.639, train_wall=56, gb_free=18, wall=0
2024-02-06 21:50:25 | INFO | train_inner | epoch 047:   2844 / 3236 loss=0.802, nll_loss=0.802, ppl=1.74, wps=2332.2, ups=1.76, wpb=1322.4, bsz=93, num_updates=151700, lr=0.000513496, gnorm=0.632, train_wall=56, gb_free=18.5, wall=0
2024-02-06 21:51:23 | INFO | train_inner | epoch 047:   2944 / 3236 loss=0.812, nll_loss=0.812, ppl=1.76, wps=2245.1, ups=1.74, wpb=1291.3, bsz=83.8, num_updates=151800, lr=0.000513327, gnorm=0.638, train_wall=57, gb_free=18.6, wall=0
2024-02-06 21:52:22 | INFO | train_inner | epoch 047:   3044 / 3236 loss=0.816, nll_loss=0.816, ppl=1.76, wps=2219, ups=1.69, wpb=1310.8, bsz=91.7, num_updates=151900, lr=0.000513158, gnorm=0.614, train_wall=58, gb_free=18.1, wall=0
2024-02-06 21:53:48 | INFO | train_inner | epoch 047:   3144 / 3236 loss=0.806, nll_loss=0.806, ppl=1.75, wps=1510.9, ups=1.16, wpb=1305.7, bsz=87, num_updates=152000, lr=0.000512989, gnorm=0.614, train_wall=85, gb_free=17.4, wall=0
2024-02-06 21:54:46 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 21:54:46 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 21:55:50 | INFO | dev | epoch 047 | valid on 'dev' subset | loss 1.117 | nll_loss 1.117 | ppl 2.17 | wps 3624.1 | wpb 1146.2 | bsz 77.6 | num_updates 152092 | best_loss 1.094
2024-02-06 21:55:50 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 47 @ 152092 updates
2024-02-06 21:55:50 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint47.pt
2024-02-06 21:55:51 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint47.pt
2024-02-06 21:55:53 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint47.pt (epoch 47 @ 152092 updates, score 1.117) (writing took 3.1714294711127877 seconds)
2024-02-06 21:55:53 | INFO | fairseq_cli.train | end of epoch 47 (average epoch stats below)
2024-02-06 21:55:53 | INFO | train | epoch 047 | loss 0.795 | nll_loss 0.795 | ppl 1.73 | wps 2088.2 | ups 1.6 | wpb 1302.4 | bsz 89.4 | num_updates 152092 | lr 0.000512834 | gnorm 0.62 | train_wall 1892 | gb_free 18 | wall 0
2024-02-06 21:55:53 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 21:55:54 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 21:55:54 | INFO | fairseq.trainer | begin training epoch 48
2024-02-06 21:55:54 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 21:55:59 | INFO | train_inner | epoch 048:      8 / 3236 loss=0.809, nll_loss=0.809, ppl=1.75, wps=997.8, ups=0.76, wpb=1309.4, bsz=88.6, num_updates=152100, lr=0.000512821, gnorm=0.613, train_wall=62, gb_free=17.9, wall=0
2024-02-06 21:56:57 | INFO | train_inner | epoch 048:    108 / 3236 loss=0.774, nll_loss=0.774, ppl=1.71, wps=2261.3, ups=1.74, wpb=1300.7, bsz=91.6, num_updates=152200, lr=0.000512652, gnorm=0.611, train_wall=57, gb_free=18.4, wall=0
2024-02-06 21:57:54 | INFO | train_inner | epoch 048:    208 / 3236 loss=0.785, nll_loss=0.785, ppl=1.72, wps=2317.1, ups=1.75, wpb=1327.8, bsz=90.7, num_updates=152300, lr=0.000512484, gnorm=0.617, train_wall=57, gb_free=17.7, wall=0
2024-02-06 21:58:52 | INFO | train_inner | epoch 048:    308 / 3236 loss=0.761, nll_loss=0.761, ppl=1.69, wps=2260.9, ups=1.74, wpb=1298, bsz=85.8, num_updates=152400, lr=0.000512316, gnorm=0.613, train_wall=57, gb_free=17.6, wall=0
2024-02-06 21:59:50 | INFO | train_inner | epoch 048:    408 / 3236 loss=0.763, nll_loss=0.763, ppl=1.7, wps=2236.1, ups=1.71, wpb=1308.6, bsz=90.9, num_updates=152500, lr=0.000512148, gnorm=0.614, train_wall=58, gb_free=18.2, wall=0
2024-02-06 22:00:48 | INFO | train_inner | epoch 048:    508 / 3236 loss=0.78, nll_loss=0.78, ppl=1.72, wps=2304.1, ups=1.74, wpb=1325.4, bsz=92.2, num_updates=152600, lr=0.00051198, gnorm=0.619, train_wall=57, gb_free=18.2, wall=0
2024-02-06 22:01:45 | INFO | train_inner | epoch 048:    608 / 3236 loss=0.792, nll_loss=0.792, ppl=1.73, wps=2262.4, ups=1.74, wpb=1299.2, bsz=88.1, num_updates=152700, lr=0.000511812, gnorm=0.634, train_wall=57, gb_free=18, wall=0
2024-02-06 22:02:42 | INFO | train_inner | epoch 048:    708 / 3236 loss=0.775, nll_loss=0.775, ppl=1.71, wps=2280.2, ups=1.75, wpb=1304.3, bsz=90.7, num_updates=152800, lr=0.000511645, gnorm=0.628, train_wall=57, gb_free=17.9, wall=0
2024-02-06 22:03:40 | INFO | train_inner | epoch 048:    808 / 3236 loss=0.776, nll_loss=0.776, ppl=1.71, wps=2239.9, ups=1.74, wpb=1289.7, bsz=88.6, num_updates=152900, lr=0.000511477, gnorm=0.638, train_wall=57, gb_free=17.2, wall=0
2024-02-06 22:04:38 | INFO | train_inner | epoch 048:    908 / 3236 loss=0.789, nll_loss=0.789, ppl=1.73, wps=2245.2, ups=1.74, wpb=1292.5, bsz=83.6, num_updates=153000, lr=0.00051131, gnorm=0.631, train_wall=57, gb_free=18.4, wall=0
2024-02-06 22:05:35 | INFO | train_inner | epoch 048:   1008 / 3236 loss=0.79, nll_loss=0.79, ppl=1.73, wps=2253, ups=1.75, wpb=1291.1, bsz=90.2, num_updates=153100, lr=0.000511143, gnorm=0.618, train_wall=57, gb_free=18.5, wall=0
2024-02-06 22:06:32 | INFO | train_inner | epoch 048:   1108 / 3236 loss=0.792, nll_loss=0.792, ppl=1.73, wps=2256.2, ups=1.74, wpb=1294.8, bsz=89.1, num_updates=153200, lr=0.000510976, gnorm=0.636, train_wall=57, gb_free=17.8, wall=0
2024-02-06 22:07:30 | INFO | train_inner | epoch 048:   1208 / 3236 loss=0.782, nll_loss=0.782, ppl=1.72, wps=2288.9, ups=1.74, wpb=1313.6, bsz=89.2, num_updates=153300, lr=0.000510809, gnorm=0.6, train_wall=57, gb_free=17.3, wall=0
2024-02-06 22:08:27 | INFO | train_inner | epoch 048:   1308 / 3236 loss=0.777, nll_loss=0.777, ppl=1.71, wps=2272.1, ups=1.74, wpb=1303.3, bsz=90.6, num_updates=153400, lr=0.000510643, gnorm=0.625, train_wall=57, gb_free=18, wall=0
2024-02-06 22:09:24 | INFO | train_inner | epoch 048:   1408 / 3236 loss=0.766, nll_loss=0.766, ppl=1.7, wps=2259.1, ups=1.74, wpb=1296.2, bsz=88.5, num_updates=153500, lr=0.000510477, gnorm=0.617, train_wall=57, gb_free=17.9, wall=0
2024-02-06 22:10:21 | INFO | train_inner | epoch 048:   1508 / 3236 loss=0.787, nll_loss=0.787, ppl=1.73, wps=2271.1, ups=1.76, wpb=1293.3, bsz=92.4, num_updates=153600, lr=0.00051031, gnorm=0.625, train_wall=56, gb_free=27.9, wall=0
2024-02-06 22:11:19 | INFO | train_inner | epoch 048:   1608 / 3236 loss=0.801, nll_loss=0.801, ppl=1.74, wps=2274.5, ups=1.74, wpb=1307, bsz=90.1, num_updates=153700, lr=0.000510144, gnorm=0.622, train_wall=57, gb_free=18.3, wall=0
2024-02-06 22:12:16 | INFO | train_inner | epoch 048:   1708 / 3236 loss=0.798, nll_loss=0.798, ppl=1.74, wps=2278.5, ups=1.74, wpb=1306.1, bsz=89.5, num_updates=153800, lr=0.000509978, gnorm=0.605, train_wall=57, gb_free=17.6, wall=0
2024-02-06 22:13:13 | INFO | train_inner | epoch 048:   1808 / 3236 loss=0.787, nll_loss=0.787, ppl=1.73, wps=2266.2, ups=1.75, wpb=1296.5, bsz=84.9, num_updates=153900, lr=0.000509813, gnorm=0.629, train_wall=57, gb_free=17.5, wall=0
2024-02-06 22:14:11 | INFO | train_inner | epoch 048:   1908 / 3236 loss=0.797, nll_loss=0.797, ppl=1.74, wps=2285.6, ups=1.75, wpb=1308.3, bsz=92.3, num_updates=154000, lr=0.000509647, gnorm=0.619, train_wall=57, gb_free=18, wall=0
2024-02-06 22:15:07 | INFO | train_inner | epoch 048:   2008 / 3236 loss=0.787, nll_loss=0.787, ppl=1.73, wps=2287.9, ups=1.76, wpb=1298.2, bsz=88.2, num_updates=154100, lr=0.000509482, gnorm=0.619, train_wall=56, gb_free=17.8, wall=0
2024-02-06 22:16:04 | INFO | train_inner | epoch 048:   2108 / 3236 loss=0.779, nll_loss=0.779, ppl=1.72, wps=2319.6, ups=1.78, wpb=1304.9, bsz=89.6, num_updates=154200, lr=0.000509317, gnorm=0.609, train_wall=56, gb_free=18.2, wall=0
2024-02-06 22:17:00 | INFO | train_inner | epoch 048:   2208 / 3236 loss=0.779, nll_loss=0.779, ppl=1.72, wps=2286, ups=1.77, wpb=1289.8, bsz=86.1, num_updates=154300, lr=0.000509152, gnorm=0.616, train_wall=56, gb_free=17.3, wall=0
2024-02-06 22:17:56 | INFO | train_inner | epoch 048:   2308 / 3236 loss=0.806, nll_loss=0.806, ppl=1.75, wps=2345.5, ups=1.77, wpb=1325.7, bsz=92.8, num_updates=154400, lr=0.000508987, gnorm=0.63, train_wall=56, gb_free=17.6, wall=0
2024-02-06 22:18:53 | INFO | train_inner | epoch 048:   2408 / 3236 loss=0.802, nll_loss=0.802, ppl=1.74, wps=2322.8, ups=1.78, wpb=1307.1, bsz=89, num_updates=154500, lr=0.000508822, gnorm=0.623, train_wall=56, gb_free=18.5, wall=0
2024-02-06 22:19:49 | INFO | train_inner | epoch 048:   2508 / 3236 loss=0.807, nll_loss=0.807, ppl=1.75, wps=2324.1, ups=1.78, wpb=1306.2, bsz=93.7, num_updates=154600, lr=0.000508657, gnorm=0.621, train_wall=56, gb_free=18.2, wall=0
2024-02-06 22:20:45 | INFO | train_inner | epoch 048:   2608 / 3236 loss=0.811, nll_loss=0.811, ppl=1.75, wps=2313.9, ups=1.78, wpb=1303.5, bsz=92.5, num_updates=154700, lr=0.000508493, gnorm=0.621, train_wall=56, gb_free=17.4, wall=0
2024-02-06 22:21:42 | INFO | train_inner | epoch 048:   2708 / 3236 loss=0.804, nll_loss=0.804, ppl=1.75, wps=2327.4, ups=1.78, wpb=1308.2, bsz=91.4, num_updates=154800, lr=0.000508329, gnorm=0.615, train_wall=56, gb_free=17.7, wall=0
2024-02-06 22:22:38 | INFO | train_inner | epoch 048:   2808 / 3236 loss=0.815, nll_loss=0.815, ppl=1.76, wps=2282.8, ups=1.78, wpb=1282.9, bsz=87.4, num_updates=154900, lr=0.000508164, gnorm=0.655, train_wall=56, gb_free=18.7, wall=0
2024-02-06 22:23:34 | INFO | train_inner | epoch 048:   2908 / 3236 loss=0.797, nll_loss=0.797, ppl=1.74, wps=2292.4, ups=1.77, wpb=1294.1, bsz=89.8, num_updates=155000, lr=0.000508001, gnorm=0.615, train_wall=56, gb_free=18, wall=0
2024-02-06 22:24:30 | INFO | train_inner | epoch 048:   3008 / 3236 loss=0.797, nll_loss=0.797, ppl=1.74, wps=2313.8, ups=1.78, wpb=1298, bsz=89.3, num_updates=155100, lr=0.000507837, gnorm=0.621, train_wall=56, gb_free=17.5, wall=0
2024-02-06 22:25:27 | INFO | train_inner | epoch 048:   3108 / 3236 loss=0.796, nll_loss=0.796, ppl=1.74, wps=2284.8, ups=1.77, wpb=1289.2, bsz=85.7, num_updates=155200, lr=0.000507673, gnorm=0.618, train_wall=56, gb_free=18.5, wall=0
2024-02-06 22:26:23 | INFO | train_inner | epoch 048:   3208 / 3236 loss=0.797, nll_loss=0.797, ppl=1.74, wps=2340, ups=1.78, wpb=1313.7, bsz=89.3, num_updates=155300, lr=0.00050751, gnorm=0.613, train_wall=56, gb_free=18.2, wall=0
2024-02-06 22:26:39 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 22:26:39 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 22:27:29 | INFO | dev | epoch 048 | valid on 'dev' subset | loss 1.128 | nll_loss 1.128 | ppl 2.19 | wps 4629.1 | wpb 1146.2 | bsz 77.6 | num_updates 155328 | best_loss 1.094
2024-02-06 22:27:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 48 @ 155328 updates
2024-02-06 22:27:29 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint48.pt
2024-02-06 22:27:31 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint48.pt
2024-02-06 22:27:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint48.pt (epoch 48 @ 155328 updates, score 1.128) (writing took 3.382454962003976 seconds)
2024-02-06 22:27:32 | INFO | fairseq_cli.train | end of epoch 48 (average epoch stats below)
2024-02-06 22:27:32 | INFO | train | epoch 048 | loss 0.789 | nll_loss 0.789 | ppl 1.73 | wps 2219.6 | ups 1.7 | wpb 1302.4 | bsz 89.4 | num_updates 155328 | lr 0.000507464 | gnorm 0.621 | train_wall 1826 | gb_free 17 | wall 0
2024-02-06 22:27:32 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 22:27:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 22:27:32 | INFO | fairseq.trainer | begin training epoch 49
2024-02-06 22:27:32 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 22:28:13 | INFO | train_inner | epoch 049:     72 / 3236 loss=0.768, nll_loss=0.768, ppl=1.7, wps=1174.6, ups=0.9, wpb=1299.8, bsz=87.2, num_updates=155400, lr=0.000507346, gnorm=0.619, train_wall=56, gb_free=18, wall=0
2024-02-06 22:29:09 | INFO | train_inner | epoch 049:    172 / 3236 loss=0.761, nll_loss=0.761, ppl=1.69, wps=2321.4, ups=1.79, wpb=1295.7, bsz=88.7, num_updates=155500, lr=0.000507183, gnorm=0.609, train_wall=55, gb_free=18.1, wall=0
2024-02-06 22:30:05 | INFO | train_inner | epoch 049:    272 / 3236 loss=0.754, nll_loss=0.754, ppl=1.69, wps=2358.3, ups=1.79, wpb=1320.2, bsz=93.9, num_updates=155600, lr=0.00050702, gnorm=0.596, train_wall=55, gb_free=18.3, wall=0
2024-02-06 22:31:01 | INFO | train_inner | epoch 049:    372 / 3236 loss=0.75, nll_loss=0.75, ppl=1.68, wps=2297.8, ups=1.79, wpb=1282.2, bsz=86.5, num_updates=155700, lr=0.000506857, gnorm=0.639, train_wall=55, gb_free=18.5, wall=0
2024-02-06 22:31:57 | INFO | train_inner | epoch 049:    472 / 3236 loss=0.762, nll_loss=0.762, ppl=1.7, wps=2324.4, ups=1.78, wpb=1304.1, bsz=87, num_updates=155800, lr=0.000506695, gnorm=0.608, train_wall=56, gb_free=17.6, wall=0
2024-02-06 22:32:53 | INFO | train_inner | epoch 049:    572 / 3236 loss=0.767, nll_loss=0.767, ppl=1.7, wps=2358.3, ups=1.79, wpb=1315.8, bsz=94.6, num_updates=155900, lr=0.000506532, gnorm=0.603, train_wall=55, gb_free=17.4, wall=0
2024-02-06 22:33:49 | INFO | train_inner | epoch 049:    672 / 3236 loss=0.745, nll_loss=0.745, ppl=1.68, wps=2289.7, ups=1.79, wpb=1280.8, bsz=87.2, num_updates=156000, lr=0.00050637, gnorm=0.622, train_wall=55, gb_free=17.6, wall=0
2024-02-06 22:34:45 | INFO | train_inner | epoch 049:    772 / 3236 loss=0.782, nll_loss=0.782, ppl=1.72, wps=2297.7, ups=1.78, wpb=1289.1, bsz=87.7, num_updates=156100, lr=0.000506207, gnorm=0.631, train_wall=56, gb_free=18.4, wall=0
2024-02-06 22:35:41 | INFO | train_inner | epoch 049:    872 / 3236 loss=0.787, nll_loss=0.787, ppl=1.73, wps=2299.7, ups=1.78, wpb=1293.4, bsz=90.4, num_updates=156200, lr=0.000506045, gnorm=0.639, train_wall=56, gb_free=18.3, wall=0
2024-02-06 22:36:37 | INFO | train_inner | epoch 049:    972 / 3236 loss=0.783, nll_loss=0.783, ppl=1.72, wps=2309.3, ups=1.79, wpb=1293.3, bsz=86.4, num_updates=156300, lr=0.000505883, gnorm=0.627, train_wall=55, gb_free=17.9, wall=0
2024-02-06 22:37:33 | INFO | train_inner | epoch 049:   1072 / 3236 loss=0.766, nll_loss=0.766, ppl=1.7, wps=2289.2, ups=1.78, wpb=1286.2, bsz=86.2, num_updates=156400, lr=0.000505722, gnorm=0.628, train_wall=56, gb_free=17.7, wall=0
2024-02-06 22:38:29 | INFO | train_inner | epoch 049:   1172 / 3236 loss=0.78, nll_loss=0.78, ppl=1.72, wps=2296.9, ups=1.79, wpb=1286.3, bsz=92.2, num_updates=156500, lr=0.00050556, gnorm=0.624, train_wall=56, gb_free=17, wall=0
2024-02-06 22:39:25 | INFO | train_inner | epoch 049:   1272 / 3236 loss=0.777, nll_loss=0.777, ppl=1.71, wps=2336, ups=1.79, wpb=1308, bsz=93.1, num_updates=156600, lr=0.000505399, gnorm=0.636, train_wall=55, gb_free=17.5, wall=0
2024-02-06 22:40:21 | INFO | train_inner | epoch 049:   1372 / 3236 loss=0.787, nll_loss=0.787, ppl=1.73, wps=2331.4, ups=1.79, wpb=1301.1, bsz=89.3, num_updates=156700, lr=0.000505237, gnorm=0.631, train_wall=55, gb_free=18.3, wall=0
2024-02-06 22:41:17 | INFO | train_inner | epoch 049:   1472 / 3236 loss=0.774, nll_loss=0.774, ppl=1.71, wps=2318.3, ups=1.79, wpb=1298.7, bsz=87.7, num_updates=156800, lr=0.000505076, gnorm=0.625, train_wall=56, gb_free=18.3, wall=0
2024-02-06 22:42:13 | INFO | train_inner | epoch 049:   1572 / 3236 loss=0.805, nll_loss=0.805, ppl=1.75, wps=2360.3, ups=1.78, wpb=1322.7, bsz=95, num_updates=156900, lr=0.000504915, gnorm=0.624, train_wall=56, gb_free=17.8, wall=0
2024-02-06 22:43:09 | INFO | train_inner | epoch 049:   1672 / 3236 loss=0.79, nll_loss=0.79, ppl=1.73, wps=2299.7, ups=1.78, wpb=1292.1, bsz=83, num_updates=157000, lr=0.000504754, gnorm=0.646, train_wall=56, gb_free=18.4, wall=0
2024-02-06 22:44:05 | INFO | train_inner | epoch 049:   1772 / 3236 loss=0.78, nll_loss=0.78, ppl=1.72, wps=2323.7, ups=1.79, wpb=1298.2, bsz=87.4, num_updates=157100, lr=0.000504594, gnorm=0.628, train_wall=55, gb_free=18.3, wall=0
2024-02-06 22:45:01 | INFO | train_inner | epoch 049:   1872 / 3236 loss=0.8, nll_loss=0.8, ppl=1.74, wps=2360, ups=1.79, wpb=1321.3, bsz=88.4, num_updates=157200, lr=0.000504433, gnorm=0.62, train_wall=55, gb_free=18.4, wall=0
2024-02-06 22:45:57 | INFO | train_inner | epoch 049:   1972 / 3236 loss=0.782, nll_loss=0.782, ppl=1.72, wps=2352.5, ups=1.79, wpb=1315.6, bsz=95.6, num_updates=157300, lr=0.000504273, gnorm=0.61, train_wall=55, gb_free=17.8, wall=0
2024-02-06 22:46:53 | INFO | train_inner | epoch 049:   2072 / 3236 loss=0.794, nll_loss=0.794, ppl=1.73, wps=2324.7, ups=1.78, wpb=1304.2, bsz=91.5, num_updates=157400, lr=0.000504113, gnorm=0.628, train_wall=56, gb_free=17.6, wall=0
2024-02-06 22:47:49 | INFO | train_inner | epoch 049:   2172 / 3236 loss=0.781, nll_loss=0.781, ppl=1.72, wps=2285.6, ups=1.78, wpb=1281.8, bsz=84.1, num_updates=157500, lr=0.000503953, gnorm=0.641, train_wall=56, gb_free=17.8, wall=0
2024-02-06 22:48:46 | INFO | train_inner | epoch 049:   2272 / 3236 loss=0.78, nll_loss=0.78, ppl=1.72, wps=2324, ups=1.78, wpb=1305.3, bsz=89.1, num_updates=157600, lr=0.000503793, gnorm=0.618, train_wall=56, gb_free=18.7, wall=0
2024-02-06 22:49:42 | INFO | train_inner | epoch 049:   2372 / 3236 loss=0.791, nll_loss=0.791, ppl=1.73, wps=2301.9, ups=1.78, wpb=1295.2, bsz=85.8, num_updates=157700, lr=0.000503633, gnorm=0.62, train_wall=56, gb_free=17.7, wall=0
2024-02-06 22:50:38 | INFO | train_inner | epoch 049:   2472 / 3236 loss=0.806, nll_loss=0.806, ppl=1.75, wps=2314.9, ups=1.78, wpb=1302.2, bsz=89.9, num_updates=157800, lr=0.000503473, gnorm=0.644, train_wall=56, gb_free=18.4, wall=0
2024-02-06 22:51:35 | INFO | train_inner | epoch 049:   2572 / 3236 loss=0.811, nll_loss=0.811, ppl=1.75, wps=2336.4, ups=1.77, wpb=1319.3, bsz=89.9, num_updates=157900, lr=0.000503314, gnorm=0.623, train_wall=56, gb_free=18.4, wall=0
2024-02-06 22:52:31 | INFO | train_inner | epoch 049:   2672 / 3236 loss=0.78, nll_loss=0.78, ppl=1.72, wps=2314.7, ups=1.78, wpb=1301.4, bsz=85.3, num_updates=158000, lr=0.000503155, gnorm=0.628, train_wall=56, gb_free=18.5, wall=0
2024-02-06 22:53:27 | INFO | train_inner | epoch 049:   2772 / 3236 loss=0.797, nll_loss=0.797, ppl=1.74, wps=2319.7, ups=1.78, wpb=1300.1, bsz=88.6, num_updates=158100, lr=0.000502995, gnorm=0.627, train_wall=56, gb_free=17.4, wall=0
2024-02-06 22:54:23 | INFO | train_inner | epoch 049:   2872 / 3236 loss=0.798, nll_loss=0.798, ppl=1.74, wps=2362.6, ups=1.79, wpb=1320.9, bsz=94.2, num_updates=158200, lr=0.000502836, gnorm=0.605, train_wall=55, gb_free=17.6, wall=0
2024-02-06 22:55:19 | INFO | train_inner | epoch 049:   2972 / 3236 loss=0.799, nll_loss=0.799, ppl=1.74, wps=2355.1, ups=1.78, wpb=1322.9, bsz=93.3, num_updates=158300, lr=0.000502678, gnorm=0.617, train_wall=56, gb_free=18.4, wall=0
2024-02-06 22:56:15 | INFO | train_inner | epoch 049:   3072 / 3236 loss=0.787, nll_loss=0.787, ppl=1.73, wps=2335.2, ups=1.78, wpb=1315, bsz=90.2, num_updates=158400, lr=0.000502519, gnorm=0.612, train_wall=56, gb_free=17.9, wall=0
2024-02-06 22:57:12 | INFO | train_inner | epoch 049:   3172 / 3236 loss=0.775, nll_loss=0.775, ppl=1.71, wps=2319.5, ups=1.78, wpb=1304.7, bsz=89.7, num_updates=158500, lr=0.00050236, gnorm=0.615, train_wall=56, gb_free=18.7, wall=0
2024-02-06 22:57:47 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 22:57:47 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 22:58:21 | INFO | dev | epoch 049 | valid on 'dev' subset | loss 1.113 | nll_loss 1.113 | ppl 2.16 | wps 6933.3 | wpb 1146.2 | bsz 77.6 | num_updates 158564 | best_loss 1.094
2024-02-06 22:58:21 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 49 @ 158564 updates
2024-02-06 22:58:21 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint49.pt
2024-02-06 22:58:22 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint49.pt
2024-02-06 22:58:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint49.pt (epoch 49 @ 158564 updates, score 1.113) (writing took 2.9086994789540768 seconds)
2024-02-06 22:58:24 | INFO | fairseq_cli.train | end of epoch 49 (average epoch stats below)
2024-02-06 22:58:24 | INFO | train | epoch 049 | loss 0.782 | nll_loss 0.782 | ppl 1.72 | wps 2276.3 | ups 1.75 | wpb 1302.4 | bsz 89.4 | num_updates 158564 | lr 0.000502259 | gnorm 0.623 | train_wall 1798 | gb_free 17.5 | wall 0
2024-02-06 22:58:24 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 22:58:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 22:58:24 | INFO | fairseq.trainer | begin training epoch 50
2024-02-06 22:58:24 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 22:58:45 | INFO | train_inner | epoch 050:     36 / 3236 loss=0.778, nll_loss=0.778, ppl=1.71, wps=1386.1, ups=1.07, wpb=1295.4, bsz=89.8, num_updates=158600, lr=0.000502202, gnorm=0.617, train_wall=55, gb_free=17.8, wall=0
2024-02-06 22:59:41 | INFO | train_inner | epoch 050:    136 / 3236 loss=0.756, nll_loss=0.756, ppl=1.69, wps=2350, ups=1.79, wpb=1313.4, bsz=87.6, num_updates=158700, lr=0.000502044, gnorm=0.617, train_wall=55, gb_free=17.2, wall=0
2024-02-06 23:00:37 | INFO | train_inner | epoch 050:    236 / 3236 loss=0.761, nll_loss=0.761, ppl=1.69, wps=2339, ups=1.79, wpb=1310.1, bsz=88, num_updates=158800, lr=0.000501886, gnorm=0.627, train_wall=56, gb_free=17.3, wall=0
2024-02-06 23:01:33 | INFO | train_inner | epoch 050:    336 / 3236 loss=0.753, nll_loss=0.753, ppl=1.68, wps=2255.6, ups=1.78, wpb=1267.2, bsz=83.4, num_updates=158900, lr=0.000501728, gnorm=0.629, train_wall=56, gb_free=18.4, wall=0
2024-02-06 23:02:29 | INFO | train_inner | epoch 050:    436 / 3236 loss=0.775, nll_loss=0.775, ppl=1.71, wps=2317.1, ups=1.79, wpb=1295.1, bsz=93.6, num_updates=159000, lr=0.00050157, gnorm=0.634, train_wall=55, gb_free=17.9, wall=0
2024-02-06 23:03:25 | INFO | train_inner | epoch 050:    536 / 3236 loss=0.746, nll_loss=0.746, ppl=1.68, wps=2312.5, ups=1.8, wpb=1287.3, bsz=89.2, num_updates=159100, lr=0.000501412, gnorm=0.612, train_wall=55, gb_free=17.9, wall=0
2024-02-06 23:04:21 | INFO | train_inner | epoch 050:    636 / 3236 loss=0.756, nll_loss=0.756, ppl=1.69, wps=2329.1, ups=1.78, wpb=1304.9, bsz=90.1, num_updates=159200, lr=0.000501255, gnorm=0.622, train_wall=55, gb_free=18.1, wall=0
2024-02-06 23:05:17 | INFO | train_inner | epoch 050:    736 / 3236 loss=0.785, nll_loss=0.785, ppl=1.72, wps=2334.1, ups=1.77, wpb=1319.3, bsz=93.7, num_updates=159300, lr=0.000501097, gnorm=0.607, train_wall=56, gb_free=17.7, wall=0
2024-02-06 23:06:20 | INFO | train_inner | epoch 050:    836 / 3236 loss=0.765, nll_loss=0.765, ppl=1.7, wps=2075, ups=1.59, wpb=1301.7, bsz=88.8, num_updates=159400, lr=0.00050094, gnorm=0.624, train_wall=62, gb_free=17.9, wall=0
2024-02-06 23:07:17 | INFO | train_inner | epoch 050:    936 / 3236 loss=0.793, nll_loss=0.793, ppl=1.73, wps=2340.7, ups=1.76, wpb=1328.6, bsz=94.3, num_updates=159500, lr=0.000500783, gnorm=0.621, train_wall=56, gb_free=17.5, wall=0
2024-02-06 23:08:13 | INFO | train_inner | epoch 050:   1036 / 3236 loss=0.771, nll_loss=0.771, ppl=1.71, wps=2326.5, ups=1.78, wpb=1308.1, bsz=88.6, num_updates=159600, lr=0.000500626, gnorm=0.627, train_wall=56, gb_free=17.5, wall=0
2024-02-06 23:09:09 | INFO | train_inner | epoch 050:   1136 / 3236 loss=0.783, nll_loss=0.783, ppl=1.72, wps=2364.8, ups=1.78, wpb=1325.2, bsz=89, num_updates=159700, lr=0.000500469, gnorm=0.607, train_wall=56, gb_free=18.3, wall=0
2024-02-06 23:10:05 | INFO | train_inner | epoch 050:   1236 / 3236 loss=0.768, nll_loss=0.768, ppl=1.7, wps=2294.2, ups=1.78, wpb=1286.2, bsz=88.9, num_updates=159800, lr=0.000500313, gnorm=0.64, train_wall=56, gb_free=18.4, wall=0
2024-02-06 23:11:01 | INFO | train_inner | epoch 050:   1336 / 3236 loss=0.799, nll_loss=0.799, ppl=1.74, wps=2356.7, ups=1.79, wpb=1319.9, bsz=85, num_updates=159900, lr=0.000500156, gnorm=0.636, train_wall=56, gb_free=18, wall=0
2024-02-06 23:11:57 | INFO | train_inner | epoch 050:   1436 / 3236 loss=0.775, nll_loss=0.775, ppl=1.71, wps=2317.2, ups=1.79, wpb=1295.9, bsz=90.8, num_updates=160000, lr=0.0005, gnorm=0.622, train_wall=55, gb_free=18.4, wall=0
2024-02-06 23:12:53 | INFO | train_inner | epoch 050:   1536 / 3236 loss=0.776, nll_loss=0.776, ppl=1.71, wps=2338.1, ups=1.78, wpb=1310.9, bsz=93.5, num_updates=160100, lr=0.000499844, gnorm=0.625, train_wall=56, gb_free=17.5, wall=0
2024-02-06 23:13:49 | INFO | train_inner | epoch 050:   1636 / 3236 loss=0.787, nll_loss=0.787, ppl=1.73, wps=2337.5, ups=1.78, wpb=1311.2, bsz=90.9, num_updates=160200, lr=0.000499688, gnorm=0.619, train_wall=56, gb_free=18.3, wall=0
2024-02-06 23:14:45 | INFO | train_inner | epoch 050:   1736 / 3236 loss=0.787, nll_loss=0.787, ppl=1.72, wps=2321.4, ups=1.79, wpb=1295.4, bsz=89.3, num_updates=160300, lr=0.000499532, gnorm=0.621, train_wall=55, gb_free=18.6, wall=0
2024-02-06 23:15:41 | INFO | train_inner | epoch 050:   1836 / 3236 loss=0.784, nll_loss=0.784, ppl=1.72, wps=2316.3, ups=1.78, wpb=1298.4, bsz=89.9, num_updates=160400, lr=0.000499376, gnorm=0.635, train_wall=56, gb_free=18.4, wall=0
2024-02-06 23:16:37 | INFO | train_inner | epoch 050:   1936 / 3236 loss=0.768, nll_loss=0.768, ppl=1.7, wps=2337.5, ups=1.79, wpb=1308.8, bsz=91.1, num_updates=160500, lr=0.000499221, gnorm=0.61, train_wall=55, gb_free=17.8, wall=0
2024-02-06 23:17:33 | INFO | train_inner | epoch 050:   2036 / 3236 loss=0.768, nll_loss=0.768, ppl=1.7, wps=2338.5, ups=1.79, wpb=1307.3, bsz=89.8, num_updates=160600, lr=0.000499065, gnorm=0.614, train_wall=55, gb_free=17.5, wall=0
2024-02-06 23:18:29 | INFO | train_inner | epoch 050:   2136 / 3236 loss=0.776, nll_loss=0.776, ppl=1.71, wps=2310.9, ups=1.78, wpb=1295, bsz=88.2, num_updates=160700, lr=0.00049891, gnorm=0.618, train_wall=56, gb_free=18, wall=0
2024-02-06 23:19:25 | INFO | train_inner | epoch 050:   2236 / 3236 loss=0.789, nll_loss=0.789, ppl=1.73, wps=2299.5, ups=1.79, wpb=1285, bsz=89.1, num_updates=160800, lr=0.000498755, gnorm=0.649, train_wall=55, gb_free=17.8, wall=0
2024-02-06 23:20:21 | INFO | train_inner | epoch 050:   2336 / 3236 loss=0.79, nll_loss=0.79, ppl=1.73, wps=2333.2, ups=1.78, wpb=1313.1, bsz=88.3, num_updates=160900, lr=0.0004986, gnorm=0.631, train_wall=56, gb_free=17.6, wall=0
2024-02-06 23:21:17 | INFO | train_inner | epoch 050:   2436 / 3236 loss=0.796, nll_loss=0.796, ppl=1.74, wps=2308.8, ups=1.78, wpb=1297.6, bsz=89.1, num_updates=161000, lr=0.000498445, gnorm=0.635, train_wall=56, gb_free=18.2, wall=0
2024-02-06 23:22:14 | INFO | train_inner | epoch 050:   2536 / 3236 loss=0.764, nll_loss=0.764, ppl=1.7, wps=2319.3, ups=1.78, wpb=1305, bsz=88.3, num_updates=161100, lr=0.00049829, gnorm=0.619, train_wall=56, gb_free=18, wall=0
2024-02-06 23:23:09 | INFO | train_inner | epoch 050:   2636 / 3236 loss=0.783, nll_loss=0.783, ppl=1.72, wps=2341.4, ups=1.8, wpb=1304.1, bsz=89.5, num_updates=161200, lr=0.000498135, gnorm=0.617, train_wall=55, gb_free=27.9, wall=0
2024-02-06 23:24:06 | INFO | train_inner | epoch 050:   2736 / 3236 loss=0.756, nll_loss=0.756, ppl=1.69, wps=2280.6, ups=1.77, wpb=1288.2, bsz=85.8, num_updates=161300, lr=0.000497981, gnorm=0.622, train_wall=56, gb_free=18.1, wall=0
2024-02-06 23:25:02 | INFO | train_inner | epoch 050:   2836 / 3236 loss=0.797, nll_loss=0.797, ppl=1.74, wps=2297.5, ups=1.77, wpb=1296.8, bsz=88.2, num_updates=161400, lr=0.000497827, gnorm=0.635, train_wall=56, gb_free=17.3, wall=0
2024-02-06 23:25:58 | INFO | train_inner | epoch 050:   2936 / 3236 loss=0.791, nll_loss=0.791, ppl=1.73, wps=2284.5, ups=1.78, wpb=1280.3, bsz=87.5, num_updates=161500, lr=0.000497673, gnorm=0.632, train_wall=56, gb_free=17.9, wall=0
2024-02-06 23:26:54 | INFO | train_inner | epoch 050:   3036 / 3236 loss=0.784, nll_loss=0.784, ppl=1.72, wps=2356.4, ups=1.78, wpb=1322.6, bsz=89.8, num_updates=161600, lr=0.000497519, gnorm=0.612, train_wall=56, gb_free=17.9, wall=0
2024-02-06 23:27:50 | INFO | train_inner | epoch 050:   3136 / 3236 loss=0.777, nll_loss=0.777, ppl=1.71, wps=2284.2, ups=1.78, wpb=1282, bsz=87, num_updates=161700, lr=0.000497365, gnorm=0.628, train_wall=56, gb_free=16.7, wall=0
2024-02-06 23:28:46 | INFO | train_inner | epoch 050:   3236 / 3236 loss=0.809, nll_loss=0.809, ppl=1.75, wps=2353.5, ups=1.79, wpb=1311.2, bsz=95.3, num_updates=161800, lr=0.000497211, gnorm=0.627, train_wall=55, gb_free=17.7, wall=0
2024-02-06 23:28:46 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 23:28:46 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 23:29:20 | INFO | dev | epoch 050 | valid on 'dev' subset | loss 1.143 | nll_loss 1.143 | ppl 2.21 | wps 6927.5 | wpb 1146.2 | bsz 77.6 | num_updates 161800 | best_loss 1.094
2024-02-06 23:29:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 50 @ 161800 updates
2024-02-06 23:29:20 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint50.pt
2024-02-06 23:29:22 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint50.pt
2024-02-06 23:29:23 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint50.pt (epoch 50 @ 161800 updates, score 1.143) (writing took 3.2030596900731325 seconds)
2024-02-06 23:29:23 | INFO | fairseq_cli.train | end of epoch 50 (average epoch stats below)
2024-02-06 23:29:23 | INFO | train | epoch 050 | loss 0.777 | nll_loss 0.777 | ppl 1.71 | wps 2266.5 | ups 1.74 | wpb 1302.4 | bsz 89.4 | num_updates 161800 | lr 0.000497211 | gnorm 0.624 | train_wall 1805 | gb_free 17.7 | wall 0
2024-02-06 23:29:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-06 23:29:23 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-06 23:29:23 | INFO | fairseq.trainer | begin training epoch 51
2024-02-06 23:29:23 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-06 23:30:19 | INFO | train_inner | epoch 051:    100 / 3236 loss=0.753, nll_loss=0.753, ppl=1.69, wps=1407.2, ups=1.08, wpb=1309, bsz=91.4, num_updates=161900, lr=0.000497057, gnorm=0.613, train_wall=55, gb_free=17.9, wall=0
2024-02-06 23:31:15 | INFO | train_inner | epoch 051:    200 / 3236 loss=0.728, nll_loss=0.728, ppl=1.66, wps=2309.3, ups=1.79, wpb=1291.6, bsz=86.6, num_updates=162000, lr=0.000496904, gnorm=0.623, train_wall=55, gb_free=17.5, wall=0
2024-02-06 23:32:11 | INFO | train_inner | epoch 051:    300 / 3236 loss=0.746, nll_loss=0.746, ppl=1.68, wps=2270.3, ups=1.78, wpb=1273.6, bsz=82.6, num_updates=162100, lr=0.000496751, gnorm=0.642, train_wall=56, gb_free=18.1, wall=0
2024-02-06 23:33:06 | INFO | train_inner | epoch 051:    400 / 3236 loss=0.762, nll_loss=0.762, ppl=1.7, wps=2349.9, ups=1.81, wpb=1297.7, bsz=91.8, num_updates=162200, lr=0.000496598, gnorm=0.62, train_wall=55, gb_free=18.2, wall=0
2024-02-06 23:34:02 | INFO | train_inner | epoch 051:    500 / 3236 loss=0.767, nll_loss=0.767, ppl=1.7, wps=2359.1, ups=1.79, wpb=1318.1, bsz=88.9, num_updates=162300, lr=0.000496445, gnorm=0.621, train_wall=55, gb_free=18.3, wall=0
2024-02-06 23:34:58 | INFO | train_inner | epoch 051:    600 / 3236 loss=0.755, nll_loss=0.755, ppl=1.69, wps=2356.1, ups=1.79, wpb=1314.3, bsz=92.7, num_updates=162400, lr=0.000496292, gnorm=0.607, train_wall=55, gb_free=17.8, wall=0
2024-02-06 23:35:54 | INFO | train_inner | epoch 051:    700 / 3236 loss=0.738, nll_loss=0.738, ppl=1.67, wps=2303.6, ups=1.79, wpb=1284, bsz=86.6, num_updates=162500, lr=0.000496139, gnorm=0.623, train_wall=55, gb_free=18.3, wall=0
2024-02-06 23:36:50 | INFO | train_inner | epoch 051:    800 / 3236 loss=0.753, nll_loss=0.753, ppl=1.69, wps=2302.6, ups=1.78, wpb=1293.1, bsz=84.8, num_updates=162600, lr=0.000495986, gnorm=0.617, train_wall=56, gb_free=17.7, wall=0
2024-02-06 23:37:46 | INFO | train_inner | epoch 051:    900 / 3236 loss=0.756, nll_loss=0.756, ppl=1.69, wps=2305.3, ups=1.79, wpb=1285.6, bsz=86.7, num_updates=162700, lr=0.000495834, gnorm=0.642, train_wall=55, gb_free=18.2, wall=0
2024-02-06 23:38:42 | INFO | train_inner | epoch 051:   1000 / 3236 loss=0.76, nll_loss=0.76, ppl=1.69, wps=2315.8, ups=1.78, wpb=1299, bsz=90.5, num_updates=162800, lr=0.000495682, gnorm=0.622, train_wall=56, gb_free=18, wall=0
2024-02-06 23:39:38 | INFO | train_inner | epoch 051:   1100 / 3236 loss=0.763, nll_loss=0.763, ppl=1.7, wps=2320.1, ups=1.79, wpb=1299.6, bsz=88.2, num_updates=162900, lr=0.000495529, gnorm=0.621, train_wall=56, gb_free=18.1, wall=0
2024-02-06 23:40:34 | INFO | train_inner | epoch 051:   1200 / 3236 loss=0.779, nll_loss=0.779, ppl=1.72, wps=2335.9, ups=1.79, wpb=1307.1, bsz=88.9, num_updates=163000, lr=0.000495377, gnorm=0.618, train_wall=55, gb_free=17.8, wall=0
2024-02-06 23:41:30 | INFO | train_inner | epoch 051:   1300 / 3236 loss=0.777, nll_loss=0.777, ppl=1.71, wps=2372.2, ups=1.79, wpb=1324.2, bsz=94.3, num_updates=163100, lr=0.000495226, gnorm=0.614, train_wall=55, gb_free=18.2, wall=0
2024-02-06 23:42:26 | INFO | train_inner | epoch 051:   1400 / 3236 loss=0.753, nll_loss=0.753, ppl=1.69, wps=2317.3, ups=1.78, wpb=1298.5, bsz=88, num_updates=163200, lr=0.000495074, gnorm=0.617, train_wall=56, gb_free=17.2, wall=0
2024-02-06 23:43:22 | INFO | train_inner | epoch 051:   1500 / 3236 loss=0.768, nll_loss=0.768, ppl=1.7, wps=2318, ups=1.78, wpb=1302.1, bsz=85.2, num_updates=163300, lr=0.000494922, gnorm=0.632, train_wall=56, gb_free=17.9, wall=0
2024-02-06 23:44:18 | INFO | train_inner | epoch 051:   1600 / 3236 loss=0.774, nll_loss=0.774, ppl=1.71, wps=2324.3, ups=1.79, wpb=1300.1, bsz=88.5, num_updates=163400, lr=0.000494771, gnorm=0.646, train_wall=55, gb_free=17.6, wall=0
2024-02-06 23:45:14 | INFO | train_inner | epoch 051:   1700 / 3236 loss=0.766, nll_loss=0.766, ppl=1.7, wps=2317, ups=1.79, wpb=1295.1, bsz=90.3, num_updates=163500, lr=0.000494619, gnorm=0.629, train_wall=55, gb_free=17.5, wall=0
2024-02-06 23:46:10 | INFO | train_inner | epoch 051:   1800 / 3236 loss=0.777, nll_loss=0.777, ppl=1.71, wps=2308.1, ups=1.79, wpb=1292.4, bsz=87.7, num_updates=163600, lr=0.000494468, gnorm=0.624, train_wall=56, gb_free=18.1, wall=0
2024-02-06 23:47:06 | INFO | train_inner | epoch 051:   1900 / 3236 loss=0.777, nll_loss=0.777, ppl=1.71, wps=2338.7, ups=1.78, wpb=1311.9, bsz=89.8, num_updates=163700, lr=0.000494317, gnorm=0.631, train_wall=56, gb_free=18.2, wall=0
2024-02-06 23:48:02 | INFO | train_inner | epoch 051:   2000 / 3236 loss=0.772, nll_loss=0.772, ppl=1.71, wps=2341.5, ups=1.79, wpb=1305.4, bsz=87, num_updates=163800, lr=0.000494166, gnorm=0.611, train_wall=55, gb_free=17.9, wall=0
2024-02-06 23:48:58 | INFO | train_inner | epoch 051:   2100 / 3236 loss=0.792, nll_loss=0.792, ppl=1.73, wps=2358.1, ups=1.78, wpb=1322.7, bsz=96, num_updates=163900, lr=0.000494015, gnorm=0.616, train_wall=56, gb_free=18, wall=0
2024-02-06 23:49:54 | INFO | train_inner | epoch 051:   2200 / 3236 loss=0.786, nll_loss=0.786, ppl=1.72, wps=2306.6, ups=1.78, wpb=1296.5, bsz=88.2, num_updates=164000, lr=0.000493865, gnorm=0.624, train_wall=56, gb_free=18.1, wall=0
2024-02-06 23:50:50 | INFO | train_inner | epoch 051:   2300 / 3236 loss=0.775, nll_loss=0.775, ppl=1.71, wps=2341.9, ups=1.79, wpb=1310.6, bsz=87.5, num_updates=164100, lr=0.000493714, gnorm=0.632, train_wall=55, gb_free=18.2, wall=0
2024-02-06 23:51:46 | INFO | train_inner | epoch 051:   2400 / 3236 loss=0.756, nll_loss=0.756, ppl=1.69, wps=2368.5, ups=1.78, wpb=1327.9, bsz=92.6, num_updates=164200, lr=0.000493564, gnorm=0.599, train_wall=56, gb_free=18.1, wall=0
2024-02-06 23:52:42 | INFO | train_inner | epoch 051:   2500 / 3236 loss=0.758, nll_loss=0.758, ppl=1.69, wps=2353.7, ups=1.79, wpb=1312.9, bsz=90.9, num_updates=164300, lr=0.000493414, gnorm=0.615, train_wall=55, gb_free=17.8, wall=0
2024-02-06 23:53:38 | INFO | train_inner | epoch 051:   2600 / 3236 loss=0.784, nll_loss=0.784, ppl=1.72, wps=2325.9, ups=1.79, wpb=1300.7, bsz=94, num_updates=164400, lr=0.000493264, gnorm=0.628, train_wall=55, gb_free=17.3, wall=0
2024-02-06 23:54:34 | INFO | train_inner | epoch 051:   2700 / 3236 loss=0.785, nll_loss=0.785, ppl=1.72, wps=2319.7, ups=1.78, wpb=1302, bsz=92.3, num_updates=164500, lr=0.000493114, gnorm=0.627, train_wall=56, gb_free=18.3, wall=0
2024-02-06 23:55:29 | INFO | train_inner | epoch 051:   2800 / 3236 loss=0.772, nll_loss=0.772, ppl=1.71, wps=2307.9, ups=1.79, wpb=1287.7, bsz=86.3, num_updates=164600, lr=0.000492964, gnorm=0.626, train_wall=55, gb_free=18, wall=0
2024-02-06 23:56:26 | INFO | train_inner | epoch 051:   2900 / 3236 loss=0.794, nll_loss=0.794, ppl=1.73, wps=2305.9, ups=1.78, wpb=1295.2, bsz=85, num_updates=164700, lr=0.000492814, gnorm=0.632, train_wall=56, gb_free=17.6, wall=0
2024-02-06 23:57:22 | INFO | train_inner | epoch 051:   3000 / 3236 loss=0.781, nll_loss=0.781, ppl=1.72, wps=2322.5, ups=1.78, wpb=1303.7, bsz=92.9, num_updates=164800, lr=0.000492665, gnorm=0.623, train_wall=56, gb_free=17.7, wall=0
2024-02-06 23:58:18 | INFO | train_inner | epoch 051:   3100 / 3236 loss=0.796, nll_loss=0.796, ppl=1.74, wps=2307.3, ups=1.78, wpb=1293.1, bsz=88.1, num_updates=164900, lr=0.000492515, gnorm=0.639, train_wall=56, gb_free=17.7, wall=0
2024-02-06 23:59:14 | INFO | train_inner | epoch 051:   3200 / 3236 loss=0.792, nll_loss=0.792, ppl=1.73, wps=2348.1, ups=1.78, wpb=1317.3, bsz=92.1, num_updates=165000, lr=0.000492366, gnorm=0.62, train_wall=56, gb_free=17.9, wall=0
2024-02-06 23:59:34 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-06 23:59:34 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-07 00:00:06 | INFO | dev | epoch 051 | valid on 'dev' subset | loss 1.131 | nll_loss 1.131 | ppl 2.19 | wps 7176.9 | wpb 1146.2 | bsz 77.6 | num_updates 165036 | best_loss 1.094
2024-02-07 00:00:06 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 51 @ 165036 updates
2024-02-07 00:00:06 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint51.pt
2024-02-07 00:00:08 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint51.pt
2024-02-07 00:00:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint51.pt (epoch 51 @ 165036 updates, score 1.131) (writing took 2.7035672531928867 seconds)
2024-02-07 00:00:09 | INFO | fairseq_cli.train | end of epoch 51 (average epoch stats below)
2024-02-07 00:00:09 | INFO | train | epoch 051 | loss 0.769 | nll_loss 0.769 | ppl 1.7 | wps 2283 | ups 1.75 | wpb 1302.4 | bsz 89.4 | num_updates 165036 | lr 0.000492312 | gnorm 0.623 | train_wall 1795 | gb_free 18.3 | wall 0
2024-02-07 00:00:09 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-07 00:00:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-07 00:00:09 | INFO | fairseq.trainer | begin training epoch 52
2024-02-07 00:00:09 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-07 00:00:46 | INFO | train_inner | epoch 052:     64 / 3236 loss=0.747, nll_loss=0.747, ppl=1.68, wps=1416.5, ups=1.09, wpb=1298.3, bsz=93, num_updates=165100, lr=0.000492217, gnorm=0.611, train_wall=56, gb_free=17.8, wall=0
2024-02-07 00:01:42 | INFO | train_inner | epoch 052:    164 / 3236 loss=0.728, nll_loss=0.728, ppl=1.66, wps=2315.1, ups=1.78, wpb=1297.1, bsz=86.1, num_updates=165200, lr=0.000492068, gnorm=0.6, train_wall=56, gb_free=17.9, wall=0
2024-02-07 00:02:37 | INFO | train_inner | epoch 052:    264 / 3236 loss=0.738, nll_loss=0.738, ppl=1.67, wps=2336, ups=1.8, wpb=1300.8, bsz=91.3, num_updates=165300, lr=0.000491919, gnorm=0.623, train_wall=55, gb_free=17.7, wall=0
2024-02-07 00:03:33 | INFO | train_inner | epoch 052:    364 / 3236 loss=0.752, nll_loss=0.752, ppl=1.68, wps=2334.2, ups=1.79, wpb=1303.2, bsz=88.1, num_updates=165400, lr=0.00049177, gnorm=0.624, train_wall=55, gb_free=17.7, wall=0
2024-02-07 00:04:29 | INFO | train_inner | epoch 052:    464 / 3236 loss=0.74, nll_loss=0.74, ppl=1.67, wps=2318, ups=1.8, wpb=1286.7, bsz=87, num_updates=165500, lr=0.000491622, gnorm=0.623, train_wall=55, gb_free=18.1, wall=0
2024-02-07 00:05:24 | INFO | train_inner | epoch 052:    564 / 3236 loss=0.764, nll_loss=0.764, ppl=1.7, wps=2339.8, ups=1.8, wpb=1301.3, bsz=89.5, num_updates=165600, lr=0.000491473, gnorm=0.617, train_wall=55, gb_free=18.3, wall=0
2024-02-07 00:06:20 | INFO | train_inner | epoch 052:    664 / 3236 loss=0.746, nll_loss=0.746, ppl=1.68, wps=2322.6, ups=1.79, wpb=1301, bsz=87.7, num_updates=165700, lr=0.000491325, gnorm=0.624, train_wall=56, gb_free=17.4, wall=0
2024-02-07 00:07:16 | INFO | train_inner | epoch 052:    764 / 3236 loss=0.745, nll_loss=0.745, ppl=1.68, wps=2282, ups=1.8, wpb=1265.8, bsz=84.1, num_updates=165800, lr=0.000491177, gnorm=0.634, train_wall=55, gb_free=18.6, wall=0
2024-02-07 00:08:12 | INFO | train_inner | epoch 052:    864 / 3236 loss=0.74, nll_loss=0.74, ppl=1.67, wps=2317.9, ups=1.79, wpb=1295.7, bsz=91.4, num_updates=165900, lr=0.000491029, gnorm=0.623, train_wall=55, gb_free=18.1, wall=0
2024-02-07 00:09:07 | INFO | train_inner | epoch 052:    964 / 3236 loss=0.757, nll_loss=0.757, ppl=1.69, wps=2389.9, ups=1.79, wpb=1331.7, bsz=99, num_updates=166000, lr=0.000490881, gnorm=0.602, train_wall=55, gb_free=17.8, wall=0
2024-02-07 00:10:04 | INFO | train_inner | epoch 052:   1064 / 3236 loss=0.756, nll_loss=0.756, ppl=1.69, wps=2308.3, ups=1.77, wpb=1303.2, bsz=85.4, num_updates=166100, lr=0.000490733, gnorm=0.632, train_wall=56, gb_free=17.8, wall=0
2024-02-07 00:11:00 | INFO | train_inner | epoch 052:   1164 / 3236 loss=0.765, nll_loss=0.765, ppl=1.7, wps=2368.3, ups=1.79, wpb=1324, bsz=98.3, num_updates=166200, lr=0.000490585, gnorm=0.617, train_wall=55, gb_free=18.1, wall=0
2024-02-07 00:12:01 | INFO | train_inner | epoch 052:   1264 / 3236 loss=0.763, nll_loss=0.763, ppl=1.7, wps=2119.3, ups=1.63, wpb=1299.1, bsz=92.6, num_updates=166300, lr=0.000490438, gnorm=0.631, train_wall=61, gb_free=17.6, wall=0
2024-02-07 00:12:57 | INFO | train_inner | epoch 052:   1364 / 3236 loss=0.758, nll_loss=0.758, ppl=1.69, wps=2336, ups=1.77, wpb=1318.3, bsz=92.4, num_updates=166400, lr=0.00049029, gnorm=0.606, train_wall=56, gb_free=17.5, wall=0
2024-02-07 00:13:54 | INFO | train_inner | epoch 052:   1464 / 3236 loss=0.77, nll_loss=0.77, ppl=1.71, wps=2336.1, ups=1.78, wpb=1310.9, bsz=89.5, num_updates=166500, lr=0.000490143, gnorm=0.629, train_wall=56, gb_free=17.6, wall=0
2024-02-07 00:14:49 | INFO | train_inner | epoch 052:   1564 / 3236 loss=0.753, nll_loss=0.753, ppl=1.68, wps=2307.3, ups=1.79, wpb=1289, bsz=84.6, num_updates=166600, lr=0.000489996, gnorm=0.626, train_wall=55, gb_free=18.1, wall=0
2024-02-07 00:15:46 | INFO | train_inner | epoch 052:   1664 / 3236 loss=0.75, nll_loss=0.75, ppl=1.68, wps=2288.1, ups=1.78, wpb=1284.7, bsz=84.6, num_updates=166700, lr=0.000489849, gnorm=0.629, train_wall=56, gb_free=17.5, wall=0
2024-02-07 00:16:41 | INFO | train_inner | epoch 052:   1764 / 3236 loss=0.796, nll_loss=0.796, ppl=1.74, wps=2328.2, ups=1.79, wpb=1298.1, bsz=92.5, num_updates=166800, lr=0.000489702, gnorm=0.647, train_wall=55, gb_free=17.4, wall=0
2024-02-07 00:17:38 | INFO | train_inner | epoch 052:   1864 / 3236 loss=0.774, nll_loss=0.774, ppl=1.71, wps=2320.4, ups=1.77, wpb=1307.9, bsz=90.2, num_updates=166900, lr=0.000489555, gnorm=0.628, train_wall=56, gb_free=17.4, wall=0
2024-02-07 00:18:34 | INFO | train_inner | epoch 052:   1964 / 3236 loss=0.775, nll_loss=0.775, ppl=1.71, wps=2334.9, ups=1.78, wpb=1313.8, bsz=89.4, num_updates=167000, lr=0.000489409, gnorm=0.631, train_wall=56, gb_free=17.8, wall=0
2024-02-07 00:19:30 | INFO | train_inner | epoch 052:   2064 / 3236 loss=0.781, nll_loss=0.781, ppl=1.72, wps=2322.8, ups=1.79, wpb=1299.7, bsz=90.8, num_updates=167100, lr=0.000489262, gnorm=0.636, train_wall=55, gb_free=17.8, wall=0
2024-02-07 00:20:26 | INFO | train_inner | epoch 052:   2164 / 3236 loss=0.788, nll_loss=0.788, ppl=1.73, wps=2376.1, ups=1.79, wpb=1331, bsz=88.9, num_updates=167200, lr=0.000489116, gnorm=0.615, train_wall=56, gb_free=18.3, wall=0
2024-02-07 00:21:22 | INFO | train_inner | epoch 052:   2264 / 3236 loss=0.772, nll_loss=0.772, ppl=1.71, wps=2328.8, ups=1.78, wpb=1306, bsz=87, num_updates=167300, lr=0.00048897, gnorm=0.628, train_wall=56, gb_free=18.2, wall=0
2024-02-07 00:22:18 | INFO | train_inner | epoch 052:   2364 / 3236 loss=0.76, nll_loss=0.76, ppl=1.69, wps=2326.9, ups=1.78, wpb=1305.3, bsz=93.3, num_updates=167400, lr=0.000488824, gnorm=0.622, train_wall=56, gb_free=17.9, wall=0
2024-02-07 00:23:14 | INFO | train_inner | epoch 052:   2464 / 3236 loss=0.787, nll_loss=0.787, ppl=1.73, wps=2325.6, ups=1.79, wpb=1302.2, bsz=91.4, num_updates=167500, lr=0.000488678, gnorm=0.626, train_wall=55, gb_free=18, wall=0
2024-02-07 00:24:10 | INFO | train_inner | epoch 052:   2564 / 3236 loss=0.778, nll_loss=0.778, ppl=1.71, wps=2309.6, ups=1.78, wpb=1296.1, bsz=90.2, num_updates=167600, lr=0.000488532, gnorm=0.629, train_wall=56, gb_free=18.3, wall=0
2024-02-07 00:25:06 | INFO | train_inner | epoch 052:   2664 / 3236 loss=0.788, nll_loss=0.788, ppl=1.73, wps=2328.7, ups=1.78, wpb=1307.1, bsz=89.2, num_updates=167700, lr=0.000488386, gnorm=0.631, train_wall=56, gb_free=17.9, wall=0
2024-02-07 00:26:03 | INFO | train_inner | epoch 052:   2764 / 3236 loss=0.771, nll_loss=0.771, ppl=1.71, wps=2336.7, ups=1.78, wpb=1312.6, bsz=90, num_updates=167800, lr=0.000488241, gnorm=0.619, train_wall=56, gb_free=18.4, wall=0
2024-02-07 00:26:59 | INFO | train_inner | epoch 052:   2864 / 3236 loss=0.789, nll_loss=0.789, ppl=1.73, wps=2344.5, ups=1.78, wpb=1314.4, bsz=92.8, num_updates=167900, lr=0.000488095, gnorm=0.632, train_wall=56, gb_free=17.9, wall=0
2024-02-07 00:27:55 | INFO | train_inner | epoch 052:   2964 / 3236 loss=0.78, nll_loss=0.78, ppl=1.72, wps=2312.6, ups=1.77, wpb=1305.2, bsz=91.4, num_updates=168000, lr=0.00048795, gnorm=0.641, train_wall=56, gb_free=18, wall=0
2024-02-07 00:28:51 | INFO | train_inner | epoch 052:   3064 / 3236 loss=0.791, nll_loss=0.791, ppl=1.73, wps=2340.6, ups=1.79, wpb=1310.2, bsz=92.6, num_updates=168100, lr=0.000487805, gnorm=0.626, train_wall=55, gb_free=17.8, wall=0
2024-02-07 00:29:47 | INFO | train_inner | epoch 052:   3164 / 3236 loss=0.759, nll_loss=0.759, ppl=1.69, wps=2282.1, ups=1.78, wpb=1282.8, bsz=78.5, num_updates=168200, lr=0.00048766, gnorm=0.63, train_wall=56, gb_free=18.1, wall=0
2024-02-07 00:30:28 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-07 00:30:28 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-07 00:31:00 | INFO | dev | epoch 052 | valid on 'dev' subset | loss 1.139 | nll_loss 1.139 | ppl 2.2 | wps 7143 | wpb 1146.2 | bsz 77.6 | num_updates 168272 | best_loss 1.094
2024-02-07 00:31:00 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 52 @ 168272 updates
2024-02-07 00:31:00 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint52.pt
2024-02-07 00:31:02 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint52.pt
2024-02-07 00:31:03 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint52.pt (epoch 52 @ 168272 updates, score 1.139) (writing took 3.0765627450309694 seconds)
2024-02-07 00:31:03 | INFO | fairseq_cli.train | end of epoch 52 (average epoch stats below)
2024-02-07 00:31:03 | INFO | train | epoch 052 | loss 0.764 | nll_loss 0.764 | ppl 1.7 | wps 2272.6 | ups 1.74 | wpb 1302.4 | bsz 89.4 | num_updates 168272 | lr 0.000487556 | gnorm 0.625 | train_wall 1802 | gb_free 18.6 | wall 0
2024-02-07 00:31:03 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-07 00:31:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-07 00:31:04 | INFO | fairseq.trainer | begin training epoch 53
2024-02-07 00:31:04 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-07 00:31:20 | INFO | train_inner | epoch 053:     28 / 3236 loss=0.751, nll_loss=0.751, ppl=1.68, wps=1374.3, ups=1.08, wpb=1271.2, bsz=82.2, num_updates=168300, lr=0.000487515, gnorm=0.638, train_wall=56, gb_free=18.1, wall=0
2024-02-07 00:32:16 | INFO | train_inner | epoch 053:    128 / 3236 loss=0.739, nll_loss=0.739, ppl=1.67, wps=2318.8, ups=1.78, wpb=1302.6, bsz=90.4, num_updates=168400, lr=0.00048737, gnorm=0.64, train_wall=56, gb_free=18.3, wall=0
2024-02-07 00:33:11 | INFO | train_inner | epoch 053:    228 / 3236 loss=0.729, nll_loss=0.729, ppl=1.66, wps=2302, ups=1.8, wpb=1276.1, bsz=86.5, num_updates=168500, lr=0.000487226, gnorm=0.629, train_wall=55, gb_free=17.8, wall=0
2024-02-07 00:34:07 | INFO | train_inner | epoch 053:    328 / 3236 loss=0.733, nll_loss=0.733, ppl=1.66, wps=2364.2, ups=1.79, wpb=1318.4, bsz=91.4, num_updates=168600, lr=0.000487081, gnorm=0.603, train_wall=55, gb_free=18.3, wall=0
2024-02-07 00:35:03 | INFO | train_inner | epoch 053:    428 / 3236 loss=0.749, nll_loss=0.749, ppl=1.68, wps=2364.2, ups=1.8, wpb=1316.5, bsz=94.5, num_updates=168700, lr=0.000486937, gnorm=0.627, train_wall=55, gb_free=16.9, wall=0
2024-02-07 00:35:59 | INFO | train_inner | epoch 053:    528 / 3236 loss=0.754, nll_loss=0.754, ppl=1.69, wps=2324.3, ups=1.78, wpb=1304.3, bsz=88.6, num_updates=168800, lr=0.000486792, gnorm=0.627, train_wall=56, gb_free=18.4, wall=0
2024-02-07 00:36:55 | INFO | train_inner | epoch 053:    628 / 3236 loss=0.746, nll_loss=0.746, ppl=1.68, wps=2335.2, ups=1.79, wpb=1302.7, bsz=88.4, num_updates=168900, lr=0.000486648, gnorm=0.638, train_wall=55, gb_free=18.5, wall=0
2024-02-07 00:37:50 | INFO | train_inner | epoch 053:    728 / 3236 loss=0.749, nll_loss=0.749, ppl=1.68, wps=2330.9, ups=1.79, wpb=1300.7, bsz=89.6, num_updates=169000, lr=0.000486504, gnorm=0.611, train_wall=55, gb_free=18.4, wall=0
2024-02-07 00:38:46 | INFO | train_inner | epoch 053:    828 / 3236 loss=0.755, nll_loss=0.755, ppl=1.69, wps=2339.5, ups=1.79, wpb=1304.7, bsz=88.8, num_updates=169100, lr=0.00048636, gnorm=0.607, train_wall=55, gb_free=17.4, wall=0
2024-02-07 00:39:42 | INFO | train_inner | epoch 053:    928 / 3236 loss=0.749, nll_loss=0.749, ppl=1.68, wps=2303.2, ups=1.78, wpb=1293.3, bsz=88.4, num_updates=169200, lr=0.000486217, gnorm=0.623, train_wall=56, gb_free=18.5, wall=0
2024-02-07 00:40:38 | INFO | train_inner | epoch 053:   1028 / 3236 loss=0.748, nll_loss=0.748, ppl=1.68, wps=2344.2, ups=1.79, wpb=1309.5, bsz=93.6, num_updates=169300, lr=0.000486073, gnorm=0.623, train_wall=55, gb_free=17.9, wall=0
2024-02-07 00:41:34 | INFO | train_inner | epoch 053:   1128 / 3236 loss=0.743, nll_loss=0.743, ppl=1.67, wps=2330.5, ups=1.79, wpb=1302.8, bsz=88.2, num_updates=169400, lr=0.00048593, gnorm=0.621, train_wall=55, gb_free=17.8, wall=0
2024-02-07 00:42:30 | INFO | train_inner | epoch 053:   1228 / 3236 loss=0.754, nll_loss=0.754, ppl=1.69, wps=2340.4, ups=1.79, wpb=1310.7, bsz=89, num_updates=169500, lr=0.000485786, gnorm=0.62, train_wall=55, gb_free=18.5, wall=0
2024-02-07 00:43:26 | INFO | train_inner | epoch 053:   1328 / 3236 loss=0.744, nll_loss=0.744, ppl=1.68, wps=2305.9, ups=1.79, wpb=1290, bsz=86.1, num_updates=169600, lr=0.000485643, gnorm=0.632, train_wall=55, gb_free=17.7, wall=0
2024-02-07 00:44:22 | INFO | train_inner | epoch 053:   1428 / 3236 loss=0.736, nll_loss=0.736, ppl=1.67, wps=2265.5, ups=1.78, wpb=1273.2, bsz=80.8, num_updates=169700, lr=0.0004855, gnorm=0.644, train_wall=56, gb_free=17.9, wall=0
2024-02-07 00:45:18 | INFO | train_inner | epoch 053:   1528 / 3236 loss=0.748, nll_loss=0.748, ppl=1.68, wps=2345.4, ups=1.78, wpb=1315.7, bsz=91.8, num_updates=169800, lr=0.000485357, gnorm=0.631, train_wall=56, gb_free=18.1, wall=0
2024-02-07 00:45:48 | INFO | fairseq_cli.train | Stopping training due to cumulative_training_time: 30.000038341614935 > stop_time_hours: 30.0 hour(s)
2024-02-07 00:45:48 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-07 00:45:48 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-07 00:46:20 | INFO | dev | epoch 053 | valid on 'dev' subset | loss 1.149 | nll_loss 1.149 | ppl 2.22 | wps 7321.7 | wpb 1146.2 | bsz 77.6 | num_updates 169853 | best_loss 1.094
2024-02-07 00:46:20 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 53 @ 169853 updates
2024-02-07 00:46:20 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt
2024-02-07 00:46:21 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt
2024-02-07 00:46:21 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt (epoch 53 @ 169853 updates, score 1.149) (writing took 1.3328545598778874 seconds)
2024-02-07 00:46:21 | INFO | fairseq_cli.train | end of epoch 53 (average epoch stats below)
2024-02-07 00:46:21 | INFO | train | epoch 053 | loss 0.745 | nll_loss 0.745 | ppl 1.68 | wps 2242.4 | ups 1.72 | wpb 1301.5 | bsz 88.9 | num_updates 169853 | lr 0.000485281 | gnorm 0.625 | train_wall 876 | gb_free 18.2 | wall 0
2024-02-07 00:46:21 | INFO | fairseq_cli.train | done training in 43083.6 seconds
Training complete.
Finetuning complete.
----------------------------------------------------------
Transcribing the test set...
Starting transcription...
Average checkpoints...
Checkpoints folder: /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models
Checkpoint path: /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
Namespace(inputs=['/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models'], output='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', num_epoch_checkpoints=5, num_update_checkpoints=None, num_best_checkpoints=0, checkpoint_upper_bound=None)
averaging checkpoints:  ['/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint52.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint51.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint50.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint49.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint48.pt']
Finished writing averaged checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
Checkpoints averaged
Generating transcriptions...
Test subset: test
Data directory: /pfs/work7/workspace/scratch/uxude-ASR/dataset/covost
Prediction output directory: /home/kit/stud/uxude/predictions/finetune_asr_covost
DEBUG:hydra.core.utils:Setting JobRuntime:name=UNKNOWN_NAME
DEBUG:hydra.core.utils:Setting JobRuntime:name=utils
INFO:fairseq_cli.generate:{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 50000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 8, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all'}, 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', simul_type=None, scoring='wer', task='speech_to_text', num_workers=1, skip_invalid_size_inputs_valid_test=True, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, path='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', post_process=None, quiet=False, model_overrides='{}', results_path=None, beam=8, beam_mt=0, nbest=1, max_len_a=0, max_len_b=200, max_len_a_mt=0, max_len_b_mt=200, min_len=1, match_source_len=False, unnormalized=False, no_early_stop=False, no_beamable_mm=False, lenpen=1, lenpen_mt=1, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=None, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, no_seed_provided=False, eos_token=None, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, arch='wav2vec2', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, force_anneal=None, lr_shrink=0.1, warmup_updates=0, wer_tokenizer='none', wer_remove_punct=False, wer_char_level=False, wer_lowercase=False, _name='speech_to_text'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'wer', 'wer_tokenizer': 'none', 'wer_remove_punct': False, 'wer_char_level': False, 'wer_lowercase': False}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
INFO:fairseq.tasks.speech_to_text:dictionary size (spm.asr.txt): 5,000
INFO:fairseq_cli.generate:loading model(s) from /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
INFO:fairseq.tasks.speech_to_text:pre-tokenizer: {'tokenizer': None}
INFO:fairseq.tasks.speech_to_text:tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
WARNING:fairseq.data.audio.data_cfg:Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
INFO:fairseq.data.audio.speech_to_text_dataset:'test' has 0.00% OOV
INFO:fairseq.data.audio.speech_to_text_dataset:SpeechToTextDataset(split="test", n_samples=15_531, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
INFO:fairseq.tasks.fairseq_task:can_reuse_epoch_itr = True
INFO:fairseq.tasks.fairseq_task:reuse_dataloader = True
INFO:fairseq.tasks.fairseq_task:rebuild_batches = False
INFO:fairseq.tasks.fairseq_task:creating new batches for epoch 1
WARNING:fairseq.tasks.fairseq_task:5 samples have invalid sizes and will be skipped, max_positions=(6000, 1024), first few sample ids=[11198, 697, 6107, 3431, 14638]
INFO:fairseq.tasks.speech_to_text:pre-tokenizer: {'tokenizer': None}
INFO:fairseq.tasks.speech_to_text:tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
INFO:fairseq.logging.progress_bar::    101 / 188 wps=617
DEBUG:fairseq.data.iterators:Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.
INFO:fairseq_cli.generate:NOTE: hypothesis and token scores are output in base 2
INFO:fairseq_cli.generate:Translated 15,520 sentences (204,003 tokens) in 87.4s (177.61 sentences/s, 2334.63 tokens/s)
Transcription done
Prediction files written for /home/kit/stud/uxude/predictions/finetune_asr_covost/hyp_asr.txt and /home/kit/stud/uxude/predictions/finetune_asr_covost/ref_asr.txt
Sampled predictions written to /home/kit/stud/uxude/predictions/finetune_asr_covost/hyp_asr.txt.sampled
Sample predictions:
Sample: for a son reason we were brought from entering
Reference: for some reason we were blocked from entering
Sample: as they sat down at the only table in the place the crystal match at last
Reference: as they sat down at the only table in the place the crystal merchant laughed
Sample: a never more layer of a round between six more and five windows
Reference: im never more aware of a rooms acoustics than when im trying to enjoy a snack i have no intention of sharing
Sample: how am i to get in
Reference: aw man thats terrible
Sample: its a dream in the language of the world she said
Reference: its a dream in the language of the world she said
Sample: this looks amazing
Reference: this looks amazing
Sample: the eye became dripping and rapped his chair around the chimney
Reference: the ivy climbed up the building and wrapped itself around the chimney
Sample: nonwerbal communication is sometimes more meaningful than the spoken words
Reference: nonverbal communication is sometimes more meaningful than the spoken words
Sample: the whole dischief grew up
Reference: the hull of the ship collapsed
Sample: the kind driver embarrassed to the boy was saying
Reference: the camel driver understood what the boy was saying
Sample: her hair floated on her back
Reference: her hair flowed down her back
Sample: when burnsing slowly he relieved the panda back suddenly
Reference: advancing slowly they searched among the stones
Sample: maybe the church was the secondlarg growing from it been haunted
Reference: maybe the church with the sycamore growing from within had been haunted
Sample: the boy knew a lot of people in the city
Reference: the boy knew a lot of people in the city
Sample: if everything worked you will see a window pop up at tea salty
Reference: if everything works youll see a window pop up after starting
Sample: then you taught me something of the universe a language and the soul of the world
Reference: then you taught me something of the universal language and the soul of the world
Sample: the term just my two sense is about your pinking knot about my knee
Reference: the term just my two cents is about opinion not about money
Sample: the floor was demolished
Reference: the drawer was stuck closed
Sample: the woman was saving for some time
Reference: the woman was silent for some time
Sample: they were rarely i think or three hundred people agoing one another
Reference: there were really i think two or three hundred people elbowing one another
WER:
Generate test with beam=8: WER: 29.91
BLEU:
{
 "name": "BLEU",
 "score": 56.1,
 "signature": "nrefs:1|case:mixed|eff:no|tok:none|smooth:none|version:2.4.0",
 "verbose_score": "73.6/60.8/51.1/43.2 (BP = 1.000 ratio = 1.008 hyp_len = 142391 ref_len = 141203)",
 "nrefs": "1",
 "case": "mixed",
 "eff": "no",
 "tok": "none",
 "smooth": "none",
 "version": "2.4.0"
}