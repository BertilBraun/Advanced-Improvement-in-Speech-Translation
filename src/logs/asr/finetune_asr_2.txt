(base) [uxude@uc2n995 train]$ cat finetune_asr_covost_23112579.txt
No extension needed for workspace ASR.
No extension needed for workspace MT.
Fairseq directory exists. Checking if installed...
fairseq                  0.12.2       /pfs/data5/home/kit/stud/uxude/fairseq
Fairseq is already installed. Skipping installation.
Setup complete. Starting script execution...
[INFO] 04:35:44 [Dataset::Prepare Datasets]: Skipping dataset preparation, all config data already exists
Finetuning the ASR model...
Training the model...
Model will be stored in /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models
Training time: 18 hours
Training subset: train
Validation subset: dev
Data directory: /pfs/work7/workspace/scratch/uxude-ASR/dataset/covost
2024-02-05 04:35:49 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 4, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 50000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'dev', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 500, 'max_update': 0, 'stop_time_hours': 18.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.002], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 50000, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 5, 'keep_best_checkpoints': 5, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_text', num_workers=4, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2t_conformer', max_epoch=500, max_update=0, stop_time_hours=18.0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.002], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=50000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=5, keep_best_checkpoints=5, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, label_smoothing=0.0, report_accuracy=False, ignore_prefix_size=0, adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, pos_enc_type='rel_pos', attn_type='espnet', no_seed_provided=False, input_feat_per_channel=80, input_channels=1, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, dropout=0.1, encoder_layers=16, depthwise_conv_kernel_size=31, encoder_freezing_updates=0, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_normalize_before=True, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.1, activation_dropout=0.1, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, no_scale_embedding=False, quant_noise_pq=0, _name='s2t_conformer'), 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='label_smoothed_cross_entropy', tokenizer=None, bpe=None, optimizer='adam', lr_scheduler='inverse_sqrt', simul_type=None, scoring='bleu', task='speech_to_text', num_workers=4, skip_invalid_size_inputs_valid_test=False, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='dev', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, arch='s2t_conformer', max_epoch=500, max_update=0, stop_time_hours=18.0, clip_norm=0.0, sentence_avg=False, update_freq=[1], lr=[0.002], stop_min_lr=-1.0, use_bmuf=False, skip_remainder_batch=False, debug_param_names=False, save_dir='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=50000, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=5, keep_best_checkpoints=5, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, store_ema=False, ema_decay=0.9999, ema_start_update=0, ema_seed_model=None, ema_update_freq=1, ema_fp32=False, conv_version='s2t_transformer', activation_fn='relu', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, label_smoothing=0.0, report_accuracy=False, ignore_prefix_size=0, adam_betas=(0.9, 0.999), adam_eps=1e-08, weight_decay=0.0, use_old_adam=False, fp16_adam_stats=False, warmup_updates=10000, warmup_init_lr=-1, pad=1, eos=2, unk=3, share_decoder_input_output_embed=True, pos_enc_type='rel_pos', attn_type='espnet', no_seed_provided=False, input_feat_per_channel=80, input_channels=1, encoder_embed_dim=256, encoder_ffn_embed_dim=2048, encoder_attention_heads=4, dropout=0.1, encoder_layers=16, depthwise_conv_kernel_size=31, encoder_freezing_updates=0, conv_kernel_sizes='5,5', conv_channels=1024, conv_out_channels=256, encoder_normalize_before=True, decoder_embed_dim=256, decoder_ffn_embed_dim=2048, decoder_layers=6, decoder_attention_heads=8, decoder_normalize_before=True, decoder_learned_pos=False, attention_dropout=0.1, activation_dropout=0.1, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, no_token_positional_embeddings=False, adaptive_input=False, decoder_layerdrop=0.0, decoder_output_dim=256, decoder_input_dim=256, no_scale_embedding=False, quant_noise_pq=0, _name='speech_to_text'), 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.0, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': [0.9, 0.999], 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.002]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 10000, 'warmup_init_lr': -1.0, 'lr': [0.002]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2024-02-05 04:35:49 | INFO | fairseq.tasks.speech_to_text | dictionary size (spm.asr.txt): 5,000
2024-02-05 04:35:53 | INFO | fairseq_cli.train | S2TConformerModel(
  (encoder): S2TConformerEncoder(
    (subsample): Conv1dSubsampler(
      (conv_layers): ModuleList(
        (0): Conv1d(80, 1024, kernel_size=(5,), stride=(2,), padding=(2,))
        (1): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,))
      )
    )
    (embed_positions): RelPositionalEncoding()
    (linear): Linear(in_features=256, out_features=256, bias=True)
    (dropout): Dropout(p=0.1, inplace=False)
    (conformer_layers): ModuleList(
      (0-15): 16 x ConformerEncoderLayer(
        (ffn1): FeedForwardModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (activation): SiLU(inplace=True)
        )
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (self_attn_dropout): Dropout(p=0.1, inplace=False)
        (self_attn): RelPositionMultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.1, inplace=False)
          (linear_pos): Linear(in_features=256, out_features=256, bias=False)
        )
        (conv_module): ConvolutionModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (pointwise_conv1): Conv1d(256, 512, kernel_size=(1,), stride=(1,), bias=False)
          (glu): GLU(dim=1)
          (depthwise_conv): Conv1d(256, 256, kernel_size=(31,), stride=(1,), padding=(15,), groups=256, bias=False)
          (batch_norm): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (activation): SiLU(inplace=True)
          (pointwise_conv2): Conv1d(256, 256, kernel_size=(1,), stride=(1,), bias=False)
          (dropout): Dropout(p=0.1, inplace=False)
        )
        (ffn2): FeedForwardModule(
          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
          (dropout1): Dropout(p=0.1, inplace=False)
          (dropout2): Dropout(p=0.1, inplace=False)
          (activation): SiLU(inplace=True)
        )
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (decoder): TransformerDecoderScriptable(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(5000, 256, padding_idx=1)
    (embed_positions): SinusoidalPositionalEmbedding()
    (layers): ModuleList(
      (0-5): 6 x TransformerDecoderLayerBase(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=256, out_features=256, bias=True)
          (v_proj): Linear(in_features=256, out_features=256, bias=True)
          (q_proj): Linear(in_features=256, out_features=256, bias=True)
          (out_proj): Linear(in_features=256, out_features=256, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=256, out_features=2048, bias=True)
        (fc2): Linear(in_features=2048, out_features=256, bias=True)
        (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      )
    )
    (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=256, out_features=5000, bias=False)
  )
)
2024-02-05 04:35:53 | INFO | fairseq_cli.train | task: SpeechToTextTask
2024-02-05 04:35:53 | INFO | fairseq_cli.train | model: S2TConformerModel
2024-02-05 04:35:53 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion
2024-02-05 04:35:53 | INFO | fairseq_cli.train | num. shared model params: 54,758,144 (num. trained: 54,758,144)
2024-02-05 04:35:53 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)
2024-02-05 04:35:53 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2024-02-05 04:35:53 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
2024-02-05 04:35:53 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
2024-02-05 04:35:53 | INFO | fairseq.data.audio.speech_to_text_dataset | 'dev' has 0.00% OOV
2024-02-05 04:35:53 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split="dev", n_samples=15_531, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.pointwise_conv1.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.depthwise_conv.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.0.conv_module.pointwise_conv2.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.self_attn.linear_pos.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.pointwise_conv1.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.depthwise_conv.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.1.conv_module.pointwise_conv2.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.self_attn.linear_pos.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.pointwise_conv1.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.depthwise_conv.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.2.conv_module.pointwise_conv2.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.self_attn.linear_pos.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.pointwise_conv1.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.depthwise_conv.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.3.conv_module.pointwise_conv2.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.self_attn.linear_pos.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.pointwise_conv1.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.depthwise_conv.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.4.conv_module.pointwise_conv2.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.self_attn.linear_pos.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.pointwise_conv1.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.depthwise_conv.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.5.conv_module.pointwise_conv2.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.self_attn.linear_pos.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.pointwise_conv1.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.depthwise_conv.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.6.conv_module.pointwise_conv2.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.self_attn.linear_pos.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.pointwise_conv1.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.depthwise_conv.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.7.conv_module.pointwise_conv2.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.self_attn.linear_pos.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.pointwise_conv1.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.depthwise_conv.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.8.conv_module.pointwise_conv2.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.self_attn.linear_pos.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.pointwise_conv1.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.depthwise_conv.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.9.conv_module.pointwise_conv2.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.self_attn.linear_pos.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.pointwise_conv1.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.depthwise_conv.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.10.conv_module.pointwise_conv2.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.self_attn.linear_pos.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.pointwise_conv1.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.depthwise_conv.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.11.conv_module.pointwise_conv2.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.self_attn.linear_pos.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.pointwise_conv1.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.depthwise_conv.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.12.conv_module.pointwise_conv2.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.self_attn.linear_pos.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.pointwise_conv1.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.depthwise_conv.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.13.conv_module.pointwise_conv2.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.self_attn.linear_pos.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.pointwise_conv1.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.depthwise_conv.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.14.conv_module.pointwise_conv2.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.self_attn.linear_pos.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.pointwise_conv1.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.depthwise_conv.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- encoder.conformer_layers.15.conv_module.pointwise_conv2.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: encoder.conformer_layers.0.self_attn.linear_pos.bias <- decoder.output_projection.bias
2024-02-05 04:35:54 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight
2024-02-05 04:35:54 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-02-05 04:35:54 | INFO | fairseq.utils | rank   0: capabilities =  7.0  ; total memory = 31.739 GB ; name = Tesla V100-SXM2-32GB
2024-02-05 04:35:54 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************
2024-02-05 04:35:54 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)
2024-02-05 04:35:54 | INFO | fairseq_cli.train | max tokens per device = 50000 and max sentences per device = None
2024-02-05 04:35:54 | INFO | fairseq.trainer | Preparing to load checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt
2024-02-05 04:35:57 | INFO | fairseq.trainer | NOTE: your device may support faster training with --fp16 or --amp
2024-02-05 04:35:59 | INFO | fairseq.trainer | Loaded checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt (epoch 12 @ 35596 updates)
2024-02-05 04:35:59 | INFO | fairseq.trainer | loading train data for epoch 12
2024-02-05 04:35:59 | INFO | fairseq.tasks.speech_to_text | pre-tokenizer: {'tokenizer': None}
2024-02-05 04:35:59 | INFO | fairseq.tasks.speech_to_text | tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
2024-02-05 04:36:03 | WARNING | fairseq.data.audio.data_cfg | Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
2024-02-05 04:36:07 | INFO | fairseq.data.audio.speech_to_text_dataset | 'train' has 0.00% OOV
2024-02-05 04:36:07 | INFO | fairseq.data.audio.speech_to_text_dataset | SpeechToTextDataset(split="train", n_samples=289_421, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
    SpecAugmentTransform(time_warp_w=0, freq_mask_n=1, freq_mask_f=27, time_mask_n=1, time_mask_t=100, time_mask_p=1.0)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
2024-02-05 04:36:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 04:36:07 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-02-05 04:36:07 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-02-05 04:36:07 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 12
2024-02-05 04:36:09 | INFO | fairseq_cli.train | begin dry-run validation on "dev" subset
2024-02-05 04:36:09 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 04:36:09 | INFO | fairseq.tasks.fairseq_task | reuse_dataloader = True
2024-02-05 04:36:09 | INFO | fairseq.tasks.fairseq_task | rebuild_batches = False
2024-02-05 04:36:09 | INFO | fairseq.tasks.fairseq_task | creating new batches for epoch 1
/home/kit/stud/uxude/miniconda3/envs/nmt/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
2024-02-05 04:37:21 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 04:37:21 | INFO | fairseq.trainer | begin training epoch 12
2024-02-05 04:37:21 | INFO | fairseq_cli.train | Start iterating over samples
/home/kit/stud/uxude/miniconda3/envs/nmt/lib/python3.10/site-packages/torch/nn/functional.py:5076: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.
  warnings.warn(
/home/kit/stud/uxude/fairseq/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  warnings.warn(
2024-02-05 04:37:54 | INFO | train_inner | epoch 012:      4 / 3236 loss=1.726, nll_loss=1.726, ppl=3.31, wps=2032.5, ups=1.63, wpb=1263.8, bsz=74, num_updates=35600, lr=0.00106, gnorm=0.601, train_wall=31, gb_free=17.1, wall=120
2024-02-05 04:38:51 | INFO | train_inner | epoch 012:    104 / 3236 loss=1.409, nll_loss=1.409, ppl=2.66, wps=2248.5, ups=1.74, wpb=1295.6, bsz=89, num_updates=35700, lr=0.00105851, gnorm=0.565, train_wall=57, gb_free=17.8, wall=178
2024-02-05 04:39:48 | INFO | train_inner | epoch 012:    204 / 3236 loss=1.44, nll_loss=1.44, ppl=2.71, wps=2317.4, ups=1.76, wpb=1316.3, bsz=90.8, num_updates=35800, lr=0.00105703, gnorm=0.559, train_wall=56, gb_free=18.4, wall=235
2024-02-05 04:40:45 | INFO | train_inner | epoch 012:    304 / 3236 loss=1.459, nll_loss=1.459, ppl=2.75, wps=2310.1, ups=1.77, wpb=1304.2, bsz=91.6, num_updates=35900, lr=0.00105556, gnorm=0.57, train_wall=56, gb_free=17.2, wall=291
2024-02-05 04:41:42 | INFO | train_inner | epoch 012:    404 / 3236 loss=1.465, nll_loss=1.465, ppl=2.76, wps=2265.2, ups=1.76, wpb=1289, bsz=86.8, num_updates=36000, lr=0.00105409, gnorm=0.583, train_wall=56, gb_free=17.7, wall=348
2024-02-05 04:42:39 | INFO | train_inner | epoch 012:    504 / 3236 loss=1.458, nll_loss=1.458, ppl=2.75, wps=2259, ups=1.75, wpb=1288.5, bsz=87.3, num_updates=36100, lr=0.00105263, gnorm=0.57, train_wall=56, gb_free=18, wall=405
2024-02-05 04:43:35 | INFO | train_inner | epoch 012:    604 / 3236 loss=1.432, nll_loss=1.432, ppl=2.7, wps=2363, ups=1.77, wpb=1333.8, bsz=93.8, num_updates=36200, lr=0.00105118, gnorm=0.558, train_wall=56, gb_free=17.7, wall=461
2024-02-05 04:44:32 | INFO | train_inner | epoch 012:    704 / 3236 loss=1.484, nll_loss=1.484, ppl=2.8, wps=2266.1, ups=1.77, wpb=1280.9, bsz=86, num_updates=36300, lr=0.00104973, gnorm=0.605, train_wall=56, gb_free=18.2, wall=518
2024-02-05 04:45:28 | INFO | train_inner | epoch 012:    804 / 3236 loss=1.459, nll_loss=1.459, ppl=2.75, wps=2315.3, ups=1.78, wpb=1297.7, bsz=88.6, num_updates=36400, lr=0.00104828, gnorm=0.574, train_wall=56, gb_free=17.4, wall=574
2024-02-05 04:46:24 | INFO | train_inner | epoch 012:    904 / 3236 loss=1.462, nll_loss=1.462, ppl=2.75, wps=2281, ups=1.78, wpb=1283.8, bsz=87.4, num_updates=36500, lr=0.00104685, gnorm=0.58, train_wall=56, gb_free=18.2, wall=630
2024-02-05 04:47:21 | INFO | train_inner | epoch 012:   1004 / 3236 loss=1.472, nll_loss=1.472, ppl=2.77, wps=2269.5, ups=1.77, wpb=1284.1, bsz=82.1, num_updates=36600, lr=0.00104542, gnorm=0.58, train_wall=56, gb_free=17.6, wall=687
2024-02-05 04:48:17 | INFO | train_inner | epoch 012:   1104 / 3236 loss=1.44, nll_loss=1.44, ppl=2.71, wps=2311.5, ups=1.77, wpb=1304.1, bsz=85.8, num_updates=36700, lr=0.00104399, gnorm=0.564, train_wall=56, gb_free=17.9, wall=743
2024-02-05 04:49:13 | INFO | train_inner | epoch 012:   1204 / 3236 loss=1.48, nll_loss=1.48, ppl=2.79, wps=2308.5, ups=1.77, wpb=1304.3, bsz=89.9, num_updates=36800, lr=0.00104257, gnorm=0.565, train_wall=56, gb_free=17.6, wall=800
2024-02-05 04:50:11 | INFO | train_inner | epoch 012:   1304 / 3236 loss=1.463, nll_loss=1.463, ppl=2.76, wps=2256.2, ups=1.74, wpb=1295.9, bsz=89, num_updates=36900, lr=0.00104116, gnorm=0.584, train_wall=57, gb_free=17.2, wall=857
2024-02-05 04:51:08 | INFO | train_inner | epoch 012:   1404 / 3236 loss=1.441, nll_loss=1.441, ppl=2.72, wps=2336.5, ups=1.76, wpb=1328.8, bsz=94.1, num_updates=37000, lr=0.00103975, gnorm=0.561, train_wall=56, gb_free=17.9, wall=914
2024-02-05 04:52:05 | INFO | train_inner | epoch 012:   1504 / 3236 loss=1.497, nll_loss=1.497, ppl=2.82, wps=2252.5, ups=1.76, wpb=1281.3, bsz=83, num_updates=37100, lr=0.00103835, gnorm=0.592, train_wall=56, gb_free=17, wall=971
2024-02-05 04:53:01 | INFO | train_inner | epoch 012:   1604 / 3236 loss=1.465, nll_loss=1.465, ppl=2.76, wps=2341.5, ups=1.77, wpb=1325.9, bsz=93.6, num_updates=37200, lr=0.00103695, gnorm=0.572, train_wall=56, gb_free=18.2, wall=1028
2024-02-05 04:53:58 | INFO | train_inner | epoch 012:   1704 / 3236 loss=1.427, nll_loss=1.427, ppl=2.69, wps=2332.4, ups=1.77, wpb=1315.5, bsz=92.6, num_updates=37300, lr=0.00103556, gnorm=0.56, train_wall=56, gb_free=17.7, wall=1084
2024-02-05 04:54:54 | INFO | train_inner | epoch 012:   1804 / 3236 loss=1.461, nll_loss=1.461, ppl=2.75, wps=2326.7, ups=1.77, wpb=1315.5, bsz=87.4, num_updates=37400, lr=0.00103418, gnorm=0.569, train_wall=56, gb_free=18.6, wall=1141
2024-02-05 04:55:50 | INFO | train_inner | epoch 012:   1904 / 3236 loss=1.481, nll_loss=1.481, ppl=2.79, wps=2341.7, ups=1.78, wpb=1317.7, bsz=91.3, num_updates=37500, lr=0.0010328, gnorm=0.573, train_wall=56, gb_free=18, wall=1197
2024-02-05 04:56:47 | INFO | train_inner | epoch 012:   2004 / 3236 loss=1.487, nll_loss=1.487, ppl=2.8, wps=2299.3, ups=1.77, wpb=1299.4, bsz=92.9, num_updates=37600, lr=0.00103142, gnorm=0.587, train_wall=56, gb_free=18.6, wall=1253
2024-02-05 04:57:44 | INFO | train_inner | epoch 012:   2104 / 3236 loss=1.479, nll_loss=1.479, ppl=2.79, wps=2320.9, ups=1.76, wpb=1317.9, bsz=92.1, num_updates=37700, lr=0.00103005, gnorm=0.575, train_wall=56, gb_free=18.2, wall=1310
2024-02-05 04:58:40 | INFO | train_inner | epoch 012:   2204 / 3236 loss=1.448, nll_loss=1.448, ppl=2.73, wps=2274.5, ups=1.77, wpb=1285.9, bsz=89.3, num_updates=37800, lr=0.00102869, gnorm=0.574, train_wall=56, gb_free=18, wall=1367
2024-02-05 04:59:37 | INFO | train_inner | epoch 012:   2304 / 3236 loss=1.454, nll_loss=1.454, ppl=2.74, wps=2288.3, ups=1.77, wpb=1291.5, bsz=87.8, num_updates=37900, lr=0.00102733, gnorm=0.581, train_wall=56, gb_free=18.5, wall=1423
2024-02-05 05:00:33 | INFO | train_inner | epoch 012:   2404 / 3236 loss=1.476, nll_loss=1.476, ppl=2.78, wps=2281.4, ups=1.77, wpb=1290.7, bsz=86.3, num_updates=38000, lr=0.00102598, gnorm=0.575, train_wall=56, gb_free=17.5, wall=1480
2024-02-05 05:01:30 | INFO | train_inner | epoch 012:   2504 / 3236 loss=1.466, nll_loss=1.466, ppl=2.76, wps=2296.8, ups=1.75, wpb=1310.8, bsz=89.4, num_updates=38100, lr=0.00102463, gnorm=0.566, train_wall=56, gb_free=17.9, wall=1537
2024-02-05 05:02:27 | INFO | train_inner | epoch 012:   2604 / 3236 loss=1.478, nll_loss=1.478, ppl=2.79, wps=2290.8, ups=1.76, wpb=1302.5, bsz=95.3, num_updates=38200, lr=0.00102329, gnorm=0.566, train_wall=56, gb_free=18, wall=1594
2024-02-05 05:03:24 | INFO | train_inner | epoch 012:   2704 / 3236 loss=1.462, nll_loss=1.462, ppl=2.75, wps=2295.3, ups=1.77, wpb=1296.3, bsz=90.8, num_updates=38300, lr=0.00102195, gnorm=0.582, train_wall=56, gb_free=17.9, wall=1650
2024-02-05 05:04:20 | INFO | train_inner | epoch 012:   2804 / 3236 loss=1.484, nll_loss=1.484, ppl=2.8, wps=2306.4, ups=1.77, wpb=1304.8, bsz=90.4, num_updates=38400, lr=0.00102062, gnorm=0.577, train_wall=56, gb_free=17.7, wall=1707
2024-02-05 05:05:17 | INFO | train_inner | epoch 012:   2904 / 3236 loss=1.501, nll_loss=1.501, ppl=2.83, wps=2272.7, ups=1.76, wpb=1288.2, bsz=89, num_updates=38500, lr=0.00101929, gnorm=0.583, train_wall=56, gb_free=18, wall=1763
2024-02-05 05:06:13 | INFO | train_inner | epoch 012:   3004 / 3236 loss=1.475, nll_loss=1.475, ppl=2.78, wps=2319.3, ups=1.78, wpb=1306.1, bsz=86.2, num_updates=38600, lr=0.00101797, gnorm=0.589, train_wall=56, gb_free=18.1, wall=1820
2024-02-05 05:07:10 | INFO | train_inner | epoch 012:   3104 / 3236 loss=1.463, nll_loss=1.463, ppl=2.76, wps=2335.7, ups=1.77, wpb=1319.5, bsz=96.3, num_updates=38700, lr=0.00101666, gnorm=0.563, train_wall=56, gb_free=17.8, wall=1876
2024-02-05 05:08:07 | INFO | train_inner | epoch 012:   3204 / 3236 loss=1.478, nll_loss=1.478, ppl=2.79, wps=2298.6, ups=1.76, wpb=1308, bsz=87.4, num_updates=38800, lr=0.00101535, gnorm=0.559, train_wall=56, gb_free=17.8, wall=1933
2024-02-05 05:08:25 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 05:08:25 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 05:09:22 | INFO | dev | epoch 012 | valid on 'dev' subset | loss 1.253 | nll_loss 1.253 | ppl 2.38 | wps 4030.8 | wpb 1146.2 | bsz 77.6 | num_updates 38832 | best_loss 1.253
2024-02-05 05:09:22 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 12 @ 38832 updates
2024-02-05 05:09:22 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint12.pt
2024-02-05 05:09:24 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint12.pt
2024-02-05 05:09:28 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint12.pt (epoch 12 @ 38832 updates, score 1.253) (writing took 5.845115447067656 seconds)
2024-02-05 05:09:28 | INFO | fairseq_cli.train | end of epoch 12 (average epoch stats below)
2024-02-05 05:09:28 | INFO | train | epoch 012 | loss 1.464 | nll_loss 1.464 | ppl 2.76 | wps 2221.8 | ups 1.71 | wpb 1302.4 | bsz 89.4 | num_updates 38832 | lr 0.00101493 | gnorm 0.574 | train_wall 1844 | gb_free 18.4 | wall 2015
2024-02-05 05:09:28 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 05:09:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 05:09:29 | INFO | fairseq.trainer | begin training epoch 13
2024-02-05 05:09:29 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 05:10:08 | INFO | train_inner | epoch 013:     68 / 3236 loss=1.399, nll_loss=1.399, ppl=2.64, wps=1062.8, ups=0.83, wpb=1284.8, bsz=89.7, num_updates=38900, lr=0.00101404, gnorm=0.576, train_wall=56, gb_free=17.8, wall=2054
2024-02-05 05:11:04 | INFO | train_inner | epoch 013:    168 / 3236 loss=1.385, nll_loss=1.385, ppl=2.61, wps=2344.2, ups=1.77, wpb=1320.7, bsz=91.4, num_updates=39000, lr=0.00101274, gnorm=0.569, train_wall=56, gb_free=18.4, wall=2110
2024-02-05 05:12:00 | INFO | train_inner | epoch 013:    268 / 3236 loss=1.418, nll_loss=1.418, ppl=2.67, wps=2332.4, ups=1.78, wpb=1309.8, bsz=91.5, num_updates=39100, lr=0.00101144, gnorm=0.578, train_wall=56, gb_free=17.8, wall=2166
2024-02-05 05:12:56 | INFO | train_inner | epoch 013:    368 / 3236 loss=1.395, nll_loss=1.395, ppl=2.63, wps=2303.7, ups=1.79, wpb=1286.7, bsz=88.1, num_updates=39200, lr=0.00101015, gnorm=0.577, train_wall=55, gb_free=18.5, wall=2222
2024-02-05 05:13:53 | INFO | train_inner | epoch 013:    468 / 3236 loss=1.394, nll_loss=1.394, ppl=2.63, wps=2278.2, ups=1.76, wpb=1294.6, bsz=87.3, num_updates=39300, lr=0.00100887, gnorm=0.568, train_wall=56, gb_free=17.9, wall=2279
2024-02-05 05:14:49 | INFO | train_inner | epoch 013:    568 / 3236 loss=1.386, nll_loss=1.386, ppl=2.61, wps=2333.3, ups=1.78, wpb=1310.6, bsz=92.4, num_updates=39400, lr=0.00100759, gnorm=0.563, train_wall=56, gb_free=18.6, wall=2335
2024-02-05 05:15:45 | INFO | train_inner | epoch 013:    668 / 3236 loss=1.401, nll_loss=1.401, ppl=2.64, wps=2295.5, ups=1.78, wpb=1287.6, bsz=87.1, num_updates=39500, lr=0.00100631, gnorm=0.577, train_wall=56, gb_free=18.2, wall=2391
2024-02-05 05:16:42 | INFO | train_inner | epoch 013:    768 / 3236 loss=1.387, nll_loss=1.387, ppl=2.62, wps=2277.3, ups=1.77, wpb=1286.8, bsz=87, num_updates=39600, lr=0.00100504, gnorm=0.577, train_wall=56, gb_free=17.7, wall=2448
2024-02-05 05:17:38 | INFO | train_inner | epoch 013:    868 / 3236 loss=1.394, nll_loss=1.394, ppl=2.63, wps=2314, ups=1.77, wpb=1307.2, bsz=88.2, num_updates=39700, lr=0.00100377, gnorm=0.58, train_wall=56, gb_free=18.4, wall=2504
2024-02-05 05:18:35 | INFO | train_inner | epoch 013:    968 / 3236 loss=1.414, nll_loss=1.414, ppl=2.67, wps=2271.5, ups=1.76, wpb=1288.9, bsz=89.3, num_updates=39800, lr=0.00100251, gnorm=0.589, train_wall=56, gb_free=18.1, wall=2561
2024-02-05 05:19:31 | INFO | train_inner | epoch 013:   1068 / 3236 loss=1.391, nll_loss=1.391, ppl=2.62, wps=2293.5, ups=1.77, wpb=1297.6, bsz=87.8, num_updates=39900, lr=0.00100125, gnorm=0.569, train_wall=56, gb_free=17.9, wall=2618
2024-02-05 05:20:28 | INFO | train_inner | epoch 013:   1168 / 3236 loss=1.433, nll_loss=1.433, ppl=2.7, wps=2307.6, ups=1.78, wpb=1299.2, bsz=85.9, num_updates=40000, lr=0.001, gnorm=0.582, train_wall=56, gb_free=17.6, wall=2674
2024-02-05 05:21:24 | INFO | train_inner | epoch 013:   1268 / 3236 loss=1.391, nll_loss=1.391, ppl=2.62, wps=2316.8, ups=1.77, wpb=1305.5, bsz=90.1, num_updates=40100, lr=0.000998752, gnorm=0.564, train_wall=56, gb_free=17.9, wall=2730
2024-02-05 05:22:21 | INFO | train_inner | epoch 013:   1368 / 3236 loss=1.398, nll_loss=1.398, ppl=2.64, wps=2262.5, ups=1.77, wpb=1279, bsz=88.8, num_updates=40200, lr=0.000997509, gnorm=0.569, train_wall=56, gb_free=17.7, wall=2787
2024-02-05 05:23:17 | INFO | train_inner | epoch 013:   1468 / 3236 loss=1.391, nll_loss=1.391, ppl=2.62, wps=2299.5, ups=1.76, wpb=1303.5, bsz=90.6, num_updates=40300, lr=0.000996271, gnorm=0.573, train_wall=56, gb_free=17.4, wall=2844
2024-02-05 05:24:14 | INFO | train_inner | epoch 013:   1568 / 3236 loss=1.392, nll_loss=1.392, ppl=2.62, wps=2324.9, ups=1.78, wpb=1309.4, bsz=89.3, num_updates=40400, lr=0.000995037, gnorm=0.567, train_wall=56, gb_free=18.3, wall=2900
2024-02-05 05:25:10 | INFO | train_inner | epoch 013:   1668 / 3236 loss=1.388, nll_loss=1.388, ppl=2.62, wps=2360.3, ups=1.77, wpb=1337.1, bsz=98, num_updates=40500, lr=0.000993808, gnorm=0.554, train_wall=56, gb_free=18, wall=2957
2024-02-05 05:26:07 | INFO | train_inner | epoch 013:   1768 / 3236 loss=1.388, nll_loss=1.388, ppl=2.62, wps=2295, ups=1.77, wpb=1296.3, bsz=88.2, num_updates=40600, lr=0.000992583, gnorm=0.577, train_wall=56, gb_free=18.9, wall=3013
2024-02-05 05:27:03 | INFO | train_inner | epoch 013:   1868 / 3236 loss=1.425, nll_loss=1.425, ppl=2.68, wps=2288.5, ups=1.76, wpb=1299.6, bsz=91.4, num_updates=40700, lr=0.000991363, gnorm=0.592, train_wall=56, gb_free=18.5, wall=3070
2024-02-05 05:27:59 | INFO | train_inner | epoch 013:   1968 / 3236 loss=1.438, nll_loss=1.438, ppl=2.71, wps=2380.2, ups=1.79, wpb=1331.3, bsz=92.9, num_updates=40800, lr=0.000990148, gnorm=0.57, train_wall=55, gb_free=18.4, wall=3126
2024-02-05 05:28:56 | INFO | train_inner | epoch 013:   2068 / 3236 loss=1.423, nll_loss=1.423, ppl=2.68, wps=2328.8, ups=1.78, wpb=1308.1, bsz=89.8, num_updates=40900, lr=0.000988936, gnorm=0.563, train_wall=56, gb_free=18.5, wall=3182
2024-02-05 05:29:52 | INFO | train_inner | epoch 013:   2168 / 3236 loss=1.413, nll_loss=1.413, ppl=2.66, wps=2326.7, ups=1.78, wpb=1308.4, bsz=91.1, num_updates=41000, lr=0.00098773, gnorm=0.591, train_wall=56, gb_free=17.8, wall=3238
2024-02-05 05:30:48 | INFO | train_inner | epoch 013:   2268 / 3236 loss=1.437, nll_loss=1.437, ppl=2.71, wps=2367.2, ups=1.79, wpb=1323.3, bsz=93.8, num_updates=41100, lr=0.000986527, gnorm=0.583, train_wall=55, gb_free=17.9, wall=3294
2024-02-05 05:31:44 | INFO | train_inner | epoch 013:   2368 / 3236 loss=1.419, nll_loss=1.419, ppl=2.67, wps=2278.7, ups=1.79, wpb=1274.2, bsz=83.9, num_updates=41200, lr=0.000985329, gnorm=0.592, train_wall=55, gb_free=17.7, wall=3350
2024-02-05 05:32:40 | INFO | train_inner | epoch 013:   2468 / 3236 loss=1.447, nll_loss=1.447, ppl=2.73, wps=2319.3, ups=1.78, wpb=1301.4, bsz=95.4, num_updates=41300, lr=0.000984136, gnorm=0.578, train_wall=56, gb_free=17.9, wall=3406
2024-02-05 05:33:36 | INFO | train_inner | epoch 013:   2568 / 3236 loss=1.395, nll_loss=1.395, ppl=2.63, wps=2297.2, ups=1.79, wpb=1284.2, bsz=85, num_updates=41400, lr=0.000982946, gnorm=0.573, train_wall=55, gb_free=17.6, wall=3462
2024-02-05 05:34:32 | INFO | train_inner | epoch 013:   2668 / 3236 loss=1.423, nll_loss=1.423, ppl=2.68, wps=2293.1, ups=1.77, wpb=1293, bsz=85.4, num_updates=41500, lr=0.000981761, gnorm=0.568, train_wall=56, gb_free=18.1, wall=3518
2024-02-05 05:35:28 | INFO | train_inner | epoch 013:   2768 / 3236 loss=1.411, nll_loss=1.411, ppl=2.66, wps=2315.1, ups=1.78, wpb=1301.1, bsz=87.8, num_updates=41600, lr=0.000980581, gnorm=0.574, train_wall=56, gb_free=18.1, wall=3575
2024-02-05 05:36:25 | INFO | train_inner | epoch 013:   2868 / 3236 loss=1.403, nll_loss=1.403, ppl=2.65, wps=2341.6, ups=1.78, wpb=1318.7, bsz=91.4, num_updates=41700, lr=0.000979404, gnorm=0.555, train_wall=56, gb_free=18.1, wall=3631
2024-02-05 05:37:21 | INFO | train_inner | epoch 013:   2968 / 3236 loss=1.406, nll_loss=1.406, ppl=2.65, wps=2306.8, ups=1.77, wpb=1303.4, bsz=86.5, num_updates=41800, lr=0.000978232, gnorm=0.561, train_wall=56, gb_free=18.4, wall=3687
2024-02-05 05:38:17 | INFO | train_inner | epoch 013:   3068 / 3236 loss=1.398, nll_loss=1.398, ppl=2.64, wps=2335.1, ups=1.78, wpb=1311.9, bsz=88.6, num_updates=41900, lr=0.000977064, gnorm=0.566, train_wall=56, gb_free=17.9, wall=3744
2024-02-05 05:39:14 | INFO | train_inner | epoch 013:   3168 / 3236 loss=1.402, nll_loss=1.402, ppl=2.64, wps=2315.9, ups=1.77, wpb=1310.3, bsz=87.8, num_updates=42000, lr=0.0009759, gnorm=0.575, train_wall=56, gb_free=18.2, wall=3800
2024-02-05 05:39:52 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 05:39:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 05:40:24 | INFO | dev | epoch 013 | valid on 'dev' subset | loss 1.217 | nll_loss 1.217 | ppl 2.32 | wps 7187.4 | wpb 1146.2 | bsz 77.6 | num_updates 42068 | best_loss 1.217
2024-02-05 05:40:24 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 13 @ 42068 updates
2024-02-05 05:40:24 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint13.pt
2024-02-05 05:40:25 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint13.pt
2024-02-05 05:40:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint13.pt (epoch 13 @ 42068 updates, score 1.217) (writing took 5.66171335906256 seconds)
2024-02-05 05:40:30 | INFO | fairseq_cli.train | end of epoch 13 (average epoch stats below)
2024-02-05 05:40:30 | INFO | train | epoch 013 | loss 1.405 | nll_loss 1.405 | ppl 2.65 | wps 2264 | ups 1.74 | wpb 1302.4 | bsz 89.4 | num_updates 42068 | lr 0.000975111 | gnorm 0.573 | train_wall 1805 | gb_free 18.3 | wall 3876
2024-02-05 05:40:30 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 05:40:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 05:40:30 | INFO | fairseq.trainer | begin training epoch 14
2024-02-05 05:40:30 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 05:40:49 | INFO | train_inner | epoch 014:     32 / 3236 loss=1.397, nll_loss=1.397, ppl=2.63, wps=1369.8, ups=1.06, wpb=1298, bsz=89.2, num_updates=42100, lr=0.00097474, gnorm=0.57, train_wall=56, gb_free=18.1, wall=3895
2024-02-05 05:41:45 | INFO | train_inner | epoch 014:    132 / 3236 loss=1.313, nll_loss=1.313, ppl=2.48, wps=2309.5, ups=1.78, wpb=1296.8, bsz=88.1, num_updates=42200, lr=0.000973585, gnorm=0.573, train_wall=56, gb_free=17.8, wall=3951
2024-02-05 05:42:41 | INFO | train_inner | epoch 014:    232 / 3236 loss=1.345, nll_loss=1.345, ppl=2.54, wps=2332.5, ups=1.79, wpb=1304, bsz=88, num_updates=42300, lr=0.000972433, gnorm=0.566, train_wall=55, gb_free=17.6, wall=4007
2024-02-05 05:43:36 | INFO | train_inner | epoch 014:    332 / 3236 loss=1.324, nll_loss=1.324, ppl=2.5, wps=2356.5, ups=1.79, wpb=1316.9, bsz=89.1, num_updates=42400, lr=0.000971286, gnorm=0.564, train_wall=55, gb_free=18.3, wall=4063
2024-02-05 05:44:32 | INFO | train_inner | epoch 014:    432 / 3236 loss=1.337, nll_loss=1.337, ppl=2.53, wps=2316.5, ups=1.79, wpb=1295.6, bsz=89.8, num_updates=42500, lr=0.000970143, gnorm=0.573, train_wall=55, gb_free=17.3, wall=4119
2024-02-05 05:45:29 | INFO | train_inner | epoch 014:    532 / 3236 loss=1.35, nll_loss=1.35, ppl=2.55, wps=2319.6, ups=1.78, wpb=1301.3, bsz=88.5, num_updates=42600, lr=0.000969003, gnorm=0.572, train_wall=56, gb_free=17.2, wall=4175
2024-02-05 05:46:25 | INFO | train_inner | epoch 014:    632 / 3236 loss=1.336, nll_loss=1.336, ppl=2.52, wps=2312.2, ups=1.78, wpb=1295.6, bsz=89.8, num_updates=42700, lr=0.000967868, gnorm=0.586, train_wall=56, gb_free=18, wall=4231
2024-02-05 05:47:21 | INFO | train_inner | epoch 014:    732 / 3236 loss=1.343, nll_loss=1.343, ppl=2.54, wps=2323.2, ups=1.78, wpb=1307.8, bsz=88.6, num_updates=42800, lr=0.000966736, gnorm=0.566, train_wall=56, gb_free=18.4, wall=4287
2024-02-05 05:48:17 | INFO | train_inner | epoch 014:    832 / 3236 loss=1.377, nll_loss=1.377, ppl=2.6, wps=2311.1, ups=1.78, wpb=1301.2, bsz=91, num_updates=42900, lr=0.000965609, gnorm=0.588, train_wall=56, gb_free=18.3, wall=4344
2024-02-05 05:49:13 | INFO | train_inner | epoch 014:    932 / 3236 loss=1.386, nll_loss=1.386, ppl=2.61, wps=2296.7, ups=1.8, wpb=1278.8, bsz=85.5, num_updates=43000, lr=0.000964486, gnorm=0.577, train_wall=55, gb_free=17.8, wall=4399
2024-02-05 05:50:09 | INFO | train_inner | epoch 014:   1032 / 3236 loss=1.337, nll_loss=1.337, ppl=2.53, wps=2327.1, ups=1.78, wpb=1305.9, bsz=88.8, num_updates=43100, lr=0.000963366, gnorm=0.56, train_wall=56, gb_free=18.5, wall=4455
2024-02-05 05:51:05 | INFO | train_inner | epoch 014:   1132 / 3236 loss=1.338, nll_loss=1.338, ppl=2.53, wps=2343.3, ups=1.79, wpb=1308.8, bsz=90.1, num_updates=43200, lr=0.00096225, gnorm=0.565, train_wall=55, gb_free=17.9, wall=4511
2024-02-05 05:52:01 | INFO | train_inner | epoch 014:   1232 / 3236 loss=1.327, nll_loss=1.327, ppl=2.51, wps=2308.5, ups=1.78, wpb=1298.6, bsz=89.3, num_updates=43300, lr=0.000961139, gnorm=0.574, train_wall=56, gb_free=18.3, wall=4567
2024-02-05 05:52:57 | INFO | train_inner | epoch 014:   1332 / 3236 loss=1.349, nll_loss=1.349, ppl=2.55, wps=2304.1, ups=1.78, wpb=1295.6, bsz=89.6, num_updates=43400, lr=0.000960031, gnorm=0.571, train_wall=56, gb_free=17.8, wall=4624
2024-02-05 05:53:54 | INFO | train_inner | epoch 014:   1432 / 3236 loss=1.366, nll_loss=1.366, ppl=2.58, wps=2362.5, ups=1.78, wpb=1330, bsz=93.7, num_updates=43500, lr=0.000958927, gnorm=0.578, train_wall=56, gb_free=17.7, wall=4680
2024-02-05 05:54:52 | INFO | train_inner | epoch 014:   1532 / 3236 loss=1.351, nll_loss=1.351, ppl=2.55, wps=2199.5, ups=1.7, wpb=1293.4, bsz=87.2, num_updates=43600, lr=0.000957826, gnorm=0.57, train_wall=55, gb_free=18.1, wall=4739
2024-02-05 05:55:49 | INFO | train_inner | epoch 014:   1632 / 3236 loss=1.369, nll_loss=1.369, ppl=2.58, wps=2285.7, ups=1.78, wpb=1287, bsz=87.2, num_updates=43700, lr=0.00095673, gnorm=0.593, train_wall=56, gb_free=18.5, wall=4795
2024-02-05 05:56:45 | INFO | train_inner | epoch 014:   1732 / 3236 loss=1.355, nll_loss=1.355, ppl=2.56, wps=2332, ups=1.78, wpb=1306.9, bsz=90.8, num_updates=43800, lr=0.000955637, gnorm=0.575, train_wall=56, gb_free=17.9, wall=4851
2024-02-05 05:57:41 | INFO | train_inner | epoch 014:   1832 / 3236 loss=1.381, nll_loss=1.381, ppl=2.6, wps=2319.8, ups=1.78, wpb=1301.2, bsz=90.3, num_updates=43900, lr=0.000954548, gnorm=0.565, train_wall=56, gb_free=18.3, wall=4907
2024-02-05 05:58:37 | INFO | train_inner | epoch 014:   1932 / 3236 loss=1.367, nll_loss=1.367, ppl=2.58, wps=2302, ups=1.79, wpb=1287.3, bsz=88.2, num_updates=44000, lr=0.000953463, gnorm=0.569, train_wall=55, gb_free=18.2, wall=4963
2024-02-05 05:59:33 | INFO | train_inner | epoch 014:   2032 / 3236 loss=1.375, nll_loss=1.375, ppl=2.59, wps=2324.3, ups=1.78, wpb=1307.7, bsz=88.2, num_updates=44100, lr=0.000952381, gnorm=0.57, train_wall=56, gb_free=17.7, wall=5019
2024-02-05 06:00:29 | INFO | train_inner | epoch 014:   2132 / 3236 loss=1.374, nll_loss=1.374, ppl=2.59, wps=2314.2, ups=1.79, wpb=1295, bsz=90.5, num_updates=44200, lr=0.000951303, gnorm=0.598, train_wall=55, gb_free=18, wall=5075
2024-02-05 06:01:25 | INFO | train_inner | epoch 014:   2232 / 3236 loss=1.357, nll_loss=1.357, ppl=2.56, wps=2340.2, ups=1.78, wpb=1312, bsz=93.9, num_updates=44300, lr=0.000950229, gnorm=0.554, train_wall=56, gb_free=17.8, wall=5131
2024-02-05 06:02:21 | INFO | train_inner | epoch 014:   2332 / 3236 loss=1.371, nll_loss=1.371, ppl=2.59, wps=2317.3, ups=1.78, wpb=1300.7, bsz=90.9, num_updates=44400, lr=0.000949158, gnorm=0.584, train_wall=56, gb_free=18.1, wall=5188
2024-02-05 06:03:17 | INFO | train_inner | epoch 014:   2432 / 3236 loss=1.376, nll_loss=1.376, ppl=2.6, wps=2295.9, ups=1.79, wpb=1279.9, bsz=85.7, num_updates=44500, lr=0.000948091, gnorm=0.585, train_wall=55, gb_free=18, wall=5243
2024-02-05 06:04:13 | INFO | train_inner | epoch 014:   2532 / 3236 loss=1.405, nll_loss=1.405, ppl=2.65, wps=2324.6, ups=1.78, wpb=1307.4, bsz=90.2, num_updates=44600, lr=0.000947027, gnorm=0.588, train_wall=56, gb_free=17.8, wall=5300
2024-02-05 06:05:10 | INFO | train_inner | epoch 014:   2632 / 3236 loss=1.386, nll_loss=1.386, ppl=2.61, wps=2335.2, ups=1.77, wpb=1319.6, bsz=91, num_updates=44700, lr=0.000945968, gnorm=0.574, train_wall=56, gb_free=18.8, wall=5356
2024-02-05 06:06:06 | INFO | train_inner | epoch 014:   2732 / 3236 loss=1.368, nll_loss=1.368, ppl=2.58, wps=2347.9, ups=1.78, wpb=1317.7, bsz=94.3, num_updates=44800, lr=0.000944911, gnorm=0.576, train_wall=56, gb_free=18.6, wall=5412
2024-02-05 06:07:02 | INFO | train_inner | epoch 014:   2832 / 3236 loss=1.383, nll_loss=1.383, ppl=2.61, wps=2329.3, ups=1.77, wpb=1313.3, bsz=90.7, num_updates=44900, lr=0.000943858, gnorm=0.57, train_wall=56, gb_free=18.4, wall=5469
2024-02-05 06:07:58 | INFO | train_inner | epoch 014:   2932 / 3236 loss=1.377, nll_loss=1.377, ppl=2.6, wps=2323.1, ups=1.78, wpb=1305.9, bsz=87.5, num_updates=45000, lr=0.000942809, gnorm=0.598, train_wall=56, gb_free=18.1, wall=5525
2024-02-05 06:08:55 | INFO | train_inner | epoch 014:   3032 / 3236 loss=1.378, nll_loss=1.378, ppl=2.6, wps=2322.7, ups=1.77, wpb=1309.2, bsz=90, num_updates=45100, lr=0.000941763, gnorm=0.568, train_wall=56, gb_free=18.2, wall=5581
2024-02-05 06:09:51 | INFO | train_inner | epoch 014:   3132 / 3236 loss=1.385, nll_loss=1.385, ppl=2.61, wps=2302.9, ups=1.78, wpb=1292.8, bsz=88.2, num_updates=45200, lr=0.000940721, gnorm=0.595, train_wall=56, gb_free=18, wall=5637
2024-02-05 06:10:47 | INFO | train_inner | epoch 014:   3232 / 3236 loss=1.347, nll_loss=1.347, ppl=2.54, wps=2307.3, ups=1.78, wpb=1297, bsz=86.5, num_updates=45300, lr=0.000939682, gnorm=0.574, train_wall=56, gb_free=17.7, wall=5693
2024-02-05 06:10:49 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 06:10:49 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 06:11:25 | INFO | dev | epoch 014 | valid on 'dev' subset | loss 1.217 | nll_loss 1.217 | ppl 2.33 | wps 6569.8 | wpb 1146.2 | bsz 77.6 | num_updates 45304 | best_loss 1.217
2024-02-05 06:11:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 14 @ 45304 updates
2024-02-05 06:11:25 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint14.pt
2024-02-05 06:11:26 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint14.pt
2024-02-05 06:11:30 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint14.pt (epoch 14 @ 45304 updates, score 1.217) (writing took 5.53460227092728 seconds)
2024-02-05 06:11:30 | INFO | fairseq_cli.train | end of epoch 14 (average epoch stats below)
2024-02-05 06:11:30 | INFO | train | epoch 014 | loss 1.36 | nll_loss 1.36 | ppl 2.57 | wps 2265.4 | ups 1.74 | wpb 1302.4 | bsz 89.4 | num_updates 45304 | lr 0.00093964 | gnorm 0.575 | train_wall 1799 | gb_free 18.4 | wall 5737
2024-02-05 06:11:30 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 06:11:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 06:11:30 | INFO | fairseq.trainer | begin training epoch 15
2024-02-05 06:11:30 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 06:12:25 | INFO | train_inner | epoch 015:     96 / 3236 loss=1.249, nll_loss=1.249, ppl=2.38, wps=1335.7, ups=1.02, wpb=1304, bsz=89.3, num_updates=45400, lr=0.000938647, gnorm=0.556, train_wall=56, gb_free=18.2, wall=5791
2024-02-05 06:13:21 | INFO | train_inner | epoch 015:    196 / 3236 loss=1.293, nll_loss=1.293, ppl=2.45, wps=2311, ups=1.78, wpb=1297.1, bsz=90.9, num_updates=45500, lr=0.000937614, gnorm=0.598, train_wall=56, gb_free=17.8, wall=5847
2024-02-05 06:14:16 | INFO | train_inner | epoch 015:    296 / 3236 loss=1.3, nll_loss=1.3, ppl=2.46, wps=2358.7, ups=1.8, wpb=1311.3, bsz=94.1, num_updates=45600, lr=0.000936586, gnorm=0.576, train_wall=55, gb_free=17.5, wall=5903
2024-02-05 06:15:13 | INFO | train_inner | epoch 015:    396 / 3236 loss=1.289, nll_loss=1.289, ppl=2.44, wps=2301.2, ups=1.78, wpb=1292.5, bsz=88.5, num_updates=45700, lr=0.000935561, gnorm=0.571, train_wall=56, gb_free=17.9, wall=5959
2024-02-05 06:16:09 | INFO | train_inner | epoch 015:    496 / 3236 loss=1.301, nll_loss=1.301, ppl=2.46, wps=2338.3, ups=1.78, wpb=1312.5, bsz=87.9, num_updates=45800, lr=0.000934539, gnorm=0.567, train_wall=56, gb_free=17.5, wall=6015
2024-02-05 06:17:05 | INFO | train_inner | epoch 015:    596 / 3236 loss=1.321, nll_loss=1.321, ppl=2.5, wps=2317.6, ups=1.78, wpb=1302.2, bsz=92, num_updates=45900, lr=0.00093352, gnorm=0.586, train_wall=56, gb_free=17.8, wall=6071
2024-02-05 06:18:01 | INFO | train_inner | epoch 015:    696 / 3236 loss=1.294, nll_loss=1.294, ppl=2.45, wps=2304.6, ups=1.79, wpb=1284.9, bsz=86.7, num_updates=46000, lr=0.000932505, gnorm=0.576, train_wall=55, gb_free=17.7, wall=6127
2024-02-05 06:18:57 | INFO | train_inner | epoch 015:    796 / 3236 loss=1.306, nll_loss=1.306, ppl=2.47, wps=2309.7, ups=1.78, wpb=1298.4, bsz=87, num_updates=46100, lr=0.000931493, gnorm=0.572, train_wall=56, gb_free=17.4, wall=6183
2024-02-05 06:19:53 | INFO | train_inner | epoch 015:    896 / 3236 loss=1.326, nll_loss=1.326, ppl=2.51, wps=2332.9, ups=1.79, wpb=1304, bsz=92.1, num_updates=46200, lr=0.000930484, gnorm=0.576, train_wall=55, gb_free=18.2, wall=6239
2024-02-05 06:20:49 | INFO | train_inner | epoch 015:    996 / 3236 loss=1.332, nll_loss=1.332, ppl=2.52, wps=2320.5, ups=1.78, wpb=1307.1, bsz=87.8, num_updates=46300, lr=0.000929479, gnorm=0.581, train_wall=56, gb_free=18.4, wall=6296
2024-02-05 06:21:45 | INFO | train_inner | epoch 015:   1096 / 3236 loss=1.287, nll_loss=1.287, ppl=2.44, wps=2365.7, ups=1.79, wpb=1322.3, bsz=90.6, num_updates=46400, lr=0.000928477, gnorm=0.571, train_wall=55, gb_free=18, wall=6351
2024-02-05 06:22:41 | INFO | train_inner | epoch 015:   1196 / 3236 loss=1.341, nll_loss=1.341, ppl=2.53, wps=2292.5, ups=1.78, wpb=1286.1, bsz=92.8, num_updates=46500, lr=0.000927478, gnorm=0.582, train_wall=56, gb_free=18, wall=6407
2024-02-05 06:23:37 | INFO | train_inner | epoch 015:   1296 / 3236 loss=1.323, nll_loss=1.323, ppl=2.5, wps=2325.7, ups=1.79, wpb=1301.9, bsz=88.3, num_updates=46600, lr=0.000926482, gnorm=0.582, train_wall=55, gb_free=18.3, wall=6463
2024-02-05 06:24:33 | INFO | train_inner | epoch 015:   1396 / 3236 loss=1.325, nll_loss=1.325, ppl=2.51, wps=2320.8, ups=1.79, wpb=1293.9, bsz=89, num_updates=46700, lr=0.00092549, gnorm=0.577, train_wall=55, gb_free=17.9, wall=6519
2024-02-05 06:25:29 | INFO | train_inner | epoch 015:   1496 / 3236 loss=1.309, nll_loss=1.309, ppl=2.48, wps=2319.7, ups=1.78, wpb=1305.8, bsz=92, num_updates=46800, lr=0.0009245, gnorm=0.572, train_wall=56, gb_free=18.1, wall=6576
2024-02-05 06:26:25 | INFO | train_inner | epoch 015:   1596 / 3236 loss=1.33, nll_loss=1.33, ppl=2.51, wps=2312, ups=1.78, wpb=1295.7, bsz=84.5, num_updates=46900, lr=0.000923514, gnorm=0.583, train_wall=56, gb_free=17.7, wall=6632
2024-02-05 06:27:22 | INFO | train_inner | epoch 015:   1696 / 3236 loss=1.317, nll_loss=1.317, ppl=2.49, wps=2334.5, ups=1.77, wpb=1321, bsz=91, num_updates=47000, lr=0.000922531, gnorm=0.588, train_wall=56, gb_free=17.9, wall=6688
2024-02-05 06:28:18 | INFO | train_inner | epoch 015:   1796 / 3236 loss=1.299, nll_loss=1.299, ppl=2.46, wps=2323.4, ups=1.79, wpb=1298.5, bsz=89.8, num_updates=47100, lr=0.000921551, gnorm=0.575, train_wall=55, gb_free=18.1, wall=6744
2024-02-05 06:29:14 | INFO | train_inner | epoch 015:   1896 / 3236 loss=1.309, nll_loss=1.309, ppl=2.48, wps=2328.6, ups=1.79, wpb=1303, bsz=91.6, num_updates=47200, lr=0.000920575, gnorm=0.566, train_wall=55, gb_free=18.2, wall=6800
2024-02-05 06:30:10 | INFO | train_inner | epoch 015:   1996 / 3236 loss=1.291, nll_loss=1.291, ppl=2.45, wps=2328.1, ups=1.79, wpb=1303, bsz=92.2, num_updates=47300, lr=0.000919601, gnorm=0.559, train_wall=55, gb_free=17.4, wall=6856
2024-02-05 06:31:08 | INFO | train_inner | epoch 015:   2096 / 3236 loss=1.307, nll_loss=1.307, ppl=2.47, wps=2234.6, ups=1.72, wpb=1297.7, bsz=87.8, num_updates=47400, lr=0.00091863, gnorm=0.567, train_wall=58, gb_free=18.4, wall=6914
2024-02-05 06:32:08 | INFO | train_inner | epoch 015:   2196 / 3236 loss=1.308, nll_loss=1.308, ppl=2.48, wps=2134.4, ups=1.64, wpb=1297.7, bsz=86.1, num_updates=47500, lr=0.000917663, gnorm=0.561, train_wall=60, gb_free=17.7, wall=6975
2024-02-05 06:33:05 | INFO | train_inner | epoch 015:   2296 / 3236 loss=1.329, nll_loss=1.329, ppl=2.51, wps=2287.1, ups=1.77, wpb=1294.7, bsz=88.7, num_updates=47600, lr=0.000916698, gnorm=0.586, train_wall=56, gb_free=18.1, wall=7031
2024-02-05 06:34:01 | INFO | train_inner | epoch 015:   2396 / 3236 loss=1.324, nll_loss=1.324, ppl=2.5, wps=2371, ups=1.77, wpb=1337.5, bsz=97.4, num_updates=47700, lr=0.000915737, gnorm=0.571, train_wall=56, gb_free=18.2, wall=7088
2024-02-05 06:34:58 | INFO | train_inner | epoch 015:   2496 / 3236 loss=1.334, nll_loss=1.334, ppl=2.52, wps=2341.4, ups=1.78, wpb=1313.6, bsz=89.9, num_updates=47800, lr=0.000914779, gnorm=0.575, train_wall=56, gb_free=18.4, wall=7144
2024-02-05 06:35:54 | INFO | train_inner | epoch 015:   2596 / 3236 loss=1.332, nll_loss=1.332, ppl=2.52, wps=2339.1, ups=1.77, wpb=1319, bsz=88.2, num_updates=47900, lr=0.000913823, gnorm=0.565, train_wall=56, gb_free=17.3, wall=7200
2024-02-05 06:36:50 | INFO | train_inner | epoch 015:   2696 / 3236 loss=1.337, nll_loss=1.337, ppl=2.53, wps=2277.5, ups=1.78, wpb=1281.5, bsz=88.2, num_updates=48000, lr=0.000912871, gnorm=0.581, train_wall=56, gb_free=17.5, wall=7257
2024-02-05 06:37:47 | INFO | train_inner | epoch 015:   2796 / 3236 loss=1.327, nll_loss=1.327, ppl=2.51, wps=2308.3, ups=1.77, wpb=1303.8, bsz=86.8, num_updates=48100, lr=0.000911922, gnorm=0.582, train_wall=56, gb_free=18.4, wall=7313
2024-02-05 06:38:43 | INFO | train_inner | epoch 015:   2896 / 3236 loss=1.33, nll_loss=1.33, ppl=2.51, wps=2306.4, ups=1.79, wpb=1290, bsz=85.4, num_updates=48200, lr=0.000910975, gnorm=0.584, train_wall=55, gb_free=17.9, wall=7369
2024-02-05 06:39:39 | INFO | train_inner | epoch 015:   2996 / 3236 loss=1.307, nll_loss=1.307, ppl=2.47, wps=2325.6, ups=1.77, wpb=1310.2, bsz=91.9, num_updates=48300, lr=0.000910032, gnorm=0.562, train_wall=56, gb_free=17.5, wall=7425
2024-02-05 06:40:35 | INFO | train_inner | epoch 015:   3096 / 3236 loss=1.36, nll_loss=1.36, ppl=2.57, wps=2305, ups=1.78, wpb=1296.1, bsz=92.5, num_updates=48400, lr=0.000909091, gnorm=0.597, train_wall=56, gb_free=17.7, wall=7482
2024-02-05 06:41:31 | INFO | train_inner | epoch 015:   3196 / 3236 loss=1.311, nll_loss=1.311, ppl=2.48, wps=2315.1, ups=1.78, wpb=1301.7, bsz=85, num_updates=48500, lr=0.000908153, gnorm=0.566, train_wall=56, gb_free=17.7, wall=7538
2024-02-05 06:41:54 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 06:41:54 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 06:42:27 | INFO | dev | epoch 015 | valid on 'dev' subset | loss 1.177 | nll_loss 1.177 | ppl 2.26 | wps 6868.9 | wpb 1146.2 | bsz 77.6 | num_updates 48540 | best_loss 1.177
2024-02-05 06:42:27 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 15 @ 48540 updates
2024-02-05 06:42:27 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint15.pt
2024-02-05 06:42:29 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint15.pt
2024-02-05 06:42:33 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint15.pt (epoch 15 @ 48540 updates, score 1.177) (writing took 5.823099815985188 seconds)
2024-02-05 06:42:33 | INFO | fairseq_cli.train | end of epoch 15 (average epoch stats below)
2024-02-05 06:42:33 | INFO | train | epoch 015 | loss 1.315 | nll_loss 1.315 | ppl 2.49 | wps 2262 | ups 1.74 | wpb 1302.4 | bsz 89.4 | num_updates 48540 | lr 0.000907779 | gnorm 0.576 | train_wall 1806 | gb_free 17.8 | wall 7600
2024-02-05 06:42:33 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 06:42:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 06:42:33 | INFO | fairseq.trainer | begin training epoch 16
2024-02-05 06:42:33 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 06:43:07 | INFO | train_inner | epoch 016:     60 / 3236 loss=1.275, nll_loss=1.275, ppl=2.42, wps=1355.4, ups=1.04, wpb=1299.8, bsz=87.8, num_updates=48600, lr=0.000907218, gnorm=0.569, train_wall=55, gb_free=17.8, wall=7634
2024-02-05 06:44:03 | INFO | train_inner | epoch 016:    160 / 3236 loss=1.255, nll_loss=1.255, ppl=2.39, wps=2315, ups=1.79, wpb=1293.5, bsz=88.7, num_updates=48700, lr=0.000906287, gnorm=0.572, train_wall=55, gb_free=17.7, wall=7690
2024-02-05 06:44:59 | INFO | train_inner | epoch 016:    260 / 3236 loss=1.225, nll_loss=1.225, ppl=2.34, wps=2344.8, ups=1.79, wpb=1311.8, bsz=92.2, num_updates=48800, lr=0.000905357, gnorm=0.568, train_wall=55, gb_free=17.2, wall=7746
2024-02-05 06:45:55 | INFO | train_inner | epoch 016:    360 / 3236 loss=1.254, nll_loss=1.254, ppl=2.39, wps=2353.6, ups=1.79, wpb=1312.7, bsz=88.2, num_updates=48900, lr=0.000904431, gnorm=0.568, train_wall=55, gb_free=17.9, wall=7801
2024-02-05 06:46:51 | INFO | train_inner | epoch 016:    460 / 3236 loss=1.24, nll_loss=1.24, ppl=2.36, wps=2302.3, ups=1.77, wpb=1298.4, bsz=82.3, num_updates=49000, lr=0.000903508, gnorm=0.575, train_wall=56, gb_free=18.2, wall=7858
2024-02-05 06:47:47 | INFO | train_inner | epoch 016:    560 / 3236 loss=1.237, nll_loss=1.237, ppl=2.36, wps=2333.1, ups=1.8, wpb=1297.9, bsz=91.2, num_updates=49100, lr=0.000902587, gnorm=0.582, train_wall=55, gb_free=17.6, wall=7913
2024-02-05 06:48:43 | INFO | train_inner | epoch 016:    660 / 3236 loss=1.262, nll_loss=1.262, ppl=2.4, wps=2330.4, ups=1.78, wpb=1305.6, bsz=92.8, num_updates=49200, lr=0.00090167, gnorm=0.583, train_wall=55, gb_free=18.1, wall=7969
2024-02-05 06:49:39 | INFO | train_inner | epoch 016:    760 / 3236 loss=1.259, nll_loss=1.259, ppl=2.39, wps=2332.8, ups=1.79, wpb=1301.6, bsz=89.1, num_updates=49300, lr=0.000900755, gnorm=0.568, train_wall=55, gb_free=18.3, wall=8025
2024-02-05 06:50:35 | INFO | train_inner | epoch 016:    860 / 3236 loss=1.255, nll_loss=1.255, ppl=2.39, wps=2315.2, ups=1.78, wpb=1299.9, bsz=84.6, num_updates=49400, lr=0.000899843, gnorm=0.573, train_wall=56, gb_free=17.4, wall=8081
2024-02-05 06:51:31 | INFO | train_inner | epoch 016:    960 / 3236 loss=1.269, nll_loss=1.269, ppl=2.41, wps=2319.4, ups=1.78, wpb=1300.4, bsz=87.3, num_updates=49500, lr=0.000898933, gnorm=0.575, train_wall=56, gb_free=18.1, wall=8137
2024-02-05 06:52:27 | INFO | train_inner | epoch 016:   1060 / 3236 loss=1.283, nll_loss=1.283, ppl=2.43, wps=2301.9, ups=1.78, wpb=1295.4, bsz=90.1, num_updates=49600, lr=0.000898027, gnorm=0.59, train_wall=56, gb_free=17.7, wall=8194
2024-02-05 06:53:23 | INFO | train_inner | epoch 016:   1160 / 3236 loss=1.287, nll_loss=1.287, ppl=2.44, wps=2347.6, ups=1.8, wpb=1307.1, bsz=91, num_updates=49700, lr=0.000897123, gnorm=0.58, train_wall=55, gb_free=17.3, wall=8249
2024-02-05 06:54:19 | INFO | train_inner | epoch 016:   1260 / 3236 loss=1.264, nll_loss=1.264, ppl=2.4, wps=2313.1, ups=1.79, wpb=1295.2, bsz=86.3, num_updates=49800, lr=0.000896221, gnorm=0.572, train_wall=55, gb_free=17.9, wall=8305
2024-02-05 06:55:15 | INFO | train_inner | epoch 016:   1360 / 3236 loss=1.276, nll_loss=1.276, ppl=2.42, wps=2303.9, ups=1.79, wpb=1286.3, bsz=87.1, num_updates=49900, lr=0.000895323, gnorm=0.577, train_wall=55, gb_free=18.1, wall=8361
2024-02-05 06:56:11 | INFO | train_inner | epoch 016:   1460 / 3236 loss=1.278, nll_loss=1.278, ppl=2.43, wps=2337.4, ups=1.78, wpb=1314, bsz=94.6, num_updates=50000, lr=0.000894427, gnorm=0.571, train_wall=56, gb_free=17.9, wall=8417
2024-02-05 06:56:11 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 06:56:11 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 06:56:43 | INFO | dev | epoch 016 | valid on 'dev' subset | loss 1.168 | nll_loss 1.168 | ppl 2.25 | wps 7282.4 | wpb 1146.2 | bsz 77.6 | num_updates 50000 | best_loss 1.168
2024-02-05 06:56:43 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 50000 updates
2024-02-05 06:56:43 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_16_50000.pt
2024-02-05 06:56:44 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_16_50000.pt
2024-02-05 06:56:48 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_16_50000.pt (epoch 16 @ 50000 updates, score 1.168) (writing took 5.591019582934678 seconds)
2024-02-05 06:57:44 | INFO | train_inner | epoch 016:   1560 / 3236 loss=1.307, nll_loss=1.307, ppl=2.47, wps=1381.4, ups=1.07, wpb=1291.5, bsz=84.1, num_updates=50100, lr=0.000893534, gnorm=0.596, train_wall=56, gb_free=18.5, wall=8511
2024-02-05 06:58:40 | INFO | train_inner | epoch 016:   1660 / 3236 loss=1.287, nll_loss=1.287, ppl=2.44, wps=2308.4, ups=1.79, wpb=1290.9, bsz=86.5, num_updates=50200, lr=0.000892644, gnorm=0.58, train_wall=55, gb_free=18.4, wall=8567
2024-02-05 06:59:37 | INFO | train_inner | epoch 016:   1760 / 3236 loss=1.284, nll_loss=1.284, ppl=2.43, wps=2326.8, ups=1.78, wpb=1309, bsz=86, num_updates=50300, lr=0.000891756, gnorm=0.575, train_wall=56, gb_free=17.5, wall=8623
2024-02-05 07:00:33 | INFO | train_inner | epoch 016:   1860 / 3236 loss=1.26, nll_loss=1.26, ppl=2.39, wps=2350.3, ups=1.78, wpb=1320, bsz=94.6, num_updates=50400, lr=0.000890871, gnorm=0.55, train_wall=56, gb_free=18, wall=8679
2024-02-05 07:01:29 | INFO | train_inner | epoch 016:   1960 / 3236 loss=1.282, nll_loss=1.282, ppl=2.43, wps=2363.6, ups=1.8, wpb=1316.4, bsz=92.9, num_updates=50500, lr=0.000889988, gnorm=0.562, train_wall=55, gb_free=17.8, wall=8735
2024-02-05 07:02:24 | INFO | train_inner | epoch 016:   2060 / 3236 loss=1.289, nll_loss=1.289, ppl=2.44, wps=2290.7, ups=1.79, wpb=1281.3, bsz=93.3, num_updates=50600, lr=0.000889108, gnorm=0.585, train_wall=55, gb_free=17.8, wall=8791
2024-02-05 07:03:20 | INFO | train_inner | epoch 016:   2160 / 3236 loss=1.26, nll_loss=1.26, ppl=2.4, wps=2325.6, ups=1.78, wpb=1303.1, bsz=90.2, num_updates=50700, lr=0.000888231, gnorm=0.568, train_wall=56, gb_free=17.6, wall=8847
2024-02-05 07:04:17 | INFO | train_inner | epoch 016:   2260 / 3236 loss=1.289, nll_loss=1.289, ppl=2.44, wps=2322.2, ups=1.78, wpb=1307.7, bsz=89, num_updates=50800, lr=0.000887357, gnorm=0.576, train_wall=56, gb_free=17.2, wall=8903
2024-02-05 07:05:13 | INFO | train_inner | epoch 016:   2360 / 3236 loss=1.289, nll_loss=1.289, ppl=2.44, wps=2353.9, ups=1.79, wpb=1313.2, bsz=91.4, num_updates=50900, lr=0.000886484, gnorm=0.58, train_wall=55, gb_free=17.9, wall=8959
2024-02-05 07:06:09 | INFO | train_inner | epoch 016:   2460 / 3236 loss=1.287, nll_loss=1.287, ppl=2.44, wps=2304.7, ups=1.78, wpb=1295, bsz=89.5, num_updates=51000, lr=0.000885615, gnorm=0.588, train_wall=56, gb_free=18.1, wall=9015
2024-02-05 07:07:05 | INFO | train_inner | epoch 016:   2560 / 3236 loss=1.298, nll_loss=1.298, ppl=2.46, wps=2317.5, ups=1.78, wpb=1303, bsz=92.8, num_updates=51100, lr=0.000884748, gnorm=0.578, train_wall=56, gb_free=17.9, wall=9071
2024-02-05 07:08:01 | INFO | train_inner | epoch 016:   2660 / 3236 loss=1.286, nll_loss=1.286, ppl=2.44, wps=2333.4, ups=1.78, wpb=1307.5, bsz=88.9, num_updates=51200, lr=0.000883883, gnorm=0.577, train_wall=55, gb_free=17.9, wall=9127
2024-02-05 07:08:57 | INFO | train_inner | epoch 016:   2760 / 3236 loss=1.303, nll_loss=1.303, ppl=2.47, wps=2314.9, ups=1.77, wpb=1306.4, bsz=89, num_updates=51300, lr=0.000883022, gnorm=0.589, train_wall=56, gb_free=17.8, wall=9184
2024-02-05 07:09:54 | INFO | train_inner | epoch 016:   2860 / 3236 loss=1.29, nll_loss=1.29, ppl=2.45, wps=2325.3, ups=1.78, wpb=1307.1, bsz=89.8, num_updates=51400, lr=0.000882162, gnorm=0.581, train_wall=56, gb_free=17.9, wall=9240
2024-02-05 07:10:50 | INFO | train_inner | epoch 016:   2960 / 3236 loss=1.301, nll_loss=1.301, ppl=2.46, wps=2330.2, ups=1.78, wpb=1306.4, bsz=90.3, num_updates=51500, lr=0.000881305, gnorm=0.585, train_wall=56, gb_free=18, wall=9296
2024-02-05 07:11:46 | INFO | train_inner | epoch 016:   3060 / 3236 loss=1.311, nll_loss=1.311, ppl=2.48, wps=2320.9, ups=1.78, wpb=1301.7, bsz=90.6, num_updates=51600, lr=0.000880451, gnorm=0.582, train_wall=56, gb_free=17.9, wall=9352
2024-02-05 07:12:42 | INFO | train_inner | epoch 016:   3160 / 3236 loss=1.311, nll_loss=1.311, ppl=2.48, wps=2290.8, ups=1.77, wpb=1291.5, bsz=86.4, num_updates=51700, lr=0.000879599, gnorm=0.573, train_wall=56, gb_free=18.1, wall=9409
2024-02-05 07:13:25 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 07:13:25 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 07:13:56 | INFO | dev | epoch 016 | valid on 'dev' subset | loss 1.182 | nll_loss 1.182 | ppl 2.27 | wps 7298.9 | wpb 1146.2 | bsz 77.6 | num_updates 51776 | best_loss 1.168
2024-02-05 07:13:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 16 @ 51776 updates
2024-02-05 07:13:56 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint16.pt
2024-02-05 07:13:58 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint16.pt
2024-02-05 07:14:01 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint16.pt (epoch 16 @ 51776 updates, score 1.182) (writing took 4.375754053937271 seconds)
2024-02-05 07:14:01 | INFO | fairseq_cli.train | end of epoch 16 (average epoch stats below)
2024-02-05 07:14:01 | INFO | train | epoch 016 | loss 1.276 | nll_loss 1.276 | ppl 2.42 | wps 2232.8 | ups 1.71 | wpb 1302.4 | bsz 89.4 | num_updates 51776 | lr 0.000878953 | gnorm 0.576 | train_wall 1796 | gb_free 18.2 | wall 9487
2024-02-05 07:14:01 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 07:14:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 07:14:01 | INFO | fairseq.trainer | begin training epoch 17
2024-02-05 07:14:01 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 07:14:15 | INFO | train_inner | epoch 017:     24 / 3236 loss=1.275, nll_loss=1.275, ppl=2.42, wps=1393.1, ups=1.08, wpb=1295.8, bsz=90.2, num_updates=51800, lr=0.00087875, gnorm=0.584, train_wall=56, gb_free=17.6, wall=9502
2024-02-05 07:15:11 | INFO | train_inner | epoch 017:    124 / 3236 loss=1.217, nll_loss=1.217, ppl=2.32, wps=2334.7, ups=1.79, wpb=1304.7, bsz=88.9, num_updates=51900, lr=0.000877903, gnorm=0.587, train_wall=55, gb_free=18.1, wall=9557
2024-02-05 07:16:07 | INFO | train_inner | epoch 017:    224 / 3236 loss=1.182, nll_loss=1.182, ppl=2.27, wps=2325.4, ups=1.79, wpb=1300.8, bsz=86.9, num_updates=52000, lr=0.000877058, gnorm=0.574, train_wall=55, gb_free=17.5, wall=9613
2024-02-05 07:17:03 | INFO | train_inner | epoch 017:    324 / 3236 loss=1.232, nll_loss=1.232, ppl=2.35, wps=2368.4, ups=1.79, wpb=1324.1, bsz=93.7, num_updates=52100, lr=0.000876216, gnorm=0.575, train_wall=55, gb_free=18, wall=9669
2024-02-05 07:17:59 | INFO | train_inner | epoch 017:    424 / 3236 loss=1.213, nll_loss=1.213, ppl=2.32, wps=2359.8, ups=1.79, wpb=1318, bsz=91.3, num_updates=52200, lr=0.000875376, gnorm=0.567, train_wall=55, gb_free=18.3, wall=9725
2024-02-05 07:18:55 | INFO | train_inner | epoch 017:    524 / 3236 loss=1.222, nll_loss=1.222, ppl=2.33, wps=2319.9, ups=1.79, wpb=1296.7, bsz=87.6, num_updates=52300, lr=0.000874539, gnorm=0.588, train_wall=55, gb_free=18, wall=9781
2024-02-05 07:19:51 | INFO | train_inner | epoch 017:    624 / 3236 loss=1.224, nll_loss=1.224, ppl=2.34, wps=2308.3, ups=1.78, wpb=1298.3, bsz=89.7, num_updates=52400, lr=0.000873704, gnorm=0.583, train_wall=56, gb_free=17.6, wall=9837
2024-02-05 07:20:47 | INFO | train_inner | epoch 017:    724 / 3236 loss=1.218, nll_loss=1.218, ppl=2.33, wps=2327.7, ups=1.79, wpb=1303.8, bsz=87.5, num_updates=52500, lr=0.000872872, gnorm=0.574, train_wall=55, gb_free=17.6, wall=9893
2024-02-05 07:21:43 | INFO | train_inner | epoch 017:    824 / 3236 loss=1.239, nll_loss=1.239, ppl=2.36, wps=2371.4, ups=1.8, wpb=1319.3, bsz=96.2, num_updates=52600, lr=0.000872041, gnorm=0.581, train_wall=55, gb_free=18.1, wall=9949
2024-02-05 07:22:38 | INFO | train_inner | epoch 017:    924 / 3236 loss=1.237, nll_loss=1.237, ppl=2.36, wps=2341.1, ups=1.79, wpb=1308.3, bsz=94.2, num_updates=52700, lr=0.000871214, gnorm=0.584, train_wall=55, gb_free=18, wall=10005
2024-02-05 07:23:35 | INFO | train_inner | epoch 017:   1024 / 3236 loss=1.246, nll_loss=1.246, ppl=2.37, wps=2308.1, ups=1.78, wpb=1294.4, bsz=86.2, num_updates=52800, lr=0.000870388, gnorm=0.602, train_wall=56, gb_free=18, wall=10061
2024-02-05 07:24:30 | INFO | train_inner | epoch 017:   1124 / 3236 loss=1.241, nll_loss=1.241, ppl=2.36, wps=2288.8, ups=1.79, wpb=1278.4, bsz=86, num_updates=52900, lr=0.000869565, gnorm=0.591, train_wall=55, gb_free=18.1, wall=10117
2024-02-05 07:25:27 | INFO | train_inner | epoch 017:   1224 / 3236 loss=1.238, nll_loss=1.238, ppl=2.36, wps=2309.3, ups=1.78, wpb=1295.1, bsz=85.8, num_updates=53000, lr=0.000868744, gnorm=0.584, train_wall=56, gb_free=18.1, wall=10173
2024-02-05 07:26:23 | INFO | train_inner | epoch 017:   1324 / 3236 loss=1.246, nll_loss=1.246, ppl=2.37, wps=2297.7, ups=1.78, wpb=1292.4, bsz=89.8, num_updates=53100, lr=0.000867926, gnorm=0.593, train_wall=56, gb_free=17.7, wall=10229
2024-02-05 07:27:19 | INFO | train_inner | epoch 017:   1424 / 3236 loss=1.244, nll_loss=1.244, ppl=2.37, wps=2309.7, ups=1.79, wpb=1287.8, bsz=84.7, num_updates=53200, lr=0.00086711, gnorm=0.59, train_wall=55, gb_free=18.4, wall=10285
2024-02-05 07:28:15 | INFO | train_inner | epoch 017:   1524 / 3236 loss=1.237, nll_loss=1.237, ppl=2.36, wps=2298.7, ups=1.78, wpb=1290.5, bsz=87.1, num_updates=53300, lr=0.000866296, gnorm=0.586, train_wall=56, gb_free=18.1, wall=10341
2024-02-05 07:29:11 | INFO | train_inner | epoch 017:   1624 / 3236 loss=1.241, nll_loss=1.241, ppl=2.36, wps=2334.7, ups=1.79, wpb=1305.3, bsz=91.3, num_updates=53400, lr=0.000865485, gnorm=0.582, train_wall=55, gb_free=17.8, wall=10397
2024-02-05 07:30:07 | INFO | train_inner | epoch 017:   1724 / 3236 loss=1.26, nll_loss=1.26, ppl=2.39, wps=2316.5, ups=1.79, wpb=1297.6, bsz=87.3, num_updates=53500, lr=0.000864675, gnorm=0.586, train_wall=56, gb_free=17.8, wall=10453
2024-02-05 07:31:03 | INFO | train_inner | epoch 017:   1824 / 3236 loss=1.259, nll_loss=1.259, ppl=2.39, wps=2327.4, ups=1.79, wpb=1302.8, bsz=92.2, num_updates=53600, lr=0.000863868, gnorm=0.579, train_wall=55, gb_free=18.6, wall=10509
2024-02-05 07:31:59 | INFO | train_inner | epoch 017:   1924 / 3236 loss=1.238, nll_loss=1.238, ppl=2.36, wps=2310.9, ups=1.78, wpb=1301.5, bsz=89.5, num_updates=53700, lr=0.000863064, gnorm=0.578, train_wall=56, gb_free=17.7, wall=10565
2024-02-05 07:32:55 | INFO | train_inner | epoch 017:   2024 / 3236 loss=1.242, nll_loss=1.242, ppl=2.37, wps=2322, ups=1.78, wpb=1304.1, bsz=88.2, num_updates=53800, lr=0.000862261, gnorm=0.568, train_wall=56, gb_free=18, wall=10621
2024-02-05 07:33:51 | INFO | train_inner | epoch 017:   2124 / 3236 loss=1.256, nll_loss=1.256, ppl=2.39, wps=2306.8, ups=1.78, wpb=1296.1, bsz=86.8, num_updates=53900, lr=0.000861461, gnorm=0.575, train_wall=56, gb_free=18.4, wall=10678
2024-02-05 07:34:48 | INFO | train_inner | epoch 017:   2224 / 3236 loss=1.232, nll_loss=1.232, ppl=2.35, wps=2317, ups=1.77, wpb=1306.7, bsz=88.8, num_updates=54000, lr=0.000860663, gnorm=0.585, train_wall=56, gb_free=18.2, wall=10734
2024-02-05 07:35:44 | INFO | train_inner | epoch 017:   2324 / 3236 loss=1.235, nll_loss=1.235, ppl=2.35, wps=2317.8, ups=1.78, wpb=1302.8, bsz=90.6, num_updates=54100, lr=0.000859867, gnorm=0.578, train_wall=56, gb_free=17.3, wall=10790
2024-02-05 07:36:40 | INFO | train_inner | epoch 017:   2424 / 3236 loss=1.232, nll_loss=1.232, ppl=2.35, wps=2325.8, ups=1.78, wpb=1307.5, bsz=91.5, num_updates=54200, lr=0.000859074, gnorm=0.595, train_wall=56, gb_free=18.9, wall=10846
2024-02-05 07:37:39 | INFO | train_inner | epoch 017:   2524 / 3236 loss=1.247, nll_loss=1.247, ppl=2.37, wps=2172.6, ups=1.69, wpb=1284.5, bsz=83.3, num_updates=54300, lr=0.000858282, gnorm=0.595, train_wall=59, gb_free=17.7, wall=10906
2024-02-05 07:38:35 | INFO | train_inner | epoch 017:   2624 / 3236 loss=1.25, nll_loss=1.25, ppl=2.38, wps=2349.2, ups=1.79, wpb=1314.5, bsz=90.3, num_updates=54400, lr=0.000857493, gnorm=0.565, train_wall=55, gb_free=18.2, wall=10962
2024-02-05 07:39:31 | INFO | train_inner | epoch 017:   2724 / 3236 loss=1.219, nll_loss=1.219, ppl=2.33, wps=2332.3, ups=1.78, wpb=1313.8, bsz=88.1, num_updates=54500, lr=0.000856706, gnorm=0.569, train_wall=56, gb_free=18.5, wall=11018
2024-02-05 07:40:28 | INFO | train_inner | epoch 017:   2824 / 3236 loss=1.243, nll_loss=1.243, ppl=2.37, wps=2315.6, ups=1.79, wpb=1297.2, bsz=88.1, num_updates=54600, lr=0.000855921, gnorm=0.575, train_wall=56, gb_free=17.9, wall=11074
2024-02-05 07:41:24 | INFO | train_inner | epoch 017:   2924 / 3236 loss=1.23, nll_loss=1.23, ppl=2.35, wps=2344.6, ups=1.78, wpb=1315.6, bsz=92.5, num_updates=54700, lr=0.000855138, gnorm=0.57, train_wall=56, gb_free=17.4, wall=11130
2024-02-05 07:42:19 | INFO | train_inner | epoch 017:   3024 / 3236 loss=1.25, nll_loss=1.25, ppl=2.38, wps=2317.7, ups=1.79, wpb=1294.5, bsz=90.7, num_updates=54800, lr=0.000854358, gnorm=0.582, train_wall=55, gb_free=18, wall=11186
2024-02-05 07:43:15 | INFO | train_inner | epoch 017:   3124 / 3236 loss=1.233, nll_loss=1.233, ppl=2.35, wps=2346.7, ups=1.79, wpb=1310.9, bsz=93.1, num_updates=54900, lr=0.000853579, gnorm=0.571, train_wall=55, gb_free=18.5, wall=11242
2024-02-05 07:44:11 | INFO | train_inner | epoch 017:   3224 / 3236 loss=1.265, nll_loss=1.265, ppl=2.4, wps=2327.8, ups=1.78, wpb=1306, bsz=94, num_updates=55000, lr=0.000852803, gnorm=0.579, train_wall=56, gb_free=18.2, wall=11298
2024-02-05 07:44:18 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 07:44:18 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 07:45:31 | INFO | dev | epoch 017 | valid on 'dev' subset | loss 1.157 | nll_loss 1.157 | ppl 2.23 | wps 3145.3 | wpb 1146.2 | bsz 77.6 | num_updates 55012 | best_loss 1.157
2024-02-05 07:45:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 17 @ 55012 updates
2024-02-05 07:45:31 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint17.pt
2024-02-05 07:45:33 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint17.pt
2024-02-05 07:45:37 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint17.pt (epoch 17 @ 55012 updates, score 1.157) (writing took 5.505271991016343 seconds)
2024-02-05 07:45:37 | INFO | fairseq_cli.train | end of epoch 17 (average epoch stats below)
2024-02-05 07:45:37 | INFO | train | epoch 017 | loss 1.237 | nll_loss 1.237 | ppl 2.36 | wps 2222.7 | ups 1.71 | wpb 1302.4 | bsz 89.4 | num_updates 55012 | lr 0.00085271 | gnorm 0.581 | train_wall 1800 | gb_free 17.9 | wall 11383
2024-02-05 07:45:37 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 07:45:37 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 07:45:37 | INFO | fairseq.trainer | begin training epoch 18
2024-02-05 07:45:37 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 07:46:29 | INFO | train_inner | epoch 018:     88 / 3236 loss=1.189, nll_loss=1.189, ppl=2.28, wps=938, ups=0.73, wpb=1287.8, bsz=84.6, num_updates=55100, lr=0.000852029, gnorm=0.58, train_wall=56, gb_free=17.7, wall=11435
2024-02-05 07:47:25 | INFO | train_inner | epoch 018:    188 / 3236 loss=1.16, nll_loss=1.16, ppl=2.23, wps=2297.7, ups=1.78, wpb=1294.2, bsz=88.7, num_updates=55200, lr=0.000851257, gnorm=0.584, train_wall=56, gb_free=17.7, wall=11491
2024-02-05 07:48:21 | INFO | train_inner | epoch 018:    288 / 3236 loss=1.169, nll_loss=1.169, ppl=2.25, wps=2363.4, ups=1.78, wpb=1324.4, bsz=98.6, num_updates=55300, lr=0.000850487, gnorm=0.57, train_wall=56, gb_free=18.1, wall=11548
2024-02-05 07:49:17 | INFO | train_inner | epoch 018:    388 / 3236 loss=1.161, nll_loss=1.161, ppl=2.24, wps=2313.9, ups=1.78, wpb=1299.1, bsz=87.4, num_updates=55400, lr=0.000849719, gnorm=0.566, train_wall=56, gb_free=18.1, wall=11604
2024-02-05 07:50:13 | INFO | train_inner | epoch 018:    488 / 3236 loss=1.203, nll_loss=1.203, ppl=2.3, wps=2339.8, ups=1.79, wpb=1310.2, bsz=93.1, num_updates=55500, lr=0.000848953, gnorm=0.575, train_wall=55, gb_free=18.4, wall=11660
2024-02-05 07:51:10 | INFO | train_inner | epoch 018:    588 / 3236 loss=1.184, nll_loss=1.184, ppl=2.27, wps=2301.1, ups=1.78, wpb=1295, bsz=87.4, num_updates=55600, lr=0.000848189, gnorm=0.577, train_wall=56, gb_free=18.3, wall=11716
2024-02-05 07:52:06 | INFO | train_inner | epoch 018:    688 / 3236 loss=1.178, nll_loss=1.178, ppl=2.26, wps=2353.5, ups=1.78, wpb=1320.2, bsz=92.8, num_updates=55700, lr=0.000847427, gnorm=0.56, train_wall=56, gb_free=17.7, wall=11772
2024-02-05 07:53:02 | INFO | train_inner | epoch 018:    788 / 3236 loss=1.176, nll_loss=1.176, ppl=2.26, wps=2318.8, ups=1.78, wpb=1300.2, bsz=87.4, num_updates=55800, lr=0.000846668, gnorm=0.573, train_wall=56, gb_free=17.3, wall=11828
2024-02-05 07:53:58 | INFO | train_inner | epoch 018:    888 / 3236 loss=1.212, nll_loss=1.212, ppl=2.32, wps=2301.6, ups=1.77, wpb=1299.3, bsz=88.9, num_updates=55900, lr=0.00084591, gnorm=0.58, train_wall=56, gb_free=17.6, wall=11885
2024-02-05 07:54:54 | INFO | train_inner | epoch 018:    988 / 3236 loss=1.183, nll_loss=1.183, ppl=2.27, wps=2319.2, ups=1.79, wpb=1293.7, bsz=93.5, num_updates=56000, lr=0.000845154, gnorm=0.577, train_wall=55, gb_free=18.2, wall=11940
2024-02-05 07:55:50 | INFO | train_inner | epoch 018:   1088 / 3236 loss=1.215, nll_loss=1.215, ppl=2.32, wps=2317.7, ups=1.78, wpb=1300.7, bsz=88, num_updates=56100, lr=0.000844401, gnorm=0.583, train_wall=56, gb_free=18, wall=11996
2024-02-05 07:56:46 | INFO | train_inner | epoch 018:   1188 / 3236 loss=1.21, nll_loss=1.21, ppl=2.31, wps=2315.8, ups=1.79, wpb=1297, bsz=91, num_updates=56200, lr=0.000843649, gnorm=0.585, train_wall=55, gb_free=27.9, wall=12052
2024-02-05 07:57:43 | INFO | train_inner | epoch 018:   1288 / 3236 loss=1.208, nll_loss=1.208, ppl=2.31, wps=2266.8, ups=1.77, wpb=1280, bsz=85.8, num_updates=56300, lr=0.0008429, gnorm=0.595, train_wall=56, gb_free=17.7, wall=12109
2024-02-05 07:58:39 | INFO | train_inner | epoch 018:   1388 / 3236 loss=1.21, nll_loss=1.21, ppl=2.31, wps=2316, ups=1.78, wpb=1302.3, bsz=90.5, num_updates=56400, lr=0.000842152, gnorm=0.56, train_wall=56, gb_free=18, wall=12165
2024-02-05 07:59:35 | INFO | train_inner | epoch 018:   1488 / 3236 loss=1.203, nll_loss=1.203, ppl=2.3, wps=2302, ups=1.79, wpb=1288.3, bsz=91, num_updates=56500, lr=0.000841406, gnorm=0.591, train_wall=55, gb_free=18, wall=12221
2024-02-05 08:00:31 | INFO | train_inner | epoch 018:   1588 / 3236 loss=1.223, nll_loss=1.223, ppl=2.33, wps=2337.4, ups=1.78, wpb=1310, bsz=88.1, num_updates=56600, lr=0.000840663, gnorm=0.576, train_wall=56, gb_free=17.2, wall=12277
2024-02-05 08:01:27 | INFO | train_inner | epoch 018:   1688 / 3236 loss=1.21, nll_loss=1.21, ppl=2.31, wps=2327.2, ups=1.78, wpb=1307.6, bsz=88.2, num_updates=56700, lr=0.000839921, gnorm=0.573, train_wall=56, gb_free=18.4, wall=12333
2024-02-05 08:02:23 | INFO | train_inner | epoch 018:   1788 / 3236 loss=1.205, nll_loss=1.205, ppl=2.31, wps=2324.7, ups=1.77, wpb=1312, bsz=86.2, num_updates=56800, lr=0.000839181, gnorm=0.56, train_wall=56, gb_free=18, wall=12390
2024-02-05 08:03:19 | INFO | train_inner | epoch 018:   1888 / 3236 loss=1.206, nll_loss=1.206, ppl=2.31, wps=2316.8, ups=1.79, wpb=1297.6, bsz=90.4, num_updates=56900, lr=0.000838444, gnorm=0.579, train_wall=56, gb_free=18.2, wall=12446
2024-02-05 08:04:15 | INFO | train_inner | epoch 018:   1988 / 3236 loss=1.184, nll_loss=1.184, ppl=2.27, wps=2341.9, ups=1.79, wpb=1306.9, bsz=90, num_updates=57000, lr=0.000837708, gnorm=0.575, train_wall=55, gb_free=17.1, wall=12502
2024-02-05 08:05:12 | INFO | train_inner | epoch 018:   2088 / 3236 loss=1.225, nll_loss=1.225, ppl=2.34, wps=2267.5, ups=1.77, wpb=1279.5, bsz=84.6, num_updates=57100, lr=0.000836974, gnorm=0.586, train_wall=56, gb_free=17.9, wall=12558
2024-02-05 08:06:08 | INFO | train_inner | epoch 018:   2188 / 3236 loss=1.22, nll_loss=1.22, ppl=2.33, wps=2332.4, ups=1.77, wpb=1314.1, bsz=94.1, num_updates=57200, lr=0.000836242, gnorm=0.57, train_wall=56, gb_free=17.9, wall=12614
2024-02-05 08:07:04 | INFO | train_inner | epoch 018:   2288 / 3236 loss=1.209, nll_loss=1.209, ppl=2.31, wps=2343.9, ups=1.77, wpb=1321, bsz=94.1, num_updates=57300, lr=0.000835512, gnorm=0.579, train_wall=56, gb_free=17.8, wall=12671
2024-02-05 08:08:00 | INFO | train_inner | epoch 018:   2388 / 3236 loss=1.231, nll_loss=1.231, ppl=2.35, wps=2351.7, ups=1.78, wpb=1320.2, bsz=93.8, num_updates=57400, lr=0.000834784, gnorm=0.568, train_wall=56, gb_free=17.5, wall=12727
2024-02-05 08:08:57 | INFO | train_inner | epoch 018:   2488 / 3236 loss=1.227, nll_loss=1.227, ppl=2.34, wps=2326.3, ups=1.78, wpb=1308.2, bsz=87.2, num_updates=57500, lr=0.000834058, gnorm=0.587, train_wall=56, gb_free=17.7, wall=12783
2024-02-05 08:09:53 | INFO | train_inner | epoch 018:   2588 / 3236 loss=1.211, nll_loss=1.211, ppl=2.32, wps=2327.3, ups=1.78, wpb=1308.2, bsz=88.4, num_updates=57600, lr=0.000833333, gnorm=0.585, train_wall=56, gb_free=18.1, wall=12839
2024-02-05 08:10:49 | INFO | train_inner | epoch 018:   2688 / 3236 loss=1.219, nll_loss=1.219, ppl=2.33, wps=2298.1, ups=1.77, wpb=1295.8, bsz=88, num_updates=57700, lr=0.000832611, gnorm=0.584, train_wall=56, gb_free=17.7, wall=12896
2024-02-05 08:11:46 | INFO | train_inner | epoch 018:   2788 / 3236 loss=1.236, nll_loss=1.236, ppl=2.36, wps=2303.5, ups=1.78, wpb=1295.2, bsz=86.8, num_updates=57800, lr=0.00083189, gnorm=0.582, train_wall=56, gb_free=18.1, wall=12952
2024-02-05 08:12:42 | INFO | train_inner | epoch 018:   2888 / 3236 loss=1.249, nll_loss=1.249, ppl=2.38, wps=2307.2, ups=1.78, wpb=1295.8, bsz=85.6, num_updates=57900, lr=0.000831172, gnorm=0.596, train_wall=56, gb_free=17.6, wall=13008
2024-02-05 08:13:38 | INFO | train_inner | epoch 018:   2988 / 3236 loss=1.233, nll_loss=1.233, ppl=2.35, wps=2317.2, ups=1.77, wpb=1307.7, bsz=89.9, num_updates=58000, lr=0.000830455, gnorm=0.582, train_wall=56, gb_free=17.9, wall=13065
2024-02-05 08:14:35 | INFO | train_inner | epoch 018:   3088 / 3236 loss=1.239, nll_loss=1.239, ppl=2.36, wps=2330.1, ups=1.77, wpb=1313.2, bsz=91.6, num_updates=58100, lr=0.00082974, gnorm=0.584, train_wall=56, gb_free=17.8, wall=13121
2024-02-05 08:15:31 | INFO | train_inner | epoch 018:   3188 / 3236 loss=1.197, nll_loss=1.197, ppl=2.29, wps=2313.9, ups=1.78, wpb=1299, bsz=86.5, num_updates=58200, lr=0.000829027, gnorm=0.568, train_wall=56, gb_free=17.6, wall=13177
2024-02-05 08:15:57 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 08:15:57 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 08:17:25 | INFO | dev | epoch 018 | valid on 'dev' subset | loss 1.151 | nll_loss 1.151 | ppl 2.22 | wps 2623.3 | wpb 1146.2 | bsz 77.6 | num_updates 58248 | best_loss 1.151
2024-02-05 08:17:25 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 18 @ 58248 updates
2024-02-05 08:17:25 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint18.pt
2024-02-05 08:17:27 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint18.pt
2024-02-05 08:17:31 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint18.pt (epoch 18 @ 58248 updates, score 1.151) (writing took 5.679437865968794 seconds)
2024-02-05 08:17:31 | INFO | fairseq_cli.train | end of epoch 18 (average epoch stats below)
2024-02-05 08:17:31 | INFO | train | epoch 018 | loss 1.206 | nll_loss 1.206 | ppl 2.31 | wps 2201.7 | ups 1.69 | wpb 1302.4 | bsz 89.4 | num_updates 58248 | lr 0.000828685 | gnorm 0.578 | train_wall 1802 | gb_free 18.5 | wall 13297
2024-02-05 08:17:31 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 08:17:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 08:17:32 | INFO | fairseq.trainer | begin training epoch 19
2024-02-05 08:17:32 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 08:18:04 | INFO | train_inner | epoch 019:     52 / 3236 loss=1.171, nll_loss=1.171, ppl=2.25, wps=841.5, ups=0.65, wpb=1292.3, bsz=89.4, num_updates=58300, lr=0.000828315, gnorm=0.576, train_wall=56, gb_free=17.2, wall=13331
2024-02-05 08:19:00 | INFO | train_inner | epoch 019:    152 / 3236 loss=1.151, nll_loss=1.151, ppl=2.22, wps=2320.7, ups=1.79, wpb=1299.5, bsz=88, num_updates=58400, lr=0.000827606, gnorm=0.583, train_wall=55, gb_free=18, wall=13387
2024-02-05 08:19:56 | INFO | train_inner | epoch 019:    252 / 3236 loss=1.158, nll_loss=1.158, ppl=2.23, wps=2322.6, ups=1.79, wpb=1297.3, bsz=85.4, num_updates=58500, lr=0.000826898, gnorm=0.597, train_wall=55, gb_free=17.9, wall=13442
2024-02-05 08:20:52 | INFO | train_inner | epoch 019:    352 / 3236 loss=1.146, nll_loss=1.146, ppl=2.21, wps=2282.7, ups=1.78, wpb=1282.8, bsz=85, num_updates=58600, lr=0.000826192, gnorm=0.594, train_wall=56, gb_free=18.3, wall=13499
2024-02-05 08:21:48 | INFO | train_inner | epoch 019:    452 / 3236 loss=1.149, nll_loss=1.149, ppl=2.22, wps=2373.1, ups=1.79, wpb=1325.6, bsz=92.6, num_updates=58700, lr=0.000825488, gnorm=0.58, train_wall=55, gb_free=18.5, wall=13554
2024-02-05 08:22:44 | INFO | train_inner | epoch 019:    552 / 3236 loss=1.164, nll_loss=1.164, ppl=2.24, wps=2300.6, ups=1.78, wpb=1292.6, bsz=87.4, num_updates=58800, lr=0.000824786, gnorm=0.58, train_wall=56, gb_free=18, wall=13611
2024-02-05 08:23:40 | INFO | train_inner | epoch 019:    652 / 3236 loss=1.175, nll_loss=1.175, ppl=2.26, wps=2335.7, ups=1.78, wpb=1312.3, bsz=92.8, num_updates=58900, lr=0.000824086, gnorm=0.578, train_wall=56, gb_free=18.1, wall=13667
2024-02-05 08:24:36 | INFO | train_inner | epoch 019:    752 / 3236 loss=1.173, nll_loss=1.173, ppl=2.26, wps=2337.7, ups=1.79, wpb=1307.5, bsz=89.9, num_updates=59000, lr=0.000823387, gnorm=0.582, train_wall=55, gb_free=17.7, wall=13723
2024-02-05 08:25:33 | INFO | train_inner | epoch 019:    852 / 3236 loss=1.192, nll_loss=1.192, ppl=2.28, wps=2321, ups=1.78, wpb=1305.4, bsz=92.2, num_updates=59100, lr=0.00082269, gnorm=0.594, train_wall=56, gb_free=18.4, wall=13779
2024-02-05 08:26:29 | INFO | train_inner | epoch 019:    952 / 3236 loss=1.147, nll_loss=1.147, ppl=2.22, wps=2321.7, ups=1.78, wpb=1303.9, bsz=87, num_updates=59200, lr=0.000821995, gnorm=0.579, train_wall=56, gb_free=17.4, wall=13835
2024-02-05 08:27:25 | INFO | train_inner | epoch 019:   1052 / 3236 loss=1.145, nll_loss=1.145, ppl=2.21, wps=2330.7, ups=1.78, wpb=1310.4, bsz=92.4, num_updates=59300, lr=0.000821302, gnorm=0.568, train_wall=56, gb_free=18.4, wall=13891
2024-02-05 08:28:21 | INFO | train_inner | epoch 019:   1152 / 3236 loss=1.174, nll_loss=1.174, ppl=2.26, wps=2355, ups=1.78, wpb=1324.1, bsz=96.4, num_updates=59400, lr=0.00082061, gnorm=0.567, train_wall=56, gb_free=18.5, wall=13948
2024-02-05 08:29:19 | INFO | train_inner | epoch 019:   1252 / 3236 loss=1.184, nll_loss=1.184, ppl=2.27, wps=2253.7, ups=1.74, wpb=1297, bsz=90.3, num_updates=59500, lr=0.00081992, gnorm=0.604, train_wall=56, gb_free=18.2, wall=14005
2024-02-05 08:30:17 | INFO | train_inner | epoch 019:   1352 / 3236 loss=1.157, nll_loss=1.157, ppl=2.23, wps=2270.7, ups=1.72, wpb=1319.3, bsz=93.3, num_updates=59600, lr=0.000819232, gnorm=0.574, train_wall=55, gb_free=17.7, wall=14063
2024-02-05 08:31:17 | INFO | train_inner | epoch 019:   1452 / 3236 loss=1.198, nll_loss=1.198, ppl=2.29, wps=2161.8, ups=1.68, wpb=1289.7, bsz=91.4, num_updates=59700, lr=0.000818546, gnorm=0.61, train_wall=56, gb_free=18.3, wall=14123
2024-02-05 08:32:14 | INFO | train_inner | epoch 019:   1552 / 3236 loss=1.195, nll_loss=1.195, ppl=2.29, wps=2277.1, ups=1.74, wpb=1306.4, bsz=88.8, num_updates=59800, lr=0.000817861, gnorm=0.592, train_wall=56, gb_free=18.4, wall=14180
2024-02-05 08:33:15 | INFO | train_inner | epoch 019:   1652 / 3236 loss=1.181, nll_loss=1.181, ppl=2.27, wps=2139.2, ups=1.64, wpb=1305.6, bsz=87.5, num_updates=59900, lr=0.000817178, gnorm=0.576, train_wall=55, gb_free=17.9, wall=14241
2024-02-05 08:34:25 | INFO | train_inner | epoch 019:   1752 / 3236 loss=1.181, nll_loss=1.181, ppl=2.27, wps=1867.7, ups=1.43, wpb=1306.9, bsz=93.8, num_updates=60000, lr=0.000816497, gnorm=0.579, train_wall=55, gb_free=18.8, wall=14311
2024-02-05 08:35:29 | INFO | train_inner | epoch 019:   1852 / 3236 loss=1.176, nll_loss=1.176, ppl=2.26, wps=2029.6, ups=1.56, wpb=1301.3, bsz=89.8, num_updates=60100, lr=0.000815817, gnorm=0.584, train_wall=56, gb_free=17.9, wall=14375
2024-02-05 08:36:29 | INFO | train_inner | epoch 019:   1952 / 3236 loss=1.198, nll_loss=1.198, ppl=2.29, wps=2160.4, ups=1.66, wpb=1297.6, bsz=85.8, num_updates=60200, lr=0.000815139, gnorm=0.582, train_wall=56, gb_free=17.8, wall=14436
2024-02-05 08:37:36 | INFO | train_inner | epoch 019:   2052 / 3236 loss=1.162, nll_loss=1.162, ppl=2.24, wps=1924.8, ups=1.49, wpb=1292.6, bsz=87.2, num_updates=60300, lr=0.000814463, gnorm=0.579, train_wall=56, gb_free=18.2, wall=14503
2024-02-05 08:38:40 | INFO | train_inner | epoch 019:   2152 / 3236 loss=1.182, nll_loss=1.182, ppl=2.27, wps=2056.1, ups=1.58, wpb=1304, bsz=87, num_updates=60400, lr=0.000813788, gnorm=0.589, train_wall=55, gb_free=18.4, wall=14566
2024-02-05 08:39:51 | INFO | train_inner | epoch 019:   2252 / 3236 loss=1.199, nll_loss=1.199, ppl=2.3, wps=1845.8, ups=1.4, wpb=1314, bsz=88.9, num_updates=60500, lr=0.000813116, gnorm=0.576, train_wall=55, gb_free=18.5, wall=14637
2024-02-05 08:40:58 | INFO | train_inner | epoch 019:   2352 / 3236 loss=1.187, nll_loss=1.187, ppl=2.28, wps=1930.4, ups=1.49, wpb=1295.5, bsz=86.2, num_updates=60600, lr=0.000812444, gnorm=0.59, train_wall=56, gb_free=17.7, wall=14704
2024-02-05 08:42:10 | INFO | train_inner | epoch 019:   2452 / 3236 loss=1.186, nll_loss=1.186, ppl=2.27, wps=1788.7, ups=1.39, wpb=1285.3, bsz=87.4, num_updates=60700, lr=0.000811775, gnorm=0.6, train_wall=55, gb_free=17.3, wall=14776
2024-02-05 08:43:24 | INFO | train_inner | epoch 019:   2552 / 3236 loss=1.192, nll_loss=1.192, ppl=2.28, wps=1759.8, ups=1.36, wpb=1297.8, bsz=89.4, num_updates=60800, lr=0.000811107, gnorm=0.579, train_wall=58, gb_free=17.9, wall=14850
2024-02-05 08:44:29 | INFO | train_inner | epoch 019:   2652 / 3236 loss=1.179, nll_loss=1.179, ppl=2.26, wps=1949.9, ups=1.52, wpb=1279.7, bsz=86.3, num_updates=60900, lr=0.000810441, gnorm=0.585, train_wall=55, gb_free=18.4, wall=14916
2024-02-05 08:45:37 | INFO | train_inner | epoch 019:   2752 / 3236 loss=1.183, nll_loss=1.183, ppl=2.27, wps=1933.5, ups=1.48, wpb=1308, bsz=88.6, num_updates=61000, lr=0.000809776, gnorm=0.579, train_wall=56, gb_free=18.2, wall=14983
2024-02-05 08:46:47 | INFO | train_inner | epoch 019:   2852 / 3236 loss=1.182, nll_loss=1.182, ppl=2.27, wps=1870.1, ups=1.44, wpb=1302.1, bsz=89.8, num_updates=61100, lr=0.000809113, gnorm=0.582, train_wall=56, gb_free=18.1, wall=15053
2024-02-05 08:48:01 | INFO | train_inner | epoch 019:   2952 / 3236 loss=1.17, nll_loss=1.17, ppl=2.25, wps=1768.7, ups=1.35, wpb=1313.5, bsz=93.9, num_updates=61200, lr=0.000808452, gnorm=0.561, train_wall=55, gb_free=18, wall=15127
2024-02-05 08:49:10 | INFO | train_inner | epoch 019:   3052 / 3236 loss=1.186, nll_loss=1.186, ppl=2.28, wps=1846.1, ups=1.44, wpb=1286, bsz=86.9, num_updates=61300, lr=0.000807792, gnorm=0.576, train_wall=55, gb_free=17, wall=15197
2024-02-05 08:50:27 | INFO | train_inner | epoch 019:   3152 / 3236 loss=1.203, nll_loss=1.203, ppl=2.3, wps=1710.4, ups=1.3, wpb=1312.2, bsz=91.4, num_updates=61400, lr=0.000807134, gnorm=0.575, train_wall=55, gb_free=17.6, wall=15274
2024-02-05 08:51:28 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 08:51:28 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 08:53:29 | INFO | dev | epoch 019 | valid on 'dev' subset | loss 1.138 | nll_loss 1.138 | ppl 2.2 | wps 1906.8 | wpb 1146.2 | bsz 77.6 | num_updates 61484 | best_loss 1.138
2024-02-05 08:53:29 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 19 @ 61484 updates
2024-02-05 08:53:29 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint19.pt
2024-02-05 08:53:30 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint19.pt
2024-02-05 08:53:35 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint19.pt (epoch 19 @ 61484 updates, score 1.138) (writing took 5.6932329789269716 seconds)
2024-02-05 08:53:35 | INFO | fairseq_cli.train | end of epoch 19 (average epoch stats below)
2024-02-05 08:53:35 | INFO | train | epoch 019 | loss 1.176 | nll_loss 1.176 | ppl 2.26 | wps 1947.9 | ups 1.5 | wpb 1302.4 | bsz 89.4 | num_updates 61484 | lr 0.000806583 | gnorm 0.583 | train_wall 1800 | gb_free 18.3 | wall 15461
2024-02-05 08:53:35 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 08:53:35 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 08:53:35 | INFO | fairseq.trainer | begin training epoch 20
2024-02-05 08:53:35 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 08:53:48 | INFO | train_inner | epoch 020:     16 / 3236 loss=1.195, nll_loss=1.195, ppl=2.29, wps=653.4, ups=0.5, wpb=1311.1, bsz=88.2, num_updates=61500, lr=0.000806478, gnorm=0.577, train_wall=56, gb_free=18.5, wall=15474
2024-02-05 08:54:48 | INFO | train_inner | epoch 020:    116 / 3236 loss=1.128, nll_loss=1.128, ppl=2.18, wps=2144.2, ups=1.65, wpb=1299.4, bsz=89.2, num_updates=61600, lr=0.000805823, gnorm=0.586, train_wall=56, gb_free=18.7, wall=15535
2024-02-05 08:55:46 | INFO | train_inner | epoch 020:    216 / 3236 loss=1.096, nll_loss=1.096, ppl=2.14, wps=2247.7, ups=1.72, wpb=1305.5, bsz=88.5, num_updates=61700, lr=0.00080517, gnorm=0.565, train_wall=56, gb_free=17.9, wall=15593
2024-02-05 08:56:43 | INFO | train_inner | epoch 020:    316 / 3236 loss=1.125, nll_loss=1.125, ppl=2.18, wps=2271.2, ups=1.78, wpb=1274.9, bsz=81.6, num_updates=61800, lr=0.000804518, gnorm=0.589, train_wall=56, gb_free=18, wall=15649
2024-02-05 08:57:39 | INFO | train_inner | epoch 020:    416 / 3236 loss=1.143, nll_loss=1.143, ppl=2.21, wps=2332.5, ups=1.77, wpb=1317.3, bsz=87.2, num_updates=61900, lr=0.000803868, gnorm=0.586, train_wall=56, gb_free=17.7, wall=15705
2024-02-05 08:58:36 | INFO | train_inner | epoch 020:    516 / 3236 loss=1.141, nll_loss=1.141, ppl=2.21, wps=2306.8, ups=1.76, wpb=1308.4, bsz=92.2, num_updates=62000, lr=0.000803219, gnorm=0.576, train_wall=56, gb_free=18.7, wall=15762
2024-02-05 08:59:41 | INFO | train_inner | epoch 020:    616 / 3236 loss=1.137, nll_loss=1.137, ppl=2.2, wps=1990.8, ups=1.52, wpb=1306.7, bsz=91.7, num_updates=62100, lr=0.000802572, gnorm=0.571, train_wall=55, gb_free=18.2, wall=15828
2024-02-05 09:00:54 | INFO | train_inner | epoch 020:    716 / 3236 loss=1.139, nll_loss=1.139, ppl=2.2, wps=1790.5, ups=1.38, wpb=1299.6, bsz=92.2, num_updates=62200, lr=0.000801927, gnorm=0.567, train_wall=56, gb_free=18.6, wall=15900
2024-02-05 09:02:04 | INFO | train_inner | epoch 020:    816 / 3236 loss=1.136, nll_loss=1.136, ppl=2.2, wps=1868.1, ups=1.43, wpb=1309.5, bsz=88.6, num_updates=62300, lr=0.000801283, gnorm=0.585, train_wall=56, gb_free=18.4, wall=15971
2024-02-05 09:03:21 | INFO | train_inner | epoch 020:    916 / 3236 loss=1.127, nll_loss=1.127, ppl=2.18, wps=1691.4, ups=1.3, wpb=1299.2, bsz=89.2, num_updates=62400, lr=0.000800641, gnorm=0.591, train_wall=55, gb_free=18, wall=16047
2024-02-05 09:04:31 | INFO | train_inner | epoch 020:   1016 / 3236 loss=1.15, nll_loss=1.15, ppl=2.22, wps=1886.3, ups=1.43, wpb=1317.4, bsz=89.6, num_updates=62500, lr=0.0008, gnorm=0.574, train_wall=56, gb_free=18.6, wall=16117
2024-02-05 09:05:44 | INFO | train_inner | epoch 020:   1116 / 3236 loss=1.128, nll_loss=1.128, ppl=2.19, wps=1804.8, ups=1.37, wpb=1320.6, bsz=93.6, num_updates=62600, lr=0.000799361, gnorm=0.56, train_wall=55, gb_free=17.1, wall=16190
2024-02-05 09:06:58 | INFO | train_inner | epoch 020:   1216 / 3236 loss=1.149, nll_loss=1.149, ppl=2.22, wps=1775.7, ups=1.35, wpb=1316.8, bsz=95.4, num_updates=62700, lr=0.000798723, gnorm=0.57, train_wall=56, gb_free=18.4, wall=16265
2024-02-05 09:08:08 | INFO | train_inner | epoch 020:   1316 / 3236 loss=1.158, nll_loss=1.158, ppl=2.23, wps=1841.1, ups=1.43, wpb=1283.4, bsz=87, num_updates=62800, lr=0.000798087, gnorm=0.603, train_wall=56, gb_free=18.1, wall=16334
2024-02-05 09:09:16 | INFO | train_inner | epoch 020:   1416 / 3236 loss=1.139, nll_loss=1.139, ppl=2.2, wps=1911.2, ups=1.46, wpb=1309.1, bsz=88, num_updates=62900, lr=0.000797452, gnorm=0.59, train_wall=55, gb_free=18.1, wall=16403
2024-02-05 09:10:24 | INFO | train_inner | epoch 020:   1516 / 3236 loss=1.152, nll_loss=1.152, ppl=2.22, wps=1916.2, ups=1.48, wpb=1293.3, bsz=82.6, num_updates=63000, lr=0.000796819, gnorm=0.589, train_wall=56, gb_free=18.4, wall=16470
2024-02-05 09:11:46 | INFO | train_inner | epoch 020:   1616 / 3236 loss=1.148, nll_loss=1.148, ppl=2.22, wps=1611.1, ups=1.22, wpb=1323.8, bsz=93.4, num_updates=63100, lr=0.000796187, gnorm=0.568, train_wall=56, gb_free=18.1, wall=16552
2024-02-05 09:13:03 | INFO | train_inner | epoch 020:   1716 / 3236 loss=1.163, nll_loss=1.163, ppl=2.24, wps=1688.8, ups=1.3, wpb=1295.2, bsz=89.1, num_updates=63200, lr=0.000795557, gnorm=0.595, train_wall=56, gb_free=18.2, wall=16629
2024-02-05 09:14:24 | INFO | train_inner | epoch 020:   1816 / 3236 loss=1.166, nll_loss=1.166, ppl=2.24, wps=1599.4, ups=1.23, wpb=1301.7, bsz=96, num_updates=63300, lr=0.000794929, gnorm=0.58, train_wall=55, gb_free=18.7, wall=16710
2024-02-05 09:15:42 | INFO | train_inner | epoch 020:   1916 / 3236 loss=1.154, nll_loss=1.154, ppl=2.23, wps=1688.2, ups=1.29, wpb=1312.3, bsz=89.8, num_updates=63400, lr=0.000794301, gnorm=0.582, train_wall=56, gb_free=17.8, wall=16788
2024-02-05 09:16:50 | INFO | train_inner | epoch 020:   2016 / 3236 loss=1.182, nll_loss=1.182, ppl=2.27, wps=1861.5, ups=1.46, wpb=1275.9, bsz=83, num_updates=63500, lr=0.000793676, gnorm=0.607, train_wall=56, gb_free=18.5, wall=16857
2024-02-05 09:18:08 | INFO | train_inner | epoch 020:   2116 / 3236 loss=1.17, nll_loss=1.17, ppl=2.25, wps=1684.5, ups=1.3, wpb=1300.7, bsz=86.6, num_updates=63600, lr=0.000793052, gnorm=0.61, train_wall=56, gb_free=18.5, wall=16934
2024-02-05 09:19:24 | INFO | train_inner | epoch 020:   2216 / 3236 loss=1.168, nll_loss=1.168, ppl=2.25, wps=1689.7, ups=1.31, wpb=1294.7, bsz=91.8, num_updates=63700, lr=0.000792429, gnorm=0.58, train_wall=55, gb_free=17.8, wall=17011
2024-02-05 09:20:48 | INFO | train_inner | epoch 020:   2316 / 3236 loss=1.15, nll_loss=1.15, ppl=2.22, wps=1554.8, ups=1.19, wpb=1309.5, bsz=87.8, num_updates=63800, lr=0.000791808, gnorm=0.586, train_wall=56, gb_free=18.2, wall=17095
2024-02-05 09:22:12 | INFO | train_inner | epoch 020:   2416 / 3236 loss=1.146, nll_loss=1.146, ppl=2.21, wps=1559.7, ups=1.2, wpb=1299.5, bsz=88.7, num_updates=63900, lr=0.000791188, gnorm=0.584, train_wall=55, gb_free=18, wall=17178
2024-02-05 09:23:31 | INFO | train_inner | epoch 020:   2516 / 3236 loss=1.157, nll_loss=1.157, ppl=2.23, wps=1622.8, ups=1.25, wpb=1294.1, bsz=90.6, num_updates=64000, lr=0.000790569, gnorm=0.582, train_wall=56, gb_free=17.5, wall=17258
2024-02-05 09:24:51 | INFO | train_inner | epoch 020:   2616 / 3236 loss=1.158, nll_loss=1.158, ppl=2.23, wps=1614.4, ups=1.25, wpb=1290.3, bsz=87.2, num_updates=64100, lr=0.000789953, gnorm=0.586, train_wall=55, gb_free=17.2, wall=17338
2024-02-05 09:26:10 | INFO | train_inner | epoch 020:   2716 / 3236 loss=1.154, nll_loss=1.154, ppl=2.22, wps=1649.5, ups=1.27, wpb=1303.5, bsz=88.4, num_updates=64200, lr=0.000789337, gnorm=0.584, train_wall=55, gb_free=18.8, wall=17417
2024-02-05 09:27:24 | INFO | train_inner | epoch 020:   2816 / 3236 loss=1.167, nll_loss=1.167, ppl=2.25, wps=1753.8, ups=1.36, wpb=1288.6, bsz=87, num_updates=64300, lr=0.000788723, gnorm=0.582, train_wall=56, gb_free=17.2, wall=17490
2024-02-05 09:28:47 | INFO | train_inner | epoch 020:   2916 / 3236 loss=1.18, nll_loss=1.18, ppl=2.27, wps=1557.7, ups=1.2, wpb=1294.4, bsz=89, num_updates=64400, lr=0.00078811, gnorm=0.587, train_wall=55, gb_free=18.3, wall=17573
2024-02-05 09:30:06 | INFO | train_inner | epoch 020:   3016 / 3236 loss=1.168, nll_loss=1.168, ppl=2.25, wps=1641, ups=1.26, wpb=1304.3, bsz=88.5, num_updates=64500, lr=0.000787499, gnorm=0.585, train_wall=56, gb_free=18, wall=17653
2024-02-05 09:31:43 | INFO | train_inner | epoch 020:   3116 / 3236 loss=1.164, nll_loss=1.164, ppl=2.24, wps=1360.4, ups=1.03, wpb=1318.7, bsz=98.7, num_updates=64600, lr=0.000786889, gnorm=0.568, train_wall=56, gb_free=18.2, wall=17750
2024-02-05 09:33:11 | INFO | train_inner | epoch 020:   3216 / 3236 loss=1.173, nll_loss=1.173, ppl=2.25, wps=1489.5, ups=1.15, wpb=1299.6, bsz=91.2, num_updates=64700, lr=0.000786281, gnorm=0.587, train_wall=55, gb_free=17.7, wall=17837
2024-02-05 09:33:25 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 09:33:25 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 09:35:34 | INFO | dev | epoch 020 | valid on 'dev' subset | loss 1.122 | nll_loss 1.122 | ppl 2.18 | wps 1786 | wpb 1146.2 | bsz 77.6 | num_updates 64720 | best_loss 1.122
2024-02-05 09:35:34 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 20 @ 64720 updates
2024-02-05 09:35:34 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint20.pt
2024-02-05 09:35:36 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint20.pt
2024-02-05 09:35:40 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint20.pt (epoch 20 @ 64720 updates, score 1.122) (writing took 5.92879905202426 seconds)
2024-02-05 09:35:40 | INFO | fairseq_cli.train | end of epoch 20 (average epoch stats below)
2024-02-05 09:35:40 | INFO | train | epoch 020 | loss 1.151 | nll_loss 1.151 | ppl 2.22 | wps 1668.8 | ups 1.28 | wpb 1302.4 | bsz 89.4 | num_updates 64720 | lr 0.00078616 | gnorm 0.583 | train_wall 1799 | gb_free 17.9 | wall 17987
2024-02-05 09:35:40 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 09:35:40 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 09:35:40 | INFO | fairseq.trainer | begin training epoch 21
2024-02-05 09:35:40 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 09:36:36 | INFO | train_inner | epoch 021:     80 / 3236 loss=1.104, nll_loss=1.104, ppl=2.15, wps=636.8, ups=0.49, wpb=1310.4, bsz=86.9, num_updates=64800, lr=0.000785674, gnorm=0.574, train_wall=56, gb_free=18, wall=18043
2024-02-05 09:37:52 | INFO | train_inner | epoch 021:    180 / 3236 loss=1.074, nll_loss=1.074, ppl=2.11, wps=1676, ups=1.32, wpb=1265, bsz=87.4, num_updates=64900, lr=0.000785069, gnorm=0.603, train_wall=56, gb_free=18.1, wall=18118
2024-02-05 09:38:53 | INFO | train_inner | epoch 021:    280 / 3236 loss=1.096, nll_loss=1.096, ppl=2.14, wps=2141.9, ups=1.64, wpb=1304.9, bsz=92.7, num_updates=65000, lr=0.000784465, gnorm=0.575, train_wall=56, gb_free=18.6, wall=18179
2024-02-05 09:40:00 | INFO | train_inner | epoch 021:    380 / 3236 loss=1.083, nll_loss=1.083, ppl=2.12, wps=1954.5, ups=1.49, wpb=1307.8, bsz=91.1, num_updates=65100, lr=0.000783862, gnorm=0.576, train_wall=56, gb_free=18.5, wall=18246
2024-02-05 09:41:08 | INFO | train_inner | epoch 021:    480 / 3236 loss=1.093, nll_loss=1.093, ppl=2.13, wps=1913, ups=1.47, wpb=1298.7, bsz=88.9, num_updates=65200, lr=0.00078326, gnorm=0.585, train_wall=56, gb_free=17.6, wall=18314
2024-02-05 09:42:17 | INFO | train_inner | epoch 021:    580 / 3236 loss=1.105, nll_loss=1.105, ppl=2.15, wps=1915.7, ups=1.45, wpb=1321.3, bsz=91, num_updates=65300, lr=0.00078266, gnorm=0.557, train_wall=56, gb_free=18.3, wall=18383
2024-02-05 09:43:19 | INFO | train_inner | epoch 021:    680 / 3236 loss=1.113, nll_loss=1.113, ppl=2.16, wps=2129, ups=1.61, wpb=1318.4, bsz=89.4, num_updates=65400, lr=0.000782062, gnorm=0.57, train_wall=56, gb_free=17.5, wall=18445
2024-02-05 09:44:29 | INFO | train_inner | epoch 021:    780 / 3236 loss=1.091, nll_loss=1.091, ppl=2.13, wps=1882.1, ups=1.42, wpb=1326.3, bsz=95, num_updates=65500, lr=0.000781465, gnorm=0.568, train_wall=56, gb_free=18.4, wall=18515
2024-02-05 09:45:39 | INFO | train_inner | epoch 021:    880 / 3236 loss=1.141, nll_loss=1.141, ppl=2.21, wps=1823, ups=1.43, wpb=1273.6, bsz=87.2, num_updates=65600, lr=0.000780869, gnorm=0.604, train_wall=56, gb_free=18, wall=18585
2024-02-05 09:46:47 | INFO | train_inner | epoch 021:    980 / 3236 loss=1.121, nll_loss=1.121, ppl=2.17, wps=1888.1, ups=1.47, wpb=1285, bsz=83.9, num_updates=65700, lr=0.000780274, gnorm=0.589, train_wall=56, gb_free=18.6, wall=18653
2024-02-05 09:48:04 | INFO | train_inner | epoch 021:   1080 / 3236 loss=1.111, nll_loss=1.111, ppl=2.16, wps=1665.6, ups=1.3, wpb=1283.7, bsz=89.7, num_updates=65800, lr=0.000779681, gnorm=0.581, train_wall=59, gb_free=18.4, wall=18731
2024-02-05 09:49:19 | INFO | train_inner | epoch 021:   1180 / 3236 loss=1.101, nll_loss=1.101, ppl=2.15, wps=1762.9, ups=1.34, wpb=1316.3, bsz=89, num_updates=65900, lr=0.000779089, gnorm=0.574, train_wall=56, gb_free=17.4, wall=18805
2024-02-05 09:50:30 | INFO | train_inner | epoch 021:   1280 / 3236 loss=1.098, nll_loss=1.098, ppl=2.14, wps=1839.6, ups=1.42, wpb=1298, bsz=91.8, num_updates=66000, lr=0.000778499, gnorm=0.588, train_wall=56, gb_free=18.1, wall=18876
2024-02-05 09:51:49 | INFO | train_inner | epoch 021:   1380 / 3236 loss=1.11, nll_loss=1.11, ppl=2.16, wps=1642.6, ups=1.26, wpb=1301.9, bsz=87.2, num_updates=66100, lr=0.00077791, gnorm=0.592, train_wall=56, gb_free=18.3, wall=18955
2024-02-05 09:53:04 | INFO | train_inner | epoch 021:   1480 / 3236 loss=1.163, nll_loss=1.163, ppl=2.24, wps=1720.1, ups=1.33, wpb=1293.8, bsz=85.7, num_updates=66200, lr=0.000777322, gnorm=0.598, train_wall=56, gb_free=17.2, wall=19030
2024-02-05 09:54:20 | INFO | train_inner | epoch 021:   1580 / 3236 loss=1.128, nll_loss=1.128, ppl=2.19, wps=1728.6, ups=1.32, wpb=1306.9, bsz=87, num_updates=66300, lr=0.000776736, gnorm=0.586, train_wall=55, gb_free=18.7, wall=19106
2024-02-05 09:55:45 | INFO | train_inner | epoch 021:   1680 / 3236 loss=1.134, nll_loss=1.134, ppl=2.2, wps=1522.6, ups=1.17, wpb=1302.5, bsz=90.9, num_updates=66400, lr=0.000776151, gnorm=0.577, train_wall=56, gb_free=17.7, wall=19192
2024-02-05 09:57:08 | INFO | train_inner | epoch 021:   1780 / 3236 loss=1.103, nll_loss=1.103, ppl=2.15, wps=1548.6, ups=1.2, wpb=1288.2, bsz=88.1, num_updates=66500, lr=0.000775567, gnorm=0.578, train_wall=55, gb_free=18.3, wall=19275
2024-02-05 09:58:42 | INFO | train_inner | epoch 021:   1880 / 3236 loss=1.13, nll_loss=1.13, ppl=2.19, wps=1402.9, ups=1.07, wpb=1310.7, bsz=93.7, num_updates=66600, lr=0.000774984, gnorm=0.583, train_wall=55, gb_free=18.2, wall=19368
2024-02-05 10:00:01 | INFO | train_inner | epoch 021:   1980 / 3236 loss=1.153, nll_loss=1.153, ppl=2.22, wps=1630, ups=1.26, wpb=1297.4, bsz=88.3, num_updates=66700, lr=0.000774403, gnorm=0.585, train_wall=55, gb_free=18.5, wall=19448
2024-02-05 10:01:22 | INFO | train_inner | epoch 021:   2080 / 3236 loss=1.12, nll_loss=1.12, ppl=2.17, wps=1635.9, ups=1.25, wpb=1313.9, bsz=88.8, num_updates=66800, lr=0.000773823, gnorm=0.572, train_wall=56, gb_free=18.3, wall=19528
2024-02-05 10:02:40 | INFO | train_inner | epoch 021:   2180 / 3236 loss=1.131, nll_loss=1.131, ppl=2.19, wps=1655.2, ups=1.27, wpb=1298.2, bsz=88.7, num_updates=66900, lr=0.000773245, gnorm=0.586, train_wall=56, gb_free=17.4, wall=19607
2024-02-05 10:04:03 | INFO | train_inner | epoch 021:   2280 / 3236 loss=1.153, nll_loss=1.153, ppl=2.22, wps=1573.2, ups=1.21, wpb=1299.1, bsz=93.2, num_updates=67000, lr=0.000772667, gnorm=0.593, train_wall=55, gb_free=18, wall=19689
2024-02-05 10:05:25 | INFO | train_inner | epoch 021:   2380 / 3236 loss=1.133, nll_loss=1.133, ppl=2.19, wps=1592.6, ups=1.21, wpb=1315.3, bsz=90.4, num_updates=67100, lr=0.000772091, gnorm=0.585, train_wall=55, gb_free=17.7, wall=19772
2024-02-05 10:06:48 | INFO | train_inner | epoch 021:   2480 / 3236 loss=1.126, nll_loss=1.126, ppl=2.18, wps=1580.8, ups=1.21, wpb=1308.9, bsz=87.8, num_updates=67200, lr=0.000771517, gnorm=0.607, train_wall=55, gb_free=17.5, wall=19855
2024-02-05 10:08:16 | INFO | train_inner | epoch 021:   2580 / 3236 loss=1.125, nll_loss=1.125, ppl=2.18, wps=1503.9, ups=1.14, wpb=1314.1, bsz=91.7, num_updates=67300, lr=0.000770943, gnorm=0.571, train_wall=55, gb_free=17.9, wall=19942
2024-02-05 10:09:40 | INFO | train_inner | epoch 021:   2680 / 3236 loss=1.148, nll_loss=1.148, ppl=2.22, wps=1554.1, ups=1.19, wpb=1308.7, bsz=92.1, num_updates=67400, lr=0.000770371, gnorm=0.578, train_wall=56, gb_free=18.6, wall=20026
2024-02-05 10:10:54 | INFO | train_inner | epoch 021:   2780 / 3236 loss=1.16, nll_loss=1.16, ppl=2.23, wps=1714.7, ups=1.34, wpb=1281, bsz=85.7, num_updates=67500, lr=0.0007698, gnorm=0.607, train_wall=56, gb_free=17.6, wall=20101
2024-02-05 10:12:19 | INFO | train_inner | epoch 021:   2880 / 3236 loss=1.13, nll_loss=1.13, ppl=2.19, wps=1560.4, ups=1.19, wpb=1314.9, bsz=91, num_updates=67600, lr=0.000769231, gnorm=0.555, train_wall=56, gb_free=18.1, wall=20185
2024-02-05 10:13:38 | INFO | train_inner | epoch 021:   2980 / 3236 loss=1.145, nll_loss=1.145, ppl=2.21, wps=1635.5, ups=1.26, wpb=1294.5, bsz=86.3, num_updates=67700, lr=0.000768662, gnorm=0.582, train_wall=56, gb_free=18.1, wall=20264
2024-02-05 10:15:04 | INFO | train_inner | epoch 021:   3080 / 3236 loss=1.143, nll_loss=1.143, ppl=2.21, wps=1518.8, ups=1.16, wpb=1303.7, bsz=86.2, num_updates=67800, lr=0.000768095, gnorm=0.595, train_wall=56, gb_free=18.1, wall=20350
2024-02-05 10:16:23 | INFO | train_inner | epoch 021:   3180 / 3236 loss=1.15, nll_loss=1.15, ppl=2.22, wps=1655.1, ups=1.26, wpb=1309.3, bsz=89.4, num_updates=67900, lr=0.00076753, gnorm=0.592, train_wall=56, gb_free=18.2, wall=20429
2024-02-05 10:17:12 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 10:17:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 10:19:23 | INFO | dev | epoch 021 | valid on 'dev' subset | loss 1.118 | nll_loss 1.118 | ppl 2.17 | wps 1759.4 | wpb 1146.2 | bsz 77.6 | num_updates 67956 | best_loss 1.118
2024-02-05 10:19:23 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 21 @ 67956 updates
2024-02-05 10:19:23 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint21.pt
2024-02-05 10:19:24 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint21.pt
2024-02-05 10:19:29 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint21.pt (epoch 21 @ 67956 updates, score 1.118) (writing took 6.104021075065248 seconds)
2024-02-05 10:19:29 | INFO | fairseq_cli.train | end of epoch 21 (average epoch stats below)
2024-02-05 10:19:29 | INFO | train | epoch 021 | loss 1.122 | nll_loss 1.122 | ppl 2.18 | wps 1603.2 | ups 1.23 | wpb 1302.4 | bsz 89.4 | num_updates 67956 | lr 0.000767213 | gnorm 0.583 | train_wall 1803 | gb_free 18.5 | wall 20615
2024-02-05 10:19:29 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 10:19:30 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 10:19:30 | INFO | fairseq.trainer | begin training epoch 22
2024-02-05 10:19:30 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 10:20:00 | INFO | train_inner | epoch 022:     44 / 3236 loss=1.12, nll_loss=1.12, ppl=2.17, wps=608.7, ups=0.46, wpb=1320.1, bsz=94.5, num_updates=68000, lr=0.000766965, gnorm=0.579, train_wall=55, gb_free=18.6, wall=20646
2024-02-05 10:21:23 | INFO | train_inner | epoch 022:    144 / 3236 loss=1.075, nll_loss=1.075, ppl=2.11, wps=1582.8, ups=1.21, wpb=1313.3, bsz=90.2, num_updates=68100, lr=0.000766402, gnorm=0.574, train_wall=55, gb_free=18.1, wall=20729
2024-02-05 10:22:52 | INFO | train_inner | epoch 022:    244 / 3236 loss=1.072, nll_loss=1.072, ppl=2.1, wps=1435.1, ups=1.12, wpb=1284.7, bsz=87.8, num_updates=68200, lr=0.00076584, gnorm=0.59, train_wall=56, gb_free=17.4, wall=20819
2024-02-05 10:24:12 | INFO | train_inner | epoch 022:    344 / 3236 loss=1.071, nll_loss=1.071, ppl=2.1, wps=1619.1, ups=1.25, wpb=1298.4, bsz=92.6, num_updates=68300, lr=0.000765279, gnorm=0.579, train_wall=56, gb_free=17.7, wall=20899
2024-02-05 10:25:19 | INFO | train_inner | epoch 022:    444 / 3236 loss=1.062, nll_loss=1.062, ppl=2.09, wps=1945.2, ups=1.5, wpb=1299.4, bsz=88.5, num_updates=68400, lr=0.000764719, gnorm=0.581, train_wall=57, gb_free=18.2, wall=20966
2024-02-05 10:26:22 | INFO | train_inner | epoch 022:    544 / 3236 loss=1.058, nll_loss=1.058, ppl=2.08, wps=2091.2, ups=1.59, wpb=1313.3, bsz=85.4, num_updates=68500, lr=0.000764161, gnorm=0.584, train_wall=56, gb_free=18.2, wall=21029
2024-02-05 10:27:37 | INFO | train_inner | epoch 022:    644 / 3236 loss=1.089, nll_loss=1.089, ppl=2.13, wps=1778.3, ups=1.34, wpb=1324.2, bsz=92, num_updates=68600, lr=0.000763604, gnorm=0.578, train_wall=56, gb_free=17.8, wall=21103
2024-02-05 10:28:46 | INFO | train_inner | epoch 022:    744 / 3236 loss=1.097, nll_loss=1.097, ppl=2.14, wps=1863.4, ups=1.44, wpb=1291.7, bsz=84.6, num_updates=68700, lr=0.000763048, gnorm=0.599, train_wall=56, gb_free=17.4, wall=21172
2024-02-05 10:30:03 | INFO | train_inner | epoch 022:    844 / 3236 loss=1.107, nll_loss=1.107, ppl=2.15, wps=1711.1, ups=1.31, wpb=1309.7, bsz=94.4, num_updates=68800, lr=0.000762493, gnorm=0.581, train_wall=56, gb_free=18, wall=21249
2024-02-05 10:31:10 | INFO | train_inner | epoch 022:    944 / 3236 loss=1.075, nll_loss=1.075, ppl=2.11, wps=1925, ups=1.48, wpb=1298.3, bsz=89.9, num_updates=68900, lr=0.000761939, gnorm=0.575, train_wall=56, gb_free=17.6, wall=21316
2024-02-05 10:32:33 | INFO | train_inner | epoch 022:   1044 / 3236 loss=1.091, nll_loss=1.091, ppl=2.13, wps=1553.2, ups=1.2, wpb=1289.1, bsz=86.2, num_updates=69000, lr=0.000761387, gnorm=0.592, train_wall=56, gb_free=17.9, wall=21399
2024-02-05 10:33:52 | INFO | train_inner | epoch 022:   1144 / 3236 loss=1.094, nll_loss=1.094, ppl=2.14, wps=1660.6, ups=1.27, wpb=1306.2, bsz=91.7, num_updates=69100, lr=0.000760836, gnorm=0.581, train_wall=56, gb_free=18.5, wall=21478
2024-02-05 10:35:20 | INFO | train_inner | epoch 022:   1244 / 3236 loss=1.099, nll_loss=1.099, ppl=2.14, wps=1489.6, ups=1.14, wpb=1312, bsz=89.7, num_updates=69200, lr=0.000760286, gnorm=0.571, train_wall=55, gb_free=17.7, wall=21566
2024-02-05 10:36:39 | INFO | train_inner | epoch 022:   1344 / 3236 loss=1.091, nll_loss=1.091, ppl=2.13, wps=1670.6, ups=1.27, wpb=1315, bsz=94.1, num_updates=69300, lr=0.000759737, gnorm=0.602, train_wall=56, gb_free=18.1, wall=21645
2024-02-05 10:37:58 | INFO | train_inner | epoch 022:   1444 / 3236 loss=1.075, nll_loss=1.075, ppl=2.11, wps=1642, ups=1.26, wpb=1305.3, bsz=90.6, num_updates=69400, lr=0.00075919, gnorm=0.569, train_wall=56, gb_free=18.1, wall=21724
2024-02-05 10:39:13 | INFO | train_inner | epoch 022:   1544 / 3236 loss=1.084, nll_loss=1.084, ppl=2.12, wps=1720.6, ups=1.33, wpb=1289.5, bsz=85.4, num_updates=69500, lr=0.000758643, gnorm=0.59, train_wall=55, gb_free=17.2, wall=21799
2024-02-05 10:40:39 | INFO | train_inner | epoch 022:   1644 / 3236 loss=1.096, nll_loss=1.096, ppl=2.14, wps=1511.9, ups=1.17, wpb=1295.5, bsz=86.2, num_updates=69600, lr=0.000758098, gnorm=0.595, train_wall=56, gb_free=18.3, wall=21885
2024-02-05 10:42:04 | INFO | train_inner | epoch 022:   1744 / 3236 loss=1.106, nll_loss=1.106, ppl=2.15, wps=1545.2, ups=1.18, wpb=1312.8, bsz=87.5, num_updates=69700, lr=0.000757554, gnorm=0.582, train_wall=57, gb_free=17.7, wall=21970
2024-02-05 10:43:31 | INFO | train_inner | epoch 022:   1844 / 3236 loss=1.113, nll_loss=1.113, ppl=2.16, wps=1477.1, ups=1.15, wpb=1288.5, bsz=91.1, num_updates=69800, lr=0.000757011, gnorm=0.589, train_wall=55, gb_free=17.7, wall=22057
2024-02-05 10:44:48 | INFO | train_inner | epoch 022:   1944 / 3236 loss=1.121, nll_loss=1.121, ppl=2.18, wps=1667.3, ups=1.29, wpb=1288.8, bsz=86.5, num_updates=69900, lr=0.000756469, gnorm=0.604, train_wall=55, gb_free=18.1, wall=22135
2024-02-05 10:46:06 | INFO | train_inner | epoch 022:   2044 / 3236 loss=1.139, nll_loss=1.139, ppl=2.2, wps=1666.2, ups=1.28, wpb=1299.5, bsz=87.9, num_updates=70000, lr=0.000755929, gnorm=0.612, train_wall=56, gb_free=17.4, wall=22213
2024-02-05 10:47:22 | INFO | train_inner | epoch 022:   2144 / 3236 loss=1.135, nll_loss=1.135, ppl=2.2, wps=1699.7, ups=1.32, wpb=1287.9, bsz=85.8, num_updates=70100, lr=0.00075539, gnorm=0.637, train_wall=56, gb_free=18.4, wall=22288
2024-02-05 10:48:57 | INFO | train_inner | epoch 022:   2244 / 3236 loss=1.1, nll_loss=1.1, ppl=2.14, wps=1376.4, ups=1.06, wpb=1301.9, bsz=92.6, num_updates=70200, lr=0.000754851, gnorm=0.569, train_wall=55, gb_free=18.1, wall=22383
2024-02-05 10:50:18 | INFO | train_inner | epoch 022:   2344 / 3236 loss=1.112, nll_loss=1.112, ppl=2.16, wps=1604.2, ups=1.23, wpb=1307.6, bsz=89.9, num_updates=70300, lr=0.000754314, gnorm=0.573, train_wall=55, gb_free=18.2, wall=22464
2024-02-05 10:51:31 | INFO | train_inner | epoch 022:   2444 / 3236 loss=1.116, nll_loss=1.116, ppl=2.17, wps=1766.5, ups=1.37, wpb=1286.8, bsz=85, num_updates=70400, lr=0.000753778, gnorm=0.592, train_wall=55, gb_free=18.4, wall=22537
2024-02-05 10:52:51 | INFO | train_inner | epoch 022:   2544 / 3236 loss=1.095, nll_loss=1.095, ppl=2.14, wps=1617.5, ups=1.24, wpb=1301.6, bsz=92.5, num_updates=70500, lr=0.000753244, gnorm=0.585, train_wall=55, gb_free=17.8, wall=22618
2024-02-05 10:54:24 | INFO | train_inner | epoch 022:   2644 / 3236 loss=1.098, nll_loss=1.098, ppl=2.14, wps=1418, ups=1.08, wpb=1315.2, bsz=97.6, num_updates=70600, lr=0.00075271, gnorm=0.574, train_wall=55, gb_free=18.7, wall=22710
2024-02-05 10:55:46 | INFO | train_inner | epoch 022:   2744 / 3236 loss=1.115, nll_loss=1.115, ppl=2.17, wps=1600.8, ups=1.22, wpb=1308.6, bsz=87.4, num_updates=70700, lr=0.000752177, gnorm=0.57, train_wall=56, gb_free=18, wall=22792
2024-02-05 10:57:14 | INFO | train_inner | epoch 022:   2844 / 3236 loss=1.14, nll_loss=1.14, ppl=2.2, wps=1485.4, ups=1.13, wpb=1310.1, bsz=93.2, num_updates=70800, lr=0.000751646, gnorm=0.601, train_wall=55, gb_free=18.2, wall=22880
2024-02-05 10:58:39 | INFO | train_inner | epoch 022:   2944 / 3236 loss=1.112, nll_loss=1.112, ppl=2.16, wps=1534.8, ups=1.18, wpb=1302.2, bsz=86.8, num_updates=70900, lr=0.000751116, gnorm=0.579, train_wall=56, gb_free=18.4, wall=22965
2024-02-05 11:00:02 | INFO | train_inner | epoch 022:   3044 / 3236 loss=1.107, nll_loss=1.107, ppl=2.15, wps=1586.6, ups=1.21, wpb=1313.7, bsz=90.6, num_updates=71000, lr=0.000750587, gnorm=0.586, train_wall=55, gb_free=17.7, wall=23048
2024-02-05 11:01:34 | INFO | train_inner | epoch 022:   3144 / 3236 loss=1.124, nll_loss=1.124, ppl=2.18, wps=1401.2, ups=1.09, wpb=1290, bsz=89.3, num_updates=71100, lr=0.000750059, gnorm=0.601, train_wall=55, gb_free=18.2, wall=23140
2024-02-05 11:02:52 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 11:02:52 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 11:05:31 | INFO | dev | epoch 022 | valid on 'dev' subset | loss 1.114 | nll_loss 1.114 | ppl 2.17 | wps 1454.3 | wpb 1146.2 | bsz 77.6 | num_updates 71192 | best_loss 1.114
2024-02-05 11:05:31 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 22 @ 71192 updates
2024-02-05 11:05:31 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint22.pt
2024-02-05 11:05:33 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint22.pt
2024-02-05 11:05:38 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint22.pt (epoch 22 @ 71192 updates, score 1.114) (writing took 6.829493056051433 seconds)
2024-02-05 11:05:38 | INFO | fairseq_cli.train | end of epoch 22 (average epoch stats below)
2024-02-05 11:05:38 | INFO | train | epoch 022 | loss 1.1 | nll_loss 1.1 | ppl 2.14 | wps 1522.2 | ups 1.17 | wpb 1302.4 | bsz 89.4 | num_updates 71192 | lr 0.000749574 | gnorm 0.587 | train_wall 1800 | gb_free 17.8 | wall 23384
2024-02-05 11:05:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 11:05:38 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 11:05:38 | INFO | fairseq.trainer | begin training epoch 23
2024-02-05 11:05:38 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 11:05:53 | INFO | train_inner | epoch 023:      8 / 3236 loss=1.124, nll_loss=1.124, ppl=2.18, wps=503.5, ups=0.39, wpb=1306.5, bsz=89.2, num_updates=71200, lr=0.000749532, gnorm=0.586, train_wall=55, gb_free=18.1, wall=23400
2024-02-05 11:07:08 | INFO | train_inner | epoch 023:    108 / 3236 loss=1.028, nll_loss=1.028, ppl=2.04, wps=1763.8, ups=1.34, wpb=1316, bsz=94.2, num_updates=71300, lr=0.000749006, gnorm=0.575, train_wall=56, gb_free=17.7, wall=23474
2024-02-05 11:08:18 | INFO | train_inner | epoch 023:    208 / 3236 loss=1.028, nll_loss=1.028, ppl=2.04, wps=1866.1, ups=1.43, wpb=1302.1, bsz=85.9, num_updates=71400, lr=0.000748481, gnorm=0.58, train_wall=56, gb_free=17.2, wall=23544
2024-02-05 11:09:32 | INFO | train_inner | epoch 023:    308 / 3236 loss=1.052, nll_loss=1.052, ppl=2.07, wps=1763.4, ups=1.34, wpb=1313.1, bsz=90.5, num_updates=71500, lr=0.000747958, gnorm=0.578, train_wall=56, gb_free=17.4, wall=23618
2024-02-05 11:10:41 | INFO | train_inner | epoch 023:    408 / 3236 loss=1.051, nll_loss=1.051, ppl=2.07, wps=1891.4, ups=1.46, wpb=1294.2, bsz=86, num_updates=71600, lr=0.000747435, gnorm=0.58, train_wall=56, gb_free=18, wall=23687
2024-02-05 11:11:55 | INFO | train_inner | epoch 023:    508 / 3236 loss=1.07, nll_loss=1.07, ppl=2.1, wps=1765, ups=1.34, wpb=1319.5, bsz=91, num_updates=71700, lr=0.000746914, gnorm=0.57, train_wall=56, gb_free=17.2, wall=23762
2024-02-05 11:13:13 | INFO | train_inner | epoch 023:    608 / 3236 loss=1.057, nll_loss=1.057, ppl=2.08, wps=1667.6, ups=1.28, wpb=1302.3, bsz=91, num_updates=71800, lr=0.000746393, gnorm=0.58, train_wall=56, gb_free=17.6, wall=23840
2024-02-05 11:14:22 | INFO | train_inner | epoch 023:    708 / 3236 loss=1.065, nll_loss=1.065, ppl=2.09, wps=1867.2, ups=1.45, wpb=1289.7, bsz=88.2, num_updates=71900, lr=0.000745874, gnorm=0.589, train_wall=56, gb_free=17.9, wall=23909
2024-02-05 11:15:27 | INFO | train_inner | epoch 023:    808 / 3236 loss=1.065, nll_loss=1.065, ppl=2.09, wps=2024.3, ups=1.55, wpb=1304.1, bsz=83, num_updates=72000, lr=0.000745356, gnorm=0.584, train_wall=56, gb_free=18.2, wall=23973
2024-02-05 11:16:35 | INFO | train_inner | epoch 023:    908 / 3236 loss=1.064, nll_loss=1.064, ppl=2.09, wps=1905.3, ups=1.47, wpb=1292, bsz=87.2, num_updates=72100, lr=0.000744839, gnorm=0.582, train_wall=56, gb_free=17.6, wall=24041
2024-02-05 11:17:57 | INFO | train_inner | epoch 023:   1008 / 3236 loss=1.074, nll_loss=1.074, ppl=2.11, wps=1596.3, ups=1.22, wpb=1311.4, bsz=93.2, num_updates=72200, lr=0.000744323, gnorm=0.588, train_wall=56, gb_free=18.1, wall=24123
2024-02-05 11:19:17 | INFO | train_inner | epoch 023:   1108 / 3236 loss=1.072, nll_loss=1.072, ppl=2.1, wps=1665.8, ups=1.25, wpb=1329.9, bsz=90.4, num_updates=72300, lr=0.000743808, gnorm=0.572, train_wall=56, gb_free=18.3, wall=24203
2024-02-05 11:20:43 | INFO | train_inner | epoch 023:   1208 / 3236 loss=1.083, nll_loss=1.083, ppl=2.12, wps=1516.4, ups=1.16, wpb=1309.8, bsz=90.4, num_updates=72400, lr=0.000743294, gnorm=0.604, train_wall=56, gb_free=17.6, wall=24289
2024-02-05 11:22:05 | INFO | train_inner | epoch 023:   1308 / 3236 loss=1.075, nll_loss=1.075, ppl=2.11, wps=1606.5, ups=1.23, wpb=1309.3, bsz=90.2, num_updates=72500, lr=0.000742781, gnorm=0.581, train_wall=56, gb_free=18.4, wall=24371
2024-02-05 11:23:21 | INFO | train_inner | epoch 023:   1408 / 3236 loss=1.059, nll_loss=1.059, ppl=2.08, wps=1672.4, ups=1.31, wpb=1276.4, bsz=85.9, num_updates=72600, lr=0.00074227, gnorm=0.591, train_wall=56, gb_free=17.9, wall=24447
2024-02-05 11:24:52 | INFO | train_inner | epoch 023:   1508 / 3236 loss=1.052, nll_loss=1.052, ppl=2.07, wps=1436.4, ups=1.1, wpb=1309.2, bsz=92.2, num_updates=72700, lr=0.000741759, gnorm=0.587, train_wall=55, gb_free=18, wall=24538
2024-02-05 11:26:19 | INFO | train_inner | epoch 023:   1608 / 3236 loss=1.096, nll_loss=1.096, ppl=2.14, wps=1499.9, ups=1.16, wpb=1297.3, bsz=93, num_updates=72800, lr=0.000741249, gnorm=0.598, train_wall=55, gb_free=18.1, wall=24625
2024-02-05 11:27:46 | INFO | train_inner | epoch 023:   1708 / 3236 loss=1.081, nll_loss=1.081, ppl=2.11, wps=1494, ups=1.14, wpb=1306.8, bsz=93.9, num_updates=72900, lr=0.000740741, gnorm=0.579, train_wall=55, gb_free=18.5, wall=24712
2024-02-05 11:29:11 | INFO | train_inner | epoch 023:   1808 / 3236 loss=1.079, nll_loss=1.079, ppl=2.11, wps=1528.2, ups=1.17, wpb=1305.5, bsz=91.1, num_updates=73000, lr=0.000740233, gnorm=0.583, train_wall=56, gb_free=17.9, wall=24798
2024-02-05 11:30:30 | INFO | train_inner | epoch 023:   1908 / 3236 loss=1.072, nll_loss=1.072, ppl=2.1, wps=1648.7, ups=1.28, wpb=1291, bsz=87.7, num_updates=73100, lr=0.000739727, gnorm=0.584, train_wall=57, gb_free=17.4, wall=24876
2024-02-05 11:31:52 | INFO | train_inner | epoch 023:   2008 / 3236 loss=1.073, nll_loss=1.073, ppl=2.1, wps=1576.2, ups=1.22, wpb=1290.7, bsz=91.2, num_updates=73200, lr=0.000739221, gnorm=0.579, train_wall=56, gb_free=18.2, wall=24958
2024-02-05 11:33:19 | INFO | train_inner | epoch 023:   2108 / 3236 loss=1.079, nll_loss=1.079, ppl=2.11, wps=1521, ups=1.15, wpb=1323.4, bsz=93.7, num_updates=73300, lr=0.000738717, gnorm=0.589, train_wall=56, gb_free=18, wall=25045
2024-02-05 11:34:43 | INFO | train_inner | epoch 023:   2208 / 3236 loss=1.119, nll_loss=1.119, ppl=2.17, wps=1545.6, ups=1.19, wpb=1296.3, bsz=89, num_updates=73400, lr=0.000738213, gnorm=0.605, train_wall=56, gb_free=18.5, wall=25129
2024-02-05 11:36:02 | INFO | train_inner | epoch 023:   2308 / 3236 loss=1.089, nll_loss=1.089, ppl=2.13, wps=1662, ups=1.26, wpb=1324.2, bsz=90.2, num_updates=73500, lr=0.000737711, gnorm=0.591, train_wall=56, gb_free=18.1, wall=25209
2024-02-05 11:37:19 | INFO | train_inner | epoch 023:   2408 / 3236 loss=1.1, nll_loss=1.1, ppl=2.14, wps=1685.8, ups=1.3, wpb=1296.8, bsz=85.7, num_updates=73600, lr=0.00073721, gnorm=0.594, train_wall=55, gb_free=27.9, wall=25286
2024-02-05 11:38:40 | INFO | train_inner | epoch 023:   2508 / 3236 loss=1.092, nll_loss=1.092, ppl=2.13, wps=1589.4, ups=1.24, wpb=1285.5, bsz=86.2, num_updates=73700, lr=0.000736709, gnorm=0.603, train_wall=56, gb_free=17.8, wall=25366
2024-02-05 11:40:00 | INFO | train_inner | epoch 023:   2608 / 3236 loss=1.099, nll_loss=1.099, ppl=2.14, wps=1587.8, ups=1.25, wpb=1274.8, bsz=89.3, num_updates=73800, lr=0.00073621, gnorm=0.613, train_wall=55, gb_free=17.9, wall=25447
2024-02-05 11:41:21 | INFO | train_inner | epoch 023:   2708 / 3236 loss=1.101, nll_loss=1.101, ppl=2.15, wps=1642.8, ups=1.24, wpb=1320.3, bsz=91, num_updates=73900, lr=0.000735712, gnorm=0.587, train_wall=56, gb_free=17.9, wall=25527
2024-02-05 11:42:36 | INFO | train_inner | epoch 023:   2808 / 3236 loss=1.108, nll_loss=1.108, ppl=2.16, wps=1714.8, ups=1.32, wpb=1295.4, bsz=89.1, num_updates=74000, lr=0.000735215, gnorm=0.61, train_wall=56, gb_free=18.2, wall=25603
2024-02-05 11:43:54 | INFO | train_inner | epoch 023:   2908 / 3236 loss=1.108, nll_loss=1.108, ppl=2.16, wps=1657.7, ups=1.29, wpb=1289, bsz=88.2, num_updates=74100, lr=0.000734718, gnorm=0.595, train_wall=56, gb_free=17.8, wall=25680
2024-02-05 11:45:15 | INFO | train_inner | epoch 023:   3008 / 3236 loss=1.09, nll_loss=1.09, ppl=2.13, wps=1607.2, ups=1.24, wpb=1299.1, bsz=89, num_updates=74200, lr=0.000734223, gnorm=0.594, train_wall=55, gb_free=17.7, wall=25761
2024-02-05 11:46:35 | INFO | train_inner | epoch 023:   3108 / 3236 loss=1.097, nll_loss=1.097, ppl=2.14, wps=1625.5, ups=1.25, wpb=1298.8, bsz=88.7, num_updates=74300, lr=0.000733729, gnorm=0.599, train_wall=56, gb_free=17.8, wall=25841
2024-02-05 11:47:50 | INFO | train_inner | epoch 023:   3208 / 3236 loss=1.113, nll_loss=1.113, ppl=2.16, wps=1713, ups=1.33, wpb=1291.8, bsz=85.1, num_updates=74400, lr=0.000733236, gnorm=0.605, train_wall=56, gb_free=17.9, wall=25917
2024-02-05 11:48:12 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 11:48:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 11:50:17 | INFO | dev | epoch 023 | valid on 'dev' subset | loss 1.114 | nll_loss 1.114 | ppl 2.16 | wps 1844.5 | wpb 1146.2 | bsz 77.6 | num_updates 74428 | best_loss 1.114
2024-02-05 11:50:17 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 23 @ 74428 updates
2024-02-05 11:50:17 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint23.pt
2024-02-05 11:50:19 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint23.pt
2024-02-05 11:50:24 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint23.pt (epoch 23 @ 74428 updates, score 1.114) (writing took 6.285777126904577 seconds)
2024-02-05 11:50:24 | INFO | fairseq_cli.train | end of epoch 23 (average epoch stats below)
2024-02-05 11:50:24 | INFO | train | epoch 023 | loss 1.077 | nll_loss 1.077 | ppl 2.11 | wps 1569 | ups 1.2 | wpb 1302.4 | bsz 89.4 | num_updates 74428 | lr 0.000733098 | gnorm 0.589 | train_wall 1799 | gb_free 17.2 | wall 26070
2024-02-05 11:50:24 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 11:50:24 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 11:50:24 | INFO | fairseq.trainer | begin training epoch 24
2024-02-05 11:50:24 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 11:51:13 | INFO | train_inner | epoch 024:     72 / 3236 loss=1.032, nll_loss=1.032, ppl=2.04, wps=647.4, ups=0.49, wpb=1314.7, bsz=88.2, num_updates=74500, lr=0.000732743, gnorm=0.556, train_wall=55, gb_free=17.3, wall=26120
2024-02-05 11:52:15 | INFO | train_inner | epoch 024:    172 / 3236 loss=1.001, nll_loss=1.001, ppl=2, wps=2130.3, ups=1.62, wpb=1315.5, bsz=88.2, num_updates=74600, lr=0.000732252, gnorm=0.568, train_wall=56, gb_free=18.6, wall=26181
2024-02-05 11:53:19 | INFO | train_inner | epoch 024:    272 / 3236 loss=1.024, nll_loss=1.024, ppl=2.03, wps=2046.2, ups=1.56, wpb=1309.1, bsz=86.3, num_updates=74700, lr=0.000731762, gnorm=0.59, train_wall=56, gb_free=17.4, wall=26245
2024-02-05 11:54:23 | INFO | train_inner | epoch 024:    372 / 3236 loss=1.027, nll_loss=1.027, ppl=2.04, wps=1995.8, ups=1.55, wpb=1284.8, bsz=87.8, num_updates=74800, lr=0.000731272, gnorm=0.588, train_wall=56, gb_free=18.1, wall=26310
2024-02-05 11:55:35 | INFO | train_inner | epoch 024:    472 / 3236 loss=1.045, nll_loss=1.045, ppl=2.06, wps=1798.8, ups=1.39, wpb=1296.1, bsz=93.7, num_updates=74900, lr=0.000730784, gnorm=0.597, train_wall=55, gb_free=18.3, wall=26382
2024-02-05 11:56:50 | INFO | train_inner | epoch 024:    572 / 3236 loss=1.057, nll_loss=1.057, ppl=2.08, wps=1765.3, ups=1.35, wpb=1312.5, bsz=95.3, num_updates=75000, lr=0.000730297, gnorm=0.578, train_wall=56, gb_free=18.1, wall=26456
2024-02-05 11:58:03 | INFO | train_inner | epoch 024:    672 / 3236 loss=1.052, nll_loss=1.052, ppl=2.07, wps=1793.7, ups=1.37, wpb=1313.9, bsz=91.3, num_updates=75100, lr=0.00072981, gnorm=0.584, train_wall=55, gb_free=17.5, wall=26529
2024-02-05 11:59:14 | INFO | train_inner | epoch 024:    772 / 3236 loss=1.037, nll_loss=1.037, ppl=2.05, wps=1785.7, ups=1.41, wpb=1262.1, bsz=87.1, num_updates=75200, lr=0.000729325, gnorm=0.617, train_wall=55, gb_free=17.4, wall=26600
2024-02-05 12:00:22 | INFO | train_inner | epoch 024:    872 / 3236 loss=1.062, nll_loss=1.062, ppl=2.09, wps=1903.1, ups=1.46, wpb=1299.5, bsz=86.4, num_updates=75300, lr=0.000728841, gnorm=0.598, train_wall=56, gb_free=17.2, wall=26668
2024-02-05 12:01:36 | INFO | train_inner | epoch 024:    972 / 3236 loss=1.037, nll_loss=1.037, ppl=2.05, wps=1739, ups=1.35, wpb=1283.8, bsz=84.2, num_updates=75400, lr=0.000728357, gnorm=0.606, train_wall=56, gb_free=17.3, wall=26742
2024-02-05 12:02:50 | INFO | train_inner | epoch 024:   1072 / 3236 loss=1.081, nll_loss=1.081, ppl=2.12, wps=1746.2, ups=1.34, wpb=1299, bsz=90.9, num_updates=75500, lr=0.000727875, gnorm=0.607, train_wall=55, gb_free=18.3, wall=26817
2024-02-05 12:04:05 | INFO | train_inner | epoch 024:   1172 / 3236 loss=1.067, nll_loss=1.067, ppl=2.1, wps=1739.3, ups=1.34, wpb=1296.4, bsz=88.7, num_updates=75600, lr=0.000727393, gnorm=0.596, train_wall=56, gb_free=18.4, wall=26891
2024-02-05 12:05:23 | INFO | train_inner | epoch 024:   1272 / 3236 loss=1.046, nll_loss=1.046, ppl=2.07, wps=1658.9, ups=1.28, wpb=1297.3, bsz=89.7, num_updates=75700, lr=0.000726912, gnorm=0.584, train_wall=55, gb_free=18.3, wall=26969
2024-02-05 12:06:44 | INFO | train_inner | epoch 024:   1372 / 3236 loss=1.039, nll_loss=1.039, ppl=2.05, wps=1608.3, ups=1.23, wpb=1309.6, bsz=93.1, num_updates=75800, lr=0.000726433, gnorm=0.581, train_wall=55, gb_free=18.3, wall=27051
2024-02-05 12:07:56 | INFO | train_inner | epoch 024:   1472 / 3236 loss=1.057, nll_loss=1.057, ppl=2.08, wps=1795.8, ups=1.39, wpb=1294.9, bsz=92.9, num_updates=75900, lr=0.000725954, gnorm=0.592, train_wall=55, gb_free=17.4, wall=27123
2024-02-05 12:09:12 | INFO | train_inner | epoch 024:   1572 / 3236 loss=1.082, nll_loss=1.082, ppl=2.12, wps=1706.9, ups=1.32, wpb=1293.5, bsz=89.4, num_updates=76000, lr=0.000725476, gnorm=0.595, train_wall=55, gb_free=18, wall=27199
2024-02-05 12:10:29 | INFO | train_inner | epoch 024:   1672 / 3236 loss=1.046, nll_loss=1.046, ppl=2.06, wps=1701.2, ups=1.31, wpb=1299.7, bsz=85.6, num_updates=76100, lr=0.000724999, gnorm=0.577, train_wall=55, gb_free=18, wall=27275
2024-02-05 12:11:55 | INFO | train_inner | epoch 024:   1772 / 3236 loss=1.05, nll_loss=1.05, ppl=2.07, wps=1510.9, ups=1.16, wpb=1304.4, bsz=87.8, num_updates=76200, lr=0.000724524, gnorm=0.585, train_wall=56, gb_free=17.4, wall=27361
2024-02-05 12:13:14 | INFO | train_inner | epoch 024:   1872 / 3236 loss=1.04, nll_loss=1.04, ppl=2.06, wps=1636.2, ups=1.26, wpb=1299.7, bsz=90.5, num_updates=76300, lr=0.000724049, gnorm=0.583, train_wall=55, gb_free=18.1, wall=27441
2024-02-05 12:14:36 | INFO | train_inner | epoch 024:   1972 / 3236 loss=1.05, nll_loss=1.05, ppl=2.07, wps=1622.3, ups=1.23, wpb=1322.1, bsz=93.2, num_updates=76400, lr=0.000723575, gnorm=0.579, train_wall=56, gb_free=17.9, wall=27522
2024-02-05 12:15:59 | INFO | train_inner | epoch 024:   2072 / 3236 loss=1.067, nll_loss=1.067, ppl=2.09, wps=1578.2, ups=1.2, wpb=1311.6, bsz=89.1, num_updates=76500, lr=0.000723102, gnorm=0.574, train_wall=56, gb_free=18.2, wall=27605
2024-02-05 12:17:19 | INFO | train_inner | epoch 024:   2172 / 3236 loss=1.07, nll_loss=1.07, ppl=2.1, wps=1645.9, ups=1.25, wpb=1313.6, bsz=90.9, num_updates=76600, lr=0.000722629, gnorm=0.591, train_wall=56, gb_free=17.9, wall=27685
2024-02-05 12:18:52 | INFO | train_inner | epoch 024:   2272 / 3236 loss=1.076, nll_loss=1.076, ppl=2.11, wps=1424, ups=1.07, wpb=1324.9, bsz=95.7, num_updates=76700, lr=0.000722158, gnorm=0.569, train_wall=55, gb_free=18.4, wall=27778
2024-02-05 12:20:03 | INFO | train_inner | epoch 024:   2372 / 3236 loss=1.052, nll_loss=1.052, ppl=2.07, wps=1826.9, ups=1.41, wpb=1291.4, bsz=83.4, num_updates=76800, lr=0.000721688, gnorm=0.603, train_wall=56, gb_free=17.2, wall=27849
2024-02-05 12:21:21 | INFO | train_inner | epoch 024:   2472 / 3236 loss=1.054, nll_loss=1.054, ppl=2.08, wps=1670, ups=1.27, wpb=1315.2, bsz=89.4, num_updates=76900, lr=0.000721218, gnorm=0.585, train_wall=56, gb_free=17.8, wall=27928
2024-02-05 12:22:40 | INFO | train_inner | epoch 024:   2572 / 3236 loss=1.086, nll_loss=1.086, ppl=2.12, wps=1657.8, ups=1.28, wpb=1300.2, bsz=89.6, num_updates=77000, lr=0.00072075, gnorm=0.605, train_wall=56, gb_free=17.9, wall=28006
2024-02-05 12:24:01 | INFO | train_inner | epoch 024:   2672 / 3236 loss=1.084, nll_loss=1.084, ppl=2.12, wps=1629.8, ups=1.24, wpb=1319, bsz=94.2, num_updates=77100, lr=0.000720282, gnorm=0.584, train_wall=56, gb_free=17.8, wall=28087
2024-02-05 12:25:25 | INFO | train_inner | epoch 024:   2772 / 3236 loss=1.078, nll_loss=1.078, ppl=2.11, wps=1561.5, ups=1.19, wpb=1310.3, bsz=89.9, num_updates=77200, lr=0.000719816, gnorm=0.578, train_wall=56, gb_free=17.9, wall=28171
2024-02-05 12:26:41 | INFO | train_inner | epoch 024:   2872 / 3236 loss=1.096, nll_loss=1.096, ppl=2.14, wps=1697.9, ups=1.31, wpb=1294.9, bsz=86.6, num_updates=77300, lr=0.00071935, gnorm=0.605, train_wall=56, gb_free=18.2, wall=28247
2024-02-05 12:28:00 | INFO | train_inner | epoch 024:   2972 / 3236 loss=1.077, nll_loss=1.077, ppl=2.11, wps=1641.1, ups=1.26, wpb=1299.2, bsz=89.4, num_updates=77400, lr=0.000718885, gnorm=0.587, train_wall=56, gb_free=18.5, wall=28326
2024-02-05 12:29:24 | INFO | train_inner | epoch 024:   3072 / 3236 loss=1.079, nll_loss=1.079, ppl=2.11, wps=1544.6, ups=1.19, wpb=1292.8, bsz=86.3, num_updates=77500, lr=0.000718421, gnorm=0.604, train_wall=56, gb_free=17.8, wall=28410
2024-02-05 12:30:47 | INFO | train_inner | epoch 024:   3172 / 3236 loss=1.082, nll_loss=1.082, ppl=2.12, wps=1552.4, ups=1.2, wpb=1288.5, bsz=86.6, num_updates=77600, lr=0.000717958, gnorm=0.606, train_wall=56, gb_free=18.5, wall=28493
2024-02-05 12:31:43 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 12:31:43 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 12:34:01 | INFO | dev | epoch 024 | valid on 'dev' subset | loss 1.112 | nll_loss 1.112 | ppl 2.16 | wps 1662.8 | wpb 1146.2 | bsz 77.6 | num_updates 77664 | best_loss 1.112
2024-02-05 12:34:01 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 24 @ 77664 updates
2024-02-05 12:34:01 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint24.pt
2024-02-05 12:34:03 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint24.pt
2024-02-05 12:34:07 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint24.pt (epoch 24 @ 77664 updates, score 1.112) (writing took 5.723468850948848 seconds)
2024-02-05 12:34:07 | INFO | fairseq_cli.train | end of epoch 24 (average epoch stats below)
2024-02-05 12:34:07 | INFO | train | epoch 024 | loss 1.057 | nll_loss 1.057 | ppl 2.08 | wps 1606.4 | ups 1.23 | wpb 1302.4 | bsz 89.4 | num_updates 77664 | lr 0.000717662 | gnorm 0.589 | train_wall 1798 | gb_free 18.2 | wall 28694
2024-02-05 12:34:07 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 12:34:08 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 12:34:08 | INFO | fairseq.trainer | begin training epoch 25
2024-02-05 12:34:08 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 12:34:30 | INFO | train_inner | epoch 025:     36 / 3236 loss=1.033, nll_loss=1.033, ppl=2.05, wps=583.6, ups=0.45, wpb=1303.6, bsz=86.6, num_updates=77700, lr=0.000717496, gnorm=0.588, train_wall=56, gb_free=17.8, wall=28716
2024-02-05 12:35:34 | INFO | train_inner | epoch 025:    136 / 3236 loss=1.003, nll_loss=1.003, ppl=2, wps=2008.7, ups=1.55, wpb=1294.6, bsz=89.2, num_updates=77800, lr=0.000717035, gnorm=0.577, train_wall=56, gb_free=18, wall=28781
2024-02-05 12:36:31 | INFO | train_inner | epoch 025:    236 / 3236 loss=1.015, nll_loss=1.015, ppl=2.02, wps=2255.2, ups=1.76, wpb=1284, bsz=83.6, num_updates=77900, lr=0.000716574, gnorm=0.593, train_wall=56, gb_free=17.7, wall=28838
2024-02-05 12:37:41 | INFO | train_inner | epoch 025:    336 / 3236 loss=1.009, nll_loss=1.009, ppl=2.01, wps=1863.4, ups=1.43, wpb=1303.8, bsz=92.7, num_updates=78000, lr=0.000716115, gnorm=0.587, train_wall=56, gb_free=18.2, wall=28908
2024-02-05 12:38:49 | INFO | train_inner | epoch 025:    436 / 3236 loss=1.023, nll_loss=1.023, ppl=2.03, wps=1925.4, ups=1.47, wpb=1309.3, bsz=90.8, num_updates=78100, lr=0.000715656, gnorm=0.579, train_wall=56, gb_free=18.4, wall=28976
2024-02-05 12:39:56 | INFO | train_inner | epoch 025:    536 / 3236 loss=1.012, nll_loss=1.012, ppl=2.02, wps=1990.8, ups=1.51, wpb=1321.5, bsz=92.1, num_updates=78200, lr=0.000715199, gnorm=0.591, train_wall=56, gb_free=18, wall=29042
2024-02-05 12:40:56 | INFO | train_inner | epoch 025:    636 / 3236 loss=1.032, nll_loss=1.032, ppl=2.04, wps=2153.8, ups=1.66, wpb=1296.2, bsz=85.3, num_updates=78300, lr=0.000714742, gnorm=0.584, train_wall=56, gb_free=18.4, wall=29102
2024-02-05 12:42:00 | INFO | train_inner | epoch 025:    736 / 3236 loss=1.025, nll_loss=1.025, ppl=2.03, wps=2043.4, ups=1.57, wpb=1301.4, bsz=90.9, num_updates=78400, lr=0.000714286, gnorm=0.587, train_wall=56, gb_free=18.4, wall=29166
2024-02-05 12:43:06 | INFO | train_inner | epoch 025:    836 / 3236 loss=1.016, nll_loss=1.016, ppl=2.02, wps=1958.5, ups=1.5, wpb=1302.5, bsz=85.6, num_updates=78500, lr=0.000713831, gnorm=0.59, train_wall=56, gb_free=16.9, wall=29233
2024-02-05 12:44:13 | INFO | train_inner | epoch 025:    936 / 3236 loss=1.042, nll_loss=1.042, ppl=2.06, wps=1953.9, ups=1.49, wpb=1308.9, bsz=91.7, num_updates=78600, lr=0.000713376, gnorm=0.584, train_wall=56, gb_free=17.8, wall=29300
2024-02-05 12:45:22 | INFO | train_inner | epoch 025:   1036 / 3236 loss=1.027, nll_loss=1.027, ppl=2.04, wps=1875, ups=1.45, wpb=1292.7, bsz=87.1, num_updates=78700, lr=0.000712923, gnorm=0.592, train_wall=56, gb_free=18.5, wall=29368
2024-02-05 12:46:36 | INFO | train_inner | epoch 025:   1136 / 3236 loss=1.033, nll_loss=1.033, ppl=2.05, wps=1767.2, ups=1.35, wpb=1312.9, bsz=93.3, num_updates=78800, lr=0.00071247, gnorm=0.586, train_wall=56, gb_free=17.6, wall=29443
2024-02-05 12:47:53 | INFO | train_inner | epoch 025:   1236 / 3236 loss=1.04, nll_loss=1.04, ppl=2.06, wps=1728.8, ups=1.31, wpb=1316.3, bsz=90.1, num_updates=78900, lr=0.000712019, gnorm=0.599, train_wall=55, gb_free=17.9, wall=29519
2024-02-05 12:49:07 | INFO | train_inner | epoch 025:   1336 / 3236 loss=1.038, nll_loss=1.038, ppl=2.05, wps=1784.1, ups=1.35, wpb=1320.5, bsz=90.6, num_updates=79000, lr=0.000711568, gnorm=0.57, train_wall=56, gb_free=17.8, wall=29593
2024-02-05 12:50:20 | INFO | train_inner | epoch 025:   1436 / 3236 loss=1.04, nll_loss=1.04, ppl=2.06, wps=1757.4, ups=1.36, wpb=1289.9, bsz=86.3, num_updates=79100, lr=0.000711118, gnorm=0.601, train_wall=55, gb_free=17.2, wall=29666
2024-02-05 12:51:30 | INFO | train_inner | epoch 025:   1536 / 3236 loss=1.044, nll_loss=1.044, ppl=2.06, wps=1855.8, ups=1.42, wpb=1309.1, bsz=92.8, num_updates=79200, lr=0.000710669, gnorm=0.588, train_wall=56, gb_free=17.5, wall=29737
2024-02-05 12:52:49 | INFO | train_inner | epoch 025:   1636 / 3236 loss=1.045, nll_loss=1.045, ppl=2.06, wps=1659.8, ups=1.28, wpb=1296.4, bsz=89.3, num_updates=79300, lr=0.000710221, gnorm=0.586, train_wall=56, gb_free=17.9, wall=29815
2024-02-05 12:54:10 | INFO | train_inner | epoch 025:   1736 / 3236 loss=1.031, nll_loss=1.031, ppl=2.04, wps=1620.4, ups=1.23, wpb=1314.2, bsz=91.6, num_updates=79400, lr=0.000709773, gnorm=0.578, train_wall=56, gb_free=18, wall=29896
2024-02-05 12:55:27 | INFO | train_inner | epoch 025:   1836 / 3236 loss=1.053, nll_loss=1.053, ppl=2.07, wps=1687.3, ups=1.3, wpb=1298, bsz=86.2, num_updates=79500, lr=0.000709327, gnorm=0.6, train_wall=58, gb_free=17.5, wall=29973
2024-02-05 12:56:46 | INFO | train_inner | epoch 025:   1936 / 3236 loss=1.044, nll_loss=1.044, ppl=2.06, wps=1639.7, ups=1.27, wpb=1294.2, bsz=86.7, num_updates=79600, lr=0.000708881, gnorm=0.597, train_wall=56, gb_free=18.4, wall=30052
2024-02-05 12:58:02 | INFO | train_inner | epoch 025:   2036 / 3236 loss=1.062, nll_loss=1.062, ppl=2.09, wps=1713.5, ups=1.32, wpb=1302, bsz=90, num_updates=79700, lr=0.000708436, gnorm=0.606, train_wall=56, gb_free=18.4, wall=30128
2024-02-05 12:59:14 | INFO | train_inner | epoch 025:   2136 / 3236 loss=1.05, nll_loss=1.05, ppl=2.07, wps=1802.1, ups=1.39, wpb=1297.3, bsz=89.3, num_updates=79800, lr=0.000707992, gnorm=0.615, train_wall=56, gb_free=18, wall=30200
2024-02-05 13:00:31 | INFO | train_inner | epoch 025:   2236 / 3236 loss=1.068, nll_loss=1.068, ppl=2.1, wps=1704.3, ups=1.29, wpb=1320.3, bsz=89.6, num_updates=79900, lr=0.000707549, gnorm=0.593, train_wall=56, gb_free=18.3, wall=30277
2024-02-05 13:01:47 | INFO | train_inner | epoch 025:   2336 / 3236 loss=1.054, nll_loss=1.054, ppl=2.08, wps=1699.9, ups=1.31, wpb=1298.9, bsz=96.1, num_updates=80000, lr=0.000707107, gnorm=0.591, train_wall=55, gb_free=17.7, wall=30354
2024-02-05 13:03:07 | INFO | train_inner | epoch 025:   2436 / 3236 loss=1.048, nll_loss=1.048, ppl=2.07, wps=1631.1, ups=1.25, wpb=1303.4, bsz=90.2, num_updates=80100, lr=0.000706665, gnorm=0.583, train_wall=56, gb_free=17.4, wall=30434
2024-02-05 13:04:26 | INFO | train_inner | epoch 025:   2536 / 3236 loss=1.065, nll_loss=1.065, ppl=2.09, wps=1665.8, ups=1.28, wpb=1305, bsz=93, num_updates=80200, lr=0.000706225, gnorm=0.603, train_wall=55, gb_free=17.6, wall=30512
2024-02-05 13:05:33 | INFO | train_inner | epoch 025:   2636 / 3236 loss=1.047, nll_loss=1.047, ppl=2.07, wps=1934.8, ups=1.5, wpb=1294, bsz=85.6, num_updates=80300, lr=0.000705785, gnorm=0.597, train_wall=55, gb_free=18.5, wall=30579
2024-02-05 13:06:45 | INFO | train_inner | epoch 025:   2736 / 3236 loss=1.051, nll_loss=1.051, ppl=2.07, wps=1788.2, ups=1.38, wpb=1297.5, bsz=88.7, num_updates=80400, lr=0.000705346, gnorm=0.593, train_wall=56, gb_free=17.4, wall=30651
2024-02-05 13:07:56 | INFO | train_inner | epoch 025:   2836 / 3236 loss=1.056, nll_loss=1.056, ppl=2.08, wps=1831.2, ups=1.41, wpb=1298.5, bsz=88.1, num_updates=80500, lr=0.000704907, gnorm=0.602, train_wall=56, gb_free=17.8, wall=30722
2024-02-05 13:09:11 | INFO | train_inner | epoch 025:   2936 / 3236 loss=1.052, nll_loss=1.052, ppl=2.07, wps=1754.7, ups=1.34, wpb=1313.1, bsz=93.4, num_updates=80600, lr=0.00070447, gnorm=0.6, train_wall=56, gb_free=17.6, wall=30797
2024-02-05 13:10:19 | INFO | train_inner | epoch 025:   3036 / 3236 loss=1.054, nll_loss=1.054, ppl=2.08, wps=1875.6, ups=1.47, wpb=1275.2, bsz=84.1, num_updates=80700, lr=0.000704033, gnorm=0.6, train_wall=56, gb_free=17.9, wall=30865
2024-02-05 13:11:31 | INFO | train_inner | epoch 025:   3136 / 3236 loss=1.068, nll_loss=1.068, ppl=2.1, wps=1802.8, ups=1.39, wpb=1297, bsz=89, num_updates=80800, lr=0.000703598, gnorm=0.592, train_wall=56, gb_free=17.9, wall=30937
2024-02-05 13:12:38 | INFO | train_inner | epoch 025:   3236 / 3236 loss=1.066, nll_loss=1.066, ppl=2.09, wps=1957.8, ups=1.49, wpb=1316.5, bsz=92.7, num_updates=80900, lr=0.000703163, gnorm=0.588, train_wall=55, gb_free=18.7, wall=31004
2024-02-05 13:12:38 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 13:12:38 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 13:14:45 | INFO | dev | epoch 025 | valid on 'dev' subset | loss 1.101 | nll_loss 1.101 | ppl 2.14 | wps 1817.1 | wpb 1146.2 | bsz 77.6 | num_updates 80900 | best_loss 1.101
2024-02-05 13:14:45 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 25 @ 80900 updates
2024-02-05 13:14:45 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint25.pt
2024-02-05 13:14:46 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint25.pt
2024-02-05 13:14:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint25.pt (epoch 25 @ 80900 updates, score 1.101) (writing took 5.537236560950987 seconds)
2024-02-05 13:14:51 | INFO | fairseq_cli.train | end of epoch 25 (average epoch stats below)
2024-02-05 13:14:51 | INFO | train | epoch 025 | loss 1.04 | nll_loss 1.04 | ppl 2.06 | wps 1724.9 | ups 1.32 | wpb 1302.4 | bsz 89.4 | num_updates 80900 | lr 0.000703163 | gnorm 0.592 | train_wall 1804 | gb_free 18.7 | wall 31137
2024-02-05 13:14:51 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 13:14:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 13:14:51 | INFO | fairseq.trainer | begin training epoch 26
2024-02-05 13:14:51 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 13:15:56 | INFO | train_inner | epoch 026:    100 / 3236 loss=0.994, nll_loss=0.994, ppl=1.99, wps=658, ups=0.51, wpb=1300.7, bsz=90.5, num_updates=81000, lr=0.000702728, gnorm=0.589, train_wall=56, gb_free=18.2, wall=31202
2024-02-05 13:16:52 | INFO | train_inner | epoch 026:    200 / 3236 loss=1.006, nll_loss=1.006, ppl=2.01, wps=2319.4, ups=1.78, wpb=1304.1, bsz=90.6, num_updates=81100, lr=0.000702295, gnorm=0.607, train_wall=56, gb_free=18.1, wall=31258
2024-02-05 13:17:48 | INFO | train_inner | epoch 026:    300 / 3236 loss=0.994, nll_loss=0.994, ppl=1.99, wps=2323.8, ups=1.78, wpb=1303.5, bsz=91.8, num_updates=81200, lr=0.000701862, gnorm=0.585, train_wall=56, gb_free=18.2, wall=31314
2024-02-05 13:18:44 | INFO | train_inner | epoch 026:    400 / 3236 loss=1.011, nll_loss=1.011, ppl=2.02, wps=2315.1, ups=1.77, wpb=1306.2, bsz=94.5, num_updates=81300, lr=0.000701431, gnorm=0.595, train_wall=56, gb_free=18.2, wall=31371
2024-02-05 13:19:41 | INFO | train_inner | epoch 026:    500 / 3236 loss=1, nll_loss=1, ppl=2, wps=2309.6, ups=1.78, wpb=1297.3, bsz=86.6, num_updates=81400, lr=0.000701, gnorm=0.606, train_wall=56, gb_free=17.6, wall=31427
2024-02-05 13:20:37 | INFO | train_inner | epoch 026:    600 / 3236 loss=1.013, nll_loss=1.013, ppl=2.02, wps=2341.2, ups=1.78, wpb=1314.6, bsz=90.6, num_updates=81500, lr=0.000700569, gnorm=0.582, train_wall=56, gb_free=17.7, wall=31483
2024-02-05 13:21:33 | INFO | train_inner | epoch 026:    700 / 3236 loss=0.993, nll_loss=0.993, ppl=1.99, wps=2297.8, ups=1.76, wpb=1302.5, bsz=88.3, num_updates=81600, lr=0.00070014, gnorm=0.572, train_wall=56, gb_free=18.1, wall=31540
2024-02-05 13:22:30 | INFO | train_inner | epoch 026:    800 / 3236 loss=0.991, nll_loss=0.991, ppl=1.99, wps=2302.8, ups=1.78, wpb=1295.1, bsz=87.4, num_updates=81700, lr=0.000699711, gnorm=0.589, train_wall=56, gb_free=17.6, wall=31596
2024-02-05 13:23:27 | INFO | train_inner | epoch 026:    900 / 3236 loss=1.011, nll_loss=1.011, ppl=2.02, wps=2252.8, ups=1.74, wpb=1293.1, bsz=89.5, num_updates=81800, lr=0.000699284, gnorm=0.607, train_wall=56, gb_free=18.7, wall=31653
2024-02-05 13:24:27 | INFO | train_inner | epoch 026:   1000 / 3236 loss=1.011, nll_loss=1.011, ppl=2.02, wps=2152.8, ups=1.66, wpb=1298.1, bsz=90.1, num_updates=81900, lr=0.000698857, gnorm=0.588, train_wall=56, gb_free=18, wall=31714
2024-02-05 13:25:35 | INFO | train_inner | epoch 026:   1100 / 3236 loss=1.001, nll_loss=1.001, ppl=2, wps=1900.2, ups=1.49, wpb=1278.8, bsz=87, num_updates=82000, lr=0.00069843, gnorm=0.599, train_wall=56, gb_free=18.3, wall=31781
2024-02-05 13:26:39 | INFO | train_inner | epoch 026:   1200 / 3236 loss=1.021, nll_loss=1.021, ppl=2.03, wps=2010.9, ups=1.56, wpb=1289.2, bsz=89.8, num_updates=82100, lr=0.000698005, gnorm=0.611, train_wall=56, gb_free=18.2, wall=31845
2024-02-05 13:27:36 | INFO | train_inner | epoch 026:   1300 / 3236 loss=1.023, nll_loss=1.023, ppl=2.03, wps=2274.2, ups=1.76, wpb=1290, bsz=81.8, num_updates=82200, lr=0.00069758, gnorm=0.61, train_wall=56, gb_free=18.4, wall=31902
2024-02-05 13:28:32 | INFO | train_inner | epoch 026:   1400 / 3236 loss=1.021, nll_loss=1.021, ppl=2.03, wps=2290, ups=1.77, wpb=1291.7, bsz=87.2, num_updates=82300, lr=0.000697156, gnorm=0.597, train_wall=56, gb_free=17.8, wall=31958
2024-02-05 13:29:28 | INFO | train_inner | epoch 026:   1500 / 3236 loss=1.02, nll_loss=1.02, ppl=2.03, wps=2324.4, ups=1.78, wpb=1309.2, bsz=87.6, num_updates=82400, lr=0.000696733, gnorm=0.593, train_wall=56, gb_free=17.7, wall=32015
2024-02-05 13:30:26 | INFO | train_inner | epoch 026:   1600 / 3236 loss=1.016, nll_loss=1.016, ppl=2.02, wps=2244.4, ups=1.73, wpb=1299.9, bsz=87.7, num_updates=82500, lr=0.000696311, gnorm=0.589, train_wall=56, gb_free=18.3, wall=32073
2024-02-05 13:31:34 | INFO | train_inner | epoch 026:   1700 / 3236 loss=1.028, nll_loss=1.028, ppl=2.04, wps=1941.5, ups=1.47, wpb=1316.7, bsz=88.7, num_updates=82600, lr=0.000695889, gnorm=0.583, train_wall=62, gb_free=18.5, wall=32140
2024-02-05 13:32:31 | INFO | train_inner | epoch 026:   1800 / 3236 loss=1.031, nll_loss=1.031, ppl=2.04, wps=2264.8, ups=1.74, wpb=1300.9, bsz=88.2, num_updates=82700, lr=0.000695468, gnorm=0.605, train_wall=56, gb_free=17.5, wall=32198
2024-02-05 13:33:34 | INFO | train_inner | epoch 026:   1900 / 3236 loss=1.039, nll_loss=1.039, ppl=2.05, wps=2068, ups=1.6, wpb=1293.6, bsz=91.7, num_updates=82800, lr=0.000695048, gnorm=0.596, train_wall=59, gb_free=17.7, wall=32260
2024-02-05 13:34:36 | INFO | train_inner | epoch 026:   2000 / 3236 loss=1.03, nll_loss=1.03, ppl=2.04, wps=2120.4, ups=1.61, wpb=1319.1, bsz=91.8, num_updates=82900, lr=0.000694629, gnorm=0.589, train_wall=56, gb_free=18.7, wall=32323
2024-02-05 13:35:40 | INFO | train_inner | epoch 026:   2100 / 3236 loss=1.009, nll_loss=1.009, ppl=2.01, wps=2056.6, ups=1.57, wpb=1311.7, bsz=91.4, num_updates=83000, lr=0.00069421, gnorm=0.589, train_wall=56, gb_free=18, wall=32386
2024-02-05 13:36:41 | INFO | train_inner | epoch 026:   2200 / 3236 loss=1.023, nll_loss=1.023, ppl=2.03, wps=2142.5, ups=1.64, wpb=1306.5, bsz=89.1, num_updates=83100, lr=0.000693792, gnorm=0.607, train_wall=56, gb_free=18.2, wall=32447
2024-02-05 13:37:41 | INFO | train_inner | epoch 026:   2300 / 3236 loss=1.024, nll_loss=1.024, ppl=2.03, wps=2184.9, ups=1.66, wpb=1312.9, bsz=91.6, num_updates=83200, lr=0.000693375, gnorm=0.58, train_wall=56, gb_free=18.2, wall=32507
2024-02-05 13:38:46 | INFO | train_inner | epoch 026:   2400 / 3236 loss=1.024, nll_loss=1.024, ppl=2.03, wps=2013.1, ups=1.54, wpb=1304.4, bsz=89.2, num_updates=83300, lr=0.000692959, gnorm=0.596, train_wall=56, gb_free=17.9, wall=32572
2024-02-05 13:39:47 | INFO | train_inner | epoch 026:   2500 / 3236 loss=1.034, nll_loss=1.034, ppl=2.05, wps=2157.1, ups=1.65, wpb=1311.2, bsz=87.1, num_updates=83400, lr=0.000692543, gnorm=0.593, train_wall=57, gb_free=18.2, wall=32633
2024-02-05 13:40:49 | INFO | train_inner | epoch 026:   2600 / 3236 loss=1.039, nll_loss=1.039, ppl=2.06, wps=2065.1, ups=1.6, wpb=1293.3, bsz=92.4, num_updates=83500, lr=0.000692129, gnorm=0.606, train_wall=56, gb_free=17.5, wall=32696
2024-02-05 13:41:53 | INFO | train_inner | epoch 026:   2700 / 3236 loss=1.045, nll_loss=1.045, ppl=2.06, wps=2037.8, ups=1.57, wpb=1300.8, bsz=92.8, num_updates=83600, lr=0.000691714, gnorm=0.595, train_wall=56, gb_free=17.9, wall=32759
2024-02-05 13:42:58 | INFO | train_inner | epoch 026:   2800 / 3236 loss=1.026, nll_loss=1.026, ppl=2.04, wps=2016.8, ups=1.53, wpb=1317.1, bsz=91.9, num_updates=83700, lr=0.000691301, gnorm=0.574, train_wall=58, gb_free=18.6, wall=32825
2024-02-05 13:43:57 | INFO | train_inner | epoch 026:   2900 / 3236 loss=1.027, nll_loss=1.027, ppl=2.04, wps=2230.2, ups=1.72, wpb=1297.3, bsz=86.2, num_updates=83800, lr=0.000690889, gnorm=0.592, train_wall=56, gb_free=17.9, wall=32883
2024-02-05 13:44:57 | INFO | train_inner | epoch 026:   3000 / 3236 loss=1.04, nll_loss=1.04, ppl=2.06, wps=2133.7, ups=1.65, wpb=1289.7, bsz=85.4, num_updates=83900, lr=0.000690477, gnorm=0.599, train_wall=56, gb_free=18, wall=32943
2024-02-05 13:45:53 | INFO | train_inner | epoch 026:   3100 / 3236 loss=1.03, nll_loss=1.03, ppl=2.04, wps=2321.5, ups=1.77, wpb=1310.9, bsz=86.2, num_updates=84000, lr=0.000690066, gnorm=0.594, train_wall=56, gb_free=17.5, wall=33000
2024-02-05 13:46:49 | INFO | train_inner | epoch 026:   3200 / 3236 loss=1.061, nll_loss=1.061, ppl=2.09, wps=2345.1, ups=1.79, wpb=1313.4, bsz=94.6, num_updates=84100, lr=0.000689655, gnorm=0.586, train_wall=56, gb_free=18, wall=33056
2024-02-05 13:47:12 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 13:47:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 13:49:05 | INFO | dev | epoch 026 | valid on 'dev' subset | loss 1.106 | nll_loss 1.106 | ppl 2.15 | wps 2047.3 | wpb 1146.2 | bsz 77.6 | num_updates 84136 | best_loss 1.101
2024-02-05 13:49:05 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 26 @ 84136 updates
2024-02-05 13:49:05 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint26.pt
2024-02-05 13:49:07 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint26.pt
2024-02-05 13:49:10 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint26.pt (epoch 26 @ 84136 updates, score 1.106) (writing took 4.629467781051062 seconds)
2024-02-05 13:49:10 | INFO | fairseq_cli.train | end of epoch 26 (average epoch stats below)
2024-02-05 13:49:10 | INFO | train | epoch 026 | loss 1.02 | nll_loss 1.02 | ppl 2.03 | wps 2046.7 | ups 1.57 | wpb 1302.4 | bsz 89.4 | num_updates 84136 | lr 0.000689508 | gnorm 0.594 | train_wall 1819 | gb_free 17.9 | wall 33196
2024-02-05 13:49:10 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 13:49:10 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 13:49:10 | INFO | fairseq.trainer | begin training epoch 27
2024-02-05 13:49:10 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 13:49:50 | INFO | train_inner | epoch 027:     64 / 3236 loss=1.005, nll_loss=1.005, ppl=2.01, wps=718.4, ups=0.56, wpb=1293.9, bsz=90.6, num_updates=84200, lr=0.000689246, gnorm=0.605, train_wall=55, gb_free=18.4, wall=33236
2024-02-05 13:50:46 | INFO | train_inner | epoch 027:    164 / 3236 loss=0.971, nll_loss=0.971, ppl=1.96, wps=2324.9, ups=1.78, wpb=1303.1, bsz=89, num_updates=84300, lr=0.000688837, gnorm=0.576, train_wall=56, gb_free=18, wall=33292
2024-02-05 13:51:42 | INFO | train_inner | epoch 027:    264 / 3236 loss=0.962, nll_loss=0.962, ppl=1.95, wps=2347.1, ups=1.78, wpb=1321.8, bsz=89.2, num_updates=84400, lr=0.000688428, gnorm=0.584, train_wall=56, gb_free=17.8, wall=33348
2024-02-05 13:52:38 | INFO | train_inner | epoch 027:    364 / 3236 loss=0.99, nll_loss=0.99, ppl=1.99, wps=2315.4, ups=1.78, wpb=1301.2, bsz=86.4, num_updates=84500, lr=0.000688021, gnorm=0.589, train_wall=56, gb_free=17.7, wall=33405
2024-02-05 13:53:35 | INFO | train_inner | epoch 027:    464 / 3236 loss=0.995, nll_loss=0.995, ppl=1.99, wps=2285.3, ups=1.76, wpb=1297.9, bsz=91.9, num_updates=84600, lr=0.000687614, gnorm=0.6, train_wall=56, gb_free=18, wall=33461
2024-02-05 13:54:31 | INFO | train_inner | epoch 027:    564 / 3236 loss=0.979, nll_loss=0.979, ppl=1.97, wps=2310.4, ups=1.79, wpb=1290.9, bsz=89.8, num_updates=84700, lr=0.000687208, gnorm=0.587, train_wall=55, gb_free=18, wall=33517
2024-02-05 13:55:27 | INFO | train_inner | epoch 027:    664 / 3236 loss=0.989, nll_loss=0.989, ppl=1.99, wps=2263.9, ups=1.78, wpb=1274.3, bsz=87.4, num_updates=84800, lr=0.000686803, gnorm=0.607, train_wall=56, gb_free=18.5, wall=33573
2024-02-05 13:56:23 | INFO | train_inner | epoch 027:    764 / 3236 loss=0.993, nll_loss=0.993, ppl=1.99, wps=2294.8, ups=1.78, wpb=1291.7, bsz=82.2, num_updates=84900, lr=0.000686398, gnorm=0.587, train_wall=56, gb_free=18.3, wall=33630
2024-02-05 13:57:19 | INFO | train_inner | epoch 027:    864 / 3236 loss=1.005, nll_loss=1.005, ppl=2.01, wps=2294.8, ups=1.79, wpb=1285, bsz=90.8, num_updates=85000, lr=0.000685994, gnorm=0.596, train_wall=55, gb_free=18.5, wall=33686
2024-02-05 13:58:18 | INFO | train_inner | epoch 027:    964 / 3236 loss=1.004, nll_loss=1.004, ppl=2, wps=2261.5, ups=1.71, wpb=1320.2, bsz=93.9, num_updates=85100, lr=0.000685591, gnorm=0.586, train_wall=56, gb_free=17.8, wall=33744
2024-02-05 13:59:25 | INFO | train_inner | epoch 027:   1064 / 3236 loss=1, nll_loss=1, ppl=2, wps=1947.8, ups=1.48, wpb=1317.7, bsz=97, num_updates=85200, lr=0.000685189, gnorm=0.601, train_wall=56, gb_free=17.7, wall=33812
2024-02-05 14:00:26 | INFO | train_inner | epoch 027:   1164 / 3236 loss=1.014, nll_loss=1.014, ppl=2.02, wps=2126.8, ups=1.64, wpb=1297, bsz=89, num_updates=85300, lr=0.000684787, gnorm=0.598, train_wall=56, gb_free=17.4, wall=33873
2024-02-05 14:01:27 | INFO | train_inner | epoch 027:   1264 / 3236 loss=0.99, nll_loss=0.99, ppl=1.99, wps=2114, ups=1.64, wpb=1287.5, bsz=86.5, num_updates=85400, lr=0.000684386, gnorm=0.595, train_wall=56, gb_free=18.7, wall=33934
2024-02-05 14:02:31 | INFO | train_inner | epoch 027:   1364 / 3236 loss=0.995, nll_loss=0.995, ppl=1.99, wps=2052.7, ups=1.56, wpb=1312.6, bsz=92, num_updates=85500, lr=0.000683986, gnorm=0.576, train_wall=56, gb_free=18.1, wall=33998
2024-02-05 14:03:31 | INFO | train_inner | epoch 027:   1464 / 3236 loss=1.013, nll_loss=1.013, ppl=2.02, wps=2173.5, ups=1.66, wpb=1307.2, bsz=84.4, num_updates=85600, lr=0.000683586, gnorm=0.609, train_wall=56, gb_free=18.5, wall=34058
2024-02-05 14:04:33 | INFO | train_inner | epoch 027:   1564 / 3236 loss=1.012, nll_loss=1.012, ppl=2.02, wps=2118.6, ups=1.64, wpb=1295.8, bsz=87.3, num_updates=85700, lr=0.000683187, gnorm=0.596, train_wall=56, gb_free=17.4, wall=34119
2024-02-05 14:05:33 | INFO | train_inner | epoch 027:   1664 / 3236 loss=1.004, nll_loss=1.004, ppl=2, wps=2129.7, ups=1.65, wpb=1287.5, bsz=87.7, num_updates=85800, lr=0.000682789, gnorm=0.611, train_wall=56, gb_free=18.1, wall=34179
2024-02-05 14:06:30 | INFO | train_inner | epoch 027:   1764 / 3236 loss=1.012, nll_loss=1.012, ppl=2.02, wps=2244.8, ups=1.74, wpb=1288.1, bsz=85.4, num_updates=85900, lr=0.000682391, gnorm=0.608, train_wall=56, gb_free=17.5, wall=34237
2024-02-05 14:07:30 | INFO | train_inner | epoch 027:   1864 / 3236 loss=1.004, nll_loss=1.004, ppl=2.01, wps=2197.3, ups=1.68, wpb=1308, bsz=91.2, num_updates=86000, lr=0.000681994, gnorm=0.599, train_wall=56, gb_free=17.3, wall=34296
2024-02-05 14:08:31 | INFO | train_inner | epoch 027:   1964 / 3236 loss=1.005, nll_loss=1.005, ppl=2.01, wps=2161.3, ups=1.65, wpb=1312.9, bsz=90.7, num_updates=86100, lr=0.000681598, gnorm=0.593, train_wall=56, gb_free=18.1, wall=34357
2024-02-05 14:09:32 | INFO | train_inner | epoch 027:   2064 / 3236 loss=1.004, nll_loss=1.004, ppl=2.01, wps=2121.9, ups=1.62, wpb=1310.7, bsz=90.9, num_updates=86200, lr=0.000681203, gnorm=0.586, train_wall=56, gb_free=18, wall=34419
2024-02-05 14:10:34 | INFO | train_inner | epoch 027:   2164 / 3236 loss=1.023, nll_loss=1.023, ppl=2.03, wps=2082.8, ups=1.61, wpb=1291.3, bsz=89.2, num_updates=86300, lr=0.000680808, gnorm=0.598, train_wall=56, gb_free=17.6, wall=34481
2024-02-05 14:11:35 | INFO | train_inner | epoch 027:   2264 / 3236 loss=1.006, nll_loss=1.006, ppl=2.01, wps=2202.8, ups=1.66, wpb=1326.3, bsz=89, num_updates=86400, lr=0.000680414, gnorm=0.593, train_wall=56, gb_free=17.5, wall=34541
2024-02-05 14:12:37 | INFO | train_inner | epoch 027:   2364 / 3236 loss=1.031, nll_loss=1.031, ppl=2.04, wps=2083.5, ups=1.61, wpb=1297.7, bsz=87.7, num_updates=86500, lr=0.00068002, gnorm=0.608, train_wall=56, gb_free=18.2, wall=34603
2024-02-05 14:13:38 | INFO | train_inner | epoch 027:   2464 / 3236 loss=1.015, nll_loss=1.015, ppl=2.02, wps=2146, ups=1.64, wpb=1304.7, bsz=89.8, num_updates=86600, lr=0.000679628, gnorm=0.599, train_wall=56, gb_free=18, wall=34664
2024-02-05 14:14:45 | INFO | train_inner | epoch 027:   2564 / 3236 loss=1.009, nll_loss=1.009, ppl=2.01, wps=1962.7, ups=1.5, wpb=1312, bsz=93.8, num_updates=86700, lr=0.000679236, gnorm=0.588, train_wall=56, gb_free=18.1, wall=34731
2024-02-05 14:15:46 | INFO | train_inner | epoch 027:   2664 / 3236 loss=1.023, nll_loss=1.023, ppl=2.03, wps=2095.9, ups=1.62, wpb=1295.7, bsz=89.3, num_updates=86800, lr=0.000678844, gnorm=0.6, train_wall=56, gb_free=18.3, wall=34793
2024-02-05 14:16:51 | INFO | train_inner | epoch 027:   2764 / 3236 loss=1.041, nll_loss=1.041, ppl=2.06, wps=2016.4, ups=1.55, wpb=1302.8, bsz=90.6, num_updates=86900, lr=0.000678454, gnorm=0.595, train_wall=56, gb_free=17.7, wall=34857
2024-02-05 14:17:56 | INFO | train_inner | epoch 027:   2864 / 3236 loss=1.02, nll_loss=1.02, ppl=2.03, wps=2060.8, ups=1.55, wpb=1331.9, bsz=93.3, num_updates=87000, lr=0.000678064, gnorm=0.582, train_wall=56, gb_free=17.9, wall=34922
2024-02-05 14:18:57 | INFO | train_inner | epoch 027:   2964 / 3236 loss=1.01, nll_loss=1.01, ppl=2.01, wps=2097.5, ups=1.62, wpb=1291.5, bsz=87.5, num_updates=87100, lr=0.000677674, gnorm=0.602, train_wall=56, gb_free=18.5, wall=34984
2024-02-05 14:20:04 | INFO | train_inner | epoch 027:   3064 / 3236 loss=1.02, nll_loss=1.02, ppl=2.03, wps=1977.2, ups=1.49, wpb=1322.8, bsz=92.9, num_updates=87200, lr=0.000677285, gnorm=0.593, train_wall=56, gb_free=18.2, wall=35050
2024-02-05 14:21:11 | INFO | train_inner | epoch 027:   3164 / 3236 loss=1.024, nll_loss=1.024, ppl=2.03, wps=1945, ups=1.49, wpb=1308.5, bsz=90.2, num_updates=87300, lr=0.000676897, gnorm=0.598, train_wall=56, gb_free=18.4, wall=35118
2024-02-05 14:21:54 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 14:21:54 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 14:23:44 | INFO | dev | epoch 027 | valid on 'dev' subset | loss 1.1 | nll_loss 1.1 | ppl 2.14 | wps 2082.2 | wpb 1146.2 | bsz 77.6 | num_updates 87372 | best_loss 1.1
2024-02-05 14:23:44 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 27 @ 87372 updates
2024-02-05 14:23:44 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint27.pt
2024-02-05 14:23:46 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint27.pt
2024-02-05 14:23:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint27.pt (epoch 27 @ 87372 updates, score 1.1) (writing took 6.01718759292271 seconds)
2024-02-05 14:23:50 | INFO | fairseq_cli.train | end of epoch 27 (average epoch stats below)
2024-02-05 14:23:50 | INFO | train | epoch 027 | loss 1.005 | nll_loss 1.005 | ppl 2.01 | wps 2025.6 | ups 1.56 | wpb 1302.4 | bsz 89.4 | num_updates 87372 | lr 0.000676618 | gnorm 0.595 | train_wall 1809 | gb_free 17.3 | wall 35277
2024-02-05 14:23:50 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 14:23:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 14:23:50 | INFO | fairseq.trainer | begin training epoch 28
2024-02-05 14:23:50 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 14:24:10 | INFO | train_inner | epoch 028:     28 / 3236 loss=1.022, nll_loss=1.022, ppl=2.03, wps=724.8, ups=0.56, wpb=1292.5, bsz=88.9, num_updates=87400, lr=0.00067651, gnorm=0.601, train_wall=56, gb_free=18.2, wall=35296
2024-02-05 14:25:06 | INFO | train_inner | epoch 028:    128 / 3236 loss=0.955, nll_loss=0.955, ppl=1.94, wps=2319.4, ups=1.77, wpb=1308.5, bsz=85, num_updates=87500, lr=0.000676123, gnorm=0.583, train_wall=56, gb_free=17.8, wall=35352
2024-02-05 14:26:02 | INFO | train_inner | epoch 028:    228 / 3236 loss=0.947, nll_loss=0.947, ppl=1.93, wps=2364.2, ups=1.78, wpb=1325.3, bsz=91, num_updates=87600, lr=0.000675737, gnorm=0.57, train_wall=56, gb_free=18.2, wall=35409
2024-02-05 14:26:59 | INFO | train_inner | epoch 028:    328 / 3236 loss=0.957, nll_loss=0.957, ppl=1.94, wps=2297.3, ups=1.77, wpb=1296.3, bsz=89.4, num_updates=87700, lr=0.000675352, gnorm=0.596, train_wall=56, gb_free=18.6, wall=35465
2024-02-05 14:27:55 | INFO | train_inner | epoch 028:    428 / 3236 loss=0.967, nll_loss=0.967, ppl=1.95, wps=2323.9, ups=1.78, wpb=1306.6, bsz=91.7, num_updates=87800, lr=0.000674967, gnorm=0.607, train_wall=56, gb_free=18.8, wall=35521
2024-02-05 14:28:51 | INFO | train_inner | epoch 028:    528 / 3236 loss=0.975, nll_loss=0.975, ppl=1.97, wps=2321.9, ups=1.77, wpb=1311.5, bsz=92.3, num_updates=87900, lr=0.000674583, gnorm=0.604, train_wall=56, gb_free=17.7, wall=35578
2024-02-05 14:29:48 | INFO | train_inner | epoch 028:    628 / 3236 loss=0.978, nll_loss=0.978, ppl=1.97, wps=2306.3, ups=1.77, wpb=1305, bsz=90.2, num_updates=88000, lr=0.0006742, gnorm=0.593, train_wall=56, gb_free=18.4, wall=35634
2024-02-05 14:30:44 | INFO | train_inner | epoch 028:    728 / 3236 loss=0.983, nll_loss=0.983, ppl=1.98, wps=2286.4, ups=1.77, wpb=1291.5, bsz=87.4, num_updates=88100, lr=0.000673817, gnorm=0.609, train_wall=56, gb_free=17.5, wall=35691
2024-02-05 14:31:41 | INFO | train_inner | epoch 028:    828 / 3236 loss=0.968, nll_loss=0.968, ppl=1.96, wps=2280.8, ups=1.76, wpb=1292.9, bsz=82.8, num_updates=88200, lr=0.000673435, gnorm=0.601, train_wall=56, gb_free=17.5, wall=35747
2024-02-05 14:32:38 | INFO | train_inner | epoch 028:    928 / 3236 loss=0.991, nll_loss=0.991, ppl=1.99, wps=2319.9, ups=1.77, wpb=1311.9, bsz=89.3, num_updates=88300, lr=0.000673054, gnorm=0.588, train_wall=56, gb_free=17.8, wall=35804
2024-02-05 14:33:37 | INFO | train_inner | epoch 028:   1028 / 3236 loss=0.986, nll_loss=0.986, ppl=1.98, wps=2172.6, ups=1.68, wpb=1293.4, bsz=89.5, num_updates=88400, lr=0.000672673, gnorm=0.596, train_wall=59, gb_free=17.9, wall=35864
2024-02-05 14:34:34 | INFO | train_inner | epoch 028:   1128 / 3236 loss=1.007, nll_loss=1.007, ppl=2.01, wps=2272.7, ups=1.76, wpb=1290.2, bsz=86.9, num_updates=88500, lr=0.000672293, gnorm=0.603, train_wall=56, gb_free=18.7, wall=35920
2024-02-05 14:35:31 | INFO | train_inner | epoch 028:   1228 / 3236 loss=1.007, nll_loss=1.007, ppl=2.01, wps=2287.3, ups=1.75, wpb=1304.2, bsz=84.5, num_updates=88600, lr=0.000671913, gnorm=0.602, train_wall=57, gb_free=18.2, wall=35977
2024-02-05 14:36:29 | INFO | train_inner | epoch 028:   1328 / 3236 loss=0.972, nll_loss=0.972, ppl=1.96, wps=2224.9, ups=1.74, wpb=1281, bsz=87.8, num_updates=88700, lr=0.000671534, gnorm=0.602, train_wall=56, gb_free=17.8, wall=36035
2024-02-05 14:37:27 | INFO | train_inner | epoch 028:   1428 / 3236 loss=0.999, nll_loss=0.999, ppl=2, wps=2210.7, ups=1.73, wpb=1279.6, bsz=90.9, num_updates=88800, lr=0.000671156, gnorm=0.638, train_wall=56, gb_free=18.5, wall=36093
2024-02-05 14:38:26 | INFO | train_inner | epoch 028:   1528 / 3236 loss=1.014, nll_loss=1.014, ppl=2.02, wps=2193.8, ups=1.68, wpb=1302.5, bsz=87.5, num_updates=88900, lr=0.000670778, gnorm=0.601, train_wall=56, gb_free=18.2, wall=36152
2024-02-05 14:39:27 | INFO | train_inner | epoch 028:   1628 / 3236 loss=0.992, nll_loss=0.992, ppl=1.99, wps=2132.1, ups=1.64, wpb=1297, bsz=86.9, num_updates=89000, lr=0.000670402, gnorm=0.593, train_wall=58, gb_free=18.1, wall=36213
2024-02-05 14:40:24 | INFO | train_inner | epoch 028:   1728 / 3236 loss=0.994, nll_loss=0.994, ppl=1.99, wps=2289.3, ups=1.76, wpb=1300.7, bsz=88.6, num_updates=89100, lr=0.000670025, gnorm=0.598, train_wall=56, gb_free=17.2, wall=36270
2024-02-05 14:41:21 | INFO | train_inner | epoch 028:   1828 / 3236 loss=0.963, nll_loss=0.963, ppl=1.95, wps=2258.3, ups=1.76, wpb=1286.6, bsz=88.8, num_updates=89200, lr=0.00066965, gnorm=0.598, train_wall=56, gb_free=17.9, wall=36327
2024-02-05 14:42:28 | INFO | train_inner | epoch 028:   1928 / 3236 loss=0.983, nll_loss=0.983, ppl=1.98, wps=1933.7, ups=1.48, wpb=1310.3, bsz=92.1, num_updates=89300, lr=0.000669274, gnorm=0.589, train_wall=56, gb_free=17.8, wall=36395
2024-02-05 14:43:40 | INFO | train_inner | epoch 028:   2028 / 3236 loss=0.999, nll_loss=0.999, ppl=2, wps=1819, ups=1.39, wpb=1308.2, bsz=93.8, num_updates=89400, lr=0.0006689, gnorm=0.598, train_wall=56, gb_free=18.4, wall=36467
2024-02-05 14:44:43 | INFO | train_inner | epoch 028:   2128 / 3236 loss=0.998, nll_loss=0.998, ppl=2, wps=2062.7, ups=1.59, wpb=1294.8, bsz=89.2, num_updates=89500, lr=0.000668526, gnorm=0.597, train_wall=56, gb_free=17.5, wall=36529
2024-02-05 14:45:43 | INFO | train_inner | epoch 028:   2228 / 3236 loss=1.01, nll_loss=1.01, ppl=2.01, wps=2152.5, ups=1.66, wpb=1295.7, bsz=88.8, num_updates=89600, lr=0.000668153, gnorm=0.592, train_wall=56, gb_free=18.1, wall=36590
2024-02-05 14:46:48 | INFO | train_inner | epoch 028:   2328 / 3236 loss=1.012, nll_loss=1.012, ppl=2.02, wps=2007.8, ups=1.54, wpb=1306.5, bsz=90.9, num_updates=89700, lr=0.000667781, gnorm=0.599, train_wall=56, gb_free=17.6, wall=36655
2024-02-05 14:47:54 | INFO | train_inner | epoch 028:   2428 / 3236 loss=1.003, nll_loss=1.003, ppl=2, wps=1986.4, ups=1.53, wpb=1297.6, bsz=88.8, num_updates=89800, lr=0.000667409, gnorm=0.586, train_wall=57, gb_free=17.5, wall=36720
2024-02-05 14:48:59 | INFO | train_inner | epoch 028:   2528 / 3236 loss=0.994, nll_loss=0.994, ppl=1.99, wps=2008.6, ups=1.53, wpb=1316.3, bsz=89.2, num_updates=89900, lr=0.000667037, gnorm=0.597, train_wall=56, gb_free=17.5, wall=36786
2024-02-05 14:50:04 | INFO | train_inner | epoch 028:   2628 / 3236 loss=1.031, nll_loss=1.031, ppl=2.04, wps=2016.9, ups=1.54, wpb=1308, bsz=95.4, num_updates=90000, lr=0.000666667, gnorm=0.613, train_wall=55, gb_free=18.6, wall=36850
2024-02-05 14:51:05 | INFO | train_inner | epoch 028:   2728 / 3236 loss=1.004, nll_loss=1.004, ppl=2.01, wps=2153.5, ups=1.64, wpb=1315.2, bsz=92.2, num_updates=90100, lr=0.000666297, gnorm=0.581, train_wall=56, gb_free=17.7, wall=36911
2024-02-05 14:52:10 | INFO | train_inner | epoch 028:   2828 / 3236 loss=1.007, nll_loss=1.007, ppl=2.01, wps=2035.5, ups=1.54, wpb=1318, bsz=93.4, num_updates=90200, lr=0.000665927, gnorm=0.592, train_wall=56, gb_free=18, wall=36976
2024-02-05 14:53:10 | INFO | train_inner | epoch 028:   2928 / 3236 loss=0.998, nll_loss=0.998, ppl=2, wps=2185.8, ups=1.67, wpb=1305.9, bsz=89.7, num_updates=90300, lr=0.000665558, gnorm=0.586, train_wall=56, gb_free=17.8, wall=37036
2024-02-05 14:54:12 | INFO | train_inner | epoch 028:   3028 / 3236 loss=1.007, nll_loss=1.007, ppl=2.01, wps=2074.1, ups=1.59, wpb=1303.6, bsz=87, num_updates=90400, lr=0.00066519, gnorm=0.603, train_wall=56, gb_free=18.2, wall=37099
2024-02-05 14:55:16 | INFO | train_inner | epoch 028:   3128 / 3236 loss=1.005, nll_loss=1.005, ppl=2.01, wps=2064.7, ups=1.58, wpb=1304, bsz=91.2, num_updates=90500, lr=0.000664822, gnorm=0.6, train_wall=56, gb_free=18, wall=37162
2024-02-05 14:56:18 | INFO | train_inner | epoch 028:   3228 / 3236 loss=1.021, nll_loss=1.021, ppl=2.03, wps=2091.2, ups=1.61, wpb=1302.8, bsz=88.8, num_updates=90600, lr=0.000664455, gnorm=0.592, train_wall=56, gb_free=17.9, wall=37224
2024-02-05 14:56:23 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 14:56:23 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 14:58:07 | INFO | dev | epoch 028 | valid on 'dev' subset | loss 1.104 | nll_loss 1.104 | ppl 2.15 | wps 2204 | wpb 1146.2 | bsz 77.6 | num_updates 90608 | best_loss 1.1
2024-02-05 14:58:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 28 @ 90608 updates
2024-02-05 14:58:07 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint28.pt
2024-02-05 14:58:09 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint28.pt
2024-02-05 14:58:12 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint28.pt (epoch 28 @ 90608 updates, score 1.104) (writing took 4.998463492025621 seconds)
2024-02-05 14:58:12 | INFO | fairseq_cli.train | end of epoch 28 (average epoch stats below)
2024-02-05 14:58:12 | INFO | train | epoch 028 | loss 0.991 | nll_loss 0.991 | ppl 1.99 | wps 2043.9 | ups 1.57 | wpb 1302.4 | bsz 89.4 | num_updates 90608 | lr 0.000664426 | gnorm 0.597 | train_wall 1818 | gb_free 18.3 | wall 37339
2024-02-05 14:58:12 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 14:58:13 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 14:58:13 | INFO | fairseq.trainer | begin training epoch 29
2024-02-05 14:58:13 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 14:59:07 | INFO | train_inner | epoch 029:     92 / 3236 loss=0.947, nll_loss=0.947, ppl=1.93, wps=780.9, ups=0.59, wpb=1321.3, bsz=92, num_updates=90700, lr=0.000664089, gnorm=0.571, train_wall=56, gb_free=17.6, wall=37393
2024-02-05 15:00:04 | INFO | train_inner | epoch 029:    192 / 3236 loss=0.934, nll_loss=0.934, ppl=1.91, wps=2326.5, ups=1.76, wpb=1318.4, bsz=93.8, num_updates=90800, lr=0.000663723, gnorm=0.58, train_wall=56, gb_free=17.9, wall=37450
2024-02-05 15:01:00 | INFO | train_inner | epoch 029:    292 / 3236 loss=0.928, nll_loss=0.928, ppl=1.9, wps=2325.5, ups=1.77, wpb=1311.4, bsz=89.4, num_updates=90900, lr=0.000663358, gnorm=0.574, train_wall=56, gb_free=17.7, wall=37507
2024-02-05 15:01:56 | INFO | train_inner | epoch 029:    392 / 3236 loss=0.934, nll_loss=0.934, ppl=1.91, wps=2334.2, ups=1.78, wpb=1308.8, bsz=89.7, num_updates=91000, lr=0.000662994, gnorm=0.583, train_wall=56, gb_free=17.8, wall=37563
2024-02-05 15:02:53 | INFO | train_inner | epoch 029:    492 / 3236 loss=0.948, nll_loss=0.948, ppl=1.93, wps=2322.2, ups=1.78, wpb=1308.1, bsz=89.4, num_updates=91100, lr=0.00066263, gnorm=0.598, train_wall=56, gb_free=17.7, wall=37619
2024-02-05 15:03:49 | INFO | train_inner | epoch 029:    592 / 3236 loss=0.936, nll_loss=0.936, ppl=1.91, wps=2310.8, ups=1.78, wpb=1298, bsz=88.6, num_updates=91200, lr=0.000662266, gnorm=0.593, train_wall=56, gb_free=17.5, wall=37675
2024-02-05 15:04:45 | INFO | train_inner | epoch 029:    692 / 3236 loss=0.969, nll_loss=0.969, ppl=1.96, wps=2331.3, ups=1.78, wpb=1311.3, bsz=92.2, num_updates=91300, lr=0.000661903, gnorm=0.589, train_wall=56, gb_free=18.4, wall=37731
2024-02-05 15:05:41 | INFO | train_inner | epoch 029:    792 / 3236 loss=0.958, nll_loss=0.958, ppl=1.94, wps=2294.4, ups=1.77, wpb=1296.3, bsz=87, num_updates=91400, lr=0.000661541, gnorm=0.596, train_wall=56, gb_free=18, wall=37788
2024-02-05 15:06:38 | INFO | train_inner | epoch 029:    892 / 3236 loss=0.961, nll_loss=0.961, ppl=1.95, wps=2341.2, ups=1.77, wpb=1323.2, bsz=90.9, num_updates=91500, lr=0.00066118, gnorm=0.593, train_wall=56, gb_free=18.2, wall=37844
2024-02-05 15:07:34 | INFO | train_inner | epoch 029:    992 / 3236 loss=0.958, nll_loss=0.958, ppl=1.94, wps=2306.9, ups=1.78, wpb=1298.2, bsz=89.5, num_updates=91600, lr=0.000660819, gnorm=0.609, train_wall=56, gb_free=18.2, wall=37901
2024-02-05 15:08:31 | INFO | train_inner | epoch 029:   1092 / 3236 loss=0.967, nll_loss=0.967, ppl=1.96, wps=2289.7, ups=1.76, wpb=1301.9, bsz=87.1, num_updates=91700, lr=0.000660458, gnorm=0.609, train_wall=56, gb_free=18.6, wall=37957
2024-02-05 15:09:28 | INFO | train_inner | epoch 029:   1192 / 3236 loss=0.979, nll_loss=0.979, ppl=1.97, wps=2291.8, ups=1.77, wpb=1293, bsz=86.6, num_updates=91800, lr=0.000660098, gnorm=0.609, train_wall=56, gb_free=17.4, wall=38014
2024-02-05 15:10:25 | INFO | train_inner | epoch 029:   1292 / 3236 loss=0.968, nll_loss=0.968, ppl=1.96, wps=2269.2, ups=1.75, wpb=1296.9, bsz=85.8, num_updates=91900, lr=0.000659739, gnorm=0.602, train_wall=57, gb_free=17.6, wall=38071
2024-02-05 15:11:21 | INFO | train_inner | epoch 029:   1392 / 3236 loss=0.988, nll_loss=0.988, ppl=1.98, wps=2329.1, ups=1.77, wpb=1314, bsz=89.4, num_updates=92000, lr=0.00065938, gnorm=0.595, train_wall=56, gb_free=18.5, wall=38127
2024-02-05 15:12:17 | INFO | train_inner | epoch 029:   1492 / 3236 loss=0.994, nll_loss=0.994, ppl=1.99, wps=2322.1, ups=1.78, wpb=1308.2, bsz=91.8, num_updates=92100, lr=0.000659022, gnorm=0.602, train_wall=56, gb_free=18.4, wall=38184
2024-02-05 15:13:14 | INFO | train_inner | epoch 029:   1592 / 3236 loss=0.98, nll_loss=0.98, ppl=1.97, wps=2314.1, ups=1.77, wpb=1304.8, bsz=86.5, num_updates=92200, lr=0.000658665, gnorm=0.602, train_wall=56, gb_free=18, wall=38240
2024-02-05 15:14:10 | INFO | train_inner | epoch 029:   1692 / 3236 loss=0.967, nll_loss=0.967, ppl=1.95, wps=2318.6, ups=1.77, wpb=1309.3, bsz=91, num_updates=92300, lr=0.000658308, gnorm=0.593, train_wall=56, gb_free=17.7, wall=38297
2024-02-05 15:15:07 | INFO | train_inner | epoch 029:   1792 / 3236 loss=0.982, nll_loss=0.982, ppl=1.98, wps=2293.4, ups=1.78, wpb=1291.3, bsz=86.2, num_updates=92400, lr=0.000657952, gnorm=0.616, train_wall=56, gb_free=17.9, wall=38353
2024-02-05 15:16:03 | INFO | train_inner | epoch 029:   1892 / 3236 loss=0.963, nll_loss=0.963, ppl=1.95, wps=2288.5, ups=1.77, wpb=1289.7, bsz=87.2, num_updates=92500, lr=0.000657596, gnorm=0.601, train_wall=56, gb_free=17.8, wall=38409
2024-02-05 15:17:02 | INFO | train_inner | epoch 029:   1992 / 3236 loss=0.981, nll_loss=0.981, ppl=1.97, wps=2209.9, ups=1.7, wpb=1299.6, bsz=91.3, num_updates=92600, lr=0.000657241, gnorm=0.583, train_wall=56, gb_free=17.9, wall=38468
2024-02-05 15:18:04 | INFO | train_inner | epoch 029:   2092 / 3236 loss=0.97, nll_loss=0.97, ppl=1.96, wps=2111.7, ups=1.62, wpb=1307.1, bsz=93.6, num_updates=92700, lr=0.000656886, gnorm=0.594, train_wall=56, gb_free=18.2, wall=38530
2024-02-05 15:19:05 | INFO | train_inner | epoch 029:   2192 / 3236 loss=0.998, nll_loss=0.998, ppl=2, wps=2085.6, ups=1.63, wpb=1280, bsz=90.2, num_updates=92800, lr=0.000656532, gnorm=0.606, train_wall=56, gb_free=18.1, wall=38591
2024-02-05 15:20:03 | INFO | train_inner | epoch 029:   2292 / 3236 loss=0.988, nll_loss=0.988, ppl=1.98, wps=2232.7, ups=1.72, wpb=1295.4, bsz=89, num_updates=92900, lr=0.000656179, gnorm=0.602, train_wall=56, gb_free=18, wall=38649
2024-02-05 15:21:05 | INFO | train_inner | epoch 029:   2392 / 3236 loss=0.994, nll_loss=0.994, ppl=1.99, wps=2145.3, ups=1.61, wpb=1334.2, bsz=96.8, num_updates=93000, lr=0.000655826, gnorm=0.598, train_wall=56, gb_free=19.1, wall=38712
2024-02-05 15:22:10 | INFO | train_inner | epoch 029:   2492 / 3236 loss=0.984, nll_loss=0.984, ppl=1.98, wps=2028, ups=1.55, wpb=1308.5, bsz=91.2, num_updates=93100, lr=0.000655474, gnorm=0.597, train_wall=56, gb_free=17.8, wall=38776
2024-02-05 15:23:19 | INFO | train_inner | epoch 029:   2592 / 3236 loss=0.992, nll_loss=0.992, ppl=1.99, wps=1877.5, ups=1.44, wpb=1307.7, bsz=88.2, num_updates=93200, lr=0.000655122, gnorm=0.602, train_wall=56, gb_free=18.4, wall=38846
2024-02-05 15:24:26 | INFO | train_inner | epoch 029:   2692 / 3236 loss=1.005, nll_loss=1.005, ppl=2.01, wps=1939, ups=1.5, wpb=1291.7, bsz=88.1, num_updates=93300, lr=0.000654771, gnorm=0.611, train_wall=56, gb_free=17.5, wall=38912
2024-02-05 15:25:30 | INFO | train_inner | epoch 029:   2792 / 3236 loss=0.992, nll_loss=0.992, ppl=1.99, wps=2009, ups=1.57, wpb=1282.4, bsz=86.9, num_updates=93400, lr=0.00065442, gnorm=0.611, train_wall=56, gb_free=17.5, wall=38976
2024-02-05 15:26:43 | INFO | train_inner | epoch 029:   2892 / 3236 loss=0.982, nll_loss=0.982, ppl=1.97, wps=1788.2, ups=1.37, wpb=1303, bsz=95.1, num_updates=93500, lr=0.00065407, gnorm=0.594, train_wall=56, gb_free=18.2, wall=39049
2024-02-05 15:27:51 | INFO | train_inner | epoch 029:   2992 / 3236 loss=1.013, nll_loss=1.013, ppl=2.02, wps=1911.5, ups=1.47, wpb=1302.5, bsz=87.2, num_updates=93600, lr=0.00065372, gnorm=0.601, train_wall=56, gb_free=18.1, wall=39117
2024-02-05 15:28:58 | INFO | train_inner | epoch 029:   3092 / 3236 loss=0.995, nll_loss=0.995, ppl=1.99, wps=1898.9, ups=1.48, wpb=1279.1, bsz=86.6, num_updates=93700, lr=0.000653372, gnorm=0.602, train_wall=56, gb_free=18.1, wall=39185
2024-02-05 15:30:00 | INFO | train_inner | epoch 029:   3192 / 3236 loss=0.987, nll_loss=0.987, ppl=1.98, wps=2079.6, ups=1.62, wpb=1287.4, bsz=85.9, num_updates=93800, lr=0.000653023, gnorm=0.596, train_wall=56, gb_free=17.8, wall=39247
2024-02-05 15:30:32 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 15:30:32 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 15:32:35 | INFO | dev | epoch 029 | valid on 'dev' subset | loss 1.096 | nll_loss 1.096 | ppl 2.14 | wps 1862.4 | wpb 1146.2 | bsz 77.6 | num_updates 93844 | best_loss 1.096
2024-02-05 15:32:35 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 29 @ 93844 updates
2024-02-05 15:32:35 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint29.pt
2024-02-05 15:32:37 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint29.pt
2024-02-05 15:32:41 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint29.pt (epoch 29 @ 93844 updates, score 1.096) (writing took 5.930623868945986 seconds)
2024-02-05 15:32:41 | INFO | fairseq_cli.train | end of epoch 29 (average epoch stats below)
2024-02-05 15:32:41 | INFO | train | epoch 029 | loss 0.974 | nll_loss 0.974 | ppl 1.96 | wps 2037 | ups 1.56 | wpb 1302.4 | bsz 89.4 | num_updates 93844 | lr 0.00065287 | gnorm 0.597 | train_wall 1809 | gb_free 17.8 | wall 39408
2024-02-05 15:32:41 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 15:32:42 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 15:32:42 | INFO | fairseq.trainer | begin training epoch 30
2024-02-05 15:32:42 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 15:33:17 | INFO | train_inner | epoch 030:     56 / 3236 loss=0.967, nll_loss=0.967, ppl=1.95, wps=665.1, ups=0.51, wpb=1308, bsz=88.6, num_updates=93900, lr=0.000652675, gnorm=0.583, train_wall=56, gb_free=18.1, wall=39443
2024-02-05 15:34:13 | INFO | train_inner | epoch 030:    156 / 3236 loss=0.926, nll_loss=0.926, ppl=1.9, wps=2314, ups=1.78, wpb=1297.4, bsz=86.2, num_updates=94000, lr=0.000652328, gnorm=0.588, train_wall=56, gb_free=18.3, wall=39499
2024-02-05 15:35:09 | INFO | train_inner | epoch 030:    256 / 3236 loss=0.924, nll_loss=0.924, ppl=1.9, wps=2295.2, ups=1.77, wpb=1295.2, bsz=87.6, num_updates=94100, lr=0.000651981, gnorm=0.588, train_wall=56, gb_free=17.6, wall=39556
2024-02-05 15:36:06 | INFO | train_inner | epoch 030:    356 / 3236 loss=0.943, nll_loss=0.943, ppl=1.92, wps=2319.6, ups=1.78, wpb=1304.3, bsz=93, num_updates=94200, lr=0.000651635, gnorm=0.598, train_wall=56, gb_free=19, wall=39612
2024-02-05 15:37:02 | INFO | train_inner | epoch 030:    456 / 3236 loss=0.943, nll_loss=0.943, ppl=1.92, wps=2332.2, ups=1.78, wpb=1313, bsz=89.9, num_updates=94300, lr=0.00065129, gnorm=0.587, train_wall=56, gb_free=17.9, wall=39668
2024-02-05 15:37:58 | INFO | train_inner | epoch 030:    556 / 3236 loss=0.951, nll_loss=0.951, ppl=1.93, wps=2298.1, ups=1.77, wpb=1301.2, bsz=90.3, num_updates=94400, lr=0.000650945, gnorm=0.607, train_wall=56, gb_free=18.1, wall=39725
2024-02-05 15:38:55 | INFO | train_inner | epoch 030:    656 / 3236 loss=0.942, nll_loss=0.942, ppl=1.92, wps=2308.3, ups=1.76, wpb=1309.8, bsz=89.9, num_updates=94500, lr=0.0006506, gnorm=0.595, train_wall=56, gb_free=17.8, wall=39782
2024-02-05 15:39:52 | INFO | train_inner | epoch 030:    756 / 3236 loss=0.937, nll_loss=0.937, ppl=1.92, wps=2276.1, ups=1.77, wpb=1286.5, bsz=87.6, num_updates=94600, lr=0.000650256, gnorm=0.6, train_wall=56, gb_free=18, wall=39838
2024-02-05 15:40:48 | INFO | train_inner | epoch 030:    856 / 3236 loss=0.939, nll_loss=0.939, ppl=1.92, wps=2292.3, ups=1.77, wpb=1294.5, bsz=87.8, num_updates=94700, lr=0.000649913, gnorm=0.606, train_wall=56, gb_free=18.9, wall=39895
2024-02-05 15:41:45 | INFO | train_inner | epoch 030:    956 / 3236 loss=0.96, nll_loss=0.96, ppl=1.95, wps=2325.7, ups=1.77, wpb=1313.6, bsz=90.6, num_updates=94800, lr=0.00064957, gnorm=0.6, train_wall=56, gb_free=18, wall=39951
2024-02-05 15:42:40 | INFO | train_inner | epoch 030:   1056 / 3236 loss=0.953, nll_loss=0.953, ppl=1.94, wps=2326.2, ups=1.79, wpb=1297.4, bsz=89, num_updates=94900, lr=0.000649227, gnorm=0.606, train_wall=55, gb_free=17.7, wall=40007
2024-02-05 15:43:39 | INFO | train_inner | epoch 030:   1156 / 3236 loss=0.952, nll_loss=0.952, ppl=1.93, wps=2280.3, ups=1.7, wpb=1338.5, bsz=95.8, num_updates=95000, lr=0.000648886, gnorm=0.578, train_wall=56, gb_free=17.4, wall=40066
2024-02-05 15:44:39 | INFO | train_inner | epoch 030:   1256 / 3236 loss=0.944, nll_loss=0.944, ppl=1.92, wps=2171.5, ups=1.67, wpb=1297.7, bsz=84.4, num_updates=95100, lr=0.000648544, gnorm=0.593, train_wall=57, gb_free=18.7, wall=40125
2024-02-05 15:45:35 | INFO | train_inner | epoch 030:   1356 / 3236 loss=0.942, nll_loss=0.942, ppl=1.92, wps=2297.2, ups=1.77, wpb=1299.2, bsz=87.4, num_updates=95200, lr=0.000648204, gnorm=0.603, train_wall=56, gb_free=18.1, wall=40182
2024-02-05 15:46:40 | INFO | train_inner | epoch 030:   1456 / 3236 loss=0.939, nll_loss=0.939, ppl=1.92, wps=2024.1, ups=1.55, wpb=1305.7, bsz=91.6, num_updates=95300, lr=0.000647864, gnorm=0.584, train_wall=56, gb_free=17.2, wall=40246
2024-02-05 15:47:42 | INFO | train_inner | epoch 030:   1556 / 3236 loss=0.961, nll_loss=0.961, ppl=1.95, wps=2074.2, ups=1.6, wpb=1296.2, bsz=93.9, num_updates=95400, lr=0.000647524, gnorm=0.614, train_wall=56, gb_free=17.5, wall=40309
2024-02-05 15:48:41 | INFO | train_inner | epoch 030:   1656 / 3236 loss=0.986, nll_loss=0.986, ppl=1.98, wps=2213.9, ups=1.7, wpb=1299.3, bsz=84.6, num_updates=95500, lr=0.000647185, gnorm=0.616, train_wall=56, gb_free=17.7, wall=40368
2024-02-05 15:49:44 | INFO | train_inner | epoch 030:   1756 / 3236 loss=0.979, nll_loss=0.979, ppl=1.97, wps=2088.4, ups=1.6, wpb=1305.5, bsz=95.2, num_updates=95600, lr=0.000646846, gnorm=0.591, train_wall=56, gb_free=17.6, wall=40430
2024-02-05 15:50:42 | INFO | train_inner | epoch 030:   1856 / 3236 loss=0.966, nll_loss=0.966, ppl=1.95, wps=2236.9, ups=1.72, wpb=1298.3, bsz=87.2, num_updates=95700, lr=0.000646508, gnorm=0.597, train_wall=56, gb_free=17.8, wall=40488
2024-02-05 15:51:41 | INFO | train_inner | epoch 030:   1956 / 3236 loss=0.967, nll_loss=0.967, ppl=1.96, wps=2203.7, ups=1.69, wpb=1301.6, bsz=89.1, num_updates=95800, lr=0.000646171, gnorm=0.593, train_wall=56, gb_free=18.3, wall=40547
2024-02-05 15:52:40 | INFO | train_inner | epoch 030:   2056 / 3236 loss=0.96, nll_loss=0.96, ppl=1.95, wps=2190.2, ups=1.68, wpb=1302, bsz=90.5, num_updates=95900, lr=0.000645834, gnorm=0.598, train_wall=58, gb_free=18.3, wall=40607
2024-02-05 15:53:41 | INFO | train_inner | epoch 030:   2156 / 3236 loss=0.985, nll_loss=0.985, ppl=1.98, wps=2137.8, ups=1.64, wpb=1304.1, bsz=89.5, num_updates=96000, lr=0.000645497, gnorm=0.601, train_wall=56, gb_free=17.9, wall=40668
2024-02-05 15:54:44 | INFO | train_inner | epoch 030:   2256 / 3236 loss=0.966, nll_loss=0.966, ppl=1.95, wps=2060.5, ups=1.59, wpb=1293.2, bsz=88.7, num_updates=96100, lr=0.000645161, gnorm=0.606, train_wall=56, gb_free=17.4, wall=40730
2024-02-05 15:55:40 | INFO | train_inner | epoch 030:   2356 / 3236 loss=0.982, nll_loss=0.982, ppl=1.98, wps=2304.6, ups=1.78, wpb=1293.8, bsz=86.3, num_updates=96200, lr=0.000644826, gnorm=0.611, train_wall=56, gb_free=17.9, wall=40787
2024-02-05 15:56:37 | INFO | train_inner | epoch 030:   2456 / 3236 loss=0.963, nll_loss=0.963, ppl=1.95, wps=2296.8, ups=1.77, wpb=1297.5, bsz=87.8, num_updates=96300, lr=0.000644491, gnorm=0.596, train_wall=56, gb_free=17.3, wall=40843
2024-02-05 15:57:33 | INFO | train_inner | epoch 030:   2556 / 3236 loss=0.98, nll_loss=0.98, ppl=1.97, wps=2307, ups=1.77, wpb=1303.5, bsz=90.6, num_updates=96400, lr=0.000644157, gnorm=0.612, train_wall=56, gb_free=17.5, wall=40899
2024-02-05 15:58:30 | INFO | train_inner | epoch 030:   2656 / 3236 loss=0.986, nll_loss=0.986, ppl=1.98, wps=2305.9, ups=1.77, wpb=1304.6, bsz=86.2, num_updates=96500, lr=0.000643823, gnorm=0.615, train_wall=56, gb_free=17.7, wall=40956
2024-02-05 15:59:29 | INFO | train_inner | epoch 030:   2756 / 3236 loss=0.984, nll_loss=0.984, ppl=1.98, wps=2201.2, ups=1.67, wpb=1315.3, bsz=93.5, num_updates=96600, lr=0.000643489, gnorm=0.607, train_wall=56, gb_free=18.2, wall=41016
2024-02-05 16:00:26 | INFO | train_inner | epoch 030:   2856 / 3236 loss=0.982, nll_loss=0.982, ppl=1.98, wps=2268.8, ups=1.77, wpb=1283.7, bsz=87.9, num_updates=96700, lr=0.000643157, gnorm=0.629, train_wall=56, gb_free=18.2, wall=41072
2024-02-05 16:01:23 | INFO | train_inner | epoch 030:   2956 / 3236 loss=0.992, nll_loss=0.992, ppl=1.99, wps=2257.4, ups=1.74, wpb=1295.9, bsz=87, num_updates=96800, lr=0.000642824, gnorm=0.615, train_wall=56, gb_free=18.2, wall=41130
2024-02-05 16:02:24 | INFO | train_inner | epoch 030:   3056 / 3236 loss=0.975, nll_loss=0.975, ppl=1.97, wps=2174.5, ups=1.66, wpb=1311, bsz=93.3, num_updates=96900, lr=0.000642493, gnorm=0.589, train_wall=56, gb_free=17.7, wall=41190
2024-02-05 16:03:26 | INFO | train_inner | epoch 030:   3156 / 3236 loss=0.96, nll_loss=0.96, ppl=1.94, wps=2106.3, ups=1.62, wpb=1301.8, bsz=88.1, num_updates=97000, lr=0.000642161, gnorm=0.598, train_wall=57, gb_free=18.2, wall=41252
2024-02-05 16:04:15 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 16:04:15 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 16:05:59 | INFO | dev | epoch 030 | valid on 'dev' subset | loss 1.099 | nll_loss 1.099 | ppl 2.14 | wps 2222.6 | wpb 1146.2 | bsz 77.6 | num_updates 97080 | best_loss 1.096
2024-02-05 16:05:59 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 30 @ 97080 updates
2024-02-05 16:05:59 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint30.pt
2024-02-05 16:06:01 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint30.pt
2024-02-05 16:06:04 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint30.pt (epoch 30 @ 97080 updates, score 1.099) (writing took 4.499643934075721 seconds)
2024-02-05 16:06:04 | INFO | fairseq_cli.train | end of epoch 30 (average epoch stats below)
2024-02-05 16:06:04 | INFO | train | epoch 030 | loss 0.96 | nll_loss 0.96 | ppl 1.95 | wps 2104.9 | ups 1.62 | wpb 1302.4 | bsz 89.4 | num_updates 97080 | lr 0.000641897 | gnorm 0.6 | train_wall 1815 | gb_free 18.2 | wall 41410
2024-02-05 16:06:04 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 16:06:04 | INFO | fairseq.data.iterators | grouped total_num_itrs = 3236
2024-02-05 16:06:04 | INFO | fairseq.trainer | begin training epoch 31
2024-02-05 16:06:04 | INFO | fairseq_cli.train | Start iterating over samples
2024-02-05 16:06:17 | INFO | train_inner | epoch 031:     20 / 3236 loss=0.968, nll_loss=0.968, ppl=1.96, wps=760.2, ups=0.58, wpb=1304.1, bsz=91.3, num_updates=97100, lr=0.000641831, gnorm=0.589, train_wall=56, gb_free=17.9, wall=41423
2024-02-05 16:07:14 | INFO | train_inner | epoch 031:    120 / 3236 loss=0.923, nll_loss=0.923, ppl=1.9, wps=2295.3, ups=1.77, wpb=1299.8, bsz=89.4, num_updates=97200, lr=0.0006415, gnorm=0.596, train_wall=56, gb_free=18.1, wall=41480
2024-02-05 16:08:10 | INFO | train_inner | epoch 031:    220 / 3236 loss=0.923, nll_loss=0.923, ppl=1.9, wps=2293.7, ups=1.76, wpb=1300.3, bsz=86.6, num_updates=97300, lr=0.000641171, gnorm=0.6, train_wall=56, gb_free=18.4, wall=41537
2024-02-05 16:09:07 | INFO | train_inner | epoch 031:    320 / 3236 loss=0.91, nll_loss=0.91, ppl=1.88, wps=2281.4, ups=1.76, wpb=1297, bsz=89, num_updates=97400, lr=0.000640841, gnorm=0.592, train_wall=56, gb_free=17.9, wall=41594
2024-02-05 16:10:05 | INFO | train_inner | epoch 031:    420 / 3236 loss=0.925, nll_loss=0.925, ppl=1.9, wps=2257.8, ups=1.75, wpb=1292.8, bsz=85.9, num_updates=97500, lr=0.000640513, gnorm=0.604, train_wall=57, gb_free=17.9, wall=41651
2024-02-05 16:11:01 | INFO | train_inner | epoch 031:    520 / 3236 loss=0.939, nll_loss=0.939, ppl=1.92, wps=2345.2, ups=1.77, wpb=1323.2, bsz=92.6, num_updates=97600, lr=0.000640184, gnorm=0.592, train_wall=56, gb_free=17.6, wall=41707
2024-02-05 16:11:24 | INFO | fairseq_cli.train | Stopping training due to cumulative_training_time: 18.000119944612184 > stop_time_hours: 18.0 hour(s)
2024-02-05 16:11:24 | INFO | fairseq_cli.train | begin validation on "dev" subset
2024-02-05 16:11:24 | INFO | fairseq.tasks.fairseq_task | can_reuse_epoch_itr = True
2024-02-05 16:11:56 | INFO | dev | epoch 031 | valid on 'dev' subset | loss 1.121 | nll_loss 1.121 | ppl 2.18 | wps 7213.3 | wpb 1146.2 | bsz 77.6 | num_updates 97640 | best_loss 1.096
2024-02-05 16:11:56 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 31 @ 97640 updates
2024-02-05 16:11:56 | INFO | fairseq.trainer | Saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt
2024-02-05 16:11:57 | INFO | fairseq.trainer | Finished saving checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt
2024-02-05 16:11:57 | INFO | fairseq.checkpoint_utils | Saved checkpoint /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint_last.pt (epoch 31 @ 97640 updates, score 1.121) (writing took 1.3451139869866893 seconds)
2024-02-05 16:11:57 | INFO | fairseq_cli.train | end of epoch 31 (average epoch stats below)
2024-02-05 16:11:57 | INFO | train | epoch 031 | loss 0.928 | nll_loss 0.928 | ppl 1.9 | wps 2064.7 | ups 1.58 | wpb 1303.9 | bsz 88.9 | num_updates 97640 | lr 0.000640053 | gnorm 0.599 | train_wall 315 | gb_free 17.5 | wall 41764
2024-02-05 16:11:57 | INFO | fairseq_cli.train | done training in 41675.8 seconds
Training complete.
Finetuning complete.
----------------------------------------------------------
Transcribing the test set...
Starting transcription...
Average checkpoints...
Checkpoints folder: /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models
Checkpoint path: /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
Namespace(inputs=['/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models'], output='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', num_epoch_checkpoints=5, num_update_checkpoints=None, num_best_checkpoints=0, checkpoint_upper_bound=None)
averaging checkpoints:  ['/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint30.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint29.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint28.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint27.pt', '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/checkpoint26.pt']
Finished writing averaged checkpoint to /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
Checkpoints averaged
Generating transcriptions...
Test subset: test
Data directory: /pfs/work7/workspace/scratch/uxude-ASR/dataset/covost
Prediction output directory: /home/kit/stud/uxude/predictions/finetune_asr_covost
DEBUG:hydra.core.utils:Setting JobRuntime:name=UNKNOWN_NAME
DEBUG:hydra.core.utils:Setting JobRuntime:name=utils
INFO:fairseq_cli.generate:{'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 50000, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 50000, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 8, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'adp_num': -1, 'adp_dim': 64, 'adp_act_fn': 'relu', 'adp_trf_idx': 'all'}, 'task': Namespace(no_progress_bar=False, log_interval=100, log_format=None, log_file=None, aim_repo=None, aim_run_hash=None, tensorboard_logdir=None, wandb_project=None, azureml_logging=False, seed=1, cpu=False, tpu=False, bf16=False, memory_efficient_bf16=False, fp16=False, memory_efficient_fp16=False, fp16_no_flatten_grads=False, fp16_init_scale=128, fp16_scale_window=None, fp16_scale_tolerance=0.0, on_cpu_convert_precision=False, min_loss_scale=0.0001, threshold_loss_scale=None, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, user_dir=None, empty_cache_freq=0, all_gather_list_size=16384, model_parallel_size=1, quantization_config_path=None, profile=False, reset_logging=False, suppress_crashes=False, use_plasma_view=False, plasma_path='/tmp/plasma', criterion='cross_entropy', tokenizer=None, bpe=None, optimizer=None, lr_scheduler='fixed', simul_type=None, scoring='wer', task='speech_to_text', num_workers=1, skip_invalid_size_inputs_valid_test=True, max_tokens=50000, batch_size=None, required_batch_size_multiple=8, required_seq_len_multiple=1, dataset_impl=None, data_buffer_size=10, train_subset='train', valid_subset='valid', combine_valid_subsets=None, ignore_unused_valid_subsets=False, validate_interval=1, validate_interval_updates=0, validate_after_updates=0, fixed_validation_seed=None, disable_validation=False, max_tokens_valid=50000, batch_size_valid=None, max_valid_steps=None, curriculum=0, gen_subset='test', num_shards=1, shard_id=0, grouped_shuffling=False, update_epoch_batch_itr=False, update_ordered_indices_seed=False, distributed_world_size=1, distributed_num_procs=1, distributed_rank=0, distributed_backend='nccl', distributed_init_method=None, distributed_port=-1, device_id=0, distributed_no_spawn=False, ddp_backend='pytorch_ddp', ddp_comm_hook='none', bucket_cap_mb=25, fix_batches_to_gpus=False, find_unused_parameters=False, gradient_as_bucket_view=False, fast_stat_sync=False, heartbeat_timeout=-1, broadcast_buffers=False, slowmo_momentum=None, slowmo_base_algorithm='localsgd', localsgd_frequency=3, nprocs_per_node=1, pipeline_model_parallel=False, pipeline_balance=None, pipeline_devices=None, pipeline_chunks=0, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_checkpoint='never', zero_sharding='none', no_reshard_after_forward=False, fp32_reduce_scatter=False, cpu_offload=False, use_sharded_state=False, not_fsdp_flatten_parameters=False, path='/pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt', post_process=None, quiet=False, model_overrides='{}', results_path=None, beam=8, beam_mt=0, nbest=1, max_len_a=0, max_len_b=200, max_len_a_mt=0, max_len_b_mt=200, min_len=1, match_source_len=False, unnormalized=False, no_early_stop=False, no_beamable_mm=False, lenpen=1, lenpen_mt=1, unkpen=0, replace_unk=None, sacrebleu=False, score_reference=False, prefix_size=0, no_repeat_ngram_size=0, sampling=False, sampling_topk=-1, sampling_topp=-1.0, constraints=None, temperature=1.0, diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, print_alignment=None, print_step=False, lm_path=None, lm_weight=0.0, iter_decode_eos_penalty=0.0, iter_decode_max_iter=10, iter_decode_force_max_iter=False, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, retain_iter_history=False, retain_dropout=False, retain_dropout_modules=None, decoding_format=None, no_seed_provided=False, eos_token=None, save_dir='checkpoints', restore_file='checkpoint_last.pt', continue_once=None, finetune_from_model=None, reset_dataloader=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, optimizer_overrides='{}', save_interval=1, save_interval_updates=0, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, keep_best_checkpoints=-1, no_save=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_save_optimizer_state=False, best_checkpoint_metric='loss', maximize_best_checkpoint_metric=False, patience=-1, checkpoint_suffix='', checkpoint_shard_count=1, load_checkpoint_on_all_dp_ranks=False, write_checkpoints_asynchronously=False, arch='wav2vec2', data='/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost', config_yaml='config.yaml', multitask_config_yaml=None, max_source_positions=6000, max_target_positions=1024, force_anneal=None, lr_shrink=0.1, warmup_updates=0, wer_tokenizer='none', wer_remove_punct=False, wer_char_level=False, wer_lowercase=False, _name='speech_to_text'), 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'wer', 'wer_tokenizer': 'none', 'wer_remove_punct': False, 'wer_char_level': False, 'wer_lowercase': False}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
INFO:fairseq.tasks.speech_to_text:dictionary size (spm.asr.txt): 5,000
INFO:fairseq_cli.generate:loading model(s) from /pfs/work7/workspace/scratch/uxude-ASR/train/finetune_asr_covost/models/avg_last_5_checkpoint.pt
INFO:fairseq.tasks.speech_to_text:pre-tokenizer: {'tokenizer': None}
INFO:fairseq.tasks.speech_to_text:tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
WARNING:fairseq.data.audio.data_cfg:Auto converting transforms into feature_transforms, but transforms will be deprecated in the future. Please update this in the config.
INFO:fairseq.data.audio.speech_to_text_dataset:'test' has 0.00% OOV
INFO:fairseq.data.audio.speech_to_text_dataset:SpeechToTextDataset(split="test", n_samples=15_531, prepend_tgt_lang_tag=False, n_frames_per_step=1, shuffle=False, feature_transforms=CompositeAudioFeatureTransform(
    UtteranceCMVN(norm_means=True, norm_vars=True)
), waveform_transforms=None, dataset_transforms=CompositeAudioDatasetTransform(
))
INFO:fairseq.tasks.fairseq_task:can_reuse_epoch_itr = True
INFO:fairseq.tasks.fairseq_task:reuse_dataloader = True
INFO:fairseq.tasks.fairseq_task:rebuild_batches = False
INFO:fairseq.tasks.fairseq_task:creating new batches for epoch 1
WARNING:fairseq.tasks.fairseq_task:5 samples have invalid sizes and will be skipped, max_positions=(6000, 1024), first few sample ids=[11198, 697, 6107, 3431, 14638]
INFO:fairseq.tasks.speech_to_text:pre-tokenizer: {'tokenizer': None}
INFO:fairseq.tasks.speech_to_text:tokenizer: {'bpe': 'sentencepiece', 'sentencepiece_model': '/pfs/work7/workspace/scratch/uxude-ASR/dataset/covost/spm.asr.model'}
INFO:fairseq.logging.progress_bar::    101 / 188 wps=512
DEBUG:fairseq.data.iterators:Data loading buffer is empty or nearly empty. This may indicate a data loading bottleneck, and increasing the number of workers (--num-workers) may help.
INFO:fairseq_cli.generate:NOTE: hypothesis and token scores are output in base 2
INFO:fairseq_cli.generate:Translated 15,520 sentences (202,875 tokens) in 89.7s (173.03 sentences/s, 2261.83 tokens/s)
Transcription done
Prediction files written for /home/kit/stud/uxude/predictions/finetune_asr_covost/hyp_asr.txt and /home/kit/stud/uxude/predictions/finetune_asr_covost/ref_asr.txt
Sampled predictions written to /home/kit/stud/uxude/predictions/finetune_asr_covost/hyp_asr.txt.sampled
Sample predictions:
Sample: four sunriseed river blocked from entering
Reference: for some reason we were blocked from entering
Sample: as they sat down at the only table in the place the crystal my chivalry
Reference: as they sat down at the only table in the place the crystal merchant laughed
Sample: i never more wear the worm between six more and five million dollars
Reference: im never more aware of a rooms acoustics than when im trying to enjoy a snack i have no intention of sharing
Sample: all man thats double
Reference: aw man thats terrible
Sample: its a dream in the language of the world she said
Reference: its a dream in the language of the world she said
Sample: this looks amazing
Reference: this looks amazing
Sample: the army came up the rebuilding and rapped his job around the chimney
Reference: the ivy climbed up the building and wrapped itself around the chimney
Sample: nonwerbal communication is sometimes more meaningful than the spoken words
Reference: nonverbal communication is sometimes more meaningful than the spoken words
Sample: the whole the ship grew up
Reference: the hull of the ship collapsed
Sample: the towns arrival under a school was the bull was sake
Reference: the camel driver understood what the boy was saying
Sample: her hair slipped on her back
Reference: her hair flowed down her back
Sample: when fasting slowly he resides the man was stolen in his mouth
Reference: advancing slowly they searched among the stones
Sample: maybe the church was the sycamore growing from it been haunted
Reference: maybe the church with the sycamore growing from within had been haunted
Sample: the boy knew a lot of people in the city
Reference: the boy knew a lot of people in the city
Sample: if everything works youll see a window perhaps
Reference: if everything works youll see a window pop up after starting
Sample: then you taught me something of the universe a language and the soul of the world
Reference: then you taught me something of the universal language and the soul of the world
Sample: the term just my two sense is about a pinying not about my knee
Reference: the term just my two cents is about opinion not about money
Sample: the door was too close
Reference: the drawer was stuck closed
Sample: the woman was saving for some time
Reference: the woman was silent for some time
Sample: they were really i think to are three hundred people ehrbling one another
Reference: there were really i think two or three hundred people elbowing one another
WER:
Generate test with beam=8: WER: 30.09
BLEU:
{
 "name": "BLEU",
 "score": 55.8,
 "signature": "nrefs:1|case:mixed|eff:no|tok:none|smooth:none|version:2.4.0",
 "verbose_score": "73.4/60.5/50.8/42.9 (BP = 1.000 ratio = 1.010 hyp_len = 142654 ref_len = 141203)",
 "nrefs": "1",
 "case": "mixed",
 "eff": "no",
 "tok": "none",
 "smooth": "none",
 "version": "2.4.0"
}